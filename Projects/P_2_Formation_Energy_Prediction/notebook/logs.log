2025-06-02 09:23:48,996:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 09:23:48,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 09:23:48,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 09:23:48,998:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 10:38:49,474:WARNING:MagpieData(impute_nan=False):
In a future release, impute_nan will be set to True by default.
                    This means that features that are missing or are NaNs for elements
                    from the data source will be replaced by the average of that value
                    over the available elements.
                    This avoids NaNs after featurization that are often replaced by
                    dataset-dependent averages.

2025-06-02 11:07:44,621:INFO:PyCaret RegressionExperiment
2025-06-02 11:07:44,622:INFO:Logging name: reg-default-name
2025-06-02 11:07:44,623:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 11:07:44,623:INFO:version 3.3.2
2025-06-02 11:07:44,623:INFO:Initializing setup()
2025-06-02 11:07:44,623:INFO:self.USI: 1676
2025-06-02 11:07:44,623:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 11:07:44,624:INFO:Checking environment
2025-06-02 11:07:44,626:INFO:python_version: 3.10.16
2025-06-02 11:07:44,627:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 11:07:44,628:INFO:machine: AMD64
2025-06-02 11:07:44,628:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 11:07:44,641:INFO:Memory: svmem(total=6378008576, available=821616640, percent=87.1, used=5556391936, free=821616640)
2025-06-02 11:07:44,642:INFO:Physical Core: 4
2025-06-02 11:07:44,642:INFO:Logical Core: 8
2025-06-02 11:07:44,642:INFO:Checking libraries
2025-06-02 11:07:44,642:INFO:System:
2025-06-02 11:07:44,643:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 11:07:44,643:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 11:07:44,643:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 11:07:44,643:INFO:PyCaret required dependencies:
2025-06-02 11:07:48,685:INFO:                 pip: 25.1
2025-06-02 11:07:48,686:INFO:          setuptools: 78.1.1
2025-06-02 11:07:48,686:INFO:             pycaret: 3.3.2
2025-06-02 11:07:48,686:INFO:             IPython: 8.37.0
2025-06-02 11:07:48,686:INFO:          ipywidgets: 8.1.7
2025-06-02 11:07:48,687:INFO:                tqdm: 4.67.1
2025-06-02 11:07:48,687:INFO:               numpy: 1.26.4
2025-06-02 11:07:48,687:INFO:              pandas: 2.0.1
2025-06-02 11:07:48,687:INFO:              jinja2: 3.1.6
2025-06-02 11:07:48,687:INFO:               scipy: 1.10.1
2025-06-02 11:07:48,687:INFO:              joblib: 1.3.2
2025-06-02 11:07:48,687:INFO:             sklearn: 1.4.2
2025-06-02 11:07:48,688:INFO:                pyod: 2.0.5
2025-06-02 11:07:48,688:INFO:            imblearn: 0.13.0
2025-06-02 11:07:48,688:INFO:   category_encoders: 2.7.0
2025-06-02 11:07:48,688:INFO:            lightgbm: 4.6.0
2025-06-02 11:07:48,688:INFO:               numba: 0.61.0
2025-06-02 11:07:48,688:INFO:            requests: 2.32.3
2025-06-02 11:07:48,688:INFO:          matplotlib: 3.7.1
2025-06-02 11:07:48,688:INFO:          scikitplot: 0.3.7
2025-06-02 11:07:48,688:INFO:         yellowbrick: 1.5
2025-06-02 11:07:48,689:INFO:              plotly: 6.1.2
2025-06-02 11:07:48,689:INFO:    plotly-resampler: Not installed
2025-06-02 11:07:48,689:INFO:             kaleido: 0.2.1
2025-06-02 11:07:48,689:INFO:           schemdraw: 0.15
2025-06-02 11:07:48,689:INFO:         statsmodels: 0.14.4
2025-06-02 11:07:48,689:INFO:              sktime: 0.26.0
2025-06-02 11:07:48,689:INFO:               tbats: 1.1.3
2025-06-02 11:07:48,690:INFO:            pmdarima: 2.0.4
2025-06-02 11:07:48,690:INFO:              psutil: 7.0.0
2025-06-02 11:07:48,690:INFO:          markupsafe: 2.1.2
2025-06-02 11:07:48,690:INFO:             pickle5: Not installed
2025-06-02 11:07:48,690:INFO:         cloudpickle: 3.1.1
2025-06-02 11:07:48,690:INFO:         deprecation: 2.1.0
2025-06-02 11:07:48,690:INFO:              xxhash: 3.5.0
2025-06-02 11:07:48,690:INFO:           wurlitzer: Not installed
2025-06-02 11:07:48,690:INFO:PyCaret optional dependencies:
2025-06-02 11:07:59,164:INFO:                shap: 0.44.1
2025-06-02 11:07:59,165:INFO:           interpret: 0.6.9
2025-06-02 11:07:59,165:INFO:                umap: 0.5.7
2025-06-02 11:07:59,165:INFO:     ydata_profiling: 4.16.1
2025-06-02 11:07:59,165:INFO:  explainerdashboard: 0.4.8
2025-06-02 11:07:59,165:INFO:             autoviz: Not installed
2025-06-02 11:07:59,165:INFO:           fairlearn: 0.7.0
2025-06-02 11:07:59,165:INFO:          deepchecks: Not installed
2025-06-02 11:07:59,165:INFO:             xgboost: 3.0.2
2025-06-02 11:07:59,165:INFO:            catboost: 1.2.8
2025-06-02 11:07:59,165:INFO:              kmodes: 0.12.2
2025-06-02 11:07:59,166:INFO:             mlxtend: 0.23.4
2025-06-02 11:07:59,166:INFO:       statsforecast: 1.5.0
2025-06-02 11:07:59,166:INFO:        tune_sklearn: Not installed
2025-06-02 11:07:59,166:INFO:                 ray: Not installed
2025-06-02 11:07:59,166:INFO:            hyperopt: 0.2.7
2025-06-02 11:07:59,166:INFO:              optuna: 4.3.0
2025-06-02 11:07:59,166:INFO:               skopt: 0.10.2
2025-06-02 11:07:59,166:INFO:              mlflow: 2.22.0
2025-06-02 11:07:59,166:INFO:              gradio: 5.32.0
2025-06-02 11:07:59,166:INFO:             fastapi: 0.115.12
2025-06-02 11:07:59,166:INFO:             uvicorn: 0.34.3
2025-06-02 11:07:59,166:INFO:              m2cgen: 0.10.0
2025-06-02 11:07:59,166:INFO:           evidently: 0.4.40
2025-06-02 11:07:59,166:INFO:               fugue: 0.8.5
2025-06-02 11:07:59,166:INFO:           streamlit: Not installed
2025-06-02 11:07:59,166:INFO:             prophet: Not installed
2025-06-02 11:07:59,166:INFO:None
2025-06-02 11:07:59,166:INFO:Set up GPU usage.
2025-06-02 11:07:59,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:07:59,168:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-06-02 11:07:59,169:INFO:Set up data.
2025-06-02 11:07:59,367:INFO:Set up folding strategy.
2025-06-02 11:07:59,371:INFO:Set up train/test split.
2025-06-02 11:08:07,748:INFO:Set up index.
2025-06-02 11:08:07,753:INFO:Assigning column types.
2025-06-02 11:08:07,847:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 11:08:07,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:07,851:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 11:08:07,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:07,865:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 11:08:07,865:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:07,881:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:08:07,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:08,149:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:08:08,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:08,274:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:08:08,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:08,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:08,278:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:08:08,866:WARNING:Could not find the number of physical cores for the following reason:
found 0 physical cores < 1
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.

2025-06-02 11:08:19,982:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:08:20,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:20,172:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 11:08:20,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:20,180:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 11:08:20,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:20,193:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:08:20,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:20,419:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:08:20,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:20,576:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:08:20,577:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:20,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:20,580:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:08:20,889:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:08:20,891:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 11:08:20,892:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:20,892:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:20,905:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 11:08:20,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:20,916:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:08:20,917:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,114:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:08:21,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,258:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:08:21,259:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,259:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,260:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:08:21,319:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:08:21,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,333:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 11:08:21,333:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,343:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:08:21,344:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,524:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:08:21,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,709:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:08:21,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,710:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:08:21,769:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:08:21,771:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 11:08:21,771:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,794:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:08:21,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:21,982:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:08:21,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,186:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:08:22,186:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,187:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,189:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:08:22,280:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:08:22,282:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,282:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,306:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:08:22,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,497:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:08:22,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,593:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:08:22,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,595:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:08:22,655:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:08:22,657:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 11:08:22,657:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,658:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,856:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:08:22,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:08:22,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,958:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:22,958:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:08:23,059:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:08:23,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,268:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:08:23,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,387:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:08:23,387:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,387:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,388:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:08:23,452:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:08:23,455:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 11:08:23,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,468:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,667:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:08:23,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,849:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,852:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:08:23,915:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:08:23,917:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,917:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:23,940:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:24,182:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:08:24,183:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:24,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:24,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:24,299:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:08:24,356:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:08:24,358:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 11:08:24,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:24,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:24,372:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:24,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:24,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:24,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:24,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:24,738:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:08:24,825:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:08:24,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:24,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:24,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:24,849:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:25,037:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:25,126:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:25,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 11:08:25,129:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:08:25,198:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:08:25,207:INFO:Preparing preprocessing pipeline...
2025-06-02 11:08:25,207:INFO:Set up simple imputation.
2025-06-02 11:08:25,248:INFO:Set up encoding of ordinal features.
2025-06-02 11:08:25,273:INFO:Set up encoding of categorical features.
2025-06-02 11:08:25,274:INFO:Set up removing multicollinearity.
2025-06-02 11:08:25,283:INFO:Set up column name cleaning.
2025-06-02 11:20:38,066:INFO:PyCaret RegressionExperiment
2025-06-02 11:20:38,067:INFO:Logging name: reg-default-name
2025-06-02 11:20:38,067:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 11:20:38,067:INFO:version 3.3.2
2025-06-02 11:20:38,067:INFO:Initializing setup()
2025-06-02 11:20:38,067:INFO:self.USI: d5e0
2025-06-02 11:20:38,068:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 11:20:38,068:INFO:Checking environment
2025-06-02 11:20:38,068:INFO:python_version: 3.10.16
2025-06-02 11:20:38,068:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 11:20:38,068:INFO:machine: AMD64
2025-06-02 11:20:38,069:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 11:20:38,080:INFO:Memory: svmem(total=6378008576, available=1044381696, percent=83.6, used=5333626880, free=1044381696)
2025-06-02 11:20:38,081:INFO:Physical Core: 4
2025-06-02 11:20:38,082:INFO:Logical Core: 8
2025-06-02 11:20:38,082:INFO:Checking libraries
2025-06-02 11:20:38,083:INFO:System:
2025-06-02 11:20:38,083:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 11:20:38,083:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 11:20:38,083:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 11:20:38,083:INFO:PyCaret required dependencies:
2025-06-02 11:20:38,084:INFO:                 pip: 25.1
2025-06-02 11:20:38,084:INFO:          setuptools: 78.1.1
2025-06-02 11:20:38,084:INFO:             pycaret: 3.3.2
2025-06-02 11:20:38,084:INFO:             IPython: 8.37.0
2025-06-02 11:20:38,084:INFO:          ipywidgets: 8.1.7
2025-06-02 11:20:38,084:INFO:                tqdm: 4.67.1
2025-06-02 11:20:38,084:INFO:               numpy: 1.26.4
2025-06-02 11:20:38,084:INFO:              pandas: 2.0.1
2025-06-02 11:20:38,085:INFO:              jinja2: 3.1.6
2025-06-02 11:20:38,085:INFO:               scipy: 1.10.1
2025-06-02 11:20:38,085:INFO:              joblib: 1.3.2
2025-06-02 11:20:38,085:INFO:             sklearn: 1.4.2
2025-06-02 11:20:38,085:INFO:                pyod: 2.0.5
2025-06-02 11:20:38,085:INFO:            imblearn: 0.13.0
2025-06-02 11:20:38,085:INFO:   category_encoders: 2.7.0
2025-06-02 11:20:38,086:INFO:            lightgbm: 4.6.0
2025-06-02 11:20:38,086:INFO:               numba: 0.61.0
2025-06-02 11:20:38,086:INFO:            requests: 2.32.3
2025-06-02 11:20:38,086:INFO:          matplotlib: 3.7.1
2025-06-02 11:20:38,086:INFO:          scikitplot: 0.3.7
2025-06-02 11:20:38,086:INFO:         yellowbrick: 1.5
2025-06-02 11:20:38,086:INFO:              plotly: 6.1.2
2025-06-02 11:20:38,086:INFO:    plotly-resampler: Not installed
2025-06-02 11:20:38,086:INFO:             kaleido: 0.2.1
2025-06-02 11:20:38,087:INFO:           schemdraw: 0.15
2025-06-02 11:20:38,087:INFO:         statsmodels: 0.14.4
2025-06-02 11:20:38,087:INFO:              sktime: 0.26.0
2025-06-02 11:20:38,087:INFO:               tbats: 1.1.3
2025-06-02 11:20:38,087:INFO:            pmdarima: 2.0.4
2025-06-02 11:20:38,087:INFO:              psutil: 7.0.0
2025-06-02 11:20:38,087:INFO:          markupsafe: 2.1.2
2025-06-02 11:20:38,087:INFO:             pickle5: Not installed
2025-06-02 11:20:38,087:INFO:         cloudpickle: 3.1.1
2025-06-02 11:20:38,088:INFO:         deprecation: 2.1.0
2025-06-02 11:20:38,088:INFO:              xxhash: 3.5.0
2025-06-02 11:20:38,088:INFO:           wurlitzer: Not installed
2025-06-02 11:20:38,088:INFO:PyCaret optional dependencies:
2025-06-02 11:20:38,088:INFO:                shap: 0.44.1
2025-06-02 11:20:38,088:INFO:           interpret: 0.6.9
2025-06-02 11:20:38,088:INFO:                umap: 0.5.7
2025-06-02 11:20:38,088:INFO:     ydata_profiling: 4.16.1
2025-06-02 11:20:38,089:INFO:  explainerdashboard: 0.4.8
2025-06-02 11:20:38,089:INFO:             autoviz: Not installed
2025-06-02 11:20:38,089:INFO:           fairlearn: 0.7.0
2025-06-02 11:20:38,089:INFO:          deepchecks: Not installed
2025-06-02 11:20:38,089:INFO:             xgboost: 3.0.2
2025-06-02 11:20:38,089:INFO:            catboost: 1.2.8
2025-06-02 11:20:38,089:INFO:              kmodes: 0.12.2
2025-06-02 11:20:38,089:INFO:             mlxtend: 0.23.4
2025-06-02 11:20:38,089:INFO:       statsforecast: 1.5.0
2025-06-02 11:20:38,090:INFO:        tune_sklearn: Not installed
2025-06-02 11:20:38,090:INFO:                 ray: Not installed
2025-06-02 11:20:38,090:INFO:            hyperopt: 0.2.7
2025-06-02 11:20:38,090:INFO:              optuna: 4.3.0
2025-06-02 11:20:38,090:INFO:               skopt: 0.10.2
2025-06-02 11:20:38,090:INFO:              mlflow: 2.22.0
2025-06-02 11:20:38,090:INFO:              gradio: 5.32.0
2025-06-02 11:20:38,090:INFO:             fastapi: 0.115.12
2025-06-02 11:20:38,090:INFO:             uvicorn: 0.34.3
2025-06-02 11:20:38,091:INFO:              m2cgen: 0.10.0
2025-06-02 11:20:38,091:INFO:           evidently: 0.4.40
2025-06-02 11:20:38,091:INFO:               fugue: 0.8.5
2025-06-02 11:20:38,091:INFO:           streamlit: Not installed
2025-06-02 11:20:38,091:INFO:             prophet: Not installed
2025-06-02 11:20:38,091:INFO:None
2025-06-02 11:20:38,091:INFO:Set up data.
2025-06-02 11:20:38,418:INFO:Set up folding strategy.
2025-06-02 11:20:38,418:INFO:Set up train/test split.
2025-06-02 11:20:38,494:INFO:Set up index.
2025-06-02 11:20:38,495:INFO:Assigning column types.
2025-06-02 11:20:38,573:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 11:20:38,574:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 11:20:38,586:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 11:20:38,597:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:20:38,794:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:20:38,903:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:20:38,904:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:20:38,910:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:20:38,913:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 11:20:38,924:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 11:20:38,935:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:20:39,164:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:20:39,283:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:20:39,285:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:20:39,292:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:20:39,294:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 11:20:39,306:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 11:20:39,318:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:20:39,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:20:39,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:20:39,633:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:20:39,639:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:20:39,652:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 11:20:39,663:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:20:39,858:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:20:39,964:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:20:39,965:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:20:39,972:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:20:39,973:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 11:20:39,997:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:20:40,201:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:20:40,306:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:20:40,307:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:20:40,313:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:20:40,337:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:20:40,527:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:20:40,631:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:20:40,633:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:20:40,639:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:20:40,641:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 11:20:40,854:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:20:40,962:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:20:40,964:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:20:40,970:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:20:41,181:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:20:41,285:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:20:41,287:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:20:41,294:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:20:41,296:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 11:20:41,515:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:20:41,622:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:20:41,629:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:20:41,839:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:20:41,944:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:20:41,951:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:20:41,953:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 11:20:42,268:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:20:42,274:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:20:42,595:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:20:42,602:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:20:42,606:INFO:Preparing preprocessing pipeline...
2025-06-02 11:20:42,606:INFO:Set up simple imputation.
2025-06-02 11:20:42,641:INFO:Set up encoding of ordinal features.
2025-06-02 11:20:42,667:INFO:Set up encoding of categorical features.
2025-06-02 11:20:42,668:INFO:Set up removing multicollinearity.
2025-06-02 11:20:42,678:INFO:Set up column name cleaning.
2025-06-02 11:37:49,748:INFO:PyCaret RegressionExperiment
2025-06-02 11:37:49,749:INFO:Logging name: reg-default-name
2025-06-02 11:37:49,749:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 11:37:49,750:INFO:version 3.3.2
2025-06-02 11:37:49,750:INFO:Initializing setup()
2025-06-02 11:37:49,750:INFO:self.USI: 982a
2025-06-02 11:37:49,750:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 11:37:49,750:INFO:Checking environment
2025-06-02 11:37:49,751:INFO:python_version: 3.10.16
2025-06-02 11:37:49,751:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 11:37:49,751:INFO:machine: AMD64
2025-06-02 11:37:49,751:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 11:37:49,765:INFO:Memory: svmem(total=6378008576, available=1101856768, percent=82.7, used=5276151808, free=1101856768)
2025-06-02 11:37:49,766:INFO:Physical Core: 4
2025-06-02 11:37:49,766:INFO:Logical Core: 8
2025-06-02 11:37:49,766:INFO:Checking libraries
2025-06-02 11:37:49,767:INFO:System:
2025-06-02 11:37:49,767:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 11:37:49,767:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 11:37:49,767:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 11:37:49,767:INFO:PyCaret required dependencies:
2025-06-02 11:37:49,768:INFO:                 pip: 25.1
2025-06-02 11:37:49,768:INFO:          setuptools: 78.1.1
2025-06-02 11:37:49,768:INFO:             pycaret: 3.3.2
2025-06-02 11:37:49,769:INFO:             IPython: 8.37.0
2025-06-02 11:37:49,769:INFO:          ipywidgets: 8.1.7
2025-06-02 11:37:49,769:INFO:                tqdm: 4.67.1
2025-06-02 11:37:49,769:INFO:               numpy: 1.26.4
2025-06-02 11:37:49,769:INFO:              pandas: 2.0.1
2025-06-02 11:37:49,769:INFO:              jinja2: 3.1.6
2025-06-02 11:37:49,770:INFO:               scipy: 1.10.1
2025-06-02 11:37:49,770:INFO:              joblib: 1.3.2
2025-06-02 11:37:49,770:INFO:             sklearn: 1.4.2
2025-06-02 11:37:49,770:INFO:                pyod: 2.0.5
2025-06-02 11:37:49,770:INFO:            imblearn: 0.13.0
2025-06-02 11:37:49,771:INFO:   category_encoders: 2.7.0
2025-06-02 11:37:49,771:INFO:            lightgbm: 4.6.0
2025-06-02 11:37:49,771:INFO:               numba: 0.61.0
2025-06-02 11:37:49,771:INFO:            requests: 2.32.3
2025-06-02 11:37:49,772:INFO:          matplotlib: 3.7.1
2025-06-02 11:37:49,772:INFO:          scikitplot: 0.3.7
2025-06-02 11:37:49,772:INFO:         yellowbrick: 1.5
2025-06-02 11:37:49,772:INFO:              plotly: 6.1.2
2025-06-02 11:37:49,772:INFO:    plotly-resampler: Not installed
2025-06-02 11:37:49,773:INFO:             kaleido: 0.2.1
2025-06-02 11:37:49,773:INFO:           schemdraw: 0.15
2025-06-02 11:37:49,773:INFO:         statsmodels: 0.14.4
2025-06-02 11:37:49,773:INFO:              sktime: 0.26.0
2025-06-02 11:37:49,774:INFO:               tbats: 1.1.3
2025-06-02 11:37:49,774:INFO:            pmdarima: 2.0.4
2025-06-02 11:37:49,775:INFO:              psutil: 7.0.0
2025-06-02 11:37:49,775:INFO:          markupsafe: 2.1.2
2025-06-02 11:37:49,775:INFO:             pickle5: Not installed
2025-06-02 11:37:49,777:INFO:         cloudpickle: 3.1.1
2025-06-02 11:37:49,778:INFO:         deprecation: 2.1.0
2025-06-02 11:37:49,779:INFO:              xxhash: 3.5.0
2025-06-02 11:37:49,779:INFO:           wurlitzer: Not installed
2025-06-02 11:37:49,780:INFO:PyCaret optional dependencies:
2025-06-02 11:37:49,780:INFO:                shap: 0.44.1
2025-06-02 11:37:49,780:INFO:           interpret: 0.6.9
2025-06-02 11:37:49,780:INFO:                umap: 0.5.7
2025-06-02 11:37:49,781:INFO:     ydata_profiling: 4.16.1
2025-06-02 11:37:49,781:INFO:  explainerdashboard: 0.4.8
2025-06-02 11:37:49,781:INFO:             autoviz: Not installed
2025-06-02 11:37:49,781:INFO:           fairlearn: 0.7.0
2025-06-02 11:37:49,781:INFO:          deepchecks: Not installed
2025-06-02 11:37:49,782:INFO:             xgboost: 3.0.2
2025-06-02 11:37:49,782:INFO:            catboost: 1.2.8
2025-06-02 11:37:49,782:INFO:              kmodes: 0.12.2
2025-06-02 11:37:49,782:INFO:             mlxtend: 0.23.4
2025-06-02 11:37:49,782:INFO:       statsforecast: 1.5.0
2025-06-02 11:37:49,783:INFO:        tune_sklearn: Not installed
2025-06-02 11:37:49,783:INFO:                 ray: Not installed
2025-06-02 11:37:49,783:INFO:            hyperopt: 0.2.7
2025-06-02 11:37:49,783:INFO:              optuna: 4.3.0
2025-06-02 11:37:49,783:INFO:               skopt: 0.10.2
2025-06-02 11:37:49,783:INFO:              mlflow: 2.22.0
2025-06-02 11:37:49,783:INFO:              gradio: 5.32.0
2025-06-02 11:37:49,783:INFO:             fastapi: 0.115.12
2025-06-02 11:37:49,784:INFO:             uvicorn: 0.34.3
2025-06-02 11:37:49,784:INFO:              m2cgen: 0.10.0
2025-06-02 11:37:49,784:INFO:           evidently: 0.4.40
2025-06-02 11:37:49,784:INFO:               fugue: 0.8.5
2025-06-02 11:37:49,786:INFO:           streamlit: Not installed
2025-06-02 11:37:49,786:INFO:             prophet: Not installed
2025-06-02 11:37:49,787:INFO:None
2025-06-02 11:37:49,787:INFO:Set up data.
2025-06-02 11:37:50,078:INFO:Set up folding strategy.
2025-06-02 11:37:50,079:INFO:Set up train/test split.
2025-06-02 11:37:50,162:INFO:Set up index.
2025-06-02 11:37:50,163:INFO:Assigning column types.
2025-06-02 11:37:50,254:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 11:37:50,255:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 11:37:50,268:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 11:37:50,282:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:37:50,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:37:50,649:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:37:50,651:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:37:50,658:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:37:50,661:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 11:37:50,674:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 11:37:50,685:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:37:50,901:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:37:51,022:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:37:51,023:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:37:51,030:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:37:51,032:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 11:37:51,043:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 11:37:51,054:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:37:51,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:37:51,378:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:37:51,380:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:37:51,386:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:37:51,400:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 11:37:51,412:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:37:51,619:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:37:51,732:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:37:51,733:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:37:51,740:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:37:51,743:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 11:37:51,767:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:37:51,986:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:37:52,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:37:52,099:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:37:52,105:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:37:52,132:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 11:37:52,334:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:37:52,439:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:37:52,440:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:37:52,447:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:37:52,449:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 11:37:52,704:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:37:52,829:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:37:52,830:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:37:52,837:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:37:53,069:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:37:53,186:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 11:37:53,187:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:37:53,194:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:37:53,196:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 11:37:53,440:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:37:53,555:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:37:53,563:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:37:53,798:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 11:37:53,906:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:37:53,913:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:37:53,915:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 11:37:54,347:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:37:54,353:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:37:54,706:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:37:54,713:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:37:54,717:INFO:Preparing preprocessing pipeline...
2025-06-02 11:37:54,717:INFO:Set up simple imputation.
2025-06-02 11:37:54,718:INFO:Set up removing multicollinearity.
2025-06-02 11:37:54,730:INFO:Set up column name cleaning.
2025-06-02 11:37:55,588:INFO:Finished creating preprocessing pipeline.
2025-06-02 11:37:55,614:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 11:37:55,614:INFO:Creating final display dataframe.
2025-06-02 11:37:57,093:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              982a
2025-06-02 11:37:57,530:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:37:57,541:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:37:58,050:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 11:37:58,057:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 11:37:58,061:INFO:setup() successfully completed in 8.33s...............
2025-06-02 11:37:58,064:INFO:Initializing compare_models()
2025-06-02 11:37:58,064:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 11:37:58,065:INFO:Checking exceptions
2025-06-02 11:37:58,101:INFO:Preparing display monitor
2025-06-02 11:37:58,255:INFO:Initializing Linear Regression
2025-06-02 11:37:58,256:INFO:Total runtime is 1.6717116038004556e-05 minutes
2025-06-02 11:37:58,287:INFO:SubProcess create_model() called ==================================
2025-06-02 11:37:58,289:INFO:Initializing create_model()
2025-06-02 11:37:58,290:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:37:58,291:INFO:Checking exceptions
2025-06-02 11:37:58,291:INFO:Importing libraries
2025-06-02 11:37:58,293:INFO:Copying training dataset
2025-06-02 11:37:58,415:INFO:Defining folds
2025-06-02 11:37:58,415:INFO:Declaring metric variables
2025-06-02 11:37:58,437:INFO:Importing untrained model
2025-06-02 11:37:58,455:INFO:Linear Regression Imported successfully
2025-06-02 11:37:58,536:INFO:Starting cross validation
2025-06-02 11:37:58,579:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:38:21,198:INFO:Calculating mean and std
2025-06-02 11:38:21,213:INFO:Creating metrics dataframe
2025-06-02 11:38:21,264:INFO:Uploading results into container
2025-06-02 11:38:21,268:INFO:Uploading model into container now
2025-06-02 11:38:21,274:INFO:_master_model_container: 1
2025-06-02 11:38:21,274:INFO:_display_container: 2
2025-06-02 11:38:21,278:INFO:LinearRegression(n_jobs=-1)
2025-06-02 11:38:21,278:INFO:create_model() successfully completed......................................
2025-06-02 11:38:32,731:INFO:SubProcess create_model() end ==================================
2025-06-02 11:38:32,732:INFO:Creating metrics dataframe
2025-06-02 11:38:32,765:INFO:Initializing Lasso Regression
2025-06-02 11:38:32,765:INFO:Total runtime is 0.5751676638921102 minutes
2025-06-02 11:38:32,784:INFO:SubProcess create_model() called ==================================
2025-06-02 11:38:32,786:INFO:Initializing create_model()
2025-06-02 11:38:32,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:38:32,787:INFO:Checking exceptions
2025-06-02 11:38:32,787:INFO:Importing libraries
2025-06-02 11:38:32,787:INFO:Copying training dataset
2025-06-02 11:38:32,985:INFO:Defining folds
2025-06-02 11:38:32,986:INFO:Declaring metric variables
2025-06-02 11:38:33,017:INFO:Importing untrained model
2025-06-02 11:38:33,056:INFO:Lasso Regression Imported successfully
2025-06-02 11:38:33,105:INFO:Starting cross validation
2025-06-02 11:38:33,113:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:38:49,877:INFO:Calculating mean and std
2025-06-02 11:38:49,883:INFO:Creating metrics dataframe
2025-06-02 11:38:49,901:INFO:Uploading results into container
2025-06-02 11:38:49,903:INFO:Uploading model into container now
2025-06-02 11:38:49,906:INFO:_master_model_container: 2
2025-06-02 11:38:49,906:INFO:_display_container: 2
2025-06-02 11:38:49,910:INFO:Lasso(random_state=123)
2025-06-02 11:38:49,911:INFO:create_model() successfully completed......................................
2025-06-02 11:38:51,178:INFO:SubProcess create_model() end ==================================
2025-06-02 11:38:51,179:INFO:Creating metrics dataframe
2025-06-02 11:38:51,202:INFO:Initializing Ridge Regression
2025-06-02 11:38:51,203:INFO:Total runtime is 0.8824576099713644 minutes
2025-06-02 11:38:51,217:INFO:SubProcess create_model() called ==================================
2025-06-02 11:38:51,218:INFO:Initializing create_model()
2025-06-02 11:38:51,219:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:38:51,220:INFO:Checking exceptions
2025-06-02 11:38:51,220:INFO:Importing libraries
2025-06-02 11:38:51,221:INFO:Copying training dataset
2025-06-02 11:38:51,352:INFO:Defining folds
2025-06-02 11:38:51,353:INFO:Declaring metric variables
2025-06-02 11:38:51,371:INFO:Importing untrained model
2025-06-02 11:38:51,390:INFO:Ridge Regression Imported successfully
2025-06-02 11:38:51,428:INFO:Starting cross validation
2025-06-02 11:38:51,435:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:38:52,318:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.75561e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 11:38:52,329:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31073e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 11:38:52,378:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.08754e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 11:38:52,392:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.24347e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 11:38:52,504:INFO:Calculating mean and std
2025-06-02 11:38:52,507:INFO:Creating metrics dataframe
2025-06-02 11:38:52,511:INFO:Uploading results into container
2025-06-02 11:38:52,512:INFO:Uploading model into container now
2025-06-02 11:38:52,513:INFO:_master_model_container: 3
2025-06-02 11:38:52,513:INFO:_display_container: 2
2025-06-02 11:38:52,514:INFO:Ridge(random_state=123)
2025-06-02 11:38:52,514:INFO:create_model() successfully completed......................................
2025-06-02 11:38:53,995:INFO:SubProcess create_model() end ==================================
2025-06-02 11:38:53,996:INFO:Creating metrics dataframe
2025-06-02 11:38:54,011:INFO:Initializing Elastic Net
2025-06-02 11:38:54,011:INFO:Total runtime is 0.9292607267697652 minutes
2025-06-02 11:38:54,019:INFO:SubProcess create_model() called ==================================
2025-06-02 11:38:54,020:INFO:Initializing create_model()
2025-06-02 11:38:54,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:38:54,021:INFO:Checking exceptions
2025-06-02 11:38:54,022:INFO:Importing libraries
2025-06-02 11:38:54,022:INFO:Copying training dataset
2025-06-02 11:38:54,104:INFO:Defining folds
2025-06-02 11:38:54,104:INFO:Declaring metric variables
2025-06-02 11:38:54,117:INFO:Importing untrained model
2025-06-02 11:38:54,130:INFO:Elastic Net Imported successfully
2025-06-02 11:38:54,155:INFO:Starting cross validation
2025-06-02 11:38:54,159:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:38:56,075:INFO:Calculating mean and std
2025-06-02 11:38:56,079:INFO:Creating metrics dataframe
2025-06-02 11:38:56,083:INFO:Uploading results into container
2025-06-02 11:38:56,085:INFO:Uploading model into container now
2025-06-02 11:38:56,086:INFO:_master_model_container: 4
2025-06-02 11:38:56,087:INFO:_display_container: 2
2025-06-02 11:38:56,087:INFO:ElasticNet(random_state=123)
2025-06-02 11:38:56,088:INFO:create_model() successfully completed......................................
2025-06-02 11:38:57,447:INFO:SubProcess create_model() end ==================================
2025-06-02 11:38:57,447:INFO:Creating metrics dataframe
2025-06-02 11:38:57,469:INFO:Initializing Least Angle Regression
2025-06-02 11:38:57,470:INFO:Total runtime is 0.9869161208470663 minutes
2025-06-02 11:38:57,481:INFO:SubProcess create_model() called ==================================
2025-06-02 11:38:57,482:INFO:Initializing create_model()
2025-06-02 11:38:57,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:38:57,482:INFO:Checking exceptions
2025-06-02 11:38:57,483:INFO:Importing libraries
2025-06-02 11:38:57,483:INFO:Copying training dataset
2025-06-02 11:38:57,570:INFO:Defining folds
2025-06-02 11:38:57,570:INFO:Declaring metric variables
2025-06-02 11:38:57,585:INFO:Importing untrained model
2025-06-02 11:38:57,633:INFO:Least Angle Regression Imported successfully
2025-06-02 11:38:57,698:INFO:Starting cross validation
2025-06-02 11:38:57,707:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:38:59,223:INFO:Calculating mean and std
2025-06-02 11:38:59,227:INFO:Creating metrics dataframe
2025-06-02 11:38:59,235:INFO:Uploading results into container
2025-06-02 11:38:59,236:INFO:Uploading model into container now
2025-06-02 11:38:59,238:INFO:_master_model_container: 5
2025-06-02 11:38:59,238:INFO:_display_container: 2
2025-06-02 11:38:59,241:INFO:Lars(random_state=123)
2025-06-02 11:38:59,242:INFO:create_model() successfully completed......................................
2025-06-02 11:39:00,730:INFO:SubProcess create_model() end ==================================
2025-06-02 11:39:00,731:INFO:Creating metrics dataframe
2025-06-02 11:39:00,822:INFO:Initializing Lasso Least Angle Regression
2025-06-02 11:39:00,823:INFO:Total runtime is 1.0427976250648499 minutes
2025-06-02 11:39:00,844:INFO:SubProcess create_model() called ==================================
2025-06-02 11:39:00,845:INFO:Initializing create_model()
2025-06-02 11:39:00,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:39:00,847:INFO:Checking exceptions
2025-06-02 11:39:00,848:INFO:Importing libraries
2025-06-02 11:39:00,848:INFO:Copying training dataset
2025-06-02 11:39:01,210:INFO:Defining folds
2025-06-02 11:39:01,212:INFO:Declaring metric variables
2025-06-02 11:39:01,239:INFO:Importing untrained model
2025-06-02 11:39:01,274:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 11:39:01,336:INFO:Starting cross validation
2025-06-02 11:39:01,343:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:39:02,996:INFO:Calculating mean and std
2025-06-02 11:39:02,999:INFO:Creating metrics dataframe
2025-06-02 11:39:03,003:INFO:Uploading results into container
2025-06-02 11:39:03,005:INFO:Uploading model into container now
2025-06-02 11:39:03,006:INFO:_master_model_container: 6
2025-06-02 11:39:03,006:INFO:_display_container: 2
2025-06-02 11:39:03,007:INFO:LassoLars(random_state=123)
2025-06-02 11:39:03,007:INFO:create_model() successfully completed......................................
2025-06-02 11:39:04,471:INFO:SubProcess create_model() end ==================================
2025-06-02 11:39:04,471:INFO:Creating metrics dataframe
2025-06-02 11:39:04,501:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 11:39:04,502:INFO:Total runtime is 1.104099722703298 minutes
2025-06-02 11:39:04,519:INFO:SubProcess create_model() called ==================================
2025-06-02 11:39:04,519:INFO:Initializing create_model()
2025-06-02 11:39:04,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:39:04,520:INFO:Checking exceptions
2025-06-02 11:39:04,521:INFO:Importing libraries
2025-06-02 11:39:04,522:INFO:Copying training dataset
2025-06-02 11:39:04,665:INFO:Defining folds
2025-06-02 11:39:04,665:INFO:Declaring metric variables
2025-06-02 11:39:04,684:INFO:Importing untrained model
2025-06-02 11:39:04,707:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 11:39:04,747:INFO:Starting cross validation
2025-06-02 11:39:04,754:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:39:06,666:INFO:Calculating mean and std
2025-06-02 11:39:06,669:INFO:Creating metrics dataframe
2025-06-02 11:39:06,674:INFO:Uploading results into container
2025-06-02 11:39:06,675:INFO:Uploading model into container now
2025-06-02 11:39:06,678:INFO:_master_model_container: 7
2025-06-02 11:39:06,678:INFO:_display_container: 2
2025-06-02 11:39:06,678:INFO:OrthogonalMatchingPursuit()
2025-06-02 11:39:06,679:INFO:create_model() successfully completed......................................
2025-06-02 11:39:07,964:INFO:SubProcess create_model() end ==================================
2025-06-02 11:39:07,965:INFO:Creating metrics dataframe
2025-06-02 11:39:07,984:INFO:Initializing Bayesian Ridge
2025-06-02 11:39:07,985:INFO:Total runtime is 1.162168840567271 minutes
2025-06-02 11:39:07,998:INFO:SubProcess create_model() called ==================================
2025-06-02 11:39:07,999:INFO:Initializing create_model()
2025-06-02 11:39:08,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:39:08,000:INFO:Checking exceptions
2025-06-02 11:39:08,001:INFO:Importing libraries
2025-06-02 11:39:08,002:INFO:Copying training dataset
2025-06-02 11:39:08,078:INFO:Defining folds
2025-06-02 11:39:08,078:INFO:Declaring metric variables
2025-06-02 11:39:08,097:INFO:Importing untrained model
2025-06-02 11:39:08,110:INFO:Bayesian Ridge Imported successfully
2025-06-02 11:39:08,137:INFO:Starting cross validation
2025-06-02 11:39:08,142:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:39:09,022:INFO:Calculating mean and std
2025-06-02 11:39:09,025:INFO:Creating metrics dataframe
2025-06-02 11:39:09,029:INFO:Uploading results into container
2025-06-02 11:39:09,030:INFO:Uploading model into container now
2025-06-02 11:39:09,030:INFO:_master_model_container: 8
2025-06-02 11:39:09,031:INFO:_display_container: 2
2025-06-02 11:39:09,031:INFO:BayesianRidge()
2025-06-02 11:39:09,032:INFO:create_model() successfully completed......................................
2025-06-02 11:39:10,231:INFO:SubProcess create_model() end ==================================
2025-06-02 11:39:10,231:INFO:Creating metrics dataframe
2025-06-02 11:39:10,251:INFO:Initializing Passive Aggressive Regressor
2025-06-02 11:39:10,251:INFO:Total runtime is 1.1999317288398743 minutes
2025-06-02 11:39:10,265:INFO:SubProcess create_model() called ==================================
2025-06-02 11:39:10,267:INFO:Initializing create_model()
2025-06-02 11:39:10,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:39:10,267:INFO:Checking exceptions
2025-06-02 11:39:10,268:INFO:Importing libraries
2025-06-02 11:39:10,268:INFO:Copying training dataset
2025-06-02 11:39:10,387:INFO:Defining folds
2025-06-02 11:39:10,387:INFO:Declaring metric variables
2025-06-02 11:39:10,401:INFO:Importing untrained model
2025-06-02 11:39:10,418:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 11:39:10,443:INFO:Starting cross validation
2025-06-02 11:39:10,448:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:39:11,423:INFO:Calculating mean and std
2025-06-02 11:39:11,426:INFO:Creating metrics dataframe
2025-06-02 11:39:11,430:INFO:Uploading results into container
2025-06-02 11:39:11,431:INFO:Uploading model into container now
2025-06-02 11:39:11,432:INFO:_master_model_container: 9
2025-06-02 11:39:11,433:INFO:_display_container: 2
2025-06-02 11:39:11,434:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 11:39:11,435:INFO:create_model() successfully completed......................................
2025-06-02 11:39:12,643:INFO:SubProcess create_model() end ==================================
2025-06-02 11:39:12,643:INFO:Creating metrics dataframe
2025-06-02 11:39:12,673:INFO:Initializing Huber Regressor
2025-06-02 11:39:12,674:INFO:Total runtime is 1.240314277013143 minutes
2025-06-02 11:39:12,686:INFO:SubProcess create_model() called ==================================
2025-06-02 11:39:12,687:INFO:Initializing create_model()
2025-06-02 11:39:12,688:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:39:12,689:INFO:Checking exceptions
2025-06-02 11:39:12,689:INFO:Importing libraries
2025-06-02 11:39:12,690:INFO:Copying training dataset
2025-06-02 11:39:12,883:INFO:Defining folds
2025-06-02 11:39:12,885:INFO:Declaring metric variables
2025-06-02 11:39:12,913:INFO:Importing untrained model
2025-06-02 11:39:12,944:INFO:Huber Regressor Imported successfully
2025-06-02 11:39:12,986:INFO:Starting cross validation
2025-06-02 11:39:12,992:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:39:14,879:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 11:39:14,927:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 11:39:14,942:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 11:39:14,954:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 11:39:14,974:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 11:39:15,057:INFO:Calculating mean and std
2025-06-02 11:39:15,060:INFO:Creating metrics dataframe
2025-06-02 11:39:15,065:INFO:Uploading results into container
2025-06-02 11:39:15,066:INFO:Uploading model into container now
2025-06-02 11:39:15,067:INFO:_master_model_container: 10
2025-06-02 11:39:15,068:INFO:_display_container: 2
2025-06-02 11:39:15,068:INFO:HuberRegressor()
2025-06-02 11:39:15,069:INFO:create_model() successfully completed......................................
2025-06-02 11:39:16,264:INFO:SubProcess create_model() end ==================================
2025-06-02 11:39:16,265:INFO:Creating metrics dataframe
2025-06-02 11:39:16,289:INFO:Initializing K Neighbors Regressor
2025-06-02 11:39:16,289:INFO:Total runtime is 1.3005662202835084 minutes
2025-06-02 11:39:16,303:INFO:SubProcess create_model() called ==================================
2025-06-02 11:39:16,303:INFO:Initializing create_model()
2025-06-02 11:39:16,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:39:16,304:INFO:Checking exceptions
2025-06-02 11:39:16,305:INFO:Importing libraries
2025-06-02 11:39:16,305:INFO:Copying training dataset
2025-06-02 11:39:16,424:INFO:Defining folds
2025-06-02 11:39:16,424:INFO:Declaring metric variables
2025-06-02 11:39:16,443:INFO:Importing untrained model
2025-06-02 11:39:16,466:INFO:K Neighbors Regressor Imported successfully
2025-06-02 11:39:16,489:INFO:Starting cross validation
2025-06-02 11:39:16,494:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:39:17,628:INFO:Calculating mean and std
2025-06-02 11:39:17,632:INFO:Creating metrics dataframe
2025-06-02 11:39:17,635:INFO:Uploading results into container
2025-06-02 11:39:17,636:INFO:Uploading model into container now
2025-06-02 11:39:17,637:INFO:_master_model_container: 11
2025-06-02 11:39:17,637:INFO:_display_container: 2
2025-06-02 11:39:17,638:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 11:39:17,638:INFO:create_model() successfully completed......................................
2025-06-02 11:39:18,775:INFO:SubProcess create_model() end ==================================
2025-06-02 11:39:18,776:INFO:Creating metrics dataframe
2025-06-02 11:39:18,799:INFO:Initializing Decision Tree Regressor
2025-06-02 11:39:18,799:INFO:Total runtime is 1.3423999468485515 minutes
2025-06-02 11:39:18,811:INFO:SubProcess create_model() called ==================================
2025-06-02 11:39:18,812:INFO:Initializing create_model()
2025-06-02 11:39:18,812:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:39:18,812:INFO:Checking exceptions
2025-06-02 11:39:18,813:INFO:Importing libraries
2025-06-02 11:39:18,813:INFO:Copying training dataset
2025-06-02 11:39:18,910:INFO:Defining folds
2025-06-02 11:39:18,912:INFO:Declaring metric variables
2025-06-02 11:39:18,925:INFO:Importing untrained model
2025-06-02 11:39:18,943:INFO:Decision Tree Regressor Imported successfully
2025-06-02 11:39:18,998:INFO:Starting cross validation
2025-06-02 11:39:19,009:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:39:20,355:INFO:Calculating mean and std
2025-06-02 11:39:20,358:INFO:Creating metrics dataframe
2025-06-02 11:39:20,363:INFO:Uploading results into container
2025-06-02 11:39:20,364:INFO:Uploading model into container now
2025-06-02 11:39:20,366:INFO:_master_model_container: 12
2025-06-02 11:39:20,366:INFO:_display_container: 2
2025-06-02 11:39:20,367:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 11:39:20,367:INFO:create_model() successfully completed......................................
2025-06-02 11:39:21,692:INFO:SubProcess create_model() end ==================================
2025-06-02 11:39:21,693:INFO:Creating metrics dataframe
2025-06-02 11:39:21,719:INFO:Initializing Random Forest Regressor
2025-06-02 11:39:21,720:INFO:Total runtime is 1.3910791675249736 minutes
2025-06-02 11:39:21,733:INFO:SubProcess create_model() called ==================================
2025-06-02 11:39:21,734:INFO:Initializing create_model()
2025-06-02 11:39:21,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:39:21,735:INFO:Checking exceptions
2025-06-02 11:39:21,735:INFO:Importing libraries
2025-06-02 11:39:21,735:INFO:Copying training dataset
2025-06-02 11:39:21,816:INFO:Defining folds
2025-06-02 11:39:21,816:INFO:Declaring metric variables
2025-06-02 11:39:21,830:INFO:Importing untrained model
2025-06-02 11:39:21,845:INFO:Random Forest Regressor Imported successfully
2025-06-02 11:39:21,872:INFO:Starting cross validation
2025-06-02 11:39:21,877:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:39:31,289:INFO:Calculating mean and std
2025-06-02 11:39:31,292:INFO:Creating metrics dataframe
2025-06-02 11:39:31,297:INFO:Uploading results into container
2025-06-02 11:39:31,298:INFO:Uploading model into container now
2025-06-02 11:39:31,299:INFO:_master_model_container: 13
2025-06-02 11:39:31,300:INFO:_display_container: 2
2025-06-02 11:39:31,301:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 11:39:31,301:INFO:create_model() successfully completed......................................
2025-06-02 11:39:32,397:INFO:SubProcess create_model() end ==================================
2025-06-02 11:39:32,397:INFO:Creating metrics dataframe
2025-06-02 11:39:32,418:INFO:Initializing Extra Trees Regressor
2025-06-02 11:39:32,418:INFO:Total runtime is 1.5693727850914003 minutes
2025-06-02 11:39:32,432:INFO:SubProcess create_model() called ==================================
2025-06-02 11:39:32,432:INFO:Initializing create_model()
2025-06-02 11:39:32,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:39:32,433:INFO:Checking exceptions
2025-06-02 11:39:32,433:INFO:Importing libraries
2025-06-02 11:39:32,434:INFO:Copying training dataset
2025-06-02 11:39:32,517:INFO:Defining folds
2025-06-02 11:39:32,517:INFO:Declaring metric variables
2025-06-02 11:39:32,528:INFO:Importing untrained model
2025-06-02 11:39:32,542:INFO:Extra Trees Regressor Imported successfully
2025-06-02 11:39:32,569:INFO:Starting cross validation
2025-06-02 11:39:32,574:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:39:38,514:INFO:Calculating mean and std
2025-06-02 11:39:38,517:INFO:Creating metrics dataframe
2025-06-02 11:39:38,521:INFO:Uploading results into container
2025-06-02 11:39:38,522:INFO:Uploading model into container now
2025-06-02 11:39:38,523:INFO:_master_model_container: 14
2025-06-02 11:39:38,524:INFO:_display_container: 2
2025-06-02 11:39:38,525:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 11:39:38,525:INFO:create_model() successfully completed......................................
2025-06-02 11:39:39,776:INFO:SubProcess create_model() end ==================================
2025-06-02 11:39:39,777:INFO:Creating metrics dataframe
2025-06-02 11:39:39,802:INFO:Initializing AdaBoost Regressor
2025-06-02 11:39:39,803:INFO:Total runtime is 1.6924563924471538 minutes
2025-06-02 11:39:39,813:INFO:SubProcess create_model() called ==================================
2025-06-02 11:39:39,813:INFO:Initializing create_model()
2025-06-02 11:39:39,814:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:39:39,814:INFO:Checking exceptions
2025-06-02 11:39:39,815:INFO:Importing libraries
2025-06-02 11:39:39,816:INFO:Copying training dataset
2025-06-02 11:39:39,901:INFO:Defining folds
2025-06-02 11:39:39,901:INFO:Declaring metric variables
2025-06-02 11:39:39,929:INFO:Importing untrained model
2025-06-02 11:39:39,947:INFO:AdaBoost Regressor Imported successfully
2025-06-02 11:39:39,989:INFO:Starting cross validation
2025-06-02 11:39:39,994:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:39:42,281:INFO:Calculating mean and std
2025-06-02 11:39:42,284:INFO:Creating metrics dataframe
2025-06-02 11:39:42,288:INFO:Uploading results into container
2025-06-02 11:39:42,290:INFO:Uploading model into container now
2025-06-02 11:39:42,290:INFO:_master_model_container: 15
2025-06-02 11:39:42,291:INFO:_display_container: 2
2025-06-02 11:39:42,291:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 11:39:42,292:INFO:create_model() successfully completed......................................
2025-06-02 11:39:43,537:INFO:SubProcess create_model() end ==================================
2025-06-02 11:39:43,538:INFO:Creating metrics dataframe
2025-06-02 11:39:43,568:INFO:Initializing Gradient Boosting Regressor
2025-06-02 11:39:43,568:INFO:Total runtime is 1.7552088936169943 minutes
2025-06-02 11:39:43,581:INFO:SubProcess create_model() called ==================================
2025-06-02 11:39:43,582:INFO:Initializing create_model()
2025-06-02 11:39:43,583:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:39:43,583:INFO:Checking exceptions
2025-06-02 11:39:43,584:INFO:Importing libraries
2025-06-02 11:39:43,584:INFO:Copying training dataset
2025-06-02 11:39:43,696:INFO:Defining folds
2025-06-02 11:39:43,696:INFO:Declaring metric variables
2025-06-02 11:39:43,712:INFO:Importing untrained model
2025-06-02 11:39:43,735:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 11:39:43,761:INFO:Starting cross validation
2025-06-02 11:39:43,765:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:39:47,629:INFO:Calculating mean and std
2025-06-02 11:39:47,632:INFO:Creating metrics dataframe
2025-06-02 11:39:47,635:INFO:Uploading results into container
2025-06-02 11:39:47,636:INFO:Uploading model into container now
2025-06-02 11:39:47,636:INFO:_master_model_container: 16
2025-06-02 11:39:47,636:INFO:_display_container: 2
2025-06-02 11:39:47,637:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 11:39:47,638:INFO:create_model() successfully completed......................................
2025-06-02 11:39:48,681:INFO:SubProcess create_model() end ==================================
2025-06-02 11:39:48,681:INFO:Creating metrics dataframe
2025-06-02 11:39:48,700:INFO:Initializing Extreme Gradient Boosting
2025-06-02 11:39:48,700:INFO:Total runtime is 1.8407446622848511 minutes
2025-06-02 11:39:48,711:INFO:SubProcess create_model() called ==================================
2025-06-02 11:39:48,712:INFO:Initializing create_model()
2025-06-02 11:39:48,712:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:39:48,712:INFO:Checking exceptions
2025-06-02 11:39:48,713:INFO:Importing libraries
2025-06-02 11:39:48,713:INFO:Copying training dataset
2025-06-02 11:39:48,788:INFO:Defining folds
2025-06-02 11:39:48,788:INFO:Declaring metric variables
2025-06-02 11:39:48,798:INFO:Importing untrained model
2025-06-02 11:39:48,810:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 11:39:48,834:INFO:Starting cross validation
2025-06-02 11:39:48,838:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:39:51,025:INFO:Calculating mean and std
2025-06-02 11:39:51,028:INFO:Creating metrics dataframe
2025-06-02 11:39:51,032:INFO:Uploading results into container
2025-06-02 11:39:51,033:INFO:Uploading model into container now
2025-06-02 11:39:51,034:INFO:_master_model_container: 17
2025-06-02 11:39:51,034:INFO:_display_container: 2
2025-06-02 11:39:51,039:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 11:39:51,043:INFO:create_model() successfully completed......................................
2025-06-02 11:39:52,114:INFO:SubProcess create_model() end ==================================
2025-06-02 11:39:52,114:INFO:Creating metrics dataframe
2025-06-02 11:39:52,135:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 11:39:52,135:INFO:Total runtime is 1.8979938785235086 minutes
2025-06-02 11:39:52,144:INFO:SubProcess create_model() called ==================================
2025-06-02 11:39:52,144:INFO:Initializing create_model()
2025-06-02 11:39:52,144:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:39:52,145:INFO:Checking exceptions
2025-06-02 11:39:52,145:INFO:Importing libraries
2025-06-02 11:39:52,146:INFO:Copying training dataset
2025-06-02 11:39:52,210:INFO:Defining folds
2025-06-02 11:39:52,211:INFO:Declaring metric variables
2025-06-02 11:39:52,223:INFO:Importing untrained model
2025-06-02 11:39:52,236:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 11:39:52,257:INFO:Starting cross validation
2025-06-02 11:39:52,261:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:39:54,184:INFO:Calculating mean and std
2025-06-02 11:39:54,186:INFO:Creating metrics dataframe
2025-06-02 11:39:54,190:INFO:Uploading results into container
2025-06-02 11:39:54,192:INFO:Uploading model into container now
2025-06-02 11:39:54,193:INFO:_master_model_container: 18
2025-06-02 11:39:54,193:INFO:_display_container: 2
2025-06-02 11:39:54,196:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 11:39:54,196:INFO:create_model() successfully completed......................................
2025-06-02 11:39:55,316:INFO:SubProcess create_model() end ==================================
2025-06-02 11:39:55,316:INFO:Creating metrics dataframe
2025-06-02 11:39:55,346:INFO:Initializing CatBoost Regressor
2025-06-02 11:39:55,346:INFO:Total runtime is 1.951507039864858 minutes
2025-06-02 11:39:55,356:INFO:SubProcess create_model() called ==================================
2025-06-02 11:39:55,357:INFO:Initializing create_model()
2025-06-02 11:39:55,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:39:55,357:INFO:Checking exceptions
2025-06-02 11:39:55,357:INFO:Importing libraries
2025-06-02 11:39:55,357:INFO:Copying training dataset
2025-06-02 11:39:55,499:INFO:Defining folds
2025-06-02 11:39:55,500:INFO:Declaring metric variables
2025-06-02 11:39:55,556:INFO:Importing untrained model
2025-06-02 11:39:55,603:INFO:CatBoost Regressor Imported successfully
2025-06-02 11:39:55,636:INFO:Starting cross validation
2025-06-02 11:39:55,641:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:40:21,598:INFO:Calculating mean and std
2025-06-02 11:40:21,600:INFO:Creating metrics dataframe
2025-06-02 11:40:21,604:INFO:Uploading results into container
2025-06-02 11:40:21,605:INFO:Uploading model into container now
2025-06-02 11:40:21,606:INFO:_master_model_container: 19
2025-06-02 11:40:21,606:INFO:_display_container: 2
2025-06-02 11:40:21,606:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6BBD76C50>
2025-06-02 11:40:21,607:INFO:create_model() successfully completed......................................
2025-06-02 11:40:22,865:INFO:SubProcess create_model() end ==================================
2025-06-02 11:40:22,865:INFO:Creating metrics dataframe
2025-06-02 11:40:22,894:INFO:Initializing Dummy Regressor
2025-06-02 11:40:22,894:INFO:Total runtime is 2.410655689239502 minutes
2025-06-02 11:40:22,905:INFO:SubProcess create_model() called ==================================
2025-06-02 11:40:22,906:INFO:Initializing create_model()
2025-06-02 11:40:22,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD753C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:40:22,907:INFO:Checking exceptions
2025-06-02 11:40:22,907:INFO:Importing libraries
2025-06-02 11:40:22,907:INFO:Copying training dataset
2025-06-02 11:40:22,998:INFO:Defining folds
2025-06-02 11:40:22,999:INFO:Declaring metric variables
2025-06-02 11:40:23,014:INFO:Importing untrained model
2025-06-02 11:40:23,028:INFO:Dummy Regressor Imported successfully
2025-06-02 11:40:23,055:INFO:Starting cross validation
2025-06-02 11:40:23,060:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:40:24,055:INFO:Calculating mean and std
2025-06-02 11:40:24,059:INFO:Creating metrics dataframe
2025-06-02 11:40:24,063:INFO:Uploading results into container
2025-06-02 11:40:24,065:INFO:Uploading model into container now
2025-06-02 11:40:24,066:INFO:_master_model_container: 20
2025-06-02 11:40:24,066:INFO:_display_container: 2
2025-06-02 11:40:24,067:INFO:DummyRegressor()
2025-06-02 11:40:24,067:INFO:create_model() successfully completed......................................
2025-06-02 11:40:25,300:INFO:SubProcess create_model() end ==================================
2025-06-02 11:40:25,301:INFO:Creating metrics dataframe
2025-06-02 11:40:25,357:INFO:Initializing create_model()
2025-06-02 11:40:25,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:40:25,357:INFO:Checking exceptions
2025-06-02 11:40:25,367:INFO:Importing libraries
2025-06-02 11:40:25,368:INFO:Copying training dataset
2025-06-02 11:40:25,446:INFO:Defining folds
2025-06-02 11:40:25,446:INFO:Declaring metric variables
2025-06-02 11:40:25,447:INFO:Importing untrained model
2025-06-02 11:40:25,447:INFO:Declaring custom model
2025-06-02 11:40:25,449:INFO:Extra Trees Regressor Imported successfully
2025-06-02 11:40:25,454:INFO:Cross validation set to False
2025-06-02 11:40:25,454:INFO:Fitting Model
2025-06-02 11:40:27,629:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 11:40:27,629:INFO:create_model() successfully completed......................................
2025-06-02 11:40:29,134:INFO:_master_model_container: 20
2025-06-02 11:40:29,134:INFO:_display_container: 2
2025-06-02 11:40:29,136:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 11:40:29,136:INFO:compare_models() successfully completed......................................
2025-06-02 11:40:29,140:INFO:Initializing tune_model()
2025-06-02 11:40:29,141:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>)
2025-06-02 11:40:29,141:INFO:Checking exceptions
2025-06-02 11:40:29,141:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 11:40:29,677:INFO:Copying training dataset
2025-06-02 11:40:29,756:INFO:Checking base model
2025-06-02 11:40:29,756:INFO:Base model : Extra Trees Regressor
2025-06-02 11:40:29,770:INFO:Declaring metric variables
2025-06-02 11:40:29,783:INFO:Defining Hyperparameters
2025-06-02 11:40:31,250:INFO:Tuning with n_jobs=-1
2025-06-02 11:40:31,276:INFO:Initializing skopt.BayesSearchCV
2025-06-02 11:44:00,053:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', False), ('actual_estimator__criterion', 'absolute_error'), ('actual_estimator__max_depth', 11), ('actual_estimator__max_features', 0.4556655086335653), ('actual_estimator__min_impurity_decrease', 0.00012891733508622256), ('actual_estimator__min_samples_leaf', 1), ('actual_estimator__min_samples_split', 9), ('actual_estimator__n_estimators', 11)])
2025-06-02 11:44:00,055:INFO:Hyperparameter search completed
2025-06-02 11:44:00,055:INFO:SubProcess create_model() called ==================================
2025-06-02 11:44:00,057:INFO:Initializing create_model()
2025-06-02 11:44:00,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC070610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bootstrap': False, 'criterion': 'absolute_error', 'max_depth': 11, 'max_features': 0.4556655086335653, 'min_impurity_decrease': 0.00012891733508622256, 'min_samples_leaf': 1, 'min_samples_split': 9, 'n_estimators': 11})
2025-06-02 11:44:00,057:INFO:Checking exceptions
2025-06-02 11:44:00,057:INFO:Importing libraries
2025-06-02 11:44:00,057:INFO:Copying training dataset
2025-06-02 11:44:00,138:INFO:Defining folds
2025-06-02 11:44:00,139:INFO:Declaring metric variables
2025-06-02 11:44:00,150:INFO:Importing untrained model
2025-06-02 11:44:00,151:INFO:Declaring custom model
2025-06-02 11:44:00,164:INFO:Extra Trees Regressor Imported successfully
2025-06-02 11:44:00,188:INFO:Starting cross validation
2025-06-02 11:44:00,193:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:44:09,746:INFO:Calculating mean and std
2025-06-02 11:44:09,747:INFO:Creating metrics dataframe
2025-06-02 11:44:09,764:INFO:Finalizing model
2025-06-02 11:44:13,356:INFO:Uploading results into container
2025-06-02 11:44:13,360:INFO:Uploading model into container now
2025-06-02 11:44:13,362:INFO:_master_model_container: 21
2025-06-02 11:44:13,362:INFO:_display_container: 3
2025-06-02 11:44:13,364:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=11,
                    max_features=0.4556655086335653,
                    min_impurity_decrease=0.00012891733508622256,
                    min_samples_split=9, n_estimators=11, n_jobs=-1,
                    random_state=123)
2025-06-02 11:44:13,364:INFO:create_model() successfully completed......................................
2025-06-02 11:44:14,719:INFO:SubProcess create_model() end ==================================
2025-06-02 11:44:14,721:INFO:choose_better activated
2025-06-02 11:44:14,729:INFO:SubProcess create_model() called ==================================
2025-06-02 11:44:14,730:INFO:Initializing create_model()
2025-06-02 11:44:14,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:44:14,731:INFO:Checking exceptions
2025-06-02 11:44:14,734:INFO:Importing libraries
2025-06-02 11:44:14,735:INFO:Copying training dataset
2025-06-02 11:44:14,788:INFO:Defining folds
2025-06-02 11:44:14,788:INFO:Declaring metric variables
2025-06-02 11:44:14,788:INFO:Importing untrained model
2025-06-02 11:44:14,788:INFO:Declaring custom model
2025-06-02 11:44:14,789:INFO:Extra Trees Regressor Imported successfully
2025-06-02 11:44:14,789:INFO:Starting cross validation
2025-06-02 11:44:14,792:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 11:44:20,719:INFO:Calculating mean and std
2025-06-02 11:44:20,721:INFO:Creating metrics dataframe
2025-06-02 11:44:20,727:INFO:Finalizing model
2025-06-02 11:44:22,318:INFO:Uploading results into container
2025-06-02 11:44:22,319:INFO:Uploading model into container now
2025-06-02 11:44:22,320:INFO:_master_model_container: 22
2025-06-02 11:44:22,320:INFO:_display_container: 4
2025-06-02 11:44:22,321:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 11:44:22,321:INFO:create_model() successfully completed......................................
2025-06-02 11:44:23,371:INFO:SubProcess create_model() end ==================================
2025-06-02 11:44:23,372:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 0.1708
2025-06-02 11:44:23,372:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=11,
                    max_features=0.4556655086335653,
                    min_impurity_decrease=0.00012891733508622256,
                    min_samples_split=9, n_estimators=11, n_jobs=-1,
                    random_state=123) result for MAE is 0.1994
2025-06-02 11:44:23,373:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 11:44:23,373:INFO:choose_better completed
2025-06-02 11:44:23,374:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 11:44:23,394:INFO:_master_model_container: 22
2025-06-02 11:44:23,395:INFO:_display_container: 3
2025-06-02 11:44:23,396:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 11:44:23,397:INFO:tune_model() successfully completed......................................
2025-06-02 11:44:24,556:INFO:Initializing finalize_model()
2025-06-02 11:44:24,557:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 11:44:24,557:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 11:44:24,599:INFO:Initializing create_model()
2025-06-02 11:44:24,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 11:44:24,600:INFO:Checking exceptions
2025-06-02 11:44:24,602:INFO:Importing libraries
2025-06-02 11:44:24,602:INFO:Copying training dataset
2025-06-02 11:44:24,609:INFO:Defining folds
2025-06-02 11:44:24,609:INFO:Declaring metric variables
2025-06-02 11:44:24,610:INFO:Importing untrained model
2025-06-02 11:44:24,610:INFO:Declaring custom model
2025-06-02 11:44:24,611:INFO:Extra Trees Regressor Imported successfully
2025-06-02 11:44:24,614:INFO:Cross validation set to False
2025-06-02 11:44:24,615:INFO:Fitting Model
2025-06-02 11:44:26,729:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 11:44:26,729:INFO:create_model() successfully completed......................................
2025-06-02 11:44:27,803:INFO:_master_model_container: 22
2025-06-02 11:44:27,803:INFO:_display_container: 3
2025-06-02 11:44:27,820:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 11:44:27,820:INFO:finalize_model() successfully completed......................................
2025-06-02 11:44:28,896:INFO:Initializing save_model()
2025-06-02 11:44:28,896:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 11:44:28,898:INFO:Adding model into prep_pipe
2025-06-02 11:44:28,898:WARNING:Only Model saved as it was a pipeline.
2025-06-02 11:44:29,075:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 11:44:29,126:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 11:44:29,126:INFO:save_model() successfully completed......................................
2025-06-02 13:29:01,020:INFO:Initializing load_model()
2025-06-02 13:29:01,046:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 13:29:01,675:INFO:Initializing get_config()
2025-06-02 13:29:01,675:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, variable=X_test)
2025-06-02 13:29:01,690:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 13:29:01,701:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 13:29:02,009:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2059                       12.0                       13.0   
2652                       29.0                       31.0   
3768                       34.0                       65.0   
3686                        8.0                       14.0   
1037                       53.0                       83.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2059                      1.0               12.500000   
2652                      2.0               29.500000   
3768                     31.0               44.782608   
3686                      6.0               10.000000   
1037                     30.0               77.545456   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2059                   0.500000                    12.0   
2652                   0.750000                    29.0   
3768                  14.064272                    34.0   
3686                   2.666667                     8.0   
1037                   8.925620                    83.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2059                                68.0                                73.0   
2652                                64.0                                74.0   
3768                                29.0                                89.0   
3686                                78.0                                87.0   
1037                                86.0                                96.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2059                               5.0                        70.500000  ...   
2652                              10.0                        66.500000  ...   
3768                              60.0                        68.130432  ...   
3686                               9.0                        84.000000  ...   
1037                              10.0                        87.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2059                 4.0                   1            32.0   
2652                 4.0                   1            32.0   
3768                 7.0                   0             2.0   
3686                 7.0                   0             2.0   
1037                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2059                 False                     False   
2652                 False                     False   
3768                 False                     False   
3686                 False                     False   
1037                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2059                      False                        False   
2652                      False                        False   
3768                      False                        False   
3686                      False                        False   
1037                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2059                       True                     False   
2652                       True                     False   
3768                      False                      True   
3686                      False                      True   
1037                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2059                    False  
2652                    False  
3768                    False  
3686                    False  
1037                    False  

[1344 rows x 146 columns]
2025-06-02 13:29:02,011:INFO:get_config() successfully completed......................................
2025-06-02 13:29:02,011:INFO:Initializing get_config()
2025-06-02 13:29:02,013:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, variable=y_test)
2025-06-02 13:29:02,013:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 13:29:02,013:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 13:29:02,059:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2059    0.014339
2652   -0.098120
3768   -1.861921
3686   -3.207308
1037   -0.156411
Name: target, Length: 1344, dtype: float32
2025-06-02 13:29:02,059:INFO:get_config() successfully completed......................................
2025-06-02 13:29:02,134:INFO:Initializing predict_model()
2025-06-02 13:29:02,134:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6BBEE69E0>)
2025-06-02 13:29:02,135:INFO:Checking exceptions
2025-06-02 13:29:02,135:INFO:Preloading libraries
2025-06-02 13:29:02,249:INFO:Set up data.
2025-06-02 13:29:10,197:INFO:Set up index.
2025-06-02 13:33:11,947:INFO:Initializing load_model()
2025-06-02 13:33:11,949:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 13:33:12,273:INFO:Initializing get_config()
2025-06-02 13:33:12,274:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, variable=X_test)
2025-06-02 13:33:12,274:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 13:33:12,274:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 13:33:12,330:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2059                       12.0                       13.0   
2652                       29.0                       31.0   
3768                       34.0                       65.0   
3686                        8.0                       14.0   
1037                       53.0                       83.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2059                      1.0               12.500000   
2652                      2.0               29.500000   
3768                     31.0               44.782608   
3686                      6.0               10.000000   
1037                     30.0               77.545456   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2059                   0.500000                    12.0   
2652                   0.750000                    29.0   
3768                  14.064272                    34.0   
3686                   2.666667                     8.0   
1037                   8.925620                    83.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2059                                68.0                                73.0   
2652                                64.0                                74.0   
3768                                29.0                                89.0   
3686                                78.0                                87.0   
1037                                86.0                                96.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2059                               5.0                        70.500000  ...   
2652                              10.0                        66.500000  ...   
3768                              60.0                        68.130432  ...   
3686                               9.0                        84.000000  ...   
1037                              10.0                        87.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2059                 4.0                   1            32.0   
2652                 4.0                   1            32.0   
3768                 7.0                   0             2.0   
3686                 7.0                   0             2.0   
1037                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2059                 False                     False   
2652                 False                     False   
3768                 False                     False   
3686                 False                     False   
1037                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2059                      False                        False   
2652                      False                        False   
3768                      False                        False   
3686                      False                        False   
1037                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2059                       True                     False   
2652                       True                     False   
3768                      False                      True   
3686                      False                      True   
1037                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2059                    False  
2652                    False  
3768                    False  
3686                    False  
1037                    False  

[1344 rows x 146 columns]
2025-06-02 13:33:12,331:INFO:get_config() successfully completed......................................
2025-06-02 13:33:12,333:INFO:Initializing get_config()
2025-06-02 13:33:12,334:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, variable=y_test)
2025-06-02 13:33:12,334:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 13:33:12,334:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 13:33:12,347:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2059    0.014339
2652   -0.098120
3768   -1.861921
3686   -3.207308
1037   -0.156411
Name: target, Length: 1344, dtype: float32
2025-06-02 13:33:12,347:INFO:get_config() successfully completed......................................
2025-06-02 13:33:12,364:INFO:Initializing predict_model()
2025-06-02 13:33:12,364:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6BBF9ED40>)
2025-06-02 13:33:12,364:INFO:Checking exceptions
2025-06-02 13:33:12,364:INFO:Preloading libraries
2025-06-02 13:33:12,371:INFO:Set up data.
2025-06-02 13:33:12,444:INFO:Set up index.
2025-06-02 13:34:21,366:INFO:Initializing load_model()
2025-06-02 13:34:21,367:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 13:34:21,717:INFO:Initializing get_config()
2025-06-02 13:34:21,717:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, variable=X_test)
2025-06-02 13:34:21,718:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 13:34:21,718:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 13:34:21,765:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2059                       12.0                       13.0   
2652                       29.0                       31.0   
3768                       34.0                       65.0   
3686                        8.0                       14.0   
1037                       53.0                       83.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2059                      1.0               12.500000   
2652                      2.0               29.500000   
3768                     31.0               44.782608   
3686                      6.0               10.000000   
1037                     30.0               77.545456   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2059                   0.500000                    12.0   
2652                   0.750000                    29.0   
3768                  14.064272                    34.0   
3686                   2.666667                     8.0   
1037                   8.925620                    83.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2059                                68.0                                73.0   
2652                                64.0                                74.0   
3768                                29.0                                89.0   
3686                                78.0                                87.0   
1037                                86.0                                96.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2059                               5.0                        70.500000  ...   
2652                              10.0                        66.500000  ...   
3768                              60.0                        68.130432  ...   
3686                               9.0                        84.000000  ...   
1037                              10.0                        87.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2059                 4.0                   1            32.0   
2652                 4.0                   1            32.0   
3768                 7.0                   0             2.0   
3686                 7.0                   0             2.0   
1037                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2059                 False                     False   
2652                 False                     False   
3768                 False                     False   
3686                 False                     False   
1037                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2059                      False                        False   
2652                      False                        False   
3768                      False                        False   
3686                      False                        False   
1037                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2059                       True                     False   
2652                       True                     False   
3768                      False                      True   
3686                      False                      True   
1037                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2059                    False  
2652                    False  
3768                    False  
3686                    False  
1037                    False  

[1344 rows x 146 columns]
2025-06-02 13:34:21,765:INFO:get_config() successfully completed......................................
2025-06-02 13:34:21,766:INFO:Initializing get_config()
2025-06-02 13:34:21,766:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, variable=y_test)
2025-06-02 13:34:21,766:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 13:34:21,766:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 13:34:21,780:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2059    0.014339
2652   -0.098120
3768   -1.861921
3686   -3.207308
1037   -0.156411
Name: target, Length: 1344, dtype: float32
2025-06-02 13:34:21,780:INFO:get_config() successfully completed......................................
2025-06-02 13:34:21,795:INFO:Initializing predict_model()
2025-06-02 13:34:21,795:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6BBF9ED40>)
2025-06-02 13:34:21,795:INFO:Checking exceptions
2025-06-02 13:34:21,795:INFO:Preloading libraries
2025-06-02 13:34:21,799:INFO:Set up data.
2025-06-02 13:34:21,865:INFO:Set up index.
2025-06-02 13:35:04,503:INFO:Initializing load_model()
2025-06-02 13:35:04,503:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 13:35:04,810:INFO:Initializing get_config()
2025-06-02 13:35:04,810:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, variable=X_test)
2025-06-02 13:35:04,810:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 13:35:04,811:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 13:35:04,848:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2059                       12.0                       13.0   
2652                       29.0                       31.0   
3768                       34.0                       65.0   
3686                        8.0                       14.0   
1037                       53.0                       83.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2059                      1.0               12.500000   
2652                      2.0               29.500000   
3768                     31.0               44.782608   
3686                      6.0               10.000000   
1037                     30.0               77.545456   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2059                   0.500000                    12.0   
2652                   0.750000                    29.0   
3768                  14.064272                    34.0   
3686                   2.666667                     8.0   
1037                   8.925620                    83.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2059                                68.0                                73.0   
2652                                64.0                                74.0   
3768                                29.0                                89.0   
3686                                78.0                                87.0   
1037                                86.0                                96.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2059                               5.0                        70.500000  ...   
2652                              10.0                        66.500000  ...   
3768                              60.0                        68.130432  ...   
3686                               9.0                        84.000000  ...   
1037                              10.0                        87.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2059                 4.0                   1            32.0   
2652                 4.0                   1            32.0   
3768                 7.0                   0             2.0   
3686                 7.0                   0             2.0   
1037                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2059                 False                     False   
2652                 False                     False   
3768                 False                     False   
3686                 False                     False   
1037                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2059                      False                        False   
2652                      False                        False   
3768                      False                        False   
3686                      False                        False   
1037                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2059                       True                     False   
2652                       True                     False   
3768                      False                      True   
3686                      False                      True   
1037                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2059                    False  
2652                    False  
3768                    False  
3686                    False  
1037                    False  

[1344 rows x 146 columns]
2025-06-02 13:35:04,848:INFO:get_config() successfully completed......................................
2025-06-02 13:35:04,849:INFO:Initializing get_config()
2025-06-02 13:35:04,849:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, variable=y_test)
2025-06-02 13:35:04,849:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 13:35:04,849:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 13:35:04,862:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2059    0.014339
2652   -0.098120
3768   -1.861921
3686   -3.207308
1037   -0.156411
Name: target, Length: 1344, dtype: float32
2025-06-02 13:35:04,862:INFO:get_config() successfully completed......................................
2025-06-02 13:35:04,876:INFO:Initializing predict_model()
2025-06-02 13:35:04,876:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6BADC8B80>)
2025-06-02 13:35:04,876:INFO:Checking exceptions
2025-06-02 13:35:04,876:INFO:Preloading libraries
2025-06-02 13:35:04,881:INFO:Set up data.
2025-06-02 13:35:04,958:INFO:Set up index.
2025-06-02 13:39:22,047:INFO:Initializing load_model()
2025-06-02 13:39:22,049:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 13:39:22,416:INFO:Initializing get_config()
2025-06-02 13:39:22,416:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, variable=X_test)
2025-06-02 13:39:22,417:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 13:39:22,417:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 13:39:22,469:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2059                       12.0                       13.0   
2652                       29.0                       31.0   
3768                       34.0                       65.0   
3686                        8.0                       14.0   
1037                       53.0                       83.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2059                      1.0               12.500000   
2652                      2.0               29.500000   
3768                     31.0               44.782608   
3686                      6.0               10.000000   
1037                     30.0               77.545456   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2059                   0.500000                    12.0   
2652                   0.750000                    29.0   
3768                  14.064272                    34.0   
3686                   2.666667                     8.0   
1037                   8.925620                    83.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2059                                68.0                                73.0   
2652                                64.0                                74.0   
3768                                29.0                                89.0   
3686                                78.0                                87.0   
1037                                86.0                                96.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2059                               5.0                        70.500000  ...   
2652                              10.0                        66.500000  ...   
3768                              60.0                        68.130432  ...   
3686                               9.0                        84.000000  ...   
1037                              10.0                        87.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2059                 4.0                   1            32.0   
2652                 4.0                   1            32.0   
3768                 7.0                   0             2.0   
3686                 7.0                   0             2.0   
1037                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2059                 False                     False   
2652                 False                     False   
3768                 False                     False   
3686                 False                     False   
1037                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2059                      False                        False   
2652                      False                        False   
3768                      False                        False   
3686                      False                        False   
1037                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2059                       True                     False   
2652                       True                     False   
3768                      False                      True   
3686                      False                      True   
1037                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2059                    False  
2652                    False  
3768                    False  
3686                    False  
1037                    False  

[1344 rows x 146 columns]
2025-06-02 13:39:22,469:INFO:get_config() successfully completed......................................
2025-06-02 13:39:22,471:INFO:Initializing get_config()
2025-06-02 13:39:22,472:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, variable=y_test)
2025-06-02 13:39:22,472:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 13:39:22,472:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 13:39:22,486:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2059    0.014339
2652   -0.098120
3768   -1.861921
3686   -3.207308
1037   -0.156411
Name: target, Length: 1344, dtype: float32
2025-06-02 13:39:22,487:INFO:get_config() successfully completed......................................
2025-06-02 13:39:22,504:INFO:Initializing predict_model()
2025-06-02 13:39:22,504:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BB087700>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6BBE7EEF0>)
2025-06-02 13:39:22,504:INFO:Checking exceptions
2025-06-02 13:39:22,504:INFO:Preloading libraries
2025-06-02 13:39:22,513:INFO:Set up data.
2025-06-02 13:39:22,598:INFO:Set up index.
2025-06-02 13:46:54,135:INFO:PyCaret RegressionExperiment
2025-06-02 13:46:54,136:INFO:Logging name: reg-default-name
2025-06-02 13:46:54,137:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 13:46:54,137:INFO:version 3.3.2
2025-06-02 13:46:54,137:INFO:Initializing setup()
2025-06-02 13:46:54,138:INFO:self.USI: 615b
2025-06-02 13:46:54,138:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 13:46:54,139:INFO:Checking environment
2025-06-02 13:46:54,139:INFO:python_version: 3.10.16
2025-06-02 13:46:54,139:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 13:46:54,139:INFO:machine: AMD64
2025-06-02 13:46:54,139:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 13:46:54,154:INFO:Memory: svmem(total=6378008576, available=996339712, percent=84.4, used=5381668864, free=996339712)
2025-06-02 13:46:54,155:INFO:Physical Core: 4
2025-06-02 13:46:54,155:INFO:Logical Core: 8
2025-06-02 13:46:54,156:INFO:Checking libraries
2025-06-02 13:46:54,156:INFO:System:
2025-06-02 13:46:54,157:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 13:46:54,157:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 13:46:54,157:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 13:46:54,158:INFO:PyCaret required dependencies:
2025-06-02 13:46:54,160:INFO:                 pip: 25.1
2025-06-02 13:46:54,161:INFO:          setuptools: 78.1.1
2025-06-02 13:46:54,161:INFO:             pycaret: 3.3.2
2025-06-02 13:46:54,161:INFO:             IPython: 8.37.0
2025-06-02 13:46:54,161:INFO:          ipywidgets: 8.1.7
2025-06-02 13:46:54,161:INFO:                tqdm: 4.67.1
2025-06-02 13:46:54,161:INFO:               numpy: 1.26.4
2025-06-02 13:46:54,162:INFO:              pandas: 2.0.1
2025-06-02 13:46:54,162:INFO:              jinja2: 3.1.6
2025-06-02 13:46:54,162:INFO:               scipy: 1.10.1
2025-06-02 13:46:54,162:INFO:              joblib: 1.3.2
2025-06-02 13:46:54,162:INFO:             sklearn: 1.4.2
2025-06-02 13:46:54,162:INFO:                pyod: 2.0.5
2025-06-02 13:46:54,162:INFO:            imblearn: 0.13.0
2025-06-02 13:46:54,162:INFO:   category_encoders: 2.7.0
2025-06-02 13:46:54,163:INFO:            lightgbm: 4.6.0
2025-06-02 13:46:54,163:INFO:               numba: 0.61.0
2025-06-02 13:46:54,163:INFO:            requests: 2.32.3
2025-06-02 13:46:54,163:INFO:          matplotlib: 3.7.1
2025-06-02 13:46:54,163:INFO:          scikitplot: 0.3.7
2025-06-02 13:46:54,163:INFO:         yellowbrick: 1.5
2025-06-02 13:46:54,163:INFO:              plotly: 6.1.2
2025-06-02 13:46:54,164:INFO:    plotly-resampler: Not installed
2025-06-02 13:46:54,164:INFO:             kaleido: 0.2.1
2025-06-02 13:46:54,164:INFO:           schemdraw: 0.15
2025-06-02 13:46:54,164:INFO:         statsmodels: 0.14.4
2025-06-02 13:46:54,164:INFO:              sktime: 0.26.0
2025-06-02 13:46:54,164:INFO:               tbats: 1.1.3
2025-06-02 13:46:54,164:INFO:            pmdarima: 2.0.4
2025-06-02 13:46:54,164:INFO:              psutil: 7.0.0
2025-06-02 13:46:54,164:INFO:          markupsafe: 2.1.2
2025-06-02 13:46:54,164:INFO:             pickle5: Not installed
2025-06-02 13:46:54,164:INFO:         cloudpickle: 3.1.1
2025-06-02 13:46:54,164:INFO:         deprecation: 2.1.0
2025-06-02 13:46:54,165:INFO:              xxhash: 3.5.0
2025-06-02 13:46:54,165:INFO:           wurlitzer: Not installed
2025-06-02 13:46:54,165:INFO:PyCaret optional dependencies:
2025-06-02 13:46:54,166:INFO:                shap: 0.44.1
2025-06-02 13:46:54,166:INFO:           interpret: 0.6.9
2025-06-02 13:46:54,167:INFO:                umap: 0.5.7
2025-06-02 13:46:54,167:INFO:     ydata_profiling: 4.16.1
2025-06-02 13:46:54,167:INFO:  explainerdashboard: 0.4.8
2025-06-02 13:46:54,167:INFO:             autoviz: Not installed
2025-06-02 13:46:54,167:INFO:           fairlearn: 0.7.0
2025-06-02 13:46:54,167:INFO:          deepchecks: Not installed
2025-06-02 13:46:54,167:INFO:             xgboost: 3.0.2
2025-06-02 13:46:54,167:INFO:            catboost: 1.2.8
2025-06-02 13:46:54,167:INFO:              kmodes: 0.12.2
2025-06-02 13:46:54,168:INFO:             mlxtend: 0.23.4
2025-06-02 13:46:54,168:INFO:       statsforecast: 1.5.0
2025-06-02 13:46:54,168:INFO:        tune_sklearn: Not installed
2025-06-02 13:46:54,168:INFO:                 ray: Not installed
2025-06-02 13:46:54,168:INFO:            hyperopt: 0.2.7
2025-06-02 13:46:54,168:INFO:              optuna: 4.3.0
2025-06-02 13:46:54,168:INFO:               skopt: 0.10.2
2025-06-02 13:46:54,168:INFO:              mlflow: 2.22.0
2025-06-02 13:46:54,169:INFO:              gradio: 5.32.0
2025-06-02 13:46:54,169:INFO:             fastapi: 0.115.12
2025-06-02 13:46:54,169:INFO:             uvicorn: 0.34.3
2025-06-02 13:46:54,169:INFO:              m2cgen: 0.10.0
2025-06-02 13:46:54,169:INFO:           evidently: 0.4.40
2025-06-02 13:46:54,169:INFO:               fugue: 0.8.5
2025-06-02 13:46:54,170:INFO:           streamlit: Not installed
2025-06-02 13:46:54,170:INFO:             prophet: Not installed
2025-06-02 13:46:54,170:INFO:None
2025-06-02 13:46:54,170:INFO:Set up data.
2025-06-02 13:46:54,330:INFO:Set up folding strategy.
2025-06-02 13:46:54,330:INFO:Set up train/test split.
2025-06-02 13:46:54,412:INFO:Set up index.
2025-06-02 13:46:54,413:INFO:Assigning column types.
2025-06-02 13:46:54,479:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 13:46:54,482:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 13:46:54,491:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 13:46:54,499:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:46:54,647:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:46:54,720:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:46:54,723:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:46:54,728:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:46:54,729:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 13:46:54,736:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 13:46:54,744:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:46:54,884:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:46:54,956:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:46:54,957:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:46:54,961:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:46:54,962:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 13:46:54,969:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 13:46:54,976:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:46:55,108:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:46:55,180:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:46:55,180:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:46:55,184:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:46:55,193:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 13:46:55,200:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:46:55,340:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:46:55,415:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:46:55,416:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:46:55,420:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:46:55,421:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 13:46:55,436:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:46:55,565:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:46:55,648:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:46:55,648:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:46:55,652:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:46:55,669:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:46:55,795:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:46:55,868:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:46:55,869:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:46:55,874:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:46:55,875:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 13:46:56,018:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:46:56,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:46:56,090:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:46:56,094:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:46:56,245:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:46:56,317:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:46:56,318:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:46:56,323:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:46:56,324:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 13:46:56,476:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:46:56,549:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:46:56,553:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:46:56,702:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:46:56,775:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:46:56,780:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:46:56,781:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 13:46:57,002:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:46:57,008:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:46:57,231:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:46:57,235:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:46:57,240:INFO:Preparing preprocessing pipeline...
2025-06-02 13:46:57,241:INFO:Set up simple imputation.
2025-06-02 13:46:57,242:INFO:Set up removing multicollinearity.
2025-06-02 13:46:57,249:INFO:Set up column name cleaning.
2025-06-02 13:46:57,494:INFO:Finished creating preprocessing pipeline.
2025-06-02 13:46:57,507:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 13:46:57,507:INFO:Creating final display dataframe.
2025-06-02 13:46:57,949:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              615b
2025-06-02 13:46:58,212:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:46:58,216:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:46:58,454:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:46:58,459:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:46:58,460:INFO:setup() successfully completed in 4.41s...............
2025-06-02 13:46:58,474:INFO:Initializing compare_models()
2025-06-02 13:46:58,475:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, include=None, fold=None, round=4, cross_validation=True, sort=MAPE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAPE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 13:46:58,476:INFO:Checking exceptions
2025-06-02 13:46:58,497:INFO:Preparing display monitor
2025-06-02 13:46:58,562:INFO:Initializing Linear Regression
2025-06-02 13:46:58,563:INFO:Total runtime is 1.6673405965169272e-05 minutes
2025-06-02 13:46:58,577:INFO:SubProcess create_model() called ==================================
2025-06-02 13:46:58,579:INFO:Initializing create_model()
2025-06-02 13:46:58,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:46:58,580:INFO:Checking exceptions
2025-06-02 13:46:58,580:INFO:Importing libraries
2025-06-02 13:46:58,582:INFO:Copying training dataset
2025-06-02 13:46:58,679:INFO:Defining folds
2025-06-02 13:46:58,679:INFO:Declaring metric variables
2025-06-02 13:46:58,694:INFO:Importing untrained model
2025-06-02 13:46:58,708:INFO:Linear Regression Imported successfully
2025-06-02 13:46:58,734:INFO:Starting cross validation
2025-06-02 13:46:58,738:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:47:14,731:INFO:Calculating mean and std
2025-06-02 13:47:14,738:INFO:Creating metrics dataframe
2025-06-02 13:47:14,752:INFO:Uploading results into container
2025-06-02 13:47:14,755:INFO:Uploading model into container now
2025-06-02 13:47:14,759:INFO:_master_model_container: 1
2025-06-02 13:47:14,759:INFO:_display_container: 2
2025-06-02 13:47:14,760:INFO:LinearRegression(n_jobs=-1)
2025-06-02 13:47:14,761:INFO:create_model() successfully completed......................................
2025-06-02 13:47:21,824:INFO:SubProcess create_model() end ==================================
2025-06-02 13:47:21,825:INFO:Creating metrics dataframe
2025-06-02 13:47:21,847:INFO:Initializing Lasso Regression
2025-06-02 13:47:21,848:INFO:Total runtime is 0.3880996108055115 minutes
2025-06-02 13:47:21,858:INFO:SubProcess create_model() called ==================================
2025-06-02 13:47:21,860:INFO:Initializing create_model()
2025-06-02 13:47:21,860:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:47:21,860:INFO:Checking exceptions
2025-06-02 13:47:21,860:INFO:Importing libraries
2025-06-02 13:47:21,861:INFO:Copying training dataset
2025-06-02 13:47:21,999:INFO:Defining folds
2025-06-02 13:47:22,000:INFO:Declaring metric variables
2025-06-02 13:47:22,012:INFO:Importing untrained model
2025-06-02 13:47:22,026:INFO:Lasso Regression Imported successfully
2025-06-02 13:47:22,048:INFO:Starting cross validation
2025-06-02 13:47:22,053:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:47:32,375:INFO:Calculating mean and std
2025-06-02 13:47:32,379:INFO:Creating metrics dataframe
2025-06-02 13:47:32,390:INFO:Uploading results into container
2025-06-02 13:47:32,391:INFO:Uploading model into container now
2025-06-02 13:47:32,393:INFO:_master_model_container: 2
2025-06-02 13:47:32,394:INFO:_display_container: 2
2025-06-02 13:47:32,397:INFO:Lasso(random_state=123)
2025-06-02 13:47:32,397:INFO:create_model() successfully completed......................................
2025-06-02 13:47:33,513:INFO:SubProcess create_model() end ==================================
2025-06-02 13:47:33,513:INFO:Creating metrics dataframe
2025-06-02 13:47:33,534:INFO:Initializing Ridge Regression
2025-06-02 13:47:33,534:INFO:Total runtime is 0.5828704396883646 minutes
2025-06-02 13:47:33,548:INFO:SubProcess create_model() called ==================================
2025-06-02 13:47:33,549:INFO:Initializing create_model()
2025-06-02 13:47:33,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:47:33,549:INFO:Checking exceptions
2025-06-02 13:47:33,550:INFO:Importing libraries
2025-06-02 13:47:33,550:INFO:Copying training dataset
2025-06-02 13:47:33,633:INFO:Defining folds
2025-06-02 13:47:33,633:INFO:Declaring metric variables
2025-06-02 13:47:33,646:INFO:Importing untrained model
2025-06-02 13:47:33,659:INFO:Ridge Regression Imported successfully
2025-06-02 13:47:33,684:INFO:Starting cross validation
2025-06-02 13:47:33,689:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:47:34,413:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.75561e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 13:47:34,442:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31073e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 13:47:34,455:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.24347e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 13:47:34,508:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.08754e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 13:47:34,588:INFO:Calculating mean and std
2025-06-02 13:47:34,591:INFO:Creating metrics dataframe
2025-06-02 13:47:34,596:INFO:Uploading results into container
2025-06-02 13:47:34,598:INFO:Uploading model into container now
2025-06-02 13:47:34,598:INFO:_master_model_container: 3
2025-06-02 13:47:34,599:INFO:_display_container: 2
2025-06-02 13:47:34,600:INFO:Ridge(random_state=123)
2025-06-02 13:47:34,601:INFO:create_model() successfully completed......................................
2025-06-02 13:47:35,701:INFO:SubProcess create_model() end ==================================
2025-06-02 13:47:35,701:INFO:Creating metrics dataframe
2025-06-02 13:47:35,715:INFO:Initializing Elastic Net
2025-06-02 13:47:35,715:INFO:Total runtime is 0.6192163189252217 minutes
2025-06-02 13:47:35,725:INFO:SubProcess create_model() called ==================================
2025-06-02 13:47:35,726:INFO:Initializing create_model()
2025-06-02 13:47:35,726:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:47:35,727:INFO:Checking exceptions
2025-06-02 13:47:35,727:INFO:Importing libraries
2025-06-02 13:47:35,728:INFO:Copying training dataset
2025-06-02 13:47:35,803:INFO:Defining folds
2025-06-02 13:47:35,803:INFO:Declaring metric variables
2025-06-02 13:47:35,815:INFO:Importing untrained model
2025-06-02 13:47:35,828:INFO:Elastic Net Imported successfully
2025-06-02 13:47:35,852:INFO:Starting cross validation
2025-06-02 13:47:35,856:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:47:36,634:INFO:Calculating mean and std
2025-06-02 13:47:36,637:INFO:Creating metrics dataframe
2025-06-02 13:47:36,643:INFO:Uploading results into container
2025-06-02 13:47:36,644:INFO:Uploading model into container now
2025-06-02 13:47:36,645:INFO:_master_model_container: 4
2025-06-02 13:47:36,645:INFO:_display_container: 2
2025-06-02 13:47:36,645:INFO:ElasticNet(random_state=123)
2025-06-02 13:47:36,646:INFO:create_model() successfully completed......................................
2025-06-02 13:47:37,777:INFO:SubProcess create_model() end ==================================
2025-06-02 13:47:37,777:INFO:Creating metrics dataframe
2025-06-02 13:47:37,794:INFO:Initializing Least Angle Regression
2025-06-02 13:47:37,794:INFO:Total runtime is 0.6538723270098368 minutes
2025-06-02 13:47:37,805:INFO:SubProcess create_model() called ==================================
2025-06-02 13:47:37,805:INFO:Initializing create_model()
2025-06-02 13:47:37,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:47:37,806:INFO:Checking exceptions
2025-06-02 13:47:37,807:INFO:Importing libraries
2025-06-02 13:47:37,807:INFO:Copying training dataset
2025-06-02 13:47:37,877:INFO:Defining folds
2025-06-02 13:47:37,878:INFO:Declaring metric variables
2025-06-02 13:47:37,890:INFO:Importing untrained model
2025-06-02 13:47:37,904:INFO:Least Angle Regression Imported successfully
2025-06-02 13:47:37,929:INFO:Starting cross validation
2025-06-02 13:47:37,933:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:47:38,831:INFO:Calculating mean and std
2025-06-02 13:47:38,833:INFO:Creating metrics dataframe
2025-06-02 13:47:38,839:INFO:Uploading results into container
2025-06-02 13:47:38,840:INFO:Uploading model into container now
2025-06-02 13:47:38,841:INFO:_master_model_container: 5
2025-06-02 13:47:38,841:INFO:_display_container: 2
2025-06-02 13:47:38,843:INFO:Lars(random_state=123)
2025-06-02 13:47:38,844:INFO:create_model() successfully completed......................................
2025-06-02 13:47:39,917:INFO:SubProcess create_model() end ==================================
2025-06-02 13:47:39,917:INFO:Creating metrics dataframe
2025-06-02 13:47:39,933:INFO:Initializing Lasso Least Angle Regression
2025-06-02 13:47:39,933:INFO:Total runtime is 0.6895224889119466 minutes
2025-06-02 13:47:39,945:INFO:SubProcess create_model() called ==================================
2025-06-02 13:47:39,946:INFO:Initializing create_model()
2025-06-02 13:47:39,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:47:39,946:INFO:Checking exceptions
2025-06-02 13:47:39,947:INFO:Importing libraries
2025-06-02 13:47:39,947:INFO:Copying training dataset
2025-06-02 13:47:40,013:INFO:Defining folds
2025-06-02 13:47:40,013:INFO:Declaring metric variables
2025-06-02 13:47:40,028:INFO:Importing untrained model
2025-06-02 13:47:40,039:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 13:47:40,062:INFO:Starting cross validation
2025-06-02 13:47:40,066:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:47:41,137:INFO:Calculating mean and std
2025-06-02 13:47:41,139:INFO:Creating metrics dataframe
2025-06-02 13:47:41,143:INFO:Uploading results into container
2025-06-02 13:47:41,144:INFO:Uploading model into container now
2025-06-02 13:47:41,145:INFO:_master_model_container: 6
2025-06-02 13:47:41,145:INFO:_display_container: 2
2025-06-02 13:47:41,145:INFO:LassoLars(random_state=123)
2025-06-02 13:47:41,146:INFO:create_model() successfully completed......................................
2025-06-02 13:47:42,280:INFO:SubProcess create_model() end ==================================
2025-06-02 13:47:42,281:INFO:Creating metrics dataframe
2025-06-02 13:47:42,298:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 13:47:42,299:INFO:Total runtime is 0.7289414485295613 minutes
2025-06-02 13:47:42,309:INFO:SubProcess create_model() called ==================================
2025-06-02 13:47:42,310:INFO:Initializing create_model()
2025-06-02 13:47:42,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:47:42,310:INFO:Checking exceptions
2025-06-02 13:47:42,311:INFO:Importing libraries
2025-06-02 13:47:42,311:INFO:Copying training dataset
2025-06-02 13:47:42,385:INFO:Defining folds
2025-06-02 13:47:42,385:INFO:Declaring metric variables
2025-06-02 13:47:42,398:INFO:Importing untrained model
2025-06-02 13:47:42,409:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 13:47:42,431:INFO:Starting cross validation
2025-06-02 13:47:42,435:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:47:43,271:INFO:Calculating mean and std
2025-06-02 13:47:43,272:INFO:Creating metrics dataframe
2025-06-02 13:47:43,276:INFO:Uploading results into container
2025-06-02 13:47:43,277:INFO:Uploading model into container now
2025-06-02 13:47:43,278:INFO:_master_model_container: 7
2025-06-02 13:47:43,279:INFO:_display_container: 2
2025-06-02 13:47:43,279:INFO:OrthogonalMatchingPursuit()
2025-06-02 13:47:43,280:INFO:create_model() successfully completed......................................
2025-06-02 13:47:44,347:INFO:SubProcess create_model() end ==================================
2025-06-02 13:47:44,347:INFO:Creating metrics dataframe
2025-06-02 13:47:44,363:INFO:Initializing Bayesian Ridge
2025-06-02 13:47:44,363:INFO:Total runtime is 0.7633485515912374 minutes
2025-06-02 13:47:44,371:INFO:SubProcess create_model() called ==================================
2025-06-02 13:47:44,372:INFO:Initializing create_model()
2025-06-02 13:47:44,372:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:47:44,373:INFO:Checking exceptions
2025-06-02 13:47:44,373:INFO:Importing libraries
2025-06-02 13:47:44,374:INFO:Copying training dataset
2025-06-02 13:47:44,447:INFO:Defining folds
2025-06-02 13:47:44,448:INFO:Declaring metric variables
2025-06-02 13:47:44,461:INFO:Importing untrained model
2025-06-02 13:47:44,472:INFO:Bayesian Ridge Imported successfully
2025-06-02 13:47:44,497:INFO:Starting cross validation
2025-06-02 13:47:44,501:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:47:45,285:INFO:Calculating mean and std
2025-06-02 13:47:45,288:INFO:Creating metrics dataframe
2025-06-02 13:47:45,292:INFO:Uploading results into container
2025-06-02 13:47:45,293:INFO:Uploading model into container now
2025-06-02 13:47:45,294:INFO:_master_model_container: 8
2025-06-02 13:47:45,294:INFO:_display_container: 2
2025-06-02 13:47:45,295:INFO:BayesianRidge()
2025-06-02 13:47:45,296:INFO:create_model() successfully completed......................................
2025-06-02 13:47:46,407:INFO:SubProcess create_model() end ==================================
2025-06-02 13:47:46,407:INFO:Creating metrics dataframe
2025-06-02 13:47:46,424:INFO:Initializing Passive Aggressive Regressor
2025-06-02 13:47:46,424:INFO:Total runtime is 0.7977009177207947 minutes
2025-06-02 13:47:46,433:INFO:SubProcess create_model() called ==================================
2025-06-02 13:47:46,433:INFO:Initializing create_model()
2025-06-02 13:47:46,434:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:47:46,434:INFO:Checking exceptions
2025-06-02 13:47:46,434:INFO:Importing libraries
2025-06-02 13:47:46,435:INFO:Copying training dataset
2025-06-02 13:47:46,506:INFO:Defining folds
2025-06-02 13:47:46,507:INFO:Declaring metric variables
2025-06-02 13:47:46,547:INFO:Importing untrained model
2025-06-02 13:47:46,565:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 13:47:46,617:INFO:Starting cross validation
2025-06-02 13:47:46,622:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:47:47,408:INFO:Calculating mean and std
2025-06-02 13:47:47,411:INFO:Creating metrics dataframe
2025-06-02 13:47:47,414:INFO:Uploading results into container
2025-06-02 13:47:47,415:INFO:Uploading model into container now
2025-06-02 13:47:47,417:INFO:_master_model_container: 9
2025-06-02 13:47:47,417:INFO:_display_container: 2
2025-06-02 13:47:47,418:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 13:47:47,418:INFO:create_model() successfully completed......................................
2025-06-02 13:47:48,513:INFO:SubProcess create_model() end ==================================
2025-06-02 13:47:48,513:INFO:Creating metrics dataframe
2025-06-02 13:47:48,532:INFO:Initializing Huber Regressor
2025-06-02 13:47:48,532:INFO:Total runtime is 0.832836886246999 minutes
2025-06-02 13:47:48,542:INFO:SubProcess create_model() called ==================================
2025-06-02 13:47:48,542:INFO:Initializing create_model()
2025-06-02 13:47:48,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:47:48,543:INFO:Checking exceptions
2025-06-02 13:47:48,543:INFO:Importing libraries
2025-06-02 13:47:48,543:INFO:Copying training dataset
2025-06-02 13:47:48,607:INFO:Defining folds
2025-06-02 13:47:48,608:INFO:Declaring metric variables
2025-06-02 13:47:48,621:INFO:Importing untrained model
2025-06-02 13:47:48,633:INFO:Huber Regressor Imported successfully
2025-06-02 13:47:48,660:INFO:Starting cross validation
2025-06-02 13:47:48,664:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:47:50,442:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:47:50,462:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:47:50,482:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:47:50,552:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:47:50,584:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:47:50,644:INFO:Calculating mean and std
2025-06-02 13:47:50,647:INFO:Creating metrics dataframe
2025-06-02 13:47:50,651:INFO:Uploading results into container
2025-06-02 13:47:50,652:INFO:Uploading model into container now
2025-06-02 13:47:50,654:INFO:_master_model_container: 10
2025-06-02 13:47:50,655:INFO:_display_container: 2
2025-06-02 13:47:50,655:INFO:HuberRegressor()
2025-06-02 13:47:50,655:INFO:create_model() successfully completed......................................
2025-06-02 13:47:51,734:INFO:SubProcess create_model() end ==================================
2025-06-02 13:47:51,735:INFO:Creating metrics dataframe
2025-06-02 13:47:51,755:INFO:Initializing K Neighbors Regressor
2025-06-02 13:47:51,755:INFO:Total runtime is 0.8865564465522765 minutes
2025-06-02 13:47:51,763:INFO:SubProcess create_model() called ==================================
2025-06-02 13:47:51,764:INFO:Initializing create_model()
2025-06-02 13:47:51,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:47:51,765:INFO:Checking exceptions
2025-06-02 13:47:51,765:INFO:Importing libraries
2025-06-02 13:47:51,765:INFO:Copying training dataset
2025-06-02 13:47:51,835:INFO:Defining folds
2025-06-02 13:47:51,836:INFO:Declaring metric variables
2025-06-02 13:47:51,848:INFO:Importing untrained model
2025-06-02 13:47:51,864:INFO:K Neighbors Regressor Imported successfully
2025-06-02 13:47:51,886:INFO:Starting cross validation
2025-06-02 13:47:51,890:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:47:52,705:INFO:Calculating mean and std
2025-06-02 13:47:52,707:INFO:Creating metrics dataframe
2025-06-02 13:47:52,711:INFO:Uploading results into container
2025-06-02 13:47:52,712:INFO:Uploading model into container now
2025-06-02 13:47:52,712:INFO:_master_model_container: 11
2025-06-02 13:47:52,712:INFO:_display_container: 2
2025-06-02 13:47:52,713:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 13:47:52,713:INFO:create_model() successfully completed......................................
2025-06-02 13:47:53,846:INFO:SubProcess create_model() end ==================================
2025-06-02 13:47:53,847:INFO:Creating metrics dataframe
2025-06-02 13:47:53,870:INFO:Initializing Decision Tree Regressor
2025-06-02 13:47:53,870:INFO:Total runtime is 0.9217932780583699 minutes
2025-06-02 13:47:53,883:INFO:SubProcess create_model() called ==================================
2025-06-02 13:47:53,883:INFO:Initializing create_model()
2025-06-02 13:47:53,884:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:47:53,884:INFO:Checking exceptions
2025-06-02 13:47:53,885:INFO:Importing libraries
2025-06-02 13:47:53,885:INFO:Copying training dataset
2025-06-02 13:47:54,027:INFO:Defining folds
2025-06-02 13:47:54,027:INFO:Declaring metric variables
2025-06-02 13:47:54,046:INFO:Importing untrained model
2025-06-02 13:47:54,063:INFO:Decision Tree Regressor Imported successfully
2025-06-02 13:47:54,103:INFO:Starting cross validation
2025-06-02 13:47:54,107:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:47:55,155:INFO:Calculating mean and std
2025-06-02 13:47:55,157:INFO:Creating metrics dataframe
2025-06-02 13:47:55,160:INFO:Uploading results into container
2025-06-02 13:47:55,161:INFO:Uploading model into container now
2025-06-02 13:47:55,162:INFO:_master_model_container: 12
2025-06-02 13:47:55,162:INFO:_display_container: 2
2025-06-02 13:47:55,163:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 13:47:55,163:INFO:create_model() successfully completed......................................
2025-06-02 13:47:56,328:INFO:SubProcess create_model() end ==================================
2025-06-02 13:47:56,328:INFO:Creating metrics dataframe
2025-06-02 13:47:56,349:INFO:Initializing Random Forest Regressor
2025-06-02 13:47:56,349:INFO:Total runtime is 0.9631111820538838 minutes
2025-06-02 13:47:56,358:INFO:SubProcess create_model() called ==================================
2025-06-02 13:47:56,359:INFO:Initializing create_model()
2025-06-02 13:47:56,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:47:56,359:INFO:Checking exceptions
2025-06-02 13:47:56,360:INFO:Importing libraries
2025-06-02 13:47:56,360:INFO:Copying training dataset
2025-06-02 13:47:56,425:INFO:Defining folds
2025-06-02 13:47:56,426:INFO:Declaring metric variables
2025-06-02 13:47:56,439:INFO:Importing untrained model
2025-06-02 13:47:56,451:INFO:Random Forest Regressor Imported successfully
2025-06-02 13:47:56,474:INFO:Starting cross validation
2025-06-02 13:47:56,479:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:48:06,139:INFO:Calculating mean and std
2025-06-02 13:48:06,142:INFO:Creating metrics dataframe
2025-06-02 13:48:06,147:INFO:Uploading results into container
2025-06-02 13:48:06,148:INFO:Uploading model into container now
2025-06-02 13:48:06,149:INFO:_master_model_container: 13
2025-06-02 13:48:06,149:INFO:_display_container: 2
2025-06-02 13:48:06,150:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 13:48:06,150:INFO:create_model() successfully completed......................................
2025-06-02 13:48:07,441:INFO:SubProcess create_model() end ==================================
2025-06-02 13:48:07,441:INFO:Creating metrics dataframe
2025-06-02 13:48:07,463:INFO:Initializing Extra Trees Regressor
2025-06-02 13:48:07,465:INFO:Total runtime is 1.1483755032221477 minutes
2025-06-02 13:48:07,476:INFO:SubProcess create_model() called ==================================
2025-06-02 13:48:07,477:INFO:Initializing create_model()
2025-06-02 13:48:07,477:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:48:07,477:INFO:Checking exceptions
2025-06-02 13:48:07,477:INFO:Importing libraries
2025-06-02 13:48:07,478:INFO:Copying training dataset
2025-06-02 13:48:07,553:INFO:Defining folds
2025-06-02 13:48:07,553:INFO:Declaring metric variables
2025-06-02 13:48:07,565:INFO:Importing untrained model
2025-06-02 13:48:07,577:INFO:Extra Trees Regressor Imported successfully
2025-06-02 13:48:07,599:INFO:Starting cross validation
2025-06-02 13:48:07,604:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:48:13,550:INFO:Calculating mean and std
2025-06-02 13:48:13,554:INFO:Creating metrics dataframe
2025-06-02 13:48:13,558:INFO:Uploading results into container
2025-06-02 13:48:13,559:INFO:Uploading model into container now
2025-06-02 13:48:13,560:INFO:_master_model_container: 14
2025-06-02 13:48:13,560:INFO:_display_container: 2
2025-06-02 13:48:13,561:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 13:48:13,561:INFO:create_model() successfully completed......................................
2025-06-02 13:48:14,719:INFO:SubProcess create_model() end ==================================
2025-06-02 13:48:14,720:INFO:Creating metrics dataframe
2025-06-02 13:48:14,739:INFO:Initializing AdaBoost Regressor
2025-06-02 13:48:14,740:INFO:Total runtime is 1.2696325063705445 minutes
2025-06-02 13:48:14,748:INFO:SubProcess create_model() called ==================================
2025-06-02 13:48:14,748:INFO:Initializing create_model()
2025-06-02 13:48:14,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:48:14,749:INFO:Checking exceptions
2025-06-02 13:48:14,749:INFO:Importing libraries
2025-06-02 13:48:14,749:INFO:Copying training dataset
2025-06-02 13:48:14,822:INFO:Defining folds
2025-06-02 13:48:14,822:INFO:Declaring metric variables
2025-06-02 13:48:14,836:INFO:Importing untrained model
2025-06-02 13:48:14,847:INFO:AdaBoost Regressor Imported successfully
2025-06-02 13:48:14,870:INFO:Starting cross validation
2025-06-02 13:48:14,874:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:48:16,829:INFO:Calculating mean and std
2025-06-02 13:48:16,832:INFO:Creating metrics dataframe
2025-06-02 13:48:16,837:INFO:Uploading results into container
2025-06-02 13:48:16,838:INFO:Uploading model into container now
2025-06-02 13:48:16,839:INFO:_master_model_container: 15
2025-06-02 13:48:16,839:INFO:_display_container: 2
2025-06-02 13:48:16,840:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 13:48:16,841:INFO:create_model() successfully completed......................................
2025-06-02 13:48:17,966:INFO:SubProcess create_model() end ==================================
2025-06-02 13:48:17,966:INFO:Creating metrics dataframe
2025-06-02 13:48:17,995:INFO:Initializing Gradient Boosting Regressor
2025-06-02 13:48:17,995:INFO:Total runtime is 1.3238866806030274 minutes
2025-06-02 13:48:18,006:INFO:SubProcess create_model() called ==================================
2025-06-02 13:48:18,007:INFO:Initializing create_model()
2025-06-02 13:48:18,007:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:48:18,007:INFO:Checking exceptions
2025-06-02 13:48:18,008:INFO:Importing libraries
2025-06-02 13:48:18,008:INFO:Copying training dataset
2025-06-02 13:48:18,073:INFO:Defining folds
2025-06-02 13:48:18,074:INFO:Declaring metric variables
2025-06-02 13:48:18,088:INFO:Importing untrained model
2025-06-02 13:48:18,100:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 13:48:18,125:INFO:Starting cross validation
2025-06-02 13:48:18,130:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:48:21,704:INFO:Calculating mean and std
2025-06-02 13:48:21,706:INFO:Creating metrics dataframe
2025-06-02 13:48:21,710:INFO:Uploading results into container
2025-06-02 13:48:21,711:INFO:Uploading model into container now
2025-06-02 13:48:21,711:INFO:_master_model_container: 16
2025-06-02 13:48:21,712:INFO:_display_container: 2
2025-06-02 13:48:21,712:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 13:48:21,712:INFO:create_model() successfully completed......................................
2025-06-02 13:48:22,851:INFO:SubProcess create_model() end ==================================
2025-06-02 13:48:22,851:INFO:Creating metrics dataframe
2025-06-02 13:48:22,872:INFO:Initializing Extreme Gradient Boosting
2025-06-02 13:48:22,872:INFO:Total runtime is 1.4051617900530498 minutes
2025-06-02 13:48:22,881:INFO:SubProcess create_model() called ==================================
2025-06-02 13:48:22,881:INFO:Initializing create_model()
2025-06-02 13:48:22,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:48:22,882:INFO:Checking exceptions
2025-06-02 13:48:22,882:INFO:Importing libraries
2025-06-02 13:48:22,882:INFO:Copying training dataset
2025-06-02 13:48:22,959:INFO:Defining folds
2025-06-02 13:48:22,960:INFO:Declaring metric variables
2025-06-02 13:48:22,973:INFO:Importing untrained model
2025-06-02 13:48:22,988:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 13:48:23,011:INFO:Starting cross validation
2025-06-02 13:48:23,014:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:48:25,216:INFO:Calculating mean and std
2025-06-02 13:48:25,218:INFO:Creating metrics dataframe
2025-06-02 13:48:25,223:INFO:Uploading results into container
2025-06-02 13:48:25,223:INFO:Uploading model into container now
2025-06-02 13:48:25,225:INFO:_master_model_container: 17
2025-06-02 13:48:25,226:INFO:_display_container: 2
2025-06-02 13:48:25,230:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 13:48:25,230:INFO:create_model() successfully completed......................................
2025-06-02 13:48:26,394:INFO:SubProcess create_model() end ==================================
2025-06-02 13:48:26,396:INFO:Creating metrics dataframe
2025-06-02 13:48:26,425:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 13:48:26,426:INFO:Total runtime is 1.4643925547599792 minutes
2025-06-02 13:48:26,437:INFO:SubProcess create_model() called ==================================
2025-06-02 13:48:26,438:INFO:Initializing create_model()
2025-06-02 13:48:26,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:48:26,438:INFO:Checking exceptions
2025-06-02 13:48:26,439:INFO:Importing libraries
2025-06-02 13:48:26,439:INFO:Copying training dataset
2025-06-02 13:48:26,509:INFO:Defining folds
2025-06-02 13:48:26,509:INFO:Declaring metric variables
2025-06-02 13:48:26,522:INFO:Importing untrained model
2025-06-02 13:48:26,534:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 13:48:26,563:INFO:Starting cross validation
2025-06-02 13:48:26,567:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:48:28,427:INFO:Calculating mean and std
2025-06-02 13:48:28,430:INFO:Creating metrics dataframe
2025-06-02 13:48:28,434:INFO:Uploading results into container
2025-06-02 13:48:28,436:INFO:Uploading model into container now
2025-06-02 13:48:28,437:INFO:_master_model_container: 18
2025-06-02 13:48:28,437:INFO:_display_container: 2
2025-06-02 13:48:28,439:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 13:48:28,439:INFO:create_model() successfully completed......................................
2025-06-02 13:48:29,635:INFO:SubProcess create_model() end ==================================
2025-06-02 13:48:29,635:INFO:Creating metrics dataframe
2025-06-02 13:48:29,658:INFO:Initializing CatBoost Regressor
2025-06-02 13:48:29,658:INFO:Total runtime is 1.518256954352061 minutes
2025-06-02 13:48:29,668:INFO:SubProcess create_model() called ==================================
2025-06-02 13:48:29,669:INFO:Initializing create_model()
2025-06-02 13:48:29,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:48:29,670:INFO:Checking exceptions
2025-06-02 13:48:29,670:INFO:Importing libraries
2025-06-02 13:48:29,671:INFO:Copying training dataset
2025-06-02 13:48:29,749:INFO:Defining folds
2025-06-02 13:48:29,750:INFO:Declaring metric variables
2025-06-02 13:48:29,763:INFO:Importing untrained model
2025-06-02 13:48:29,787:INFO:CatBoost Regressor Imported successfully
2025-06-02 13:48:29,811:INFO:Starting cross validation
2025-06-02 13:48:29,815:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:48:54,907:INFO:Calculating mean and std
2025-06-02 13:48:54,910:INFO:Creating metrics dataframe
2025-06-02 13:48:54,920:INFO:Uploading results into container
2025-06-02 13:48:54,922:INFO:Uploading model into container now
2025-06-02 13:48:54,923:INFO:_master_model_container: 19
2025-06-02 13:48:54,923:INFO:_display_container: 2
2025-06-02 13:48:54,923:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6BB848F40>
2025-06-02 13:48:54,924:INFO:create_model() successfully completed......................................
2025-06-02 13:48:56,371:INFO:SubProcess create_model() end ==================================
2025-06-02 13:48:56,371:INFO:Creating metrics dataframe
2025-06-02 13:48:56,396:INFO:Initializing Dummy Regressor
2025-06-02 13:48:56,396:INFO:Total runtime is 1.9639031569163006 minutes
2025-06-02 13:48:56,407:INFO:SubProcess create_model() called ==================================
2025-06-02 13:48:56,408:INFO:Initializing create_model()
2025-06-02 13:48:56,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBBE5F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:48:56,409:INFO:Checking exceptions
2025-06-02 13:48:56,409:INFO:Importing libraries
2025-06-02 13:48:56,409:INFO:Copying training dataset
2025-06-02 13:48:56,484:INFO:Defining folds
2025-06-02 13:48:56,485:INFO:Declaring metric variables
2025-06-02 13:48:56,500:INFO:Importing untrained model
2025-06-02 13:48:56,512:INFO:Dummy Regressor Imported successfully
2025-06-02 13:48:56,537:INFO:Starting cross validation
2025-06-02 13:48:56,542:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:48:57,537:INFO:Calculating mean and std
2025-06-02 13:48:57,540:INFO:Creating metrics dataframe
2025-06-02 13:48:57,544:INFO:Uploading results into container
2025-06-02 13:48:57,546:INFO:Uploading model into container now
2025-06-02 13:48:57,547:INFO:_master_model_container: 20
2025-06-02 13:48:57,547:INFO:_display_container: 2
2025-06-02 13:48:57,548:INFO:DummyRegressor()
2025-06-02 13:48:57,548:INFO:create_model() successfully completed......................................
2025-06-02 13:48:58,731:INFO:SubProcess create_model() end ==================================
2025-06-02 13:48:58,731:INFO:Creating metrics dataframe
2025-06-02 13:48:58,783:INFO:Initializing create_model()
2025-06-02 13:48:58,784:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:48:58,784:INFO:Checking exceptions
2025-06-02 13:48:58,792:INFO:Importing libraries
2025-06-02 13:48:58,793:INFO:Copying training dataset
2025-06-02 13:48:58,870:INFO:Defining folds
2025-06-02 13:48:58,870:INFO:Declaring metric variables
2025-06-02 13:48:58,870:INFO:Importing untrained model
2025-06-02 13:48:58,871:INFO:Declaring custom model
2025-06-02 13:48:58,872:INFO:Decision Tree Regressor Imported successfully
2025-06-02 13:48:58,875:INFO:Cross validation set to False
2025-06-02 13:48:58,875:INFO:Fitting Model
2025-06-02 13:48:59,426:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 13:48:59,426:INFO:create_model() successfully completed......................................
2025-06-02 13:49:00,727:INFO:_master_model_container: 20
2025-06-02 13:49:00,727:INFO:_display_container: 2
2025-06-02 13:49:00,728:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 13:49:00,729:INFO:compare_models() successfully completed......................................
2025-06-02 13:49:00,871:INFO:Initializing tune_model()
2025-06-02 13:49:00,872:INFO:tune_model(estimator=DecisionTreeRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAPE, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>)
2025-06-02 13:49:00,872:INFO:Checking exceptions
2025-06-02 13:49:00,873:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 13:49:00,965:INFO:Copying training dataset
2025-06-02 13:49:01,115:INFO:Checking base model
2025-06-02 13:49:01,115:INFO:Base model : Decision Tree Regressor
2025-06-02 13:49:01,139:INFO:Declaring metric variables
2025-06-02 13:49:01,170:INFO:Defining Hyperparameters
2025-06-02 13:49:02,571:INFO:Tuning with n_jobs=-1
2025-06-02 13:49:02,584:INFO:Initializing skopt.BayesSearchCV
2025-06-02 13:49:16,622:INFO:best_params: OrderedDict([('actual_estimator__criterion', 'absolute_error'), ('actual_estimator__max_depth', 6), ('actual_estimator__max_features', 0.6501266156948922), ('actual_estimator__min_impurity_decrease', 0.00035738874823356006), ('actual_estimator__min_samples_leaf', 4), ('actual_estimator__min_samples_split', 5)])
2025-06-02 13:49:16,623:INFO:Hyperparameter search completed
2025-06-02 13:49:16,623:INFO:SubProcess create_model() called ==================================
2025-06-02 13:49:16,624:INFO:Initializing create_model()
2025-06-02 13:49:16,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBD7DB70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'criterion': 'absolute_error', 'max_depth': 6, 'max_features': 0.6501266156948922, 'min_impurity_decrease': 0.00035738874823356006, 'min_samples_leaf': 4, 'min_samples_split': 5})
2025-06-02 13:49:16,625:INFO:Checking exceptions
2025-06-02 13:49:16,625:INFO:Importing libraries
2025-06-02 13:49:16,625:INFO:Copying training dataset
2025-06-02 13:49:16,682:INFO:Defining folds
2025-06-02 13:49:16,682:INFO:Declaring metric variables
2025-06-02 13:49:16,690:INFO:Importing untrained model
2025-06-02 13:49:16,690:INFO:Declaring custom model
2025-06-02 13:49:16,701:INFO:Decision Tree Regressor Imported successfully
2025-06-02 13:49:16,723:INFO:Starting cross validation
2025-06-02 13:49:16,726:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:49:19,317:INFO:Calculating mean and std
2025-06-02 13:49:19,319:INFO:Creating metrics dataframe
2025-06-02 13:49:19,333:INFO:Finalizing model
2025-06-02 13:49:21,565:INFO:Uploading results into container
2025-06-02 13:49:21,567:INFO:Uploading model into container now
2025-06-02 13:49:21,568:INFO:_master_model_container: 21
2025-06-02 13:49:21,568:INFO:_display_container: 3
2025-06-02 13:49:21,570:INFO:DecisionTreeRegressor(criterion='absolute_error', max_depth=6,
                      max_features=0.6501266156948922,
                      min_impurity_decrease=0.00035738874823356006,
                      min_samples_leaf=4, min_samples_split=5,
                      random_state=123)
2025-06-02 13:49:21,570:INFO:create_model() successfully completed......................................
2025-06-02 13:49:22,704:INFO:SubProcess create_model() end ==================================
2025-06-02 13:49:22,704:INFO:choose_better activated
2025-06-02 13:49:22,715:INFO:SubProcess create_model() called ==================================
2025-06-02 13:49:22,716:INFO:Initializing create_model()
2025-06-02 13:49:22,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:49:22,716:INFO:Checking exceptions
2025-06-02 13:49:22,719:INFO:Importing libraries
2025-06-02 13:49:22,719:INFO:Copying training dataset
2025-06-02 13:49:22,783:INFO:Defining folds
2025-06-02 13:49:22,783:INFO:Declaring metric variables
2025-06-02 13:49:22,784:INFO:Importing untrained model
2025-06-02 13:49:22,784:INFO:Declaring custom model
2025-06-02 13:49:22,785:INFO:Decision Tree Regressor Imported successfully
2025-06-02 13:49:22,786:INFO:Starting cross validation
2025-06-02 13:49:22,788:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:49:23,636:INFO:Calculating mean and std
2025-06-02 13:49:23,637:INFO:Creating metrics dataframe
2025-06-02 13:49:23,640:INFO:Finalizing model
2025-06-02 13:49:24,087:INFO:Uploading results into container
2025-06-02 13:49:24,088:INFO:Uploading model into container now
2025-06-02 13:49:24,088:INFO:_master_model_container: 22
2025-06-02 13:49:24,089:INFO:_display_container: 4
2025-06-02 13:49:24,089:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 13:49:24,089:INFO:create_model() successfully completed......................................
2025-06-02 13:49:25,185:INFO:SubProcess create_model() end ==================================
2025-06-02 13:49:25,186:INFO:DecisionTreeRegressor(random_state=123) result for MAPE is 50923476.4821
2025-06-02 13:49:25,187:INFO:DecisionTreeRegressor(criterion='absolute_error', max_depth=6,
                      max_features=0.6501266156948922,
                      min_impurity_decrease=0.00035738874823356006,
                      min_samples_leaf=4, min_samples_split=5,
                      random_state=123) result for MAPE is 1817017492.6908
2025-06-02 13:49:25,188:INFO:DecisionTreeRegressor(random_state=123) is best model
2025-06-02 13:49:25,188:INFO:choose_better completed
2025-06-02 13:49:25,188:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 13:49:25,204:INFO:_master_model_container: 22
2025-06-02 13:49:25,204:INFO:_display_container: 3
2025-06-02 13:49:25,205:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 13:49:25,206:INFO:tune_model() successfully completed......................................
2025-06-02 13:49:26,369:INFO:Initializing finalize_model()
2025-06-02 13:49:26,370:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=DecisionTreeRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 13:49:26,371:INFO:Finalizing DecisionTreeRegressor(random_state=123)
2025-06-02 13:49:26,415:INFO:Initializing create_model()
2025-06-02 13:49:26,415:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BBD7C760>, estimator=DecisionTreeRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:49:26,416:INFO:Checking exceptions
2025-06-02 13:49:26,418:INFO:Importing libraries
2025-06-02 13:49:26,418:INFO:Copying training dataset
2025-06-02 13:49:26,425:INFO:Defining folds
2025-06-02 13:49:26,426:INFO:Declaring metric variables
2025-06-02 13:49:26,426:INFO:Importing untrained model
2025-06-02 13:49:26,426:INFO:Declaring custom model
2025-06-02 13:49:26,427:INFO:Decision Tree Regressor Imported successfully
2025-06-02 13:49:26,430:INFO:Cross validation set to False
2025-06-02 13:49:26,430:INFO:Fitting Model
2025-06-02 13:49:27,024:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', DecisionTreeRegressor(random_state=123))])
2025-06-02 13:49:27,025:INFO:create_model() successfully completed......................................
2025-06-02 13:49:28,106:INFO:_master_model_container: 22
2025-06-02 13:49:28,106:INFO:_display_container: 3
2025-06-02 13:49:28,120:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', DecisionTreeRegressor(random_state=123))])
2025-06-02 13:49:28,120:INFO:finalize_model() successfully completed......................................
2025-06-02 13:49:29,241:INFO:Initializing save_model()
2025-06-02 13:49:29,241:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', DecisionTreeRegressor(random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 13:49:29,243:INFO:Adding model into prep_pipe
2025-06-02 13:49:29,243:WARNING:Only Model saved as it was a pipeline.
2025-06-02 13:49:29,260:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 13:49:29,273:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', DecisionTreeRegressor(random_state=123))])
2025-06-02 13:49:29,273:INFO:save_model() successfully completed......................................
2025-06-02 13:56:06,009:INFO:PyCaret RegressionExperiment
2025-06-02 13:56:06,009:INFO:Logging name: reg-default-name
2025-06-02 13:56:06,009:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 13:56:06,009:INFO:version 3.3.2
2025-06-02 13:56:06,010:INFO:Initializing setup()
2025-06-02 13:56:06,010:INFO:self.USI: bc31
2025-06-02 13:56:06,010:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 13:56:06,011:INFO:Checking environment
2025-06-02 13:56:06,011:INFO:python_version: 3.10.16
2025-06-02 13:56:06,011:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 13:56:06,011:INFO:machine: AMD64
2025-06-02 13:56:06,011:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 13:56:06,017:INFO:Memory: svmem(total=6378008576, available=820842496, percent=87.1, used=5557166080, free=820842496)
2025-06-02 13:56:06,018:INFO:Physical Core: 4
2025-06-02 13:56:06,018:INFO:Logical Core: 8
2025-06-02 13:56:06,018:INFO:Checking libraries
2025-06-02 13:56:06,019:INFO:System:
2025-06-02 13:56:06,019:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 13:56:06,019:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 13:56:06,019:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 13:56:06,019:INFO:PyCaret required dependencies:
2025-06-02 13:56:06,019:INFO:                 pip: 25.1
2025-06-02 13:56:06,020:INFO:          setuptools: 78.1.1
2025-06-02 13:56:06,020:INFO:             pycaret: 3.3.2
2025-06-02 13:56:06,020:INFO:             IPython: 8.37.0
2025-06-02 13:56:06,020:INFO:          ipywidgets: 8.1.7
2025-06-02 13:56:06,020:INFO:                tqdm: 4.67.1
2025-06-02 13:56:06,020:INFO:               numpy: 1.26.4
2025-06-02 13:56:06,020:INFO:              pandas: 2.0.1
2025-06-02 13:56:06,020:INFO:              jinja2: 3.1.6
2025-06-02 13:56:06,020:INFO:               scipy: 1.10.1
2025-06-02 13:56:06,020:INFO:              joblib: 1.3.2
2025-06-02 13:56:06,020:INFO:             sklearn: 1.4.2
2025-06-02 13:56:06,020:INFO:                pyod: 2.0.5
2025-06-02 13:56:06,020:INFO:            imblearn: 0.13.0
2025-06-02 13:56:06,021:INFO:   category_encoders: 2.7.0
2025-06-02 13:56:06,021:INFO:            lightgbm: 4.6.0
2025-06-02 13:56:06,021:INFO:               numba: 0.61.0
2025-06-02 13:56:06,021:INFO:            requests: 2.32.3
2025-06-02 13:56:06,021:INFO:          matplotlib: 3.7.1
2025-06-02 13:56:06,021:INFO:          scikitplot: 0.3.7
2025-06-02 13:56:06,021:INFO:         yellowbrick: 1.5
2025-06-02 13:56:06,021:INFO:              plotly: 6.1.2
2025-06-02 13:56:06,021:INFO:    plotly-resampler: Not installed
2025-06-02 13:56:06,021:INFO:             kaleido: 0.2.1
2025-06-02 13:56:06,021:INFO:           schemdraw: 0.15
2025-06-02 13:56:06,022:INFO:         statsmodels: 0.14.4
2025-06-02 13:56:06,022:INFO:              sktime: 0.26.0
2025-06-02 13:56:06,022:INFO:               tbats: 1.1.3
2025-06-02 13:56:06,022:INFO:            pmdarima: 2.0.4
2025-06-02 13:56:06,022:INFO:              psutil: 7.0.0
2025-06-02 13:56:06,022:INFO:          markupsafe: 2.1.2
2025-06-02 13:56:06,022:INFO:             pickle5: Not installed
2025-06-02 13:56:06,022:INFO:         cloudpickle: 3.1.1
2025-06-02 13:56:06,022:INFO:         deprecation: 2.1.0
2025-06-02 13:56:06,022:INFO:              xxhash: 3.5.0
2025-06-02 13:56:06,022:INFO:           wurlitzer: Not installed
2025-06-02 13:56:06,023:INFO:PyCaret optional dependencies:
2025-06-02 13:56:06,023:INFO:                shap: 0.44.1
2025-06-02 13:56:06,023:INFO:           interpret: 0.6.9
2025-06-02 13:56:06,023:INFO:                umap: 0.5.7
2025-06-02 13:56:06,023:INFO:     ydata_profiling: 4.16.1
2025-06-02 13:56:06,023:INFO:  explainerdashboard: 0.4.8
2025-06-02 13:56:06,023:INFO:             autoviz: Not installed
2025-06-02 13:56:06,023:INFO:           fairlearn: 0.7.0
2025-06-02 13:56:06,023:INFO:          deepchecks: Not installed
2025-06-02 13:56:06,023:INFO:             xgboost: 3.0.2
2025-06-02 13:56:06,024:INFO:            catboost: 1.2.8
2025-06-02 13:56:06,024:INFO:              kmodes: 0.12.2
2025-06-02 13:56:06,024:INFO:             mlxtend: 0.23.4
2025-06-02 13:56:06,024:INFO:       statsforecast: 1.5.0
2025-06-02 13:56:06,024:INFO:        tune_sklearn: Not installed
2025-06-02 13:56:06,024:INFO:                 ray: Not installed
2025-06-02 13:56:06,024:INFO:            hyperopt: 0.2.7
2025-06-02 13:56:06,024:INFO:              optuna: 4.3.0
2025-06-02 13:56:06,024:INFO:               skopt: 0.10.2
2025-06-02 13:56:06,024:INFO:              mlflow: 2.22.0
2025-06-02 13:56:06,024:INFO:              gradio: 5.32.0
2025-06-02 13:56:06,025:INFO:             fastapi: 0.115.12
2025-06-02 13:56:06,025:INFO:             uvicorn: 0.34.3
2025-06-02 13:56:06,025:INFO:              m2cgen: 0.10.0
2025-06-02 13:56:06,025:INFO:           evidently: 0.4.40
2025-06-02 13:56:06,025:INFO:               fugue: 0.8.5
2025-06-02 13:56:06,025:INFO:           streamlit: Not installed
2025-06-02 13:56:06,025:INFO:             prophet: Not installed
2025-06-02 13:56:06,025:INFO:None
2025-06-02 13:56:06,025:INFO:Set up data.
2025-06-02 13:56:06,119:INFO:Set up folding strategy.
2025-06-02 13:56:06,119:INFO:Set up train/test split.
2025-06-02 13:56:06,165:INFO:Set up index.
2025-06-02 13:56:06,166:INFO:Assigning column types.
2025-06-02 13:56:06,219:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 13:56:06,220:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 13:56:06,229:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 13:56:06,236:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:56:06,362:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:56:06,431:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:56:06,432:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:56:06,436:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:56:06,437:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 13:56:06,445:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 13:56:06,452:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:56:06,641:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:56:06,742:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:56:06,743:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:56:06,749:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:56:06,751:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 13:56:06,760:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 13:56:06,767:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:56:06,902:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:56:06,983:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:56:06,984:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:56:06,988:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:56:06,996:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 13:56:07,004:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:56:07,141:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:56:07,212:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:56:07,213:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:56:07,217:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:56:07,218:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 13:56:07,232:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:56:07,359:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:56:07,431:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:56:07,432:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:56:07,436:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:56:07,452:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:56:07,582:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:56:07,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:56:07,654:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:56:07,658:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:56:07,659:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 13:56:07,801:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:56:07,873:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:56:07,874:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:56:07,878:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:56:08,019:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:56:08,091:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:56:08,091:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:56:08,095:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:56:08,096:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 13:56:08,239:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:56:08,310:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:56:08,315:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:56:08,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:56:08,526:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:56:08,530:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:56:08,531:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 13:56:08,760:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:56:08,763:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:56:08,982:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:56:08,986:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:56:08,989:INFO:Preparing preprocessing pipeline...
2025-06-02 13:56:08,989:INFO:Set up simple imputation.
2025-06-02 13:56:08,989:INFO:Set up removing multicollinearity.
2025-06-02 13:56:08,996:INFO:Set up column name cleaning.
2025-06-02 13:56:09,218:INFO:Finished creating preprocessing pipeline.
2025-06-02 13:56:09,231:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 13:56:09,231:INFO:Creating final display dataframe.
2025-06-02 13:56:09,623:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              bc31
2025-06-02 13:56:09,876:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:56:09,880:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:56:10,095:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:56:10,099:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:56:10,101:INFO:setup() successfully completed in 4.1s...............
2025-06-02 13:56:10,106:INFO:Initializing compare_models()
2025-06-02 13:56:10,106:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 13:56:10,107:INFO:Checking exceptions
2025-06-02 13:56:10,129:INFO:Preparing display monitor
2025-06-02 13:56:10,184:INFO:Initializing Linear Regression
2025-06-02 13:56:10,185:INFO:Total runtime is 1.6733010609944662e-05 minutes
2025-06-02 13:56:10,196:INFO:SubProcess create_model() called ==================================
2025-06-02 13:56:10,196:INFO:Initializing create_model()
2025-06-02 13:56:10,197:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:56:10,197:INFO:Checking exceptions
2025-06-02 13:56:10,198:INFO:Importing libraries
2025-06-02 13:56:10,198:INFO:Copying training dataset
2025-06-02 13:56:10,297:INFO:Defining folds
2025-06-02 13:56:10,298:INFO:Declaring metric variables
2025-06-02 13:56:10,340:INFO:Importing untrained model
2025-06-02 13:56:10,356:INFO:Linear Regression Imported successfully
2025-06-02 13:56:10,422:INFO:Starting cross validation
2025-06-02 13:56:10,427:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:56:23,795:INFO:Calculating mean and std
2025-06-02 13:56:23,799:INFO:Creating metrics dataframe
2025-06-02 13:56:23,810:INFO:Uploading results into container
2025-06-02 13:56:23,811:INFO:Uploading model into container now
2025-06-02 13:56:23,813:INFO:_master_model_container: 1
2025-06-02 13:56:23,813:INFO:_display_container: 2
2025-06-02 13:56:23,814:INFO:LinearRegression(n_jobs=-1)
2025-06-02 13:56:23,814:INFO:create_model() successfully completed......................................
2025-06-02 13:56:29,511:INFO:SubProcess create_model() end ==================================
2025-06-02 13:56:29,512:INFO:Creating metrics dataframe
2025-06-02 13:56:29,537:INFO:Initializing Lasso Regression
2025-06-02 13:56:29,537:INFO:Total runtime is 0.3225461681683858 minutes
2025-06-02 13:56:29,547:INFO:SubProcess create_model() called ==================================
2025-06-02 13:56:29,548:INFO:Initializing create_model()
2025-06-02 13:56:29,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:56:29,548:INFO:Checking exceptions
2025-06-02 13:56:29,549:INFO:Importing libraries
2025-06-02 13:56:29,549:INFO:Copying training dataset
2025-06-02 13:56:29,685:INFO:Defining folds
2025-06-02 13:56:29,686:INFO:Declaring metric variables
2025-06-02 13:56:29,704:INFO:Importing untrained model
2025-06-02 13:56:29,723:INFO:Lasso Regression Imported successfully
2025-06-02 13:56:29,754:INFO:Starting cross validation
2025-06-02 13:56:29,759:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:56:40,138:INFO:Calculating mean and std
2025-06-02 13:56:40,143:INFO:Creating metrics dataframe
2025-06-02 13:56:40,153:INFO:Uploading results into container
2025-06-02 13:56:40,155:INFO:Uploading model into container now
2025-06-02 13:56:40,156:INFO:_master_model_container: 2
2025-06-02 13:56:40,157:INFO:_display_container: 2
2025-06-02 13:56:40,160:INFO:Lasso(random_state=123)
2025-06-02 13:56:40,160:INFO:create_model() successfully completed......................................
2025-06-02 13:56:41,309:INFO:SubProcess create_model() end ==================================
2025-06-02 13:56:41,310:INFO:Creating metrics dataframe
2025-06-02 13:56:41,327:INFO:Initializing Ridge Regression
2025-06-02 13:56:41,328:INFO:Total runtime is 0.5190648953119914 minutes
2025-06-02 13:56:41,337:INFO:SubProcess create_model() called ==================================
2025-06-02 13:56:41,338:INFO:Initializing create_model()
2025-06-02 13:56:41,338:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:56:41,338:INFO:Checking exceptions
2025-06-02 13:56:41,339:INFO:Importing libraries
2025-06-02 13:56:41,339:INFO:Copying training dataset
2025-06-02 13:56:41,413:INFO:Defining folds
2025-06-02 13:56:41,414:INFO:Declaring metric variables
2025-06-02 13:56:41,426:INFO:Importing untrained model
2025-06-02 13:56:41,438:INFO:Ridge Regression Imported successfully
2025-06-02 13:56:41,463:INFO:Starting cross validation
2025-06-02 13:56:41,467:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:56:42,171:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.75561e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 13:56:42,190:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.24347e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 13:56:42,206:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31073e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 13:56:42,215:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.08754e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 13:56:42,322:INFO:Calculating mean and std
2025-06-02 13:56:42,324:INFO:Creating metrics dataframe
2025-06-02 13:56:42,329:INFO:Uploading results into container
2025-06-02 13:56:42,330:INFO:Uploading model into container now
2025-06-02 13:56:42,331:INFO:_master_model_container: 3
2025-06-02 13:56:42,331:INFO:_display_container: 2
2025-06-02 13:56:42,332:INFO:Ridge(random_state=123)
2025-06-02 13:56:42,333:INFO:create_model() successfully completed......................................
2025-06-02 13:56:43,430:INFO:SubProcess create_model() end ==================================
2025-06-02 13:56:43,431:INFO:Creating metrics dataframe
2025-06-02 13:56:43,446:INFO:Initializing Elastic Net
2025-06-02 13:56:43,447:INFO:Total runtime is 0.554380452632904 minutes
2025-06-02 13:56:43,456:INFO:SubProcess create_model() called ==================================
2025-06-02 13:56:43,457:INFO:Initializing create_model()
2025-06-02 13:56:43,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:56:43,458:INFO:Checking exceptions
2025-06-02 13:56:43,458:INFO:Importing libraries
2025-06-02 13:56:43,459:INFO:Copying training dataset
2025-06-02 13:56:43,532:INFO:Defining folds
2025-06-02 13:56:43,533:INFO:Declaring metric variables
2025-06-02 13:56:43,547:INFO:Importing untrained model
2025-06-02 13:56:43,559:INFO:Elastic Net Imported successfully
2025-06-02 13:56:43,585:INFO:Starting cross validation
2025-06-02 13:56:43,590:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:56:44,346:INFO:Calculating mean and std
2025-06-02 13:56:44,348:INFO:Creating metrics dataframe
2025-06-02 13:56:44,352:INFO:Uploading results into container
2025-06-02 13:56:44,353:INFO:Uploading model into container now
2025-06-02 13:56:44,354:INFO:_master_model_container: 4
2025-06-02 13:56:44,354:INFO:_display_container: 2
2025-06-02 13:56:44,355:INFO:ElasticNet(random_state=123)
2025-06-02 13:56:44,356:INFO:create_model() successfully completed......................................
2025-06-02 13:56:45,492:INFO:SubProcess create_model() end ==================================
2025-06-02 13:56:45,493:INFO:Creating metrics dataframe
2025-06-02 13:56:45,509:INFO:Initializing Least Angle Regression
2025-06-02 13:56:45,509:INFO:Total runtime is 0.5887535095214843 minutes
2025-06-02 13:56:45,518:INFO:SubProcess create_model() called ==================================
2025-06-02 13:56:45,519:INFO:Initializing create_model()
2025-06-02 13:56:45,519:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:56:45,519:INFO:Checking exceptions
2025-06-02 13:56:45,520:INFO:Importing libraries
2025-06-02 13:56:45,520:INFO:Copying training dataset
2025-06-02 13:56:45,601:INFO:Defining folds
2025-06-02 13:56:45,601:INFO:Declaring metric variables
2025-06-02 13:56:45,613:INFO:Importing untrained model
2025-06-02 13:56:45,624:INFO:Least Angle Regression Imported successfully
2025-06-02 13:56:45,646:INFO:Starting cross validation
2025-06-02 13:56:45,649:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:56:46,473:INFO:Calculating mean and std
2025-06-02 13:56:46,475:INFO:Creating metrics dataframe
2025-06-02 13:56:46,479:INFO:Uploading results into container
2025-06-02 13:56:46,480:INFO:Uploading model into container now
2025-06-02 13:56:46,481:INFO:_master_model_container: 5
2025-06-02 13:56:46,481:INFO:_display_container: 2
2025-06-02 13:56:46,483:INFO:Lars(random_state=123)
2025-06-02 13:56:46,483:INFO:create_model() successfully completed......................................
2025-06-02 13:56:47,563:INFO:SubProcess create_model() end ==================================
2025-06-02 13:56:47,564:INFO:Creating metrics dataframe
2025-06-02 13:56:47,586:INFO:Initializing Lasso Least Angle Regression
2025-06-02 13:56:47,586:INFO:Total runtime is 0.623362135887146 minutes
2025-06-02 13:56:47,595:INFO:SubProcess create_model() called ==================================
2025-06-02 13:56:47,596:INFO:Initializing create_model()
2025-06-02 13:56:47,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:56:47,597:INFO:Checking exceptions
2025-06-02 13:56:47,597:INFO:Importing libraries
2025-06-02 13:56:47,597:INFO:Copying training dataset
2025-06-02 13:56:47,671:INFO:Defining folds
2025-06-02 13:56:47,672:INFO:Declaring metric variables
2025-06-02 13:56:47,686:INFO:Importing untrained model
2025-06-02 13:56:47,699:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 13:56:47,723:INFO:Starting cross validation
2025-06-02 13:56:47,727:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:56:48,675:INFO:Calculating mean and std
2025-06-02 13:56:48,677:INFO:Creating metrics dataframe
2025-06-02 13:56:48,681:INFO:Uploading results into container
2025-06-02 13:56:48,682:INFO:Uploading model into container now
2025-06-02 13:56:48,683:INFO:_master_model_container: 6
2025-06-02 13:56:48,683:INFO:_display_container: 2
2025-06-02 13:56:48,684:INFO:LassoLars(random_state=123)
2025-06-02 13:56:48,685:INFO:create_model() successfully completed......................................
2025-06-02 13:56:49,767:INFO:SubProcess create_model() end ==================================
2025-06-02 13:56:49,767:INFO:Creating metrics dataframe
2025-06-02 13:56:49,784:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 13:56:49,785:INFO:Total runtime is 0.6600126862525939 minutes
2025-06-02 13:56:49,795:INFO:SubProcess create_model() called ==================================
2025-06-02 13:56:49,795:INFO:Initializing create_model()
2025-06-02 13:56:49,796:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:56:49,796:INFO:Checking exceptions
2025-06-02 13:56:49,796:INFO:Importing libraries
2025-06-02 13:56:49,796:INFO:Copying training dataset
2025-06-02 13:56:49,872:INFO:Defining folds
2025-06-02 13:56:49,873:INFO:Declaring metric variables
2025-06-02 13:56:49,887:INFO:Importing untrained model
2025-06-02 13:56:49,897:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 13:56:49,924:INFO:Starting cross validation
2025-06-02 13:56:49,928:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:56:50,705:INFO:Calculating mean and std
2025-06-02 13:56:50,707:INFO:Creating metrics dataframe
2025-06-02 13:56:50,711:INFO:Uploading results into container
2025-06-02 13:56:50,712:INFO:Uploading model into container now
2025-06-02 13:56:50,713:INFO:_master_model_container: 7
2025-06-02 13:56:50,713:INFO:_display_container: 2
2025-06-02 13:56:50,714:INFO:OrthogonalMatchingPursuit()
2025-06-02 13:56:50,714:INFO:create_model() successfully completed......................................
2025-06-02 13:56:51,778:INFO:SubProcess create_model() end ==================================
2025-06-02 13:56:51,778:INFO:Creating metrics dataframe
2025-06-02 13:56:51,796:INFO:Initializing Bayesian Ridge
2025-06-02 13:56:51,797:INFO:Total runtime is 0.6935436129570006 minutes
2025-06-02 13:56:51,806:INFO:SubProcess create_model() called ==================================
2025-06-02 13:56:51,806:INFO:Initializing create_model()
2025-06-02 13:56:51,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:56:51,807:INFO:Checking exceptions
2025-06-02 13:56:51,807:INFO:Importing libraries
2025-06-02 13:56:51,807:INFO:Copying training dataset
2025-06-02 13:56:51,876:INFO:Defining folds
2025-06-02 13:56:51,877:INFO:Declaring metric variables
2025-06-02 13:56:51,889:INFO:Importing untrained model
2025-06-02 13:56:51,900:INFO:Bayesian Ridge Imported successfully
2025-06-02 13:56:51,929:INFO:Starting cross validation
2025-06-02 13:56:51,934:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:56:52,858:INFO:Calculating mean and std
2025-06-02 13:56:52,860:INFO:Creating metrics dataframe
2025-06-02 13:56:52,864:INFO:Uploading results into container
2025-06-02 13:56:52,865:INFO:Uploading model into container now
2025-06-02 13:56:52,866:INFO:_master_model_container: 8
2025-06-02 13:56:52,866:INFO:_display_container: 2
2025-06-02 13:56:52,867:INFO:BayesianRidge()
2025-06-02 13:56:52,867:INFO:create_model() successfully completed......................................
2025-06-02 13:56:53,937:INFO:SubProcess create_model() end ==================================
2025-06-02 13:56:53,938:INFO:Creating metrics dataframe
2025-06-02 13:56:53,955:INFO:Initializing Passive Aggressive Regressor
2025-06-02 13:56:53,955:INFO:Total runtime is 0.729518969853719 minutes
2025-06-02 13:56:53,963:INFO:SubProcess create_model() called ==================================
2025-06-02 13:56:53,964:INFO:Initializing create_model()
2025-06-02 13:56:53,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:56:53,965:INFO:Checking exceptions
2025-06-02 13:56:53,965:INFO:Importing libraries
2025-06-02 13:56:53,965:INFO:Copying training dataset
2025-06-02 13:56:54,037:INFO:Defining folds
2025-06-02 13:56:54,040:INFO:Declaring metric variables
2025-06-02 13:56:54,049:INFO:Importing untrained model
2025-06-02 13:56:54,061:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 13:56:54,086:INFO:Starting cross validation
2025-06-02 13:56:54,090:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:56:54,873:INFO:Calculating mean and std
2025-06-02 13:56:54,875:INFO:Creating metrics dataframe
2025-06-02 13:56:54,879:INFO:Uploading results into container
2025-06-02 13:56:54,880:INFO:Uploading model into container now
2025-06-02 13:56:54,881:INFO:_master_model_container: 9
2025-06-02 13:56:54,881:INFO:_display_container: 2
2025-06-02 13:56:54,882:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 13:56:54,882:INFO:create_model() successfully completed......................................
2025-06-02 13:56:55,973:INFO:SubProcess create_model() end ==================================
2025-06-02 13:56:55,973:INFO:Creating metrics dataframe
2025-06-02 13:56:55,994:INFO:Initializing Huber Regressor
2025-06-02 13:56:55,994:INFO:Total runtime is 0.7635025779406229 minutes
2025-06-02 13:56:56,003:INFO:SubProcess create_model() called ==================================
2025-06-02 13:56:56,003:INFO:Initializing create_model()
2025-06-02 13:56:56,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:56:56,004:INFO:Checking exceptions
2025-06-02 13:56:56,004:INFO:Importing libraries
2025-06-02 13:56:56,004:INFO:Copying training dataset
2025-06-02 13:56:56,063:INFO:Defining folds
2025-06-02 13:56:56,063:INFO:Declaring metric variables
2025-06-02 13:56:56,075:INFO:Importing untrained model
2025-06-02 13:56:56,087:INFO:Huber Regressor Imported successfully
2025-06-02 13:56:56,114:INFO:Starting cross validation
2025-06-02 13:56:56,119:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:56:57,781:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:56:57,833:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:56:57,854:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:56:57,879:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:56:57,909:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:56:57,956:INFO:Calculating mean and std
2025-06-02 13:56:57,959:INFO:Creating metrics dataframe
2025-06-02 13:56:57,964:INFO:Uploading results into container
2025-06-02 13:56:57,965:INFO:Uploading model into container now
2025-06-02 13:56:57,966:INFO:_master_model_container: 10
2025-06-02 13:56:57,966:INFO:_display_container: 2
2025-06-02 13:56:57,967:INFO:HuberRegressor()
2025-06-02 13:56:57,967:INFO:create_model() successfully completed......................................
2025-06-02 13:56:59,053:INFO:SubProcess create_model() end ==================================
2025-06-02 13:56:59,053:INFO:Creating metrics dataframe
2025-06-02 13:56:59,072:INFO:Initializing K Neighbors Regressor
2025-06-02 13:56:59,073:INFO:Total runtime is 0.814811340967814 minutes
2025-06-02 13:56:59,081:INFO:SubProcess create_model() called ==================================
2025-06-02 13:56:59,081:INFO:Initializing create_model()
2025-06-02 13:56:59,081:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:56:59,082:INFO:Checking exceptions
2025-06-02 13:56:59,082:INFO:Importing libraries
2025-06-02 13:56:59,082:INFO:Copying training dataset
2025-06-02 13:56:59,150:INFO:Defining folds
2025-06-02 13:56:59,150:INFO:Declaring metric variables
2025-06-02 13:56:59,163:INFO:Importing untrained model
2025-06-02 13:56:59,177:INFO:K Neighbors Regressor Imported successfully
2025-06-02 13:56:59,203:INFO:Starting cross validation
2025-06-02 13:56:59,207:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:57:00,078:INFO:Calculating mean and std
2025-06-02 13:57:00,081:INFO:Creating metrics dataframe
2025-06-02 13:57:00,086:INFO:Uploading results into container
2025-06-02 13:57:00,087:INFO:Uploading model into container now
2025-06-02 13:57:00,088:INFO:_master_model_container: 11
2025-06-02 13:57:00,088:INFO:_display_container: 2
2025-06-02 13:57:00,088:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 13:57:00,089:INFO:create_model() successfully completed......................................
2025-06-02 13:57:01,502:INFO:SubProcess create_model() end ==================================
2025-06-02 13:57:01,502:INFO:Creating metrics dataframe
2025-06-02 13:57:01,528:INFO:Initializing Decision Tree Regressor
2025-06-02 13:57:01,529:INFO:Total runtime is 0.85575133562088 minutes
2025-06-02 13:57:01,540:INFO:SubProcess create_model() called ==================================
2025-06-02 13:57:01,540:INFO:Initializing create_model()
2025-06-02 13:57:01,541:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:57:01,541:INFO:Checking exceptions
2025-06-02 13:57:01,541:INFO:Importing libraries
2025-06-02 13:57:01,541:INFO:Copying training dataset
2025-06-02 13:57:01,709:INFO:Defining folds
2025-06-02 13:57:01,710:INFO:Declaring metric variables
2025-06-02 13:57:01,730:INFO:Importing untrained model
2025-06-02 13:57:01,765:INFO:Decision Tree Regressor Imported successfully
2025-06-02 13:57:01,792:INFO:Starting cross validation
2025-06-02 13:57:01,798:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:57:02,761:INFO:Calculating mean and std
2025-06-02 13:57:02,763:INFO:Creating metrics dataframe
2025-06-02 13:57:02,768:INFO:Uploading results into container
2025-06-02 13:57:02,769:INFO:Uploading model into container now
2025-06-02 13:57:02,770:INFO:_master_model_container: 12
2025-06-02 13:57:02,771:INFO:_display_container: 2
2025-06-02 13:57:02,771:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 13:57:02,772:INFO:create_model() successfully completed......................................
2025-06-02 13:57:03,916:INFO:SubProcess create_model() end ==================================
2025-06-02 13:57:03,916:INFO:Creating metrics dataframe
2025-06-02 13:57:03,938:INFO:Initializing Random Forest Regressor
2025-06-02 13:57:03,938:INFO:Total runtime is 0.8959013660748798 minutes
2025-06-02 13:57:03,948:INFO:SubProcess create_model() called ==================================
2025-06-02 13:57:03,949:INFO:Initializing create_model()
2025-06-02 13:57:03,949:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:57:03,949:INFO:Checking exceptions
2025-06-02 13:57:03,950:INFO:Importing libraries
2025-06-02 13:57:03,950:INFO:Copying training dataset
2025-06-02 13:57:04,028:INFO:Defining folds
2025-06-02 13:57:04,029:INFO:Declaring metric variables
2025-06-02 13:57:04,045:INFO:Importing untrained model
2025-06-02 13:57:04,057:INFO:Random Forest Regressor Imported successfully
2025-06-02 13:57:04,083:INFO:Starting cross validation
2025-06-02 13:57:04,087:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:57:12,893:INFO:Calculating mean and std
2025-06-02 13:57:12,896:INFO:Creating metrics dataframe
2025-06-02 13:57:12,901:INFO:Uploading results into container
2025-06-02 13:57:12,902:INFO:Uploading model into container now
2025-06-02 13:57:12,904:INFO:_master_model_container: 13
2025-06-02 13:57:12,904:INFO:_display_container: 2
2025-06-02 13:57:12,905:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 13:57:12,906:INFO:create_model() successfully completed......................................
2025-06-02 13:57:14,031:INFO:SubProcess create_model() end ==================================
2025-06-02 13:57:14,031:INFO:Creating metrics dataframe
2025-06-02 13:57:14,056:INFO:Initializing Extra Trees Regressor
2025-06-02 13:57:14,057:INFO:Total runtime is 1.0645492593447365 minutes
2025-06-02 13:57:14,072:INFO:SubProcess create_model() called ==================================
2025-06-02 13:57:14,073:INFO:Initializing create_model()
2025-06-02 13:57:14,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:57:14,074:INFO:Checking exceptions
2025-06-02 13:57:14,074:INFO:Importing libraries
2025-06-02 13:57:14,075:INFO:Copying training dataset
2025-06-02 13:57:14,147:INFO:Defining folds
2025-06-02 13:57:14,148:INFO:Declaring metric variables
2025-06-02 13:57:14,161:INFO:Importing untrained model
2025-06-02 13:57:14,174:INFO:Extra Trees Regressor Imported successfully
2025-06-02 13:57:14,204:INFO:Starting cross validation
2025-06-02 13:57:14,208:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:57:20,025:INFO:Calculating mean and std
2025-06-02 13:57:20,028:INFO:Creating metrics dataframe
2025-06-02 13:57:20,034:INFO:Uploading results into container
2025-06-02 13:57:20,036:INFO:Uploading model into container now
2025-06-02 13:57:20,037:INFO:_master_model_container: 14
2025-06-02 13:57:20,037:INFO:_display_container: 2
2025-06-02 13:57:20,038:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 13:57:20,039:INFO:create_model() successfully completed......................................
2025-06-02 13:57:21,267:INFO:SubProcess create_model() end ==================================
2025-06-02 13:57:21,267:INFO:Creating metrics dataframe
2025-06-02 13:57:21,289:INFO:Initializing AdaBoost Regressor
2025-06-02 13:57:21,289:INFO:Total runtime is 1.1850860675175983 minutes
2025-06-02 13:57:21,300:INFO:SubProcess create_model() called ==================================
2025-06-02 13:57:21,301:INFO:Initializing create_model()
2025-06-02 13:57:21,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:57:21,302:INFO:Checking exceptions
2025-06-02 13:57:21,303:INFO:Importing libraries
2025-06-02 13:57:21,303:INFO:Copying training dataset
2025-06-02 13:57:21,391:INFO:Defining folds
2025-06-02 13:57:21,392:INFO:Declaring metric variables
2025-06-02 13:57:21,407:INFO:Importing untrained model
2025-06-02 13:57:21,421:INFO:AdaBoost Regressor Imported successfully
2025-06-02 13:57:21,449:INFO:Starting cross validation
2025-06-02 13:57:21,453:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:57:23,796:INFO:Calculating mean and std
2025-06-02 13:57:23,798:INFO:Creating metrics dataframe
2025-06-02 13:57:23,802:INFO:Uploading results into container
2025-06-02 13:57:23,803:INFO:Uploading model into container now
2025-06-02 13:57:23,804:INFO:_master_model_container: 15
2025-06-02 13:57:23,805:INFO:_display_container: 2
2025-06-02 13:57:23,806:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 13:57:23,807:INFO:create_model() successfully completed......................................
2025-06-02 13:57:24,958:INFO:SubProcess create_model() end ==================================
2025-06-02 13:57:24,958:INFO:Creating metrics dataframe
2025-06-02 13:57:24,980:INFO:Initializing Gradient Boosting Regressor
2025-06-02 13:57:24,980:INFO:Total runtime is 1.2465988993644712 minutes
2025-06-02 13:57:24,990:INFO:SubProcess create_model() called ==================================
2025-06-02 13:57:24,990:INFO:Initializing create_model()
2025-06-02 13:57:24,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6BC2EA200>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BBEBCF40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:57:24,991:INFO:Checking exceptions
2025-06-02 13:57:24,991:INFO:Importing libraries
2025-06-02 13:57:24,991:INFO:Copying training dataset
2025-06-02 13:57:25,061:INFO:Defining folds
2025-06-02 13:57:25,062:INFO:Declaring metric variables
2025-06-02 13:57:25,074:INFO:Importing untrained model
2025-06-02 13:57:25,089:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 13:57:25,118:INFO:Starting cross validation
2025-06-02 13:57:25,123:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:57:29,115:INFO:Calculating mean and std
2025-06-02 13:57:29,117:INFO:Creating metrics dataframe
2025-06-02 13:57:29,122:INFO:Uploading results into container
2025-06-02 13:57:29,123:INFO:Uploading model into container now
2025-06-02 13:57:29,124:INFO:_master_model_container: 16
2025-06-02 13:57:29,125:INFO:_display_container: 2
2025-06-02 13:57:29,126:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 13:57:29,126:INFO:create_model() successfully completed......................................
2025-06-02 13:58:24,231:INFO:PyCaret RegressionExperiment
2025-06-02 13:58:24,232:INFO:Logging name: reg-default-name
2025-06-02 13:58:24,232:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 13:58:24,232:INFO:version 3.3.2
2025-06-02 13:58:24,233:INFO:Initializing setup()
2025-06-02 13:58:24,233:INFO:self.USI: dfd3
2025-06-02 13:58:24,233:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 13:58:24,233:INFO:Checking environment
2025-06-02 13:58:24,233:INFO:python_version: 3.10.16
2025-06-02 13:58:24,233:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 13:58:24,233:INFO:machine: AMD64
2025-06-02 13:58:24,233:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 13:58:24,242:INFO:Memory: svmem(total=6378008576, available=827039744, percent=87.0, used=5550968832, free=827039744)
2025-06-02 13:58:24,243:INFO:Physical Core: 4
2025-06-02 13:58:24,243:INFO:Logical Core: 8
2025-06-02 13:58:24,243:INFO:Checking libraries
2025-06-02 13:58:24,243:INFO:System:
2025-06-02 13:58:24,243:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 13:58:24,244:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 13:58:24,244:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 13:58:24,244:INFO:PyCaret required dependencies:
2025-06-02 13:58:24,244:INFO:                 pip: 25.1
2025-06-02 13:58:24,244:INFO:          setuptools: 78.1.1
2025-06-02 13:58:24,244:INFO:             pycaret: 3.3.2
2025-06-02 13:58:24,245:INFO:             IPython: 8.37.0
2025-06-02 13:58:24,245:INFO:          ipywidgets: 8.1.7
2025-06-02 13:58:24,245:INFO:                tqdm: 4.67.1
2025-06-02 13:58:24,245:INFO:               numpy: 1.26.4
2025-06-02 13:58:24,245:INFO:              pandas: 2.0.1
2025-06-02 13:58:24,245:INFO:              jinja2: 3.1.6
2025-06-02 13:58:24,245:INFO:               scipy: 1.10.1
2025-06-02 13:58:24,245:INFO:              joblib: 1.3.2
2025-06-02 13:58:24,245:INFO:             sklearn: 1.4.2
2025-06-02 13:58:24,245:INFO:                pyod: 2.0.5
2025-06-02 13:58:24,245:INFO:            imblearn: 0.13.0
2025-06-02 13:58:24,245:INFO:   category_encoders: 2.7.0
2025-06-02 13:58:24,245:INFO:            lightgbm: 4.6.0
2025-06-02 13:58:24,246:INFO:               numba: 0.61.0
2025-06-02 13:58:24,246:INFO:            requests: 2.32.3
2025-06-02 13:58:24,246:INFO:          matplotlib: 3.7.1
2025-06-02 13:58:24,246:INFO:          scikitplot: 0.3.7
2025-06-02 13:58:24,246:INFO:         yellowbrick: 1.5
2025-06-02 13:58:24,246:INFO:              plotly: 6.1.2
2025-06-02 13:58:24,246:INFO:    plotly-resampler: Not installed
2025-06-02 13:58:24,246:INFO:             kaleido: 0.2.1
2025-06-02 13:58:24,246:INFO:           schemdraw: 0.15
2025-06-02 13:58:24,246:INFO:         statsmodels: 0.14.4
2025-06-02 13:58:24,246:INFO:              sktime: 0.26.0
2025-06-02 13:58:24,246:INFO:               tbats: 1.1.3
2025-06-02 13:58:24,247:INFO:            pmdarima: 2.0.4
2025-06-02 13:58:24,247:INFO:              psutil: 7.0.0
2025-06-02 13:58:24,247:INFO:          markupsafe: 2.1.2
2025-06-02 13:58:24,247:INFO:             pickle5: Not installed
2025-06-02 13:58:24,247:INFO:         cloudpickle: 3.1.1
2025-06-02 13:58:24,247:INFO:         deprecation: 2.1.0
2025-06-02 13:58:24,247:INFO:              xxhash: 3.5.0
2025-06-02 13:58:24,247:INFO:           wurlitzer: Not installed
2025-06-02 13:58:24,247:INFO:PyCaret optional dependencies:
2025-06-02 13:58:24,247:INFO:                shap: 0.44.1
2025-06-02 13:58:24,247:INFO:           interpret: 0.6.9
2025-06-02 13:58:24,247:INFO:                umap: 0.5.7
2025-06-02 13:58:24,248:INFO:     ydata_profiling: 4.16.1
2025-06-02 13:58:24,248:INFO:  explainerdashboard: 0.4.8
2025-06-02 13:58:24,248:INFO:             autoviz: Not installed
2025-06-02 13:58:24,248:INFO:           fairlearn: 0.7.0
2025-06-02 13:58:24,248:INFO:          deepchecks: Not installed
2025-06-02 13:58:24,248:INFO:             xgboost: 3.0.2
2025-06-02 13:58:24,248:INFO:            catboost: 1.2.8
2025-06-02 13:58:24,248:INFO:              kmodes: 0.12.2
2025-06-02 13:58:24,248:INFO:             mlxtend: 0.23.4
2025-06-02 13:58:24,248:INFO:       statsforecast: 1.5.0
2025-06-02 13:58:24,248:INFO:        tune_sklearn: Not installed
2025-06-02 13:58:24,248:INFO:                 ray: Not installed
2025-06-02 13:58:24,248:INFO:            hyperopt: 0.2.7
2025-06-02 13:58:24,249:INFO:              optuna: 4.3.0
2025-06-02 13:58:24,249:INFO:               skopt: 0.10.2
2025-06-02 13:58:24,249:INFO:              mlflow: 2.22.0
2025-06-02 13:58:24,249:INFO:              gradio: 5.32.0
2025-06-02 13:58:24,249:INFO:             fastapi: 0.115.12
2025-06-02 13:58:24,249:INFO:             uvicorn: 0.34.3
2025-06-02 13:58:24,249:INFO:              m2cgen: 0.10.0
2025-06-02 13:58:24,249:INFO:           evidently: 0.4.40
2025-06-02 13:58:24,249:INFO:               fugue: 0.8.5
2025-06-02 13:58:24,249:INFO:           streamlit: Not installed
2025-06-02 13:58:24,249:INFO:             prophet: Not installed
2025-06-02 13:58:24,249:INFO:None
2025-06-02 13:58:24,250:INFO:Set up data.
2025-06-02 13:58:24,394:INFO:Set up folding strategy.
2025-06-02 13:58:24,395:INFO:Set up train/test split.
2025-06-02 13:58:24,489:INFO:Set up index.
2025-06-02 13:58:24,490:INFO:Assigning column types.
2025-06-02 13:58:24,559:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 13:58:24,560:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 13:58:24,571:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 13:58:24,583:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:58:24,779:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:58:24,890:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:58:24,892:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:58:24,899:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:58:24,901:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 13:58:24,913:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 13:58:24,926:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:58:25,123:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:58:25,220:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:58:25,221:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:58:25,228:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:58:25,230:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 13:58:25,244:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 13:58:25,257:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:58:25,429:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:58:25,527:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:58:25,528:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:58:25,534:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:58:25,544:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 13:58:25,554:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:58:25,722:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:58:25,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:58:25,818:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:58:25,824:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:58:25,825:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 13:58:25,850:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:58:26,016:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:58:26,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:58:26,116:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:58:26,122:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:58:26,142:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 13:58:26,311:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:58:26,408:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:58:26,409:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:58:26,414:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:58:26,416:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 13:58:26,611:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:58:26,708:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:58:26,709:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:58:26,714:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:58:26,907:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:58:27,033:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 13:58:27,035:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:58:27,044:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:58:27,045:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 13:58:27,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:58:27,353:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:58:27,361:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:58:27,575:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 13:58:27,678:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:58:27,684:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:58:27,685:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 13:58:27,996:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:58:28,004:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:58:28,310:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:58:28,317:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:58:28,322:INFO:Preparing preprocessing pipeline...
2025-06-02 13:58:28,322:INFO:Set up simple imputation.
2025-06-02 13:58:28,323:INFO:Set up removing multicollinearity.
2025-06-02 13:58:28,331:INFO:Set up column name cleaning.
2025-06-02 13:58:28,570:INFO:Finished creating preprocessing pipeline.
2025-06-02 13:58:28,584:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 13:58:28,584:INFO:Creating final display dataframe.
2025-06-02 13:58:28,997:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              dfd3
2025-06-02 13:58:29,264:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:58:29,268:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:58:29,508:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 13:58:29,513:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 13:58:29,514:INFO:setup() successfully completed in 5.31s...............
2025-06-02 13:58:29,514:INFO:Initializing compare_models()
2025-06-02 13:58:29,515:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 13:58:29,515:INFO:Checking exceptions
2025-06-02 13:58:29,535:INFO:Preparing display monitor
2025-06-02 13:58:29,595:INFO:Initializing Linear Regression
2025-06-02 13:58:29,595:INFO:Total runtime is 0.0 minutes
2025-06-02 13:58:29,610:INFO:SubProcess create_model() called ==================================
2025-06-02 13:58:29,611:INFO:Initializing create_model()
2025-06-02 13:58:29,611:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:58:29,612:INFO:Checking exceptions
2025-06-02 13:58:29,613:INFO:Importing libraries
2025-06-02 13:58:29,614:INFO:Copying training dataset
2025-06-02 13:58:29,821:INFO:Defining folds
2025-06-02 13:58:29,821:INFO:Declaring metric variables
2025-06-02 13:58:29,837:INFO:Importing untrained model
2025-06-02 13:58:29,872:INFO:Linear Regression Imported successfully
2025-06-02 13:58:29,901:INFO:Starting cross validation
2025-06-02 13:58:29,906:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:58:30,842:INFO:Calculating mean and std
2025-06-02 13:58:30,844:INFO:Creating metrics dataframe
2025-06-02 13:58:30,848:INFO:Uploading results into container
2025-06-02 13:58:30,848:INFO:Uploading model into container now
2025-06-02 13:58:30,849:INFO:_master_model_container: 1
2025-06-02 13:58:30,849:INFO:_display_container: 2
2025-06-02 13:58:30,850:INFO:LinearRegression(n_jobs=-1)
2025-06-02 13:58:30,850:INFO:create_model() successfully completed......................................
2025-06-02 13:58:32,334:INFO:SubProcess create_model() end ==================================
2025-06-02 13:58:32,335:INFO:Creating metrics dataframe
2025-06-02 13:58:32,351:INFO:Initializing Lasso Regression
2025-06-02 13:58:32,351:INFO:Total runtime is 0.045921190579732256 minutes
2025-06-02 13:58:32,365:INFO:SubProcess create_model() called ==================================
2025-06-02 13:58:32,366:INFO:Initializing create_model()
2025-06-02 13:58:32,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:58:32,366:INFO:Checking exceptions
2025-06-02 13:58:32,367:INFO:Importing libraries
2025-06-02 13:58:32,367:INFO:Copying training dataset
2025-06-02 13:58:32,447:INFO:Defining folds
2025-06-02 13:58:32,448:INFO:Declaring metric variables
2025-06-02 13:58:32,462:INFO:Importing untrained model
2025-06-02 13:58:32,473:INFO:Lasso Regression Imported successfully
2025-06-02 13:58:32,501:INFO:Starting cross validation
2025-06-02 13:58:32,507:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:58:33,514:INFO:Calculating mean and std
2025-06-02 13:58:33,516:INFO:Creating metrics dataframe
2025-06-02 13:58:33,520:INFO:Uploading results into container
2025-06-02 13:58:33,521:INFO:Uploading model into container now
2025-06-02 13:58:33,522:INFO:_master_model_container: 2
2025-06-02 13:58:33,522:INFO:_display_container: 2
2025-06-02 13:58:33,523:INFO:Lasso(random_state=123)
2025-06-02 13:58:33,523:INFO:create_model() successfully completed......................................
2025-06-02 13:58:34,766:INFO:SubProcess create_model() end ==================================
2025-06-02 13:58:34,767:INFO:Creating metrics dataframe
2025-06-02 13:58:34,782:INFO:Initializing Ridge Regression
2025-06-02 13:58:34,782:INFO:Total runtime is 0.08643691142400106 minutes
2025-06-02 13:58:34,791:INFO:SubProcess create_model() called ==================================
2025-06-02 13:58:34,792:INFO:Initializing create_model()
2025-06-02 13:58:34,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:58:34,793:INFO:Checking exceptions
2025-06-02 13:58:34,793:INFO:Importing libraries
2025-06-02 13:58:34,793:INFO:Copying training dataset
2025-06-02 13:58:34,864:INFO:Defining folds
2025-06-02 13:58:34,864:INFO:Declaring metric variables
2025-06-02 13:58:34,880:INFO:Importing untrained model
2025-06-02 13:58:34,893:INFO:Ridge Regression Imported successfully
2025-06-02 13:58:34,918:INFO:Starting cross validation
2025-06-02 13:58:34,923:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:58:35,544:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.75561e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 13:58:35,584:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31073e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 13:58:35,657:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.24347e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 13:58:35,691:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.08754e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 13:58:35,747:INFO:Calculating mean and std
2025-06-02 13:58:35,750:INFO:Creating metrics dataframe
2025-06-02 13:58:35,753:INFO:Uploading results into container
2025-06-02 13:58:35,754:INFO:Uploading model into container now
2025-06-02 13:58:35,754:INFO:_master_model_container: 3
2025-06-02 13:58:35,755:INFO:_display_container: 2
2025-06-02 13:58:35,755:INFO:Ridge(random_state=123)
2025-06-02 13:58:35,755:INFO:create_model() successfully completed......................................
2025-06-02 13:58:37,062:INFO:SubProcess create_model() end ==================================
2025-06-02 13:58:37,062:INFO:Creating metrics dataframe
2025-06-02 13:58:37,081:INFO:Initializing Elastic Net
2025-06-02 13:58:37,082:INFO:Total runtime is 0.12477569580078125 minutes
2025-06-02 13:58:37,096:INFO:SubProcess create_model() called ==================================
2025-06-02 13:58:37,097:INFO:Initializing create_model()
2025-06-02 13:58:37,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:58:37,097:INFO:Checking exceptions
2025-06-02 13:58:37,098:INFO:Importing libraries
2025-06-02 13:58:37,098:INFO:Copying training dataset
2025-06-02 13:58:37,179:INFO:Defining folds
2025-06-02 13:58:37,179:INFO:Declaring metric variables
2025-06-02 13:58:37,192:INFO:Importing untrained model
2025-06-02 13:58:37,205:INFO:Elastic Net Imported successfully
2025-06-02 13:58:37,231:INFO:Starting cross validation
2025-06-02 13:58:37,236:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:58:38,176:INFO:Calculating mean and std
2025-06-02 13:58:38,179:INFO:Creating metrics dataframe
2025-06-02 13:58:38,183:INFO:Uploading results into container
2025-06-02 13:58:38,184:INFO:Uploading model into container now
2025-06-02 13:58:38,185:INFO:_master_model_container: 4
2025-06-02 13:58:38,185:INFO:_display_container: 2
2025-06-02 13:58:38,186:INFO:ElasticNet(random_state=123)
2025-06-02 13:58:38,186:INFO:create_model() successfully completed......................................
2025-06-02 13:58:39,462:INFO:SubProcess create_model() end ==================================
2025-06-02 13:58:39,462:INFO:Creating metrics dataframe
2025-06-02 13:58:39,482:INFO:Initializing Least Angle Regression
2025-06-02 13:58:39,484:INFO:Total runtime is 0.1648022969563802 minutes
2025-06-02 13:58:39,495:INFO:SubProcess create_model() called ==================================
2025-06-02 13:58:39,496:INFO:Initializing create_model()
2025-06-02 13:58:39,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:58:39,497:INFO:Checking exceptions
2025-06-02 13:58:39,497:INFO:Importing libraries
2025-06-02 13:58:39,498:INFO:Copying training dataset
2025-06-02 13:58:39,568:INFO:Defining folds
2025-06-02 13:58:39,569:INFO:Declaring metric variables
2025-06-02 13:58:39,584:INFO:Importing untrained model
2025-06-02 13:58:39,606:INFO:Least Angle Regression Imported successfully
2025-06-02 13:58:39,675:INFO:Starting cross validation
2025-06-02 13:58:39,681:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:58:40,779:INFO:Calculating mean and std
2025-06-02 13:58:40,782:INFO:Creating metrics dataframe
2025-06-02 13:58:40,786:INFO:Uploading results into container
2025-06-02 13:58:40,787:INFO:Uploading model into container now
2025-06-02 13:58:40,788:INFO:_master_model_container: 5
2025-06-02 13:58:40,789:INFO:_display_container: 2
2025-06-02 13:58:40,790:INFO:Lars(random_state=123)
2025-06-02 13:58:40,790:INFO:create_model() successfully completed......................................
2025-06-02 13:58:42,042:INFO:SubProcess create_model() end ==================================
2025-06-02 13:58:42,042:INFO:Creating metrics dataframe
2025-06-02 13:58:42,062:INFO:Initializing Lasso Least Angle Regression
2025-06-02 13:58:42,062:INFO:Total runtime is 0.20777161518732706 minutes
2025-06-02 13:58:42,078:INFO:SubProcess create_model() called ==================================
2025-06-02 13:58:42,079:INFO:Initializing create_model()
2025-06-02 13:58:42,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:58:42,080:INFO:Checking exceptions
2025-06-02 13:58:42,081:INFO:Importing libraries
2025-06-02 13:58:42,081:INFO:Copying training dataset
2025-06-02 13:58:42,197:INFO:Defining folds
2025-06-02 13:58:42,198:INFO:Declaring metric variables
2025-06-02 13:58:42,214:INFO:Importing untrained model
2025-06-02 13:58:42,233:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 13:58:42,261:INFO:Starting cross validation
2025-06-02 13:58:42,265:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:58:43,150:INFO:Calculating mean and std
2025-06-02 13:58:43,153:INFO:Creating metrics dataframe
2025-06-02 13:58:43,158:INFO:Uploading results into container
2025-06-02 13:58:43,159:INFO:Uploading model into container now
2025-06-02 13:58:43,161:INFO:_master_model_container: 6
2025-06-02 13:58:43,161:INFO:_display_container: 2
2025-06-02 13:58:43,162:INFO:LassoLars(random_state=123)
2025-06-02 13:58:43,162:INFO:create_model() successfully completed......................................
2025-06-02 13:58:44,380:INFO:SubProcess create_model() end ==================================
2025-06-02 13:58:44,380:INFO:Creating metrics dataframe
2025-06-02 13:58:44,393:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 13:58:44,393:INFO:Total runtime is 0.24661890665690103 minutes
2025-06-02 13:58:44,402:INFO:SubProcess create_model() called ==================================
2025-06-02 13:58:44,403:INFO:Initializing create_model()
2025-06-02 13:58:44,403:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:58:44,404:INFO:Checking exceptions
2025-06-02 13:58:44,404:INFO:Importing libraries
2025-06-02 13:58:44,404:INFO:Copying training dataset
2025-06-02 13:58:44,489:INFO:Defining folds
2025-06-02 13:58:44,490:INFO:Declaring metric variables
2025-06-02 13:58:44,501:INFO:Importing untrained model
2025-06-02 13:58:44,516:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 13:58:44,544:INFO:Starting cross validation
2025-06-02 13:58:44,548:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:58:45,380:INFO:Calculating mean and std
2025-06-02 13:58:45,382:INFO:Creating metrics dataframe
2025-06-02 13:58:45,386:INFO:Uploading results into container
2025-06-02 13:58:45,387:INFO:Uploading model into container now
2025-06-02 13:58:45,388:INFO:_master_model_container: 7
2025-06-02 13:58:45,388:INFO:_display_container: 2
2025-06-02 13:58:45,389:INFO:OrthogonalMatchingPursuit()
2025-06-02 13:58:45,389:INFO:create_model() successfully completed......................................
2025-06-02 13:58:46,605:INFO:SubProcess create_model() end ==================================
2025-06-02 13:58:46,605:INFO:Creating metrics dataframe
2025-06-02 13:58:46,624:INFO:Initializing Bayesian Ridge
2025-06-02 13:58:46,624:INFO:Total runtime is 0.28380390405654904 minutes
2025-06-02 13:58:46,632:INFO:SubProcess create_model() called ==================================
2025-06-02 13:58:46,633:INFO:Initializing create_model()
2025-06-02 13:58:46,633:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:58:46,633:INFO:Checking exceptions
2025-06-02 13:58:46,634:INFO:Importing libraries
2025-06-02 13:58:46,634:INFO:Copying training dataset
2025-06-02 13:58:46,804:INFO:Defining folds
2025-06-02 13:58:46,805:INFO:Declaring metric variables
2025-06-02 13:58:46,848:INFO:Importing untrained model
2025-06-02 13:58:46,870:INFO:Bayesian Ridge Imported successfully
2025-06-02 13:58:46,908:INFO:Starting cross validation
2025-06-02 13:58:46,912:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:58:47,900:INFO:Calculating mean and std
2025-06-02 13:58:47,902:INFO:Creating metrics dataframe
2025-06-02 13:58:47,906:INFO:Uploading results into container
2025-06-02 13:58:47,907:INFO:Uploading model into container now
2025-06-02 13:58:47,907:INFO:_master_model_container: 8
2025-06-02 13:58:47,908:INFO:_display_container: 2
2025-06-02 13:58:47,908:INFO:BayesianRidge()
2025-06-02 13:58:47,909:INFO:create_model() successfully completed......................................
2025-06-02 13:58:49,134:INFO:SubProcess create_model() end ==================================
2025-06-02 13:58:49,135:INFO:Creating metrics dataframe
2025-06-02 13:58:49,154:INFO:Initializing Passive Aggressive Regressor
2025-06-02 13:58:49,154:INFO:Total runtime is 0.32597140868504837 minutes
2025-06-02 13:58:49,165:INFO:SubProcess create_model() called ==================================
2025-06-02 13:58:49,166:INFO:Initializing create_model()
2025-06-02 13:58:49,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:58:49,167:INFO:Checking exceptions
2025-06-02 13:58:49,167:INFO:Importing libraries
2025-06-02 13:58:49,167:INFO:Copying training dataset
2025-06-02 13:58:49,239:INFO:Defining folds
2025-06-02 13:58:49,240:INFO:Declaring metric variables
2025-06-02 13:58:49,253:INFO:Importing untrained model
2025-06-02 13:58:49,264:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 13:58:49,295:INFO:Starting cross validation
2025-06-02 13:58:49,299:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:58:50,169:INFO:Calculating mean and std
2025-06-02 13:58:50,171:INFO:Creating metrics dataframe
2025-06-02 13:58:50,174:INFO:Uploading results into container
2025-06-02 13:58:50,175:INFO:Uploading model into container now
2025-06-02 13:58:50,176:INFO:_master_model_container: 9
2025-06-02 13:58:50,176:INFO:_display_container: 2
2025-06-02 13:58:50,177:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 13:58:50,177:INFO:create_model() successfully completed......................................
2025-06-02 13:58:51,423:INFO:SubProcess create_model() end ==================================
2025-06-02 13:58:51,424:INFO:Creating metrics dataframe
2025-06-02 13:58:51,438:INFO:Initializing Huber Regressor
2025-06-02 13:58:51,439:INFO:Total runtime is 0.3640661199887593 minutes
2025-06-02 13:58:51,448:INFO:SubProcess create_model() called ==================================
2025-06-02 13:58:51,448:INFO:Initializing create_model()
2025-06-02 13:58:51,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:58:51,449:INFO:Checking exceptions
2025-06-02 13:58:51,449:INFO:Importing libraries
2025-06-02 13:58:51,450:INFO:Copying training dataset
2025-06-02 13:58:51,573:INFO:Defining folds
2025-06-02 13:58:51,573:INFO:Declaring metric variables
2025-06-02 13:58:51,591:INFO:Importing untrained model
2025-06-02 13:58:51,607:INFO:Huber Regressor Imported successfully
2025-06-02 13:58:51,668:INFO:Starting cross validation
2025-06-02 13:58:51,692:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:58:53,635:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:58:53,638:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:58:53,699:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:58:53,706:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:58:53,768:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 13:58:53,825:INFO:Calculating mean and std
2025-06-02 13:58:53,828:INFO:Creating metrics dataframe
2025-06-02 13:58:53,832:INFO:Uploading results into container
2025-06-02 13:58:53,834:INFO:Uploading model into container now
2025-06-02 13:58:53,835:INFO:_master_model_container: 10
2025-06-02 13:58:53,835:INFO:_display_container: 2
2025-06-02 13:58:53,836:INFO:HuberRegressor()
2025-06-02 13:58:53,837:INFO:create_model() successfully completed......................................
2025-06-02 13:58:55,094:INFO:SubProcess create_model() end ==================================
2025-06-02 13:58:55,095:INFO:Creating metrics dataframe
2025-06-02 13:58:55,115:INFO:Initializing K Neighbors Regressor
2025-06-02 13:58:55,115:INFO:Total runtime is 0.4253306865692138 minutes
2025-06-02 13:58:55,128:INFO:SubProcess create_model() called ==================================
2025-06-02 13:58:55,128:INFO:Initializing create_model()
2025-06-02 13:58:55,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:58:55,129:INFO:Checking exceptions
2025-06-02 13:58:55,129:INFO:Importing libraries
2025-06-02 13:58:55,130:INFO:Copying training dataset
2025-06-02 13:58:55,297:INFO:Defining folds
2025-06-02 13:58:55,298:INFO:Declaring metric variables
2025-06-02 13:58:55,313:INFO:Importing untrained model
2025-06-02 13:58:55,333:INFO:K Neighbors Regressor Imported successfully
2025-06-02 13:58:55,368:INFO:Starting cross validation
2025-06-02 13:58:55,373:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:58:56,438:INFO:Calculating mean and std
2025-06-02 13:58:56,440:INFO:Creating metrics dataframe
2025-06-02 13:58:56,444:INFO:Uploading results into container
2025-06-02 13:58:56,445:INFO:Uploading model into container now
2025-06-02 13:58:56,446:INFO:_master_model_container: 11
2025-06-02 13:58:56,446:INFO:_display_container: 2
2025-06-02 13:58:56,447:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 13:58:56,447:INFO:create_model() successfully completed......................................
2025-06-02 13:58:57,683:INFO:SubProcess create_model() end ==================================
2025-06-02 13:58:57,683:INFO:Creating metrics dataframe
2025-06-02 13:58:57,699:INFO:Initializing Decision Tree Regressor
2025-06-02 13:58:57,699:INFO:Total runtime is 0.4683906197547912 minutes
2025-06-02 13:58:57,710:INFO:SubProcess create_model() called ==================================
2025-06-02 13:58:57,711:INFO:Initializing create_model()
2025-06-02 13:58:57,711:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:58:57,712:INFO:Checking exceptions
2025-06-02 13:58:57,712:INFO:Importing libraries
2025-06-02 13:58:57,712:INFO:Copying training dataset
2025-06-02 13:58:57,795:INFO:Defining folds
2025-06-02 13:58:57,796:INFO:Declaring metric variables
2025-06-02 13:58:57,808:INFO:Importing untrained model
2025-06-02 13:58:57,821:INFO:Decision Tree Regressor Imported successfully
2025-06-02 13:58:57,847:INFO:Starting cross validation
2025-06-02 13:58:57,851:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:58:59,012:INFO:Calculating mean and std
2025-06-02 13:58:59,014:INFO:Creating metrics dataframe
2025-06-02 13:58:59,017:INFO:Uploading results into container
2025-06-02 13:58:59,018:INFO:Uploading model into container now
2025-06-02 13:58:59,020:INFO:_master_model_container: 12
2025-06-02 13:58:59,020:INFO:_display_container: 2
2025-06-02 13:58:59,021:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 13:58:59,021:INFO:create_model() successfully completed......................................
2025-06-02 13:59:00,355:INFO:SubProcess create_model() end ==================================
2025-06-02 13:59:00,355:INFO:Creating metrics dataframe
2025-06-02 13:59:00,378:INFO:Initializing Random Forest Regressor
2025-06-02 13:59:00,378:INFO:Total runtime is 0.5130432446797688 minutes
2025-06-02 13:59:00,391:INFO:SubProcess create_model() called ==================================
2025-06-02 13:59:00,392:INFO:Initializing create_model()
2025-06-02 13:59:00,392:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:59:00,393:INFO:Checking exceptions
2025-06-02 13:59:00,393:INFO:Importing libraries
2025-06-02 13:59:00,393:INFO:Copying training dataset
2025-06-02 13:59:00,494:INFO:Defining folds
2025-06-02 13:59:00,494:INFO:Declaring metric variables
2025-06-02 13:59:00,511:INFO:Importing untrained model
2025-06-02 13:59:00,528:INFO:Random Forest Regressor Imported successfully
2025-06-02 13:59:00,558:INFO:Starting cross validation
2025-06-02 13:59:00,563:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:59:10,652:INFO:Calculating mean and std
2025-06-02 13:59:10,655:INFO:Creating metrics dataframe
2025-06-02 13:59:10,659:INFO:Uploading results into container
2025-06-02 13:59:10,660:INFO:Uploading model into container now
2025-06-02 13:59:10,661:INFO:_master_model_container: 13
2025-06-02 13:59:10,661:INFO:_display_container: 2
2025-06-02 13:59:10,662:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 13:59:10,662:INFO:create_model() successfully completed......................................
2025-06-02 13:59:11,953:INFO:SubProcess create_model() end ==================================
2025-06-02 13:59:11,953:INFO:Creating metrics dataframe
2025-06-02 13:59:11,977:INFO:Initializing Extra Trees Regressor
2025-06-02 13:59:11,978:INFO:Total runtime is 0.7063693205515543 minutes
2025-06-02 13:59:11,988:INFO:SubProcess create_model() called ==================================
2025-06-02 13:59:11,989:INFO:Initializing create_model()
2025-06-02 13:59:11,990:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:59:11,990:INFO:Checking exceptions
2025-06-02 13:59:11,990:INFO:Importing libraries
2025-06-02 13:59:11,991:INFO:Copying training dataset
2025-06-02 13:59:12,063:INFO:Defining folds
2025-06-02 13:59:12,063:INFO:Declaring metric variables
2025-06-02 13:59:12,076:INFO:Importing untrained model
2025-06-02 13:59:12,088:INFO:Extra Trees Regressor Imported successfully
2025-06-02 13:59:12,120:INFO:Starting cross validation
2025-06-02 13:59:12,125:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:59:18,760:INFO:Calculating mean and std
2025-06-02 13:59:18,762:INFO:Creating metrics dataframe
2025-06-02 13:59:18,766:INFO:Uploading results into container
2025-06-02 13:59:18,767:INFO:Uploading model into container now
2025-06-02 13:59:18,768:INFO:_master_model_container: 14
2025-06-02 13:59:18,768:INFO:_display_container: 2
2025-06-02 13:59:18,769:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 13:59:18,770:INFO:create_model() successfully completed......................................
2025-06-02 13:59:20,114:INFO:SubProcess create_model() end ==================================
2025-06-02 13:59:20,115:INFO:Creating metrics dataframe
2025-06-02 13:59:20,139:INFO:Initializing AdaBoost Regressor
2025-06-02 13:59:20,140:INFO:Total runtime is 0.8424014846483866 minutes
2025-06-02 13:59:20,149:INFO:SubProcess create_model() called ==================================
2025-06-02 13:59:20,149:INFO:Initializing create_model()
2025-06-02 13:59:20,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:59:20,150:INFO:Checking exceptions
2025-06-02 13:59:20,150:INFO:Importing libraries
2025-06-02 13:59:20,151:INFO:Copying training dataset
2025-06-02 13:59:20,242:INFO:Defining folds
2025-06-02 13:59:20,245:INFO:Declaring metric variables
2025-06-02 13:59:20,267:INFO:Importing untrained model
2025-06-02 13:59:20,301:INFO:AdaBoost Regressor Imported successfully
2025-06-02 13:59:20,415:INFO:Starting cross validation
2025-06-02 13:59:20,420:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:59:23,329:INFO:Calculating mean and std
2025-06-02 13:59:23,332:INFO:Creating metrics dataframe
2025-06-02 13:59:23,337:INFO:Uploading results into container
2025-06-02 13:59:23,338:INFO:Uploading model into container now
2025-06-02 13:59:23,339:INFO:_master_model_container: 15
2025-06-02 13:59:23,340:INFO:_display_container: 2
2025-06-02 13:59:23,341:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 13:59:23,341:INFO:create_model() successfully completed......................................
2025-06-02 13:59:24,793:INFO:SubProcess create_model() end ==================================
2025-06-02 13:59:24,793:INFO:Creating metrics dataframe
2025-06-02 13:59:24,818:INFO:Initializing Gradient Boosting Regressor
2025-06-02 13:59:24,818:INFO:Total runtime is 0.9203676025072733 minutes
2025-06-02 13:59:24,832:INFO:SubProcess create_model() called ==================================
2025-06-02 13:59:24,833:INFO:Initializing create_model()
2025-06-02 13:59:24,833:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:59:24,834:INFO:Checking exceptions
2025-06-02 13:59:24,834:INFO:Importing libraries
2025-06-02 13:59:24,834:INFO:Copying training dataset
2025-06-02 13:59:24,913:INFO:Defining folds
2025-06-02 13:59:24,914:INFO:Declaring metric variables
2025-06-02 13:59:24,927:INFO:Importing untrained model
2025-06-02 13:59:24,944:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 13:59:24,976:INFO:Starting cross validation
2025-06-02 13:59:24,981:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:59:29,220:INFO:Calculating mean and std
2025-06-02 13:59:29,222:INFO:Creating metrics dataframe
2025-06-02 13:59:29,226:INFO:Uploading results into container
2025-06-02 13:59:29,228:INFO:Uploading model into container now
2025-06-02 13:59:29,229:INFO:_master_model_container: 16
2025-06-02 13:59:29,229:INFO:_display_container: 2
2025-06-02 13:59:29,230:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 13:59:29,230:INFO:create_model() successfully completed......................................
2025-06-02 13:59:30,491:INFO:SubProcess create_model() end ==================================
2025-06-02 13:59:30,491:INFO:Creating metrics dataframe
2025-06-02 13:59:30,513:INFO:Initializing Extreme Gradient Boosting
2025-06-02 13:59:30,513:INFO:Total runtime is 1.015291146437327 minutes
2025-06-02 13:59:30,522:INFO:SubProcess create_model() called ==================================
2025-06-02 13:59:30,523:INFO:Initializing create_model()
2025-06-02 13:59:30,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:59:30,523:INFO:Checking exceptions
2025-06-02 13:59:30,523:INFO:Importing libraries
2025-06-02 13:59:30,523:INFO:Copying training dataset
2025-06-02 13:59:30,613:INFO:Defining folds
2025-06-02 13:59:30,615:INFO:Declaring metric variables
2025-06-02 13:59:30,626:INFO:Importing untrained model
2025-06-02 13:59:30,641:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 13:59:30,668:INFO:Starting cross validation
2025-06-02 13:59:30,672:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:59:34,921:INFO:Calculating mean and std
2025-06-02 13:59:34,924:INFO:Creating metrics dataframe
2025-06-02 13:59:34,928:INFO:Uploading results into container
2025-06-02 13:59:34,929:INFO:Uploading model into container now
2025-06-02 13:59:34,930:INFO:_master_model_container: 17
2025-06-02 13:59:34,930:INFO:_display_container: 2
2025-06-02 13:59:34,932:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 13:59:34,932:INFO:create_model() successfully completed......................................
2025-06-02 13:59:36,221:INFO:SubProcess create_model() end ==================================
2025-06-02 13:59:36,221:INFO:Creating metrics dataframe
2025-06-02 13:59:36,244:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 13:59:36,244:INFO:Total runtime is 1.1108122626940409 minutes
2025-06-02 13:59:36,256:INFO:SubProcess create_model() called ==================================
2025-06-02 13:59:36,256:INFO:Initializing create_model()
2025-06-02 13:59:36,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:59:36,257:INFO:Checking exceptions
2025-06-02 13:59:36,257:INFO:Importing libraries
2025-06-02 13:59:36,258:INFO:Copying training dataset
2025-06-02 13:59:36,329:INFO:Defining folds
2025-06-02 13:59:36,329:INFO:Declaring metric variables
2025-06-02 13:59:36,343:INFO:Importing untrained model
2025-06-02 13:59:36,358:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 13:59:36,387:INFO:Starting cross validation
2025-06-02 13:59:36,391:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 13:59:39,280:INFO:Calculating mean and std
2025-06-02 13:59:39,295:INFO:Creating metrics dataframe
2025-06-02 13:59:39,307:INFO:Uploading results into container
2025-06-02 13:59:39,309:INFO:Uploading model into container now
2025-06-02 13:59:39,310:INFO:_master_model_container: 18
2025-06-02 13:59:39,310:INFO:_display_container: 2
2025-06-02 13:59:39,314:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 13:59:39,314:INFO:create_model() successfully completed......................................
2025-06-02 13:59:40,678:INFO:SubProcess create_model() end ==================================
2025-06-02 13:59:40,678:INFO:Creating metrics dataframe
2025-06-02 13:59:40,703:INFO:Initializing CatBoost Regressor
2025-06-02 13:59:40,703:INFO:Total runtime is 1.185125474135081 minutes
2025-06-02 13:59:40,712:INFO:SubProcess create_model() called ==================================
2025-06-02 13:59:40,713:INFO:Initializing create_model()
2025-06-02 13:59:40,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 13:59:40,713:INFO:Checking exceptions
2025-06-02 13:59:40,714:INFO:Importing libraries
2025-06-02 13:59:40,714:INFO:Copying training dataset
2025-06-02 13:59:40,787:INFO:Defining folds
2025-06-02 13:59:40,788:INFO:Declaring metric variables
2025-06-02 13:59:40,804:INFO:Importing untrained model
2025-06-02 13:59:40,829:INFO:CatBoost Regressor Imported successfully
2025-06-02 13:59:40,855:INFO:Starting cross validation
2025-06-02 13:59:40,859:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:00:09,932:INFO:Calculating mean and std
2025-06-02 14:00:09,937:INFO:Creating metrics dataframe
2025-06-02 14:00:09,944:INFO:Uploading results into container
2025-06-02 14:00:09,946:INFO:Uploading model into container now
2025-06-02 14:00:09,947:INFO:_master_model_container: 19
2025-06-02 14:00:09,948:INFO:_display_container: 2
2025-06-02 14:00:09,948:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6D72F7160>
2025-06-02 14:00:09,948:INFO:create_model() successfully completed......................................
2025-06-02 14:00:11,492:INFO:SubProcess create_model() end ==================================
2025-06-02 14:00:11,492:INFO:Creating metrics dataframe
2025-06-02 14:00:11,517:INFO:Initializing Dummy Regressor
2025-06-02 14:00:11,518:INFO:Total runtime is 1.6987114866574604 minutes
2025-06-02 14:00:11,530:INFO:SubProcess create_model() called ==================================
2025-06-02 14:00:11,531:INFO:Initializing create_model()
2025-06-02 14:00:11,531:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D71837C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:00:11,531:INFO:Checking exceptions
2025-06-02 14:00:11,532:INFO:Importing libraries
2025-06-02 14:00:11,532:INFO:Copying training dataset
2025-06-02 14:00:11,619:INFO:Defining folds
2025-06-02 14:00:11,620:INFO:Declaring metric variables
2025-06-02 14:00:11,633:INFO:Importing untrained model
2025-06-02 14:00:11,647:INFO:Dummy Regressor Imported successfully
2025-06-02 14:00:11,676:INFO:Starting cross validation
2025-06-02 14:00:11,680:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:00:12,697:INFO:Calculating mean and std
2025-06-02 14:00:12,700:INFO:Creating metrics dataframe
2025-06-02 14:00:12,705:INFO:Uploading results into container
2025-06-02 14:00:12,707:INFO:Uploading model into container now
2025-06-02 14:00:12,708:INFO:_master_model_container: 20
2025-06-02 14:00:12,708:INFO:_display_container: 2
2025-06-02 14:00:12,711:INFO:DummyRegressor()
2025-06-02 14:00:12,712:INFO:create_model() successfully completed......................................
2025-06-02 14:00:14,150:INFO:SubProcess create_model() end ==================================
2025-06-02 14:00:14,150:INFO:Creating metrics dataframe
2025-06-02 14:00:14,204:INFO:Initializing create_model()
2025-06-02 14:00:14,205:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:00:14,205:INFO:Checking exceptions
2025-06-02 14:00:14,209:INFO:Importing libraries
2025-06-02 14:00:14,210:INFO:Copying training dataset
2025-06-02 14:00:14,288:INFO:Defining folds
2025-06-02 14:00:14,288:INFO:Declaring metric variables
2025-06-02 14:00:14,289:INFO:Importing untrained model
2025-06-02 14:00:14,289:INFO:Declaring custom model
2025-06-02 14:00:14,291:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:00:14,294:INFO:Cross validation set to False
2025-06-02 14:00:14,294:INFO:Fitting Model
2025-06-02 14:00:14,775:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:00:14,785:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006965 seconds.
2025-06-02 14:00:14,785:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:00:14,787:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 14:00:14,791:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 14:00:14,794:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:00:15,016:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:00:15,016:INFO:create_model() successfully completed......................................
2025-06-02 14:00:16,449:INFO:_master_model_container: 20
2025-06-02 14:00:16,449:INFO:_display_container: 2
2025-06-02 14:00:16,451:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:00:16,452:INFO:compare_models() successfully completed......................................
2025-06-02 14:00:16,455:INFO:Initializing tune_model()
2025-06-02 14:00:16,456:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>)
2025-06-02 14:00:16,456:INFO:Checking exceptions
2025-06-02 14:00:16,457:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 14:00:16,517:INFO:Copying training dataset
2025-06-02 14:00:16,593:INFO:Checking base model
2025-06-02 14:00:16,594:INFO:Base model : Light Gradient Boosting Machine
2025-06-02 14:00:16,618:INFO:Declaring metric variables
2025-06-02 14:00:16,639:INFO:Defining Hyperparameters
2025-06-02 14:00:18,064:INFO:Tuning with n_jobs=-1
2025-06-02 14:00:18,078:INFO:Initializing skopt.BayesSearchCV
2025-06-02 14:00:37,248:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.8608120752388259), ('actual_estimator__bagging_freq', 1), ('actual_estimator__feature_fraction', 0.4284489606984907), ('actual_estimator__learning_rate', 0.016133245419918712), ('actual_estimator__min_child_samples', 95), ('actual_estimator__min_split_gain', 0.8209314243567916), ('actual_estimator__n_estimators', 239), ('actual_estimator__num_leaves', 183), ('actual_estimator__reg_alpha', 8.662569304197528e-07), ('actual_estimator__reg_lambda', 5.001062744294253e-06)])
2025-06-02 14:00:37,250:INFO:Hyperparameter search completed
2025-06-02 14:00:37,250:INFO:SubProcess create_model() called ==================================
2025-06-02 14:00:37,252:INFO:Initializing create_model()
2025-06-02 14:00:37,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6C3B8D720>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.8608120752388259, 'bagging_freq': 1, 'feature_fraction': 0.4284489606984907, 'learning_rate': 0.016133245419918712, 'min_child_samples': 95, 'min_split_gain': 0.8209314243567916, 'n_estimators': 239, 'num_leaves': 183, 'reg_alpha': 8.662569304197528e-07, 'reg_lambda': 5.001062744294253e-06})
2025-06-02 14:00:37,252:INFO:Checking exceptions
2025-06-02 14:00:37,253:INFO:Importing libraries
2025-06-02 14:00:37,253:INFO:Copying training dataset
2025-06-02 14:00:37,319:INFO:Defining folds
2025-06-02 14:00:37,319:INFO:Declaring metric variables
2025-06-02 14:00:37,329:INFO:Importing untrained model
2025-06-02 14:00:37,330:INFO:Declaring custom model
2025-06-02 14:00:37,347:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:00:37,372:INFO:Starting cross validation
2025-06-02 14:00:37,376:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:00:39,934:INFO:Calculating mean and std
2025-06-02 14:00:39,937:INFO:Creating metrics dataframe
2025-06-02 14:00:39,957:INFO:Finalizing model
2025-06-02 14:00:40,379:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 14:00:40,379:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 14:00:40,380:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 14:00:40,408:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:00:40,409:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 14:00:40,409:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 14:00:40,410:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 14:00:40,417:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004507 seconds.
2025-06-02 14:00:40,417:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:00:40,419:INFO:[LightGBM] [Info] Total Bins 6220
2025-06-02 14:00:40,435:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 94
2025-06-02 14:00:40,437:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:00:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:00:40,733:INFO:Uploading results into container
2025-06-02 14:00:40,737:INFO:Uploading model into container now
2025-06-02 14:00:40,738:INFO:_master_model_container: 21
2025-06-02 14:00:40,739:INFO:_display_container: 3
2025-06-02 14:00:40,743:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06)
2025-06-02 14:00:40,743:INFO:create_model() successfully completed......................................
2025-06-02 14:00:42,095:INFO:SubProcess create_model() end ==================================
2025-06-02 14:00:42,095:INFO:choose_better activated
2025-06-02 14:00:42,104:INFO:SubProcess create_model() called ==================================
2025-06-02 14:00:42,106:INFO:Initializing create_model()
2025-06-02 14:00:42,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:00:42,106:INFO:Checking exceptions
2025-06-02 14:00:42,110:INFO:Importing libraries
2025-06-02 14:00:42,110:INFO:Copying training dataset
2025-06-02 14:00:42,178:INFO:Defining folds
2025-06-02 14:00:42,178:INFO:Declaring metric variables
2025-06-02 14:00:42,178:INFO:Importing untrained model
2025-06-02 14:00:42,178:INFO:Declaring custom model
2025-06-02 14:00:42,181:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:00:42,181:INFO:Starting cross validation
2025-06-02 14:00:42,184:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:00:44,125:INFO:Calculating mean and std
2025-06-02 14:00:44,126:INFO:Creating metrics dataframe
2025-06-02 14:00:44,131:INFO:Finalizing model
2025-06-02 14:00:44,533:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:00:44,541:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006126 seconds.
2025-06-02 14:00:44,541:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:00:44,542:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 14:00:44,543:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 14:00:44,544:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:00:44,762:INFO:Uploading results into container
2025-06-02 14:00:44,763:INFO:Uploading model into container now
2025-06-02 14:00:44,764:INFO:_master_model_container: 22
2025-06-02 14:00:44,764:INFO:_display_container: 4
2025-06-02 14:00:44,765:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:00:44,765:INFO:create_model() successfully completed......................................
2025-06-02 14:00:46,189:INFO:SubProcess create_model() end ==================================
2025-06-02 14:00:46,191:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8764
2025-06-02 14:00:46,194:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06) result for R2 is 0.8217
2025-06-02 14:00:46,195:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 14:00:46,196:INFO:choose_better completed
2025-06-02 14:00:46,196:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 14:00:46,215:INFO:_master_model_container: 22
2025-06-02 14:00:46,215:INFO:_display_container: 3
2025-06-02 14:00:46,216:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:00:46,217:INFO:tune_model() successfully completed......................................
2025-06-02 14:00:47,531:INFO:Initializing finalize_model()
2025-06-02 14:00:47,531:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 14:00:47,532:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:00:47,569:INFO:Initializing create_model()
2025-06-02 14:00:47,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:00:47,569:INFO:Checking exceptions
2025-06-02 14:00:47,572:INFO:Importing libraries
2025-06-02 14:00:47,572:INFO:Copying training dataset
2025-06-02 14:00:47,578:INFO:Defining folds
2025-06-02 14:00:47,579:INFO:Declaring metric variables
2025-06-02 14:00:47,579:INFO:Importing untrained model
2025-06-02 14:00:47,579:INFO:Declaring custom model
2025-06-02 14:00:47,581:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:00:47,584:INFO:Cross validation set to False
2025-06-02 14:00:47,584:INFO:Fitting Model
2025-06-02 14:00:48,011:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:00:48,018:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005096 seconds.
2025-06-02 14:00:48,019:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:00:48,019:INFO:[LightGBM] [Info] Total Bins 6237
2025-06-02 14:00:48,020:INFO:[LightGBM] [Info] Number of data points in the train set: 4478, number of used features: 95
2025-06-02 14:00:48,021:INFO:[LightGBM] [Info] Start training from score -0.483793
2025-06-02 14:00:48,238:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:00:48,238:INFO:create_model() successfully completed......................................
2025-06-02 14:00:49,466:INFO:_master_model_container: 22
2025-06-02 14:00:49,466:INFO:_display_container: 3
2025-06-02 14:00:49,482:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:00:49,482:INFO:finalize_model() successfully completed......................................
2025-06-02 14:00:50,788:INFO:Initializing save_model()
2025-06-02 14:00:50,788:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 14:00:50,788:INFO:Adding model into prep_pipe
2025-06-02 14:00:50,788:WARNING:Only Model saved as it was a pipeline.
2025-06-02 14:00:50,814:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 14:00:50,836:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:00:50,836:INFO:save_model() successfully completed......................................
2025-06-02 14:00:52,137:INFO:Initializing predict_model()
2025-06-02 14:00:52,137:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7361E10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6D70DA290>)
2025-06-02 14:00:52,138:INFO:Checking exceptions
2025-06-02 14:00:52,138:INFO:Preloading libraries
2025-06-02 14:09:42,976:INFO:PyCaret RegressionExperiment
2025-06-02 14:09:42,978:INFO:Logging name: reg-default-name
2025-06-02 14:09:42,978:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 14:09:42,978:INFO:version 3.3.2
2025-06-02 14:09:42,979:INFO:Initializing setup()
2025-06-02 14:09:42,979:INFO:self.USI: 5494
2025-06-02 14:09:42,979:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 14:09:42,979:INFO:Checking environment
2025-06-02 14:09:42,980:INFO:python_version: 3.10.16
2025-06-02 14:09:42,980:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 14:09:42,980:INFO:machine: AMD64
2025-06-02 14:09:42,980:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 14:09:42,990:INFO:Memory: svmem(total=6378008576, available=1007996928, percent=84.2, used=5370011648, free=1007996928)
2025-06-02 14:09:42,991:INFO:Physical Core: 4
2025-06-02 14:09:42,992:INFO:Logical Core: 8
2025-06-02 14:09:42,992:INFO:Checking libraries
2025-06-02 14:09:42,993:INFO:System:
2025-06-02 14:09:42,994:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 14:09:42,994:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 14:09:42,995:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 14:09:42,995:INFO:PyCaret required dependencies:
2025-06-02 14:09:43,002:INFO:                 pip: 25.1
2025-06-02 14:09:43,002:INFO:          setuptools: 78.1.1
2025-06-02 14:09:43,002:INFO:             pycaret: 3.3.2
2025-06-02 14:09:43,002:INFO:             IPython: 8.37.0
2025-06-02 14:09:43,003:INFO:          ipywidgets: 8.1.7
2025-06-02 14:09:43,003:INFO:                tqdm: 4.67.1
2025-06-02 14:09:43,003:INFO:               numpy: 1.26.4
2025-06-02 14:09:43,003:INFO:              pandas: 2.0.1
2025-06-02 14:09:43,003:INFO:              jinja2: 3.1.6
2025-06-02 14:09:43,004:INFO:               scipy: 1.10.1
2025-06-02 14:09:43,004:INFO:              joblib: 1.3.2
2025-06-02 14:09:43,004:INFO:             sklearn: 1.4.2
2025-06-02 14:09:43,004:INFO:                pyod: 2.0.5
2025-06-02 14:09:43,004:INFO:            imblearn: 0.13.0
2025-06-02 14:09:43,004:INFO:   category_encoders: 2.7.0
2025-06-02 14:09:43,004:INFO:            lightgbm: 4.6.0
2025-06-02 14:09:43,004:INFO:               numba: 0.61.0
2025-06-02 14:09:43,004:INFO:            requests: 2.32.3
2025-06-02 14:09:43,004:INFO:          matplotlib: 3.7.1
2025-06-02 14:09:43,004:INFO:          scikitplot: 0.3.7
2025-06-02 14:09:43,004:INFO:         yellowbrick: 1.5
2025-06-02 14:09:43,005:INFO:              plotly: 6.1.2
2025-06-02 14:09:43,005:INFO:    plotly-resampler: Not installed
2025-06-02 14:09:43,005:INFO:             kaleido: 0.2.1
2025-06-02 14:09:43,005:INFO:           schemdraw: 0.15
2025-06-02 14:09:43,005:INFO:         statsmodels: 0.14.4
2025-06-02 14:09:43,005:INFO:              sktime: 0.26.0
2025-06-02 14:09:43,005:INFO:               tbats: 1.1.3
2025-06-02 14:09:43,005:INFO:            pmdarima: 2.0.4
2025-06-02 14:09:43,005:INFO:              psutil: 7.0.0
2025-06-02 14:09:43,005:INFO:          markupsafe: 2.1.2
2025-06-02 14:09:43,005:INFO:             pickle5: Not installed
2025-06-02 14:09:43,005:INFO:         cloudpickle: 3.1.1
2025-06-02 14:09:43,005:INFO:         deprecation: 2.1.0
2025-06-02 14:09:43,006:INFO:              xxhash: 3.5.0
2025-06-02 14:09:43,006:INFO:           wurlitzer: Not installed
2025-06-02 14:09:43,006:INFO:PyCaret optional dependencies:
2025-06-02 14:09:43,006:INFO:                shap: 0.44.1
2025-06-02 14:09:43,006:INFO:           interpret: 0.6.9
2025-06-02 14:09:43,006:INFO:                umap: 0.5.7
2025-06-02 14:09:43,006:INFO:     ydata_profiling: 4.16.1
2025-06-02 14:09:43,006:INFO:  explainerdashboard: 0.4.8
2025-06-02 14:09:43,006:INFO:             autoviz: Not installed
2025-06-02 14:09:43,006:INFO:           fairlearn: 0.7.0
2025-06-02 14:09:43,007:INFO:          deepchecks: Not installed
2025-06-02 14:09:43,007:INFO:             xgboost: 3.0.2
2025-06-02 14:09:43,007:INFO:            catboost: 1.2.8
2025-06-02 14:09:43,007:INFO:              kmodes: 0.12.2
2025-06-02 14:09:43,007:INFO:             mlxtend: 0.23.4
2025-06-02 14:09:43,007:INFO:       statsforecast: 1.5.0
2025-06-02 14:09:43,007:INFO:        tune_sklearn: Not installed
2025-06-02 14:09:43,007:INFO:                 ray: Not installed
2025-06-02 14:09:43,007:INFO:            hyperopt: 0.2.7
2025-06-02 14:09:43,007:INFO:              optuna: 4.3.0
2025-06-02 14:09:43,007:INFO:               skopt: 0.10.2
2025-06-02 14:09:43,007:INFO:              mlflow: 2.22.0
2025-06-02 14:09:43,007:INFO:              gradio: 5.32.0
2025-06-02 14:09:43,008:INFO:             fastapi: 0.115.12
2025-06-02 14:09:43,008:INFO:             uvicorn: 0.34.3
2025-06-02 14:09:43,008:INFO:              m2cgen: 0.10.0
2025-06-02 14:09:43,008:INFO:           evidently: 0.4.40
2025-06-02 14:09:43,008:INFO:               fugue: 0.8.5
2025-06-02 14:09:43,008:INFO:           streamlit: Not installed
2025-06-02 14:09:43,008:INFO:             prophet: Not installed
2025-06-02 14:09:43,008:INFO:None
2025-06-02 14:09:43,008:INFO:Set up data.
2025-06-02 14:09:43,144:INFO:Set up folding strategy.
2025-06-02 14:09:43,144:INFO:Set up train/test split.
2025-06-02 14:09:43,219:INFO:Set up index.
2025-06-02 14:09:43,223:INFO:Assigning column types.
2025-06-02 14:09:43,288:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 14:09:43,292:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 14:09:43,303:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:09:43,314:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:09:43,468:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:09:43,548:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:09:43,550:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:09:43,562:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:09:43,563:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 14:09:43,571:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:09:43,579:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:09:43,710:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:09:43,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:09:43,797:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:09:43,802:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:09:43,803:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 14:09:43,811:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:09:43,819:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:09:43,961:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:09:44,046:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:09:44,047:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:09:44,052:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:09:44,061:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:09:44,068:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:09:44,211:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:09:44,291:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:09:44,291:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:09:44,295:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:09:44,296:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 14:09:44,311:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:09:44,445:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:09:44,534:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:09:44,535:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:09:44,539:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:09:44,557:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:09:44,702:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:09:44,776:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:09:44,776:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:09:44,780:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:09:44,781:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 14:09:44,929:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:09:45,023:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:09:45,025:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:09:45,030:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:09:45,215:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:09:45,303:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:09:45,305:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:09:45,310:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:09:45,311:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 14:09:45,467:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:09:45,539:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:09:45,543:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:09:45,693:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:09:45,769:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:09:45,774:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:09:45,775:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 14:09:45,999:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:09:46,003:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:09:46,230:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:09:46,234:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:09:46,240:INFO:Preparing preprocessing pipeline...
2025-06-02 14:09:46,240:INFO:Set up simple imputation.
2025-06-02 14:09:46,240:INFO:Set up removing multicollinearity.
2025-06-02 14:09:46,247:INFO:Set up column name cleaning.
2025-06-02 14:09:46,473:INFO:Finished creating preprocessing pipeline.
2025-06-02 14:09:46,485:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 14:09:46,486:INFO:Creating final display dataframe.
2025-06-02 14:09:46,886:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              5494
2025-06-02 14:09:47,134:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:09:47,138:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:09:47,353:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:09:47,357:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:09:47,360:INFO:setup() successfully completed in 4.54s...............
2025-06-02 14:09:47,361:INFO:Initializing compare_models()
2025-06-02 14:09:47,361:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 14:09:47,361:INFO:Checking exceptions
2025-06-02 14:09:47,381:INFO:Preparing display monitor
2025-06-02 14:09:47,449:INFO:Initializing Linear Regression
2025-06-02 14:09:47,449:INFO:Total runtime is 1.665353775024414e-05 minutes
2025-06-02 14:09:47,462:INFO:SubProcess create_model() called ==================================
2025-06-02 14:09:47,465:INFO:Initializing create_model()
2025-06-02 14:09:47,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:09:47,466:INFO:Checking exceptions
2025-06-02 14:09:47,466:INFO:Importing libraries
2025-06-02 14:09:47,466:INFO:Copying training dataset
2025-06-02 14:09:47,556:INFO:Defining folds
2025-06-02 14:09:47,557:INFO:Declaring metric variables
2025-06-02 14:09:47,567:INFO:Importing untrained model
2025-06-02 14:09:47,583:INFO:Linear Regression Imported successfully
2025-06-02 14:09:47,605:INFO:Starting cross validation
2025-06-02 14:09:47,610:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:10:02,124:INFO:Calculating mean and std
2025-06-02 14:10:02,132:INFO:Creating metrics dataframe
2025-06-02 14:10:02,148:INFO:Uploading results into container
2025-06-02 14:10:02,151:INFO:Uploading model into container now
2025-06-02 14:10:02,154:INFO:_master_model_container: 1
2025-06-02 14:10:02,155:INFO:_display_container: 2
2025-06-02 14:10:02,157:INFO:LinearRegression(n_jobs=-1)
2025-06-02 14:10:02,158:INFO:create_model() successfully completed......................................
2025-06-02 14:10:10,646:INFO:SubProcess create_model() end ==================================
2025-06-02 14:10:10,647:INFO:Creating metrics dataframe
2025-06-02 14:10:10,693:INFO:Initializing Lasso Regression
2025-06-02 14:10:10,694:INFO:Total runtime is 0.3874298453330994 minutes
2025-06-02 14:10:10,709:INFO:SubProcess create_model() called ==================================
2025-06-02 14:10:10,710:INFO:Initializing create_model()
2025-06-02 14:10:10,711:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:10:10,711:INFO:Checking exceptions
2025-06-02 14:10:10,711:INFO:Importing libraries
2025-06-02 14:10:10,713:INFO:Copying training dataset
2025-06-02 14:10:10,823:INFO:Defining folds
2025-06-02 14:10:10,824:INFO:Declaring metric variables
2025-06-02 14:10:10,837:INFO:Importing untrained model
2025-06-02 14:10:10,848:INFO:Lasso Regression Imported successfully
2025-06-02 14:10:10,879:INFO:Starting cross validation
2025-06-02 14:10:10,883:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:10:20,784:INFO:Calculating mean and std
2025-06-02 14:10:20,788:INFO:Creating metrics dataframe
2025-06-02 14:10:20,795:INFO:Uploading results into container
2025-06-02 14:10:20,797:INFO:Uploading model into container now
2025-06-02 14:10:20,798:INFO:_master_model_container: 2
2025-06-02 14:10:20,798:INFO:_display_container: 2
2025-06-02 14:10:20,800:INFO:Lasso(random_state=123)
2025-06-02 14:10:20,800:INFO:create_model() successfully completed......................................
2025-06-02 14:10:21,960:INFO:SubProcess create_model() end ==================================
2025-06-02 14:10:21,960:INFO:Creating metrics dataframe
2025-06-02 14:10:21,976:INFO:Initializing Ridge Regression
2025-06-02 14:10:21,976:INFO:Total runtime is 0.5754711627960205 minutes
2025-06-02 14:10:21,987:INFO:SubProcess create_model() called ==================================
2025-06-02 14:10:21,988:INFO:Initializing create_model()
2025-06-02 14:10:21,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:10:21,988:INFO:Checking exceptions
2025-06-02 14:10:21,988:INFO:Importing libraries
2025-06-02 14:10:21,988:INFO:Copying training dataset
2025-06-02 14:10:22,057:INFO:Defining folds
2025-06-02 14:10:22,057:INFO:Declaring metric variables
2025-06-02 14:10:22,070:INFO:Importing untrained model
2025-06-02 14:10:22,082:INFO:Ridge Regression Imported successfully
2025-06-02 14:10:22,107:INFO:Starting cross validation
2025-06-02 14:10:22,112:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:10:22,728:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31073e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:10:22,728:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.75561e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:10:22,769:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.24347e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:10:22,806:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.08754e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:10:22,911:INFO:Calculating mean and std
2025-06-02 14:10:22,912:INFO:Creating metrics dataframe
2025-06-02 14:10:22,915:INFO:Uploading results into container
2025-06-02 14:10:22,916:INFO:Uploading model into container now
2025-06-02 14:10:22,917:INFO:_master_model_container: 3
2025-06-02 14:10:22,918:INFO:_display_container: 2
2025-06-02 14:10:22,918:INFO:Ridge(random_state=123)
2025-06-02 14:10:22,919:INFO:create_model() successfully completed......................................
2025-06-02 14:10:24,077:INFO:SubProcess create_model() end ==================================
2025-06-02 14:10:24,077:INFO:Creating metrics dataframe
2025-06-02 14:10:24,096:INFO:Initializing Elastic Net
2025-06-02 14:10:24,097:INFO:Total runtime is 0.6108149568239848 minutes
2025-06-02 14:10:24,107:INFO:SubProcess create_model() called ==================================
2025-06-02 14:10:24,108:INFO:Initializing create_model()
2025-06-02 14:10:24,108:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:10:24,108:INFO:Checking exceptions
2025-06-02 14:10:24,108:INFO:Importing libraries
2025-06-02 14:10:24,109:INFO:Copying training dataset
2025-06-02 14:10:24,175:INFO:Defining folds
2025-06-02 14:10:24,176:INFO:Declaring metric variables
2025-06-02 14:10:24,189:INFO:Importing untrained model
2025-06-02 14:10:24,202:INFO:Elastic Net Imported successfully
2025-06-02 14:10:24,228:INFO:Starting cross validation
2025-06-02 14:10:24,233:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:10:25,174:INFO:Calculating mean and std
2025-06-02 14:10:25,177:INFO:Creating metrics dataframe
2025-06-02 14:10:25,181:INFO:Uploading results into container
2025-06-02 14:10:25,182:INFO:Uploading model into container now
2025-06-02 14:10:25,183:INFO:_master_model_container: 4
2025-06-02 14:10:25,184:INFO:_display_container: 2
2025-06-02 14:10:25,186:INFO:ElasticNet(random_state=123)
2025-06-02 14:10:25,186:INFO:create_model() successfully completed......................................
2025-06-02 14:10:26,295:INFO:SubProcess create_model() end ==================================
2025-06-02 14:10:26,296:INFO:Creating metrics dataframe
2025-06-02 14:10:26,311:INFO:Initializing Least Angle Regression
2025-06-02 14:10:26,311:INFO:Total runtime is 0.647710116704305 minutes
2025-06-02 14:10:26,320:INFO:SubProcess create_model() called ==================================
2025-06-02 14:10:26,320:INFO:Initializing create_model()
2025-06-02 14:10:26,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:10:26,321:INFO:Checking exceptions
2025-06-02 14:10:26,322:INFO:Importing libraries
2025-06-02 14:10:26,322:INFO:Copying training dataset
2025-06-02 14:10:26,396:INFO:Defining folds
2025-06-02 14:10:26,397:INFO:Declaring metric variables
2025-06-02 14:10:26,410:INFO:Importing untrained model
2025-06-02 14:10:26,421:INFO:Least Angle Regression Imported successfully
2025-06-02 14:10:26,446:INFO:Starting cross validation
2025-06-02 14:10:26,450:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:10:27,554:INFO:Calculating mean and std
2025-06-02 14:10:27,558:INFO:Creating metrics dataframe
2025-06-02 14:10:27,561:INFO:Uploading results into container
2025-06-02 14:10:27,564:INFO:Uploading model into container now
2025-06-02 14:10:27,564:INFO:_master_model_container: 5
2025-06-02 14:10:27,564:INFO:_display_container: 2
2025-06-02 14:10:27,566:INFO:Lars(random_state=123)
2025-06-02 14:10:27,566:INFO:create_model() successfully completed......................................
2025-06-02 14:10:28,707:INFO:SubProcess create_model() end ==================================
2025-06-02 14:10:28,707:INFO:Creating metrics dataframe
2025-06-02 14:10:28,724:INFO:Initializing Lasso Least Angle Regression
2025-06-02 14:10:28,724:INFO:Total runtime is 0.6879276315371196 minutes
2025-06-02 14:10:28,734:INFO:SubProcess create_model() called ==================================
2025-06-02 14:10:28,735:INFO:Initializing create_model()
2025-06-02 14:10:28,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:10:28,736:INFO:Checking exceptions
2025-06-02 14:10:28,736:INFO:Importing libraries
2025-06-02 14:10:28,736:INFO:Copying training dataset
2025-06-02 14:10:28,805:INFO:Defining folds
2025-06-02 14:10:28,806:INFO:Declaring metric variables
2025-06-02 14:10:28,816:INFO:Importing untrained model
2025-06-02 14:10:28,830:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 14:10:28,857:INFO:Starting cross validation
2025-06-02 14:10:28,862:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:10:29,634:INFO:Calculating mean and std
2025-06-02 14:10:29,637:INFO:Creating metrics dataframe
2025-06-02 14:10:29,640:INFO:Uploading results into container
2025-06-02 14:10:29,641:INFO:Uploading model into container now
2025-06-02 14:10:29,641:INFO:_master_model_container: 6
2025-06-02 14:10:29,642:INFO:_display_container: 2
2025-06-02 14:10:29,642:INFO:LassoLars(random_state=123)
2025-06-02 14:10:29,643:INFO:create_model() successfully completed......................................
2025-06-02 14:10:30,798:INFO:SubProcess create_model() end ==================================
2025-06-02 14:10:30,799:INFO:Creating metrics dataframe
2025-06-02 14:10:30,816:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 14:10:30,816:INFO:Total runtime is 0.7227954109509787 minutes
2025-06-02 14:10:30,825:INFO:SubProcess create_model() called ==================================
2025-06-02 14:10:30,826:INFO:Initializing create_model()
2025-06-02 14:10:30,826:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:10:30,826:INFO:Checking exceptions
2025-06-02 14:10:30,826:INFO:Importing libraries
2025-06-02 14:10:30,827:INFO:Copying training dataset
2025-06-02 14:10:30,910:INFO:Defining folds
2025-06-02 14:10:30,911:INFO:Declaring metric variables
2025-06-02 14:10:30,925:INFO:Importing untrained model
2025-06-02 14:10:30,939:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 14:10:30,964:INFO:Starting cross validation
2025-06-02 14:10:30,970:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:10:31,739:INFO:Calculating mean and std
2025-06-02 14:10:31,743:INFO:Creating metrics dataframe
2025-06-02 14:10:31,747:INFO:Uploading results into container
2025-06-02 14:10:31,748:INFO:Uploading model into container now
2025-06-02 14:10:31,749:INFO:_master_model_container: 7
2025-06-02 14:10:31,749:INFO:_display_container: 2
2025-06-02 14:10:31,750:INFO:OrthogonalMatchingPursuit()
2025-06-02 14:10:31,750:INFO:create_model() successfully completed......................................
2025-06-02 14:10:32,890:INFO:SubProcess create_model() end ==================================
2025-06-02 14:10:32,890:INFO:Creating metrics dataframe
2025-06-02 14:10:32,909:INFO:Initializing Bayesian Ridge
2025-06-02 14:10:32,909:INFO:Total runtime is 0.7576816399892172 minutes
2025-06-02 14:10:32,918:INFO:SubProcess create_model() called ==================================
2025-06-02 14:10:32,919:INFO:Initializing create_model()
2025-06-02 14:10:32,919:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:10:32,921:INFO:Checking exceptions
2025-06-02 14:10:32,922:INFO:Importing libraries
2025-06-02 14:10:32,922:INFO:Copying training dataset
2025-06-02 14:10:32,996:INFO:Defining folds
2025-06-02 14:10:32,997:INFO:Declaring metric variables
2025-06-02 14:10:33,009:INFO:Importing untrained model
2025-06-02 14:10:33,021:INFO:Bayesian Ridge Imported successfully
2025-06-02 14:10:33,045:INFO:Starting cross validation
2025-06-02 14:10:33,049:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:10:34,043:INFO:Calculating mean and std
2025-06-02 14:10:34,045:INFO:Creating metrics dataframe
2025-06-02 14:10:34,048:INFO:Uploading results into container
2025-06-02 14:10:34,049:INFO:Uploading model into container now
2025-06-02 14:10:34,049:INFO:_master_model_container: 8
2025-06-02 14:10:34,049:INFO:_display_container: 2
2025-06-02 14:10:34,050:INFO:BayesianRidge()
2025-06-02 14:10:34,050:INFO:create_model() successfully completed......................................
2025-06-02 14:10:35,208:INFO:SubProcess create_model() end ==================================
2025-06-02 14:10:35,209:INFO:Creating metrics dataframe
2025-06-02 14:10:35,226:INFO:Initializing Passive Aggressive Regressor
2025-06-02 14:10:35,226:INFO:Total runtime is 0.7963038484255474 minutes
2025-06-02 14:10:35,234:INFO:SubProcess create_model() called ==================================
2025-06-02 14:10:35,235:INFO:Initializing create_model()
2025-06-02 14:10:35,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:10:35,236:INFO:Checking exceptions
2025-06-02 14:10:35,236:INFO:Importing libraries
2025-06-02 14:10:35,236:INFO:Copying training dataset
2025-06-02 14:10:35,313:INFO:Defining folds
2025-06-02 14:10:35,313:INFO:Declaring metric variables
2025-06-02 14:10:35,326:INFO:Importing untrained model
2025-06-02 14:10:35,336:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 14:10:35,363:INFO:Starting cross validation
2025-06-02 14:10:35,367:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:10:36,165:INFO:Calculating mean and std
2025-06-02 14:10:36,168:INFO:Creating metrics dataframe
2025-06-02 14:10:36,173:INFO:Uploading results into container
2025-06-02 14:10:36,174:INFO:Uploading model into container now
2025-06-02 14:10:36,175:INFO:_master_model_container: 9
2025-06-02 14:10:36,176:INFO:_display_container: 2
2025-06-02 14:10:36,177:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 14:10:36,177:INFO:create_model() successfully completed......................................
2025-06-02 14:10:37,305:INFO:SubProcess create_model() end ==================================
2025-06-02 14:10:37,305:INFO:Creating metrics dataframe
2025-06-02 14:10:37,326:INFO:Initializing Huber Regressor
2025-06-02 14:10:37,326:INFO:Total runtime is 0.8312896688779196 minutes
2025-06-02 14:10:37,337:INFO:SubProcess create_model() called ==================================
2025-06-02 14:10:37,337:INFO:Initializing create_model()
2025-06-02 14:10:37,338:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:10:37,338:INFO:Checking exceptions
2025-06-02 14:10:37,338:INFO:Importing libraries
2025-06-02 14:10:37,338:INFO:Copying training dataset
2025-06-02 14:10:37,404:INFO:Defining folds
2025-06-02 14:10:37,405:INFO:Declaring metric variables
2025-06-02 14:10:37,420:INFO:Importing untrained model
2025-06-02 14:10:37,433:INFO:Huber Regressor Imported successfully
2025-06-02 14:10:37,459:INFO:Starting cross validation
2025-06-02 14:10:37,463:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:10:39,079:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:10:39,174:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:10:39,196:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:10:39,210:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:10:39,217:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:10:39,276:INFO:Calculating mean and std
2025-06-02 14:10:39,279:INFO:Creating metrics dataframe
2025-06-02 14:10:39,282:INFO:Uploading results into container
2025-06-02 14:10:39,283:INFO:Uploading model into container now
2025-06-02 14:10:39,285:INFO:_master_model_container: 10
2025-06-02 14:10:39,285:INFO:_display_container: 2
2025-06-02 14:10:39,286:INFO:HuberRegressor()
2025-06-02 14:10:39,286:INFO:create_model() successfully completed......................................
2025-06-02 14:10:40,404:INFO:SubProcess create_model() end ==================================
2025-06-02 14:10:40,404:INFO:Creating metrics dataframe
2025-06-02 14:10:40,421:INFO:Initializing K Neighbors Regressor
2025-06-02 14:10:40,422:INFO:Total runtime is 0.8829044977823893 minutes
2025-06-02 14:10:40,430:INFO:SubProcess create_model() called ==================================
2025-06-02 14:10:40,431:INFO:Initializing create_model()
2025-06-02 14:10:40,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:10:40,431:INFO:Checking exceptions
2025-06-02 14:10:40,431:INFO:Importing libraries
2025-06-02 14:10:40,432:INFO:Copying training dataset
2025-06-02 14:10:40,501:INFO:Defining folds
2025-06-02 14:10:40,501:INFO:Declaring metric variables
2025-06-02 14:10:40,514:INFO:Importing untrained model
2025-06-02 14:10:40,526:INFO:K Neighbors Regressor Imported successfully
2025-06-02 14:10:40,552:INFO:Starting cross validation
2025-06-02 14:10:40,557:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:10:41,604:INFO:Calculating mean and std
2025-06-02 14:10:41,606:INFO:Creating metrics dataframe
2025-06-02 14:10:41,611:INFO:Uploading results into container
2025-06-02 14:10:41,612:INFO:Uploading model into container now
2025-06-02 14:10:41,613:INFO:_master_model_container: 11
2025-06-02 14:10:41,613:INFO:_display_container: 2
2025-06-02 14:10:41,614:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 14:10:41,614:INFO:create_model() successfully completed......................................
2025-06-02 14:10:42,763:INFO:SubProcess create_model() end ==================================
2025-06-02 14:10:42,763:INFO:Creating metrics dataframe
2025-06-02 14:10:42,780:INFO:Initializing Decision Tree Regressor
2025-06-02 14:10:42,781:INFO:Total runtime is 0.9222222328186035 minutes
2025-06-02 14:10:42,790:INFO:SubProcess create_model() called ==================================
2025-06-02 14:10:42,791:INFO:Initializing create_model()
2025-06-02 14:10:42,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:10:42,791:INFO:Checking exceptions
2025-06-02 14:10:42,792:INFO:Importing libraries
2025-06-02 14:10:42,792:INFO:Copying training dataset
2025-06-02 14:10:42,865:INFO:Defining folds
2025-06-02 14:10:42,865:INFO:Declaring metric variables
2025-06-02 14:10:42,877:INFO:Importing untrained model
2025-06-02 14:10:42,892:INFO:Decision Tree Regressor Imported successfully
2025-06-02 14:10:42,916:INFO:Starting cross validation
2025-06-02 14:10:42,920:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:10:43,854:INFO:Calculating mean and std
2025-06-02 14:10:43,856:INFO:Creating metrics dataframe
2025-06-02 14:10:43,859:INFO:Uploading results into container
2025-06-02 14:10:43,860:INFO:Uploading model into container now
2025-06-02 14:10:43,862:INFO:_master_model_container: 12
2025-06-02 14:10:43,862:INFO:_display_container: 2
2025-06-02 14:10:43,863:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 14:10:43,863:INFO:create_model() successfully completed......................................
2025-06-02 14:10:45,011:INFO:SubProcess create_model() end ==================================
2025-06-02 14:10:45,011:INFO:Creating metrics dataframe
2025-06-02 14:10:45,034:INFO:Initializing Random Forest Regressor
2025-06-02 14:10:45,034:INFO:Total runtime is 0.959770389397939 minutes
2025-06-02 14:10:45,045:INFO:SubProcess create_model() called ==================================
2025-06-02 14:10:45,045:INFO:Initializing create_model()
2025-06-02 14:10:45,046:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:10:45,046:INFO:Checking exceptions
2025-06-02 14:10:45,046:INFO:Importing libraries
2025-06-02 14:10:45,046:INFO:Copying training dataset
2025-06-02 14:10:45,119:INFO:Defining folds
2025-06-02 14:10:45,119:INFO:Declaring metric variables
2025-06-02 14:10:45,130:INFO:Importing untrained model
2025-06-02 14:10:45,144:INFO:Random Forest Regressor Imported successfully
2025-06-02 14:10:45,169:INFO:Starting cross validation
2025-06-02 14:10:45,173:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:10:53,672:INFO:Calculating mean and std
2025-06-02 14:10:53,675:INFO:Creating metrics dataframe
2025-06-02 14:10:53,680:INFO:Uploading results into container
2025-06-02 14:10:53,681:INFO:Uploading model into container now
2025-06-02 14:10:53,682:INFO:_master_model_container: 13
2025-06-02 14:10:53,682:INFO:_display_container: 2
2025-06-02 14:10:53,683:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:10:53,684:INFO:create_model() successfully completed......................................
2025-06-02 14:10:54,828:INFO:SubProcess create_model() end ==================================
2025-06-02 14:10:54,829:INFO:Creating metrics dataframe
2025-06-02 14:10:54,851:INFO:Initializing Extra Trees Regressor
2025-06-02 14:10:54,851:INFO:Total runtime is 1.1233727097511292 minutes
2025-06-02 14:10:54,861:INFO:SubProcess create_model() called ==================================
2025-06-02 14:10:54,862:INFO:Initializing create_model()
2025-06-02 14:10:54,862:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:10:54,862:INFO:Checking exceptions
2025-06-02 14:10:54,863:INFO:Importing libraries
2025-06-02 14:10:54,863:INFO:Copying training dataset
2025-06-02 14:10:54,933:INFO:Defining folds
2025-06-02 14:10:54,934:INFO:Declaring metric variables
2025-06-02 14:10:54,958:INFO:Importing untrained model
2025-06-02 14:10:54,991:INFO:Extra Trees Regressor Imported successfully
2025-06-02 14:10:55,036:INFO:Starting cross validation
2025-06-02 14:10:55,041:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:11:00,918:INFO:Calculating mean and std
2025-06-02 14:11:00,921:INFO:Creating metrics dataframe
2025-06-02 14:11:00,924:INFO:Uploading results into container
2025-06-02 14:11:00,925:INFO:Uploading model into container now
2025-06-02 14:11:00,925:INFO:_master_model_container: 14
2025-06-02 14:11:00,926:INFO:_display_container: 2
2025-06-02 14:11:00,926:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:11:00,927:INFO:create_model() successfully completed......................................
2025-06-02 14:11:02,245:INFO:SubProcess create_model() end ==================================
2025-06-02 14:11:02,246:INFO:Creating metrics dataframe
2025-06-02 14:11:02,265:INFO:Initializing AdaBoost Regressor
2025-06-02 14:11:02,265:INFO:Total runtime is 1.2469454328219096 minutes
2025-06-02 14:11:02,275:INFO:SubProcess create_model() called ==================================
2025-06-02 14:11:02,275:INFO:Initializing create_model()
2025-06-02 14:11:02,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:11:02,276:INFO:Checking exceptions
2025-06-02 14:11:02,276:INFO:Importing libraries
2025-06-02 14:11:02,277:INFO:Copying training dataset
2025-06-02 14:11:02,345:INFO:Defining folds
2025-06-02 14:11:02,346:INFO:Declaring metric variables
2025-06-02 14:11:02,358:INFO:Importing untrained model
2025-06-02 14:11:02,369:INFO:AdaBoost Regressor Imported successfully
2025-06-02 14:11:02,393:INFO:Starting cross validation
2025-06-02 14:11:02,397:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:11:04,508:INFO:Calculating mean and std
2025-06-02 14:11:04,511:INFO:Creating metrics dataframe
2025-06-02 14:11:04,514:INFO:Uploading results into container
2025-06-02 14:11:04,515:INFO:Uploading model into container now
2025-06-02 14:11:04,516:INFO:_master_model_container: 15
2025-06-02 14:11:04,516:INFO:_display_container: 2
2025-06-02 14:11:04,516:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 14:11:04,516:INFO:create_model() successfully completed......................................
2025-06-02 14:11:05,661:INFO:SubProcess create_model() end ==================================
2025-06-02 14:11:05,662:INFO:Creating metrics dataframe
2025-06-02 14:11:05,689:INFO:Initializing Gradient Boosting Regressor
2025-06-02 14:11:05,689:INFO:Total runtime is 1.3040165026982626 minutes
2025-06-02 14:11:05,698:INFO:SubProcess create_model() called ==================================
2025-06-02 14:11:05,699:INFO:Initializing create_model()
2025-06-02 14:11:05,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:11:05,699:INFO:Checking exceptions
2025-06-02 14:11:05,700:INFO:Importing libraries
2025-06-02 14:11:05,700:INFO:Copying training dataset
2025-06-02 14:11:05,772:INFO:Defining folds
2025-06-02 14:11:05,773:INFO:Declaring metric variables
2025-06-02 14:11:05,784:INFO:Importing untrained model
2025-06-02 14:11:05,797:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 14:11:05,822:INFO:Starting cross validation
2025-06-02 14:11:05,827:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:11:09,289:INFO:Calculating mean and std
2025-06-02 14:11:09,291:INFO:Creating metrics dataframe
2025-06-02 14:11:09,294:INFO:Uploading results into container
2025-06-02 14:11:09,295:INFO:Uploading model into container now
2025-06-02 14:11:09,296:INFO:_master_model_container: 16
2025-06-02 14:11:09,296:INFO:_display_container: 2
2025-06-02 14:11:09,297:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 14:11:09,297:INFO:create_model() successfully completed......................................
2025-06-02 14:11:10,442:INFO:SubProcess create_model() end ==================================
2025-06-02 14:11:10,442:INFO:Creating metrics dataframe
2025-06-02 14:11:10,463:INFO:Initializing Extreme Gradient Boosting
2025-06-02 14:11:10,463:INFO:Total runtime is 1.3835814356803895 minutes
2025-06-02 14:11:10,473:INFO:SubProcess create_model() called ==================================
2025-06-02 14:11:10,473:INFO:Initializing create_model()
2025-06-02 14:11:10,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:11:10,474:INFO:Checking exceptions
2025-06-02 14:11:10,474:INFO:Importing libraries
2025-06-02 14:11:10,474:INFO:Copying training dataset
2025-06-02 14:11:10,556:INFO:Defining folds
2025-06-02 14:11:10,556:INFO:Declaring metric variables
2025-06-02 14:11:10,569:INFO:Importing untrained model
2025-06-02 14:11:10,583:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 14:11:10,609:INFO:Starting cross validation
2025-06-02 14:11:10,613:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:11:12,925:INFO:Calculating mean and std
2025-06-02 14:11:12,927:INFO:Creating metrics dataframe
2025-06-02 14:11:12,930:INFO:Uploading results into container
2025-06-02 14:11:12,931:INFO:Uploading model into container now
2025-06-02 14:11:12,932:INFO:_master_model_container: 17
2025-06-02 14:11:12,932:INFO:_display_container: 2
2025-06-02 14:11:12,937:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 14:11:12,938:INFO:create_model() successfully completed......................................
2025-06-02 14:11:14,074:INFO:SubProcess create_model() end ==================================
2025-06-02 14:11:14,074:INFO:Creating metrics dataframe
2025-06-02 14:11:14,096:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 14:11:14,096:INFO:Total runtime is 1.4441280603408815 minutes
2025-06-02 14:11:14,105:INFO:SubProcess create_model() called ==================================
2025-06-02 14:11:14,106:INFO:Initializing create_model()
2025-06-02 14:11:14,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:11:14,107:INFO:Checking exceptions
2025-06-02 14:11:14,107:INFO:Importing libraries
2025-06-02 14:11:14,107:INFO:Copying training dataset
2025-06-02 14:11:14,183:INFO:Defining folds
2025-06-02 14:11:14,183:INFO:Declaring metric variables
2025-06-02 14:11:14,196:INFO:Importing untrained model
2025-06-02 14:11:14,208:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:11:14,233:INFO:Starting cross validation
2025-06-02 14:11:14,238:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:11:15,986:INFO:Calculating mean and std
2025-06-02 14:11:15,988:INFO:Creating metrics dataframe
2025-06-02 14:11:15,994:INFO:Uploading results into container
2025-06-02 14:11:15,995:INFO:Uploading model into container now
2025-06-02 14:11:15,996:INFO:_master_model_container: 18
2025-06-02 14:11:15,996:INFO:_display_container: 2
2025-06-02 14:11:15,998:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:11:15,998:INFO:create_model() successfully completed......................................
2025-06-02 14:11:17,143:INFO:SubProcess create_model() end ==================================
2025-06-02 14:11:17,143:INFO:Creating metrics dataframe
2025-06-02 14:11:17,166:INFO:Initializing CatBoost Regressor
2025-06-02 14:11:17,166:INFO:Total runtime is 1.4952973127365115 minutes
2025-06-02 14:11:17,175:INFO:SubProcess create_model() called ==================================
2025-06-02 14:11:17,176:INFO:Initializing create_model()
2025-06-02 14:11:17,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:11:17,177:INFO:Checking exceptions
2025-06-02 14:11:17,177:INFO:Importing libraries
2025-06-02 14:11:17,177:INFO:Copying training dataset
2025-06-02 14:11:17,251:INFO:Defining folds
2025-06-02 14:11:17,252:INFO:Declaring metric variables
2025-06-02 14:11:17,265:INFO:Importing untrained model
2025-06-02 14:11:17,288:INFO:CatBoost Regressor Imported successfully
2025-06-02 14:11:17,312:INFO:Starting cross validation
2025-06-02 14:11:17,316:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:11:41,436:INFO:Calculating mean and std
2025-06-02 14:11:41,439:INFO:Creating metrics dataframe
2025-06-02 14:11:41,444:INFO:Uploading results into container
2025-06-02 14:11:41,445:INFO:Uploading model into container now
2025-06-02 14:11:41,446:INFO:_master_model_container: 19
2025-06-02 14:11:41,446:INFO:_display_container: 2
2025-06-02 14:11:41,447:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6D827E290>
2025-06-02 14:11:41,447:INFO:create_model() successfully completed......................................
2025-06-02 14:11:42,761:INFO:SubProcess create_model() end ==================================
2025-06-02 14:11:42,761:INFO:Creating metrics dataframe
2025-06-02 14:11:42,786:INFO:Initializing Dummy Regressor
2025-06-02 14:11:42,787:INFO:Total runtime is 1.9223123153050743 minutes
2025-06-02 14:11:42,799:INFO:SubProcess create_model() called ==================================
2025-06-02 14:11:42,800:INFO:Initializing create_model()
2025-06-02 14:11:42,800:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BAF69300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:11:42,801:INFO:Checking exceptions
2025-06-02 14:11:42,801:INFO:Importing libraries
2025-06-02 14:11:42,801:INFO:Copying training dataset
2025-06-02 14:11:42,900:INFO:Defining folds
2025-06-02 14:11:42,901:INFO:Declaring metric variables
2025-06-02 14:11:42,914:INFO:Importing untrained model
2025-06-02 14:11:42,927:INFO:Dummy Regressor Imported successfully
2025-06-02 14:11:42,957:INFO:Starting cross validation
2025-06-02 14:11:42,962:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:11:43,902:INFO:Calculating mean and std
2025-06-02 14:11:43,905:INFO:Creating metrics dataframe
2025-06-02 14:11:43,910:INFO:Uploading results into container
2025-06-02 14:11:43,911:INFO:Uploading model into container now
2025-06-02 14:11:43,912:INFO:_master_model_container: 20
2025-06-02 14:11:43,913:INFO:_display_container: 2
2025-06-02 14:11:43,913:INFO:DummyRegressor()
2025-06-02 14:11:43,913:INFO:create_model() successfully completed......................................
2025-06-02 14:11:45,180:INFO:SubProcess create_model() end ==================================
2025-06-02 14:11:45,181:INFO:Creating metrics dataframe
2025-06-02 14:11:45,231:INFO:Initializing create_model()
2025-06-02 14:11:45,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:11:45,232:INFO:Checking exceptions
2025-06-02 14:11:45,242:INFO:Importing libraries
2025-06-02 14:11:45,243:INFO:Copying training dataset
2025-06-02 14:11:45,316:INFO:Defining folds
2025-06-02 14:11:45,317:INFO:Declaring metric variables
2025-06-02 14:11:45,317:INFO:Importing untrained model
2025-06-02 14:11:45,317:INFO:Declaring custom model
2025-06-02 14:11:45,320:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:11:45,323:INFO:Cross validation set to False
2025-06-02 14:11:45,324:INFO:Fitting Model
2025-06-02 14:11:46,010:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:11:46,026:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009208 seconds.
2025-06-02 14:11:46,027:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:11:46,027:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 14:11:46,037:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 14:11:46,039:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:11:46,221:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:11:46,221:INFO:create_model() successfully completed......................................
2025-06-02 14:11:47,439:INFO:_master_model_container: 20
2025-06-02 14:11:47,439:INFO:_display_container: 2
2025-06-02 14:11:47,440:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:11:47,441:INFO:compare_models() successfully completed......................................
2025-06-02 14:11:47,465:INFO:Initializing tune_model()
2025-06-02 14:11:47,465:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>)
2025-06-02 14:11:47,465:INFO:Checking exceptions
2025-06-02 14:11:47,465:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 14:11:47,515:INFO:Copying training dataset
2025-06-02 14:11:47,576:INFO:Checking base model
2025-06-02 14:11:47,577:INFO:Base model : Light Gradient Boosting Machine
2025-06-02 14:11:47,592:INFO:Declaring metric variables
2025-06-02 14:11:47,608:INFO:Defining Hyperparameters
2025-06-02 14:11:48,943:INFO:Tuning with n_jobs=-1
2025-06-02 14:11:48,962:INFO:Initializing skopt.BayesSearchCV
2025-06-02 14:12:06,859:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.8608120752388259), ('actual_estimator__bagging_freq', 1), ('actual_estimator__feature_fraction', 0.4284489606984907), ('actual_estimator__learning_rate', 0.016133245419918712), ('actual_estimator__min_child_samples', 95), ('actual_estimator__min_split_gain', 0.8209314243567916), ('actual_estimator__n_estimators', 239), ('actual_estimator__num_leaves', 183), ('actual_estimator__reg_alpha', 8.662569304197528e-07), ('actual_estimator__reg_lambda', 5.001062744294253e-06)])
2025-06-02 14:12:06,862:INFO:Hyperparameter search completed
2025-06-02 14:12:06,862:INFO:SubProcess create_model() called ==================================
2025-06-02 14:12:06,864:INFO:Initializing create_model()
2025-06-02 14:12:06,864:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B699D2B3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.8608120752388259, 'bagging_freq': 1, 'feature_fraction': 0.4284489606984907, 'learning_rate': 0.016133245419918712, 'min_child_samples': 95, 'min_split_gain': 0.8209314243567916, 'n_estimators': 239, 'num_leaves': 183, 'reg_alpha': 8.662569304197528e-07, 'reg_lambda': 5.001062744294253e-06})
2025-06-02 14:12:06,864:INFO:Checking exceptions
2025-06-02 14:12:06,864:INFO:Importing libraries
2025-06-02 14:12:06,865:INFO:Copying training dataset
2025-06-02 14:12:06,928:INFO:Defining folds
2025-06-02 14:12:06,929:INFO:Declaring metric variables
2025-06-02 14:12:06,940:INFO:Importing untrained model
2025-06-02 14:12:06,940:INFO:Declaring custom model
2025-06-02 14:12:06,957:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:12:06,977:INFO:Starting cross validation
2025-06-02 14:12:06,981:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:12:08,728:INFO:Calculating mean and std
2025-06-02 14:12:08,730:INFO:Creating metrics dataframe
2025-06-02 14:12:08,746:INFO:Finalizing model
2025-06-02 14:12:09,120:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 14:12:09,120:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 14:12:09,120:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 14:12:09,141:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:12:09,143:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 14:12:09,143:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 14:12:09,143:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 14:12:09,155:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008271 seconds.
2025-06-02 14:12:09,155:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:12:09,156:INFO:[LightGBM] [Info] Total Bins 6220
2025-06-02 14:12:09,176:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 94
2025-06-02 14:12:09,178:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:12:09,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:12:09,413:INFO:Uploading results into container
2025-06-02 14:12:09,415:INFO:Uploading model into container now
2025-06-02 14:12:09,416:INFO:_master_model_container: 21
2025-06-02 14:12:09,417:INFO:_display_container: 3
2025-06-02 14:12:09,420:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06)
2025-06-02 14:12:09,421:INFO:create_model() successfully completed......................................
2025-06-02 14:12:10,725:INFO:SubProcess create_model() end ==================================
2025-06-02 14:12:10,727:INFO:choose_better activated
2025-06-02 14:12:10,736:INFO:SubProcess create_model() called ==================================
2025-06-02 14:12:10,737:INFO:Initializing create_model()
2025-06-02 14:12:10,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:12:10,738:INFO:Checking exceptions
2025-06-02 14:12:10,741:INFO:Importing libraries
2025-06-02 14:12:10,742:INFO:Copying training dataset
2025-06-02 14:12:10,804:INFO:Defining folds
2025-06-02 14:12:10,804:INFO:Declaring metric variables
2025-06-02 14:12:10,804:INFO:Importing untrained model
2025-06-02 14:12:10,804:INFO:Declaring custom model
2025-06-02 14:12:10,807:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:12:10,807:INFO:Starting cross validation
2025-06-02 14:12:10,811:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:12:12,350:INFO:Calculating mean and std
2025-06-02 14:12:12,351:INFO:Creating metrics dataframe
2025-06-02 14:12:12,355:INFO:Finalizing model
2025-06-02 14:12:12,769:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:12:12,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004041 seconds.
2025-06-02 14:12:12,776:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:12:12,776:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 14:12:12,777:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 14:12:12,778:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:12:12,983:INFO:Uploading results into container
2025-06-02 14:12:12,984:INFO:Uploading model into container now
2025-06-02 14:12:12,986:INFO:_master_model_container: 22
2025-06-02 14:12:12,986:INFO:_display_container: 4
2025-06-02 14:12:12,987:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:12:12,987:INFO:create_model() successfully completed......................................
2025-06-02 14:12:14,347:INFO:SubProcess create_model() end ==================================
2025-06-02 14:12:14,349:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8764
2025-06-02 14:12:14,352:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06) result for R2 is 0.8217
2025-06-02 14:12:14,353:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 14:12:14,354:INFO:choose_better completed
2025-06-02 14:12:14,354:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 14:12:14,380:INFO:_master_model_container: 22
2025-06-02 14:12:14,381:INFO:_display_container: 3
2025-06-02 14:12:14,382:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:12:14,382:INFO:tune_model() successfully completed......................................
2025-06-02 14:12:15,605:INFO:Initializing finalize_model()
2025-06-02 14:12:15,606:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 14:12:15,606:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:12:15,648:INFO:Initializing create_model()
2025-06-02 14:12:15,648:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:12:15,648:INFO:Checking exceptions
2025-06-02 14:12:15,650:INFO:Importing libraries
2025-06-02 14:12:15,650:INFO:Copying training dataset
2025-06-02 14:12:15,656:INFO:Defining folds
2025-06-02 14:12:15,656:INFO:Declaring metric variables
2025-06-02 14:12:15,657:INFO:Importing untrained model
2025-06-02 14:12:15,657:INFO:Declaring custom model
2025-06-02 14:12:15,659:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:12:15,663:INFO:Cross validation set to False
2025-06-02 14:12:15,664:INFO:Fitting Model
2025-06-02 14:12:16,062:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:12:16,066:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002917 seconds.
2025-06-02 14:12:16,066:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:12:16,067:INFO:[LightGBM] [Info] Total Bins 6237
2025-06-02 14:12:16,068:INFO:[LightGBM] [Info] Number of data points in the train set: 4478, number of used features: 95
2025-06-02 14:12:16,069:INFO:[LightGBM] [Info] Start training from score -0.483793
2025-06-02 14:12:16,253:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:12:16,253:INFO:create_model() successfully completed......................................
2025-06-02 14:12:17,393:INFO:_master_model_container: 22
2025-06-02 14:12:17,394:INFO:_display_container: 3
2025-06-02 14:12:17,408:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:12:17,408:INFO:finalize_model() successfully completed......................................
2025-06-02 14:12:18,593:INFO:Initializing save_model()
2025-06-02 14:12:18,593:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 14:12:18,593:INFO:Adding model into prep_pipe
2025-06-02 14:12:18,593:WARNING:Only Model saved as it was a pipeline.
2025-06-02 14:12:18,611:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 14:12:18,633:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:12:18,634:INFO:save_model() successfully completed......................................
2025-06-02 14:12:19,825:INFO:Initializing predict_model()
2025-06-02 14:12:19,825:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D7E50DC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6D80CE0E0>)
2025-06-02 14:12:19,825:INFO:Checking exceptions
2025-06-02 14:12:19,826:INFO:Preloading libraries
2025-06-02 14:19:25,344:INFO:PyCaret RegressionExperiment
2025-06-02 14:19:25,346:INFO:Logging name: reg-default-name
2025-06-02 14:19:25,347:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 14:19:25,347:INFO:version 3.3.2
2025-06-02 14:19:25,347:INFO:Initializing setup()
2025-06-02 14:19:25,347:INFO:self.USI: 5ecd
2025-06-02 14:19:25,347:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 14:19:25,348:INFO:Checking environment
2025-06-02 14:19:25,348:INFO:python_version: 3.10.16
2025-06-02 14:19:25,348:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 14:19:25,348:INFO:machine: AMD64
2025-06-02 14:19:25,349:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 14:19:25,356:INFO:Memory: svmem(total=6378008576, available=721162240, percent=88.7, used=5656846336, free=721162240)
2025-06-02 14:19:25,357:INFO:Physical Core: 4
2025-06-02 14:19:25,357:INFO:Logical Core: 8
2025-06-02 14:19:25,358:INFO:Checking libraries
2025-06-02 14:19:25,359:INFO:System:
2025-06-02 14:19:25,360:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 14:19:25,360:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 14:19:25,360:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 14:19:25,360:INFO:PyCaret required dependencies:
2025-06-02 14:19:25,364:INFO:                 pip: 25.1
2025-06-02 14:19:25,364:INFO:          setuptools: 78.1.1
2025-06-02 14:19:25,364:INFO:             pycaret: 3.3.2
2025-06-02 14:19:25,364:INFO:             IPython: 8.37.0
2025-06-02 14:19:25,364:INFO:          ipywidgets: 8.1.7
2025-06-02 14:19:25,364:INFO:                tqdm: 4.67.1
2025-06-02 14:19:25,365:INFO:               numpy: 1.26.4
2025-06-02 14:19:25,365:INFO:              pandas: 2.0.1
2025-06-02 14:19:25,365:INFO:              jinja2: 3.1.6
2025-06-02 14:19:25,365:INFO:               scipy: 1.10.1
2025-06-02 14:19:25,365:INFO:              joblib: 1.3.2
2025-06-02 14:19:25,365:INFO:             sklearn: 1.4.2
2025-06-02 14:19:25,365:INFO:                pyod: 2.0.5
2025-06-02 14:19:25,365:INFO:            imblearn: 0.13.0
2025-06-02 14:19:25,366:INFO:   category_encoders: 2.7.0
2025-06-02 14:19:25,366:INFO:            lightgbm: 4.6.0
2025-06-02 14:19:25,366:INFO:               numba: 0.61.0
2025-06-02 14:19:25,366:INFO:            requests: 2.32.3
2025-06-02 14:19:25,366:INFO:          matplotlib: 3.7.1
2025-06-02 14:19:25,366:INFO:          scikitplot: 0.3.7
2025-06-02 14:19:25,366:INFO:         yellowbrick: 1.5
2025-06-02 14:19:25,366:INFO:              plotly: 6.1.2
2025-06-02 14:19:25,366:INFO:    plotly-resampler: Not installed
2025-06-02 14:19:25,366:INFO:             kaleido: 0.2.1
2025-06-02 14:19:25,366:INFO:           schemdraw: 0.15
2025-06-02 14:19:25,367:INFO:         statsmodels: 0.14.4
2025-06-02 14:19:25,367:INFO:              sktime: 0.26.0
2025-06-02 14:19:25,367:INFO:               tbats: 1.1.3
2025-06-02 14:19:25,367:INFO:            pmdarima: 2.0.4
2025-06-02 14:19:25,367:INFO:              psutil: 7.0.0
2025-06-02 14:19:25,367:INFO:          markupsafe: 2.1.2
2025-06-02 14:19:25,367:INFO:             pickle5: Not installed
2025-06-02 14:19:25,367:INFO:         cloudpickle: 3.1.1
2025-06-02 14:19:25,368:INFO:         deprecation: 2.1.0
2025-06-02 14:19:25,368:INFO:              xxhash: 3.5.0
2025-06-02 14:19:25,368:INFO:           wurlitzer: Not installed
2025-06-02 14:19:25,368:INFO:PyCaret optional dependencies:
2025-06-02 14:19:25,368:INFO:                shap: 0.44.1
2025-06-02 14:19:25,368:INFO:           interpret: 0.6.9
2025-06-02 14:19:25,368:INFO:                umap: 0.5.7
2025-06-02 14:19:25,368:INFO:     ydata_profiling: 4.16.1
2025-06-02 14:19:25,368:INFO:  explainerdashboard: 0.4.8
2025-06-02 14:19:25,368:INFO:             autoviz: Not installed
2025-06-02 14:19:25,369:INFO:           fairlearn: 0.7.0
2025-06-02 14:19:25,369:INFO:          deepchecks: Not installed
2025-06-02 14:19:25,369:INFO:             xgboost: 3.0.2
2025-06-02 14:19:25,369:INFO:            catboost: 1.2.8
2025-06-02 14:19:25,369:INFO:              kmodes: 0.12.2
2025-06-02 14:19:25,369:INFO:             mlxtend: 0.23.4
2025-06-02 14:19:25,369:INFO:       statsforecast: 1.5.0
2025-06-02 14:19:25,369:INFO:        tune_sklearn: Not installed
2025-06-02 14:19:25,369:INFO:                 ray: Not installed
2025-06-02 14:19:25,369:INFO:            hyperopt: 0.2.7
2025-06-02 14:19:25,369:INFO:              optuna: 4.3.0
2025-06-02 14:19:25,370:INFO:               skopt: 0.10.2
2025-06-02 14:19:25,370:INFO:              mlflow: 2.22.0
2025-06-02 14:19:25,370:INFO:              gradio: 5.32.0
2025-06-02 14:19:25,370:INFO:             fastapi: 0.115.12
2025-06-02 14:19:25,370:INFO:             uvicorn: 0.34.3
2025-06-02 14:19:25,370:INFO:              m2cgen: 0.10.0
2025-06-02 14:19:25,370:INFO:           evidently: 0.4.40
2025-06-02 14:19:25,370:INFO:               fugue: 0.8.5
2025-06-02 14:19:25,370:INFO:           streamlit: Not installed
2025-06-02 14:19:25,370:INFO:             prophet: Not installed
2025-06-02 14:19:25,371:INFO:None
2025-06-02 14:19:25,372:INFO:Set up data.
2025-06-02 14:19:25,480:INFO:Set up folding strategy.
2025-06-02 14:19:25,480:INFO:Set up train/test split.
2025-06-02 14:19:25,539:INFO:Set up index.
2025-06-02 14:19:25,541:INFO:Assigning column types.
2025-06-02 14:19:25,605:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 14:19:25,608:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 14:19:25,620:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:19:25,628:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:19:25,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:19:25,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:19:25,835:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:19:25,843:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:19:25,844:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 14:19:25,851:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:19:25,859:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:19:25,989:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,069:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,070:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:19:26,074:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:19:26,075:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 14:19:26,083:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,091:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,221:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,297:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,298:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:19:26,302:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:19:26,311:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,318:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,448:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,521:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,522:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:19:26,526:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:19:26,527:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 14:19:26,542:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,684:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,760:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,761:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:19:26,765:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:19:26,780:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,912:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,986:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:19:26,987:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:19:26,991:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:19:26,992:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 14:19:27,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:19:27,209:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:19:27,210:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:19:27,214:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:19:27,365:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:19:27,444:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:19:27,445:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:19:27,449:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:19:27,450:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 14:19:27,601:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:19:27,678:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:19:27,682:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:19:27,842:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:19:27,918:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:19:27,922:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:19:27,923:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 14:19:28,151:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:19:28,156:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:19:28,372:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:19:28,376:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:19:28,383:INFO:Preparing preprocessing pipeline...
2025-06-02 14:19:28,383:INFO:Set up simple imputation.
2025-06-02 14:19:28,383:INFO:Set up removing multicollinearity.
2025-06-02 14:19:28,391:INFO:Set up column name cleaning.
2025-06-02 14:19:28,629:INFO:Finished creating preprocessing pipeline.
2025-06-02 14:19:28,644:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 14:19:28,645:INFO:Creating final display dataframe.
2025-06-02 14:19:29,048:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              5ecd
2025-06-02 14:19:29,308:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:19:29,312:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:19:29,527:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:19:29,531:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:19:29,534:INFO:setup() successfully completed in 4.32s...............
2025-06-02 14:19:29,536:INFO:Initializing compare_models()
2025-06-02 14:19:29,536:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 14:19:29,536:INFO:Checking exceptions
2025-06-02 14:19:29,557:INFO:Preparing display monitor
2025-06-02 14:19:29,624:INFO:Initializing Linear Regression
2025-06-02 14:19:29,625:INFO:Total runtime is 1.6701221466064452e-05 minutes
2025-06-02 14:19:29,639:INFO:SubProcess create_model() called ==================================
2025-06-02 14:19:29,640:INFO:Initializing create_model()
2025-06-02 14:19:29,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:19:29,641:INFO:Checking exceptions
2025-06-02 14:19:29,641:INFO:Importing libraries
2025-06-02 14:19:29,642:INFO:Copying training dataset
2025-06-02 14:19:29,721:INFO:Defining folds
2025-06-02 14:19:29,721:INFO:Declaring metric variables
2025-06-02 14:19:29,731:INFO:Importing untrained model
2025-06-02 14:19:29,742:INFO:Linear Regression Imported successfully
2025-06-02 14:19:29,772:INFO:Starting cross validation
2025-06-02 14:19:29,777:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:19:43,907:INFO:Calculating mean and std
2025-06-02 14:19:43,920:INFO:Creating metrics dataframe
2025-06-02 14:19:43,949:INFO:Uploading results into container
2025-06-02 14:19:43,955:INFO:Uploading model into container now
2025-06-02 14:19:43,958:INFO:_master_model_container: 1
2025-06-02 14:19:43,958:INFO:_display_container: 2
2025-06-02 14:19:43,959:INFO:LinearRegression(n_jobs=-1)
2025-06-02 14:19:43,959:INFO:create_model() successfully completed......................................
2025-06-02 14:19:54,987:INFO:SubProcess create_model() end ==================================
2025-06-02 14:19:54,988:INFO:Creating metrics dataframe
2025-06-02 14:19:55,028:INFO:Initializing Lasso Regression
2025-06-02 14:19:55,028:INFO:Total runtime is 0.42340139945348104 minutes
2025-06-02 14:19:55,046:INFO:SubProcess create_model() called ==================================
2025-06-02 14:19:55,047:INFO:Initializing create_model()
2025-06-02 14:19:55,048:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:19:55,048:INFO:Checking exceptions
2025-06-02 14:19:55,049:INFO:Importing libraries
2025-06-02 14:19:55,049:INFO:Copying training dataset
2025-06-02 14:19:55,200:INFO:Defining folds
2025-06-02 14:19:55,201:INFO:Declaring metric variables
2025-06-02 14:19:55,215:INFO:Importing untrained model
2025-06-02 14:19:55,228:INFO:Lasso Regression Imported successfully
2025-06-02 14:19:55,252:INFO:Starting cross validation
2025-06-02 14:19:55,257:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:05,841:INFO:Calculating mean and std
2025-06-02 14:20:05,846:INFO:Creating metrics dataframe
2025-06-02 14:20:05,859:INFO:Uploading results into container
2025-06-02 14:20:05,862:INFO:Uploading model into container now
2025-06-02 14:20:05,863:INFO:_master_model_container: 2
2025-06-02 14:20:05,864:INFO:_display_container: 2
2025-06-02 14:20:05,871:INFO:Lasso(random_state=123)
2025-06-02 14:20:05,871:INFO:create_model() successfully completed......................................
2025-06-02 14:20:07,211:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:07,211:INFO:Creating metrics dataframe
2025-06-02 14:20:07,235:INFO:Initializing Ridge Regression
2025-06-02 14:20:07,237:INFO:Total runtime is 0.6268736799558003 minutes
2025-06-02 14:20:07,248:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:07,248:INFO:Initializing create_model()
2025-06-02 14:20:07,248:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:07,249:INFO:Checking exceptions
2025-06-02 14:20:07,249:INFO:Importing libraries
2025-06-02 14:20:07,249:INFO:Copying training dataset
2025-06-02 14:20:07,320:INFO:Defining folds
2025-06-02 14:20:07,320:INFO:Declaring metric variables
2025-06-02 14:20:07,332:INFO:Importing untrained model
2025-06-02 14:20:07,346:INFO:Ridge Regression Imported successfully
2025-06-02 14:20:07,373:INFO:Starting cross validation
2025-06-02 14:20:07,377:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:07,964:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.75561e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:20:08,037:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31073e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:20:08,118:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.24347e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:20:08,119:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.08754e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:20:08,251:INFO:Calculating mean and std
2025-06-02 14:20:08,254:INFO:Creating metrics dataframe
2025-06-02 14:20:08,260:INFO:Uploading results into container
2025-06-02 14:20:08,261:INFO:Uploading model into container now
2025-06-02 14:20:08,262:INFO:_master_model_container: 3
2025-06-02 14:20:08,263:INFO:_display_container: 2
2025-06-02 14:20:08,263:INFO:Ridge(random_state=123)
2025-06-02 14:20:08,263:INFO:create_model() successfully completed......................................
2025-06-02 14:20:09,448:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:09,448:INFO:Creating metrics dataframe
2025-06-02 14:20:09,466:INFO:Initializing Elastic Net
2025-06-02 14:20:09,466:INFO:Total runtime is 0.6640378514925639 minutes
2025-06-02 14:20:09,477:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:09,477:INFO:Initializing create_model()
2025-06-02 14:20:09,478:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:09,478:INFO:Checking exceptions
2025-06-02 14:20:09,478:INFO:Importing libraries
2025-06-02 14:20:09,479:INFO:Copying training dataset
2025-06-02 14:20:09,545:INFO:Defining folds
2025-06-02 14:20:09,546:INFO:Declaring metric variables
2025-06-02 14:20:09,558:INFO:Importing untrained model
2025-06-02 14:20:09,570:INFO:Elastic Net Imported successfully
2025-06-02 14:20:09,595:INFO:Starting cross validation
2025-06-02 14:20:09,598:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:10,687:INFO:Calculating mean and std
2025-06-02 14:20:10,689:INFO:Creating metrics dataframe
2025-06-02 14:20:10,693:INFO:Uploading results into container
2025-06-02 14:20:10,694:INFO:Uploading model into container now
2025-06-02 14:20:10,694:INFO:_master_model_container: 4
2025-06-02 14:20:10,694:INFO:_display_container: 2
2025-06-02 14:20:10,695:INFO:ElasticNet(random_state=123)
2025-06-02 14:20:10,695:INFO:create_model() successfully completed......................................
2025-06-02 14:20:11,842:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:11,842:INFO:Creating metrics dataframe
2025-06-02 14:20:11,862:INFO:Initializing Least Angle Regression
2025-06-02 14:20:11,863:INFO:Total runtime is 0.7039782762527466 minutes
2025-06-02 14:20:11,872:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:11,872:INFO:Initializing create_model()
2025-06-02 14:20:11,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:11,873:INFO:Checking exceptions
2025-06-02 14:20:11,873:INFO:Importing libraries
2025-06-02 14:20:11,874:INFO:Copying training dataset
2025-06-02 14:20:11,961:INFO:Defining folds
2025-06-02 14:20:11,962:INFO:Declaring metric variables
2025-06-02 14:20:11,975:INFO:Importing untrained model
2025-06-02 14:20:11,987:INFO:Least Angle Regression Imported successfully
2025-06-02 14:20:12,008:INFO:Starting cross validation
2025-06-02 14:20:12,013:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:12,825:INFO:Calculating mean and std
2025-06-02 14:20:12,828:INFO:Creating metrics dataframe
2025-06-02 14:20:12,831:INFO:Uploading results into container
2025-06-02 14:20:12,832:INFO:Uploading model into container now
2025-06-02 14:20:12,832:INFO:_master_model_container: 5
2025-06-02 14:20:12,833:INFO:_display_container: 2
2025-06-02 14:20:12,835:INFO:Lars(random_state=123)
2025-06-02 14:20:12,835:INFO:create_model() successfully completed......................................
2025-06-02 14:20:14,158:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:14,159:INFO:Creating metrics dataframe
2025-06-02 14:20:14,179:INFO:Initializing Lasso Least Angle Regression
2025-06-02 14:20:14,179:INFO:Total runtime is 0.7425758679707845 minutes
2025-06-02 14:20:14,189:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:14,190:INFO:Initializing create_model()
2025-06-02 14:20:14,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:14,191:INFO:Checking exceptions
2025-06-02 14:20:14,191:INFO:Importing libraries
2025-06-02 14:20:14,191:INFO:Copying training dataset
2025-06-02 14:20:14,263:INFO:Defining folds
2025-06-02 14:20:14,264:INFO:Declaring metric variables
2025-06-02 14:20:14,275:INFO:Importing untrained model
2025-06-02 14:20:14,287:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 14:20:14,314:INFO:Starting cross validation
2025-06-02 14:20:14,319:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:15,153:INFO:Calculating mean and std
2025-06-02 14:20:15,156:INFO:Creating metrics dataframe
2025-06-02 14:20:15,159:INFO:Uploading results into container
2025-06-02 14:20:15,160:INFO:Uploading model into container now
2025-06-02 14:20:15,161:INFO:_master_model_container: 6
2025-06-02 14:20:15,161:INFO:_display_container: 2
2025-06-02 14:20:15,162:INFO:LassoLars(random_state=123)
2025-06-02 14:20:15,162:INFO:create_model() successfully completed......................................
2025-06-02 14:20:16,420:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:16,420:INFO:Creating metrics dataframe
2025-06-02 14:20:16,439:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 14:20:16,440:INFO:Total runtime is 0.7802660425504048 minutes
2025-06-02 14:20:16,449:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:16,449:INFO:Initializing create_model()
2025-06-02 14:20:16,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:16,450:INFO:Checking exceptions
2025-06-02 14:20:16,450:INFO:Importing libraries
2025-06-02 14:20:16,451:INFO:Copying training dataset
2025-06-02 14:20:16,523:INFO:Defining folds
2025-06-02 14:20:16,524:INFO:Declaring metric variables
2025-06-02 14:20:16,537:INFO:Importing untrained model
2025-06-02 14:20:16,549:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 14:20:16,574:INFO:Starting cross validation
2025-06-02 14:20:16,578:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:17,343:INFO:Calculating mean and std
2025-06-02 14:20:17,346:INFO:Creating metrics dataframe
2025-06-02 14:20:17,349:INFO:Uploading results into container
2025-06-02 14:20:17,350:INFO:Uploading model into container now
2025-06-02 14:20:17,351:INFO:_master_model_container: 7
2025-06-02 14:20:17,351:INFO:_display_container: 2
2025-06-02 14:20:17,351:INFO:OrthogonalMatchingPursuit()
2025-06-02 14:20:17,352:INFO:create_model() successfully completed......................................
2025-06-02 14:20:18,540:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:18,540:INFO:Creating metrics dataframe
2025-06-02 14:20:18,557:INFO:Initializing Bayesian Ridge
2025-06-02 14:20:18,557:INFO:Total runtime is 0.8155562798182169 minutes
2025-06-02 14:20:18,565:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:18,566:INFO:Initializing create_model()
2025-06-02 14:20:18,567:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:18,567:INFO:Checking exceptions
2025-06-02 14:20:18,568:INFO:Importing libraries
2025-06-02 14:20:18,568:INFO:Copying training dataset
2025-06-02 14:20:18,644:INFO:Defining folds
2025-06-02 14:20:18,645:INFO:Declaring metric variables
2025-06-02 14:20:18,656:INFO:Importing untrained model
2025-06-02 14:20:18,668:INFO:Bayesian Ridge Imported successfully
2025-06-02 14:20:18,694:INFO:Starting cross validation
2025-06-02 14:20:18,697:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:19,748:INFO:Calculating mean and std
2025-06-02 14:20:19,751:INFO:Creating metrics dataframe
2025-06-02 14:20:19,754:INFO:Uploading results into container
2025-06-02 14:20:19,755:INFO:Uploading model into container now
2025-06-02 14:20:19,756:INFO:_master_model_container: 8
2025-06-02 14:20:19,756:INFO:_display_container: 2
2025-06-02 14:20:19,757:INFO:BayesianRidge()
2025-06-02 14:20:19,757:INFO:create_model() successfully completed......................................
2025-06-02 14:20:21,062:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:21,062:INFO:Creating metrics dataframe
2025-06-02 14:20:21,081:INFO:Initializing Passive Aggressive Regressor
2025-06-02 14:20:21,082:INFO:Total runtime is 0.8576258222262064 minutes
2025-06-02 14:20:21,094:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:21,095:INFO:Initializing create_model()
2025-06-02 14:20:21,095:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:21,096:INFO:Checking exceptions
2025-06-02 14:20:21,096:INFO:Importing libraries
2025-06-02 14:20:21,097:INFO:Copying training dataset
2025-06-02 14:20:21,167:INFO:Defining folds
2025-06-02 14:20:21,167:INFO:Declaring metric variables
2025-06-02 14:20:21,179:INFO:Importing untrained model
2025-06-02 14:20:21,192:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 14:20:21,216:INFO:Starting cross validation
2025-06-02 14:20:21,221:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:21,996:INFO:Calculating mean and std
2025-06-02 14:20:21,999:INFO:Creating metrics dataframe
2025-06-02 14:20:22,004:INFO:Uploading results into container
2025-06-02 14:20:22,004:INFO:Uploading model into container now
2025-06-02 14:20:22,005:INFO:_master_model_container: 9
2025-06-02 14:20:22,005:INFO:_display_container: 2
2025-06-02 14:20:22,006:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 14:20:22,006:INFO:create_model() successfully completed......................................
2025-06-02 14:20:23,187:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:23,188:INFO:Creating metrics dataframe
2025-06-02 14:20:23,203:INFO:Initializing Huber Regressor
2025-06-02 14:20:23,203:INFO:Total runtime is 0.8929800550142923 minutes
2025-06-02 14:20:23,213:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:23,214:INFO:Initializing create_model()
2025-06-02 14:20:23,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:23,214:INFO:Checking exceptions
2025-06-02 14:20:23,214:INFO:Importing libraries
2025-06-02 14:20:23,214:INFO:Copying training dataset
2025-06-02 14:20:23,282:INFO:Defining folds
2025-06-02 14:20:23,283:INFO:Declaring metric variables
2025-06-02 14:20:23,295:INFO:Importing untrained model
2025-06-02 14:20:23,307:INFO:Huber Regressor Imported successfully
2025-06-02 14:20:23,329:INFO:Starting cross validation
2025-06-02 14:20:23,332:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:24,886:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:20:24,904:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:20:24,936:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:20:24,976:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:20:24,983:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:20:25,048:INFO:Calculating mean and std
2025-06-02 14:20:25,050:INFO:Creating metrics dataframe
2025-06-02 14:20:25,053:INFO:Uploading results into container
2025-06-02 14:20:25,054:INFO:Uploading model into container now
2025-06-02 14:20:25,055:INFO:_master_model_container: 10
2025-06-02 14:20:25,055:INFO:_display_container: 2
2025-06-02 14:20:25,056:INFO:HuberRegressor()
2025-06-02 14:20:25,056:INFO:create_model() successfully completed......................................
2025-06-02 14:20:26,230:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:26,231:INFO:Creating metrics dataframe
2025-06-02 14:20:26,250:INFO:Initializing K Neighbors Regressor
2025-06-02 14:20:26,250:INFO:Total runtime is 0.9437705397605896 minutes
2025-06-02 14:20:26,258:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:26,259:INFO:Initializing create_model()
2025-06-02 14:20:26,259:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:26,259:INFO:Checking exceptions
2025-06-02 14:20:26,260:INFO:Importing libraries
2025-06-02 14:20:26,260:INFO:Copying training dataset
2025-06-02 14:20:26,328:INFO:Defining folds
2025-06-02 14:20:26,328:INFO:Declaring metric variables
2025-06-02 14:20:26,341:INFO:Importing untrained model
2025-06-02 14:20:26,352:INFO:K Neighbors Regressor Imported successfully
2025-06-02 14:20:26,375:INFO:Starting cross validation
2025-06-02 14:20:26,380:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:27,215:INFO:Calculating mean and std
2025-06-02 14:20:27,217:INFO:Creating metrics dataframe
2025-06-02 14:20:27,221:INFO:Uploading results into container
2025-06-02 14:20:27,221:INFO:Uploading model into container now
2025-06-02 14:20:27,222:INFO:_master_model_container: 11
2025-06-02 14:20:27,222:INFO:_display_container: 2
2025-06-02 14:20:27,223:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 14:20:27,223:INFO:create_model() successfully completed......................................
2025-06-02 14:20:28,380:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:28,380:INFO:Creating metrics dataframe
2025-06-02 14:20:28,400:INFO:Initializing Decision Tree Regressor
2025-06-02 14:20:28,401:INFO:Total runtime is 0.9796188314755757 minutes
2025-06-02 14:20:28,409:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:28,409:INFO:Initializing create_model()
2025-06-02 14:20:28,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:28,410:INFO:Checking exceptions
2025-06-02 14:20:28,410:INFO:Importing libraries
2025-06-02 14:20:28,411:INFO:Copying training dataset
2025-06-02 14:20:28,489:INFO:Defining folds
2025-06-02 14:20:28,490:INFO:Declaring metric variables
2025-06-02 14:20:28,502:INFO:Importing untrained model
2025-06-02 14:20:28,514:INFO:Decision Tree Regressor Imported successfully
2025-06-02 14:20:28,539:INFO:Starting cross validation
2025-06-02 14:20:28,543:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:29,696:INFO:Calculating mean and std
2025-06-02 14:20:29,698:INFO:Creating metrics dataframe
2025-06-02 14:20:29,703:INFO:Uploading results into container
2025-06-02 14:20:29,704:INFO:Uploading model into container now
2025-06-02 14:20:29,705:INFO:_master_model_container: 12
2025-06-02 14:20:29,705:INFO:_display_container: 2
2025-06-02 14:20:29,706:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 14:20:29,706:INFO:create_model() successfully completed......................................
2025-06-02 14:20:30,861:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:30,861:INFO:Creating metrics dataframe
2025-06-02 14:20:30,878:INFO:Initializing Random Forest Regressor
2025-06-02 14:20:30,878:INFO:Total runtime is 1.0208983341852824 minutes
2025-06-02 14:20:30,887:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:30,888:INFO:Initializing create_model()
2025-06-02 14:20:30,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:30,888:INFO:Checking exceptions
2025-06-02 14:20:30,889:INFO:Importing libraries
2025-06-02 14:20:30,889:INFO:Copying training dataset
2025-06-02 14:20:30,961:INFO:Defining folds
2025-06-02 14:20:30,961:INFO:Declaring metric variables
2025-06-02 14:20:30,972:INFO:Importing untrained model
2025-06-02 14:20:30,987:INFO:Random Forest Regressor Imported successfully
2025-06-02 14:20:31,012:INFO:Starting cross validation
2025-06-02 14:20:31,015:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:40,167:INFO:Calculating mean and std
2025-06-02 14:20:40,170:INFO:Creating metrics dataframe
2025-06-02 14:20:40,174:INFO:Uploading results into container
2025-06-02 14:20:40,175:INFO:Uploading model into container now
2025-06-02 14:20:40,176:INFO:_master_model_container: 13
2025-06-02 14:20:40,176:INFO:_display_container: 2
2025-06-02 14:20:40,177:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:20:40,178:INFO:create_model() successfully completed......................................
2025-06-02 14:20:41,385:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:41,386:INFO:Creating metrics dataframe
2025-06-02 14:20:41,407:INFO:Initializing Extra Trees Regressor
2025-06-02 14:20:41,407:INFO:Total runtime is 1.1963746905326844 minutes
2025-06-02 14:20:41,415:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:41,416:INFO:Initializing create_model()
2025-06-02 14:20:41,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:41,416:INFO:Checking exceptions
2025-06-02 14:20:41,416:INFO:Importing libraries
2025-06-02 14:20:41,417:INFO:Copying training dataset
2025-06-02 14:20:41,488:INFO:Defining folds
2025-06-02 14:20:41,488:INFO:Declaring metric variables
2025-06-02 14:20:41,501:INFO:Importing untrained model
2025-06-02 14:20:41,514:INFO:Extra Trees Regressor Imported successfully
2025-06-02 14:20:41,540:INFO:Starting cross validation
2025-06-02 14:20:41,545:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:47,200:INFO:Calculating mean and std
2025-06-02 14:20:47,203:INFO:Creating metrics dataframe
2025-06-02 14:20:47,208:INFO:Uploading results into container
2025-06-02 14:20:47,209:INFO:Uploading model into container now
2025-06-02 14:20:47,210:INFO:_master_model_container: 14
2025-06-02 14:20:47,210:INFO:_display_container: 2
2025-06-02 14:20:47,211:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:20:47,212:INFO:create_model() successfully completed......................................
2025-06-02 14:20:48,385:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:48,385:INFO:Creating metrics dataframe
2025-06-02 14:20:48,408:INFO:Initializing AdaBoost Regressor
2025-06-02 14:20:48,408:INFO:Total runtime is 1.3130722562472026 minutes
2025-06-02 14:20:48,420:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:48,421:INFO:Initializing create_model()
2025-06-02 14:20:48,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:48,421:INFO:Checking exceptions
2025-06-02 14:20:48,422:INFO:Importing libraries
2025-06-02 14:20:48,422:INFO:Copying training dataset
2025-06-02 14:20:48,492:INFO:Defining folds
2025-06-02 14:20:48,492:INFO:Declaring metric variables
2025-06-02 14:20:48,505:INFO:Importing untrained model
2025-06-02 14:20:48,518:INFO:AdaBoost Regressor Imported successfully
2025-06-02 14:20:48,543:INFO:Starting cross validation
2025-06-02 14:20:48,546:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:50,406:INFO:Calculating mean and std
2025-06-02 14:20:50,409:INFO:Creating metrics dataframe
2025-06-02 14:20:50,414:INFO:Uploading results into container
2025-06-02 14:20:50,415:INFO:Uploading model into container now
2025-06-02 14:20:50,416:INFO:_master_model_container: 15
2025-06-02 14:20:50,416:INFO:_display_container: 2
2025-06-02 14:20:50,417:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 14:20:50,418:INFO:create_model() successfully completed......................................
2025-06-02 14:20:51,573:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:51,574:INFO:Creating metrics dataframe
2025-06-02 14:20:51,599:INFO:Initializing Gradient Boosting Regressor
2025-06-02 14:20:51,600:INFO:Total runtime is 1.3662717421849568 minutes
2025-06-02 14:20:51,611:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:51,612:INFO:Initializing create_model()
2025-06-02 14:20:51,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:51,612:INFO:Checking exceptions
2025-06-02 14:20:51,613:INFO:Importing libraries
2025-06-02 14:20:51,613:INFO:Copying training dataset
2025-06-02 14:20:51,722:INFO:Defining folds
2025-06-02 14:20:51,723:INFO:Declaring metric variables
2025-06-02 14:20:51,748:INFO:Importing untrained model
2025-06-02 14:20:51,771:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 14:20:51,803:INFO:Starting cross validation
2025-06-02 14:20:51,815:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:55,333:INFO:Calculating mean and std
2025-06-02 14:20:55,336:INFO:Creating metrics dataframe
2025-06-02 14:20:55,341:INFO:Uploading results into container
2025-06-02 14:20:55,342:INFO:Uploading model into container now
2025-06-02 14:20:55,343:INFO:_master_model_container: 16
2025-06-02 14:20:55,343:INFO:_display_container: 2
2025-06-02 14:20:55,344:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 14:20:55,345:INFO:create_model() successfully completed......................................
2025-06-02 14:20:56,510:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:56,510:INFO:Creating metrics dataframe
2025-06-02 14:20:56,531:INFO:Initializing Extreme Gradient Boosting
2025-06-02 14:20:56,531:INFO:Total runtime is 1.4484513521194458 minutes
2025-06-02 14:20:56,544:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:56,545:INFO:Initializing create_model()
2025-06-02 14:20:56,545:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:56,546:INFO:Checking exceptions
2025-06-02 14:20:56,546:INFO:Importing libraries
2025-06-02 14:20:56,546:INFO:Copying training dataset
2025-06-02 14:20:56,611:INFO:Defining folds
2025-06-02 14:20:56,611:INFO:Declaring metric variables
2025-06-02 14:20:56,624:INFO:Importing untrained model
2025-06-02 14:20:56,638:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 14:20:56,662:INFO:Starting cross validation
2025-06-02 14:20:56,667:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:20:58,764:INFO:Calculating mean and std
2025-06-02 14:20:58,767:INFO:Creating metrics dataframe
2025-06-02 14:20:58,771:INFO:Uploading results into container
2025-06-02 14:20:58,773:INFO:Uploading model into container now
2025-06-02 14:20:58,774:INFO:_master_model_container: 17
2025-06-02 14:20:58,774:INFO:_display_container: 2
2025-06-02 14:20:58,777:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 14:20:58,778:INFO:create_model() successfully completed......................................
2025-06-02 14:20:59,921:INFO:SubProcess create_model() end ==================================
2025-06-02 14:20:59,922:INFO:Creating metrics dataframe
2025-06-02 14:20:59,943:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 14:20:59,943:INFO:Total runtime is 1.5053187727928161 minutes
2025-06-02 14:20:59,951:INFO:SubProcess create_model() called ==================================
2025-06-02 14:20:59,953:INFO:Initializing create_model()
2025-06-02 14:20:59,953:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:20:59,953:INFO:Checking exceptions
2025-06-02 14:20:59,954:INFO:Importing libraries
2025-06-02 14:20:59,954:INFO:Copying training dataset
2025-06-02 14:21:00,027:INFO:Defining folds
2025-06-02 14:21:00,028:INFO:Declaring metric variables
2025-06-02 14:21:00,043:INFO:Importing untrained model
2025-06-02 14:21:00,056:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:21:00,086:INFO:Starting cross validation
2025-06-02 14:21:00,090:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:21:02,280:INFO:Calculating mean and std
2025-06-02 14:21:02,282:INFO:Creating metrics dataframe
2025-06-02 14:21:02,286:INFO:Uploading results into container
2025-06-02 14:21:02,287:INFO:Uploading model into container now
2025-06-02 14:21:02,288:INFO:_master_model_container: 18
2025-06-02 14:21:02,288:INFO:_display_container: 2
2025-06-02 14:21:02,289:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:21:02,290:INFO:create_model() successfully completed......................................
2025-06-02 14:21:03,480:INFO:SubProcess create_model() end ==================================
2025-06-02 14:21:03,480:INFO:Creating metrics dataframe
2025-06-02 14:21:03,504:INFO:Initializing CatBoost Regressor
2025-06-02 14:21:03,504:INFO:Total runtime is 1.5646589716275532 minutes
2025-06-02 14:21:03,515:INFO:SubProcess create_model() called ==================================
2025-06-02 14:21:03,515:INFO:Initializing create_model()
2025-06-02 14:21:03,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:21:03,516:INFO:Checking exceptions
2025-06-02 14:21:03,516:INFO:Importing libraries
2025-06-02 14:21:03,516:INFO:Copying training dataset
2025-06-02 14:21:03,586:INFO:Defining folds
2025-06-02 14:21:03,586:INFO:Declaring metric variables
2025-06-02 14:21:03,599:INFO:Importing untrained model
2025-06-02 14:21:03,620:INFO:CatBoost Regressor Imported successfully
2025-06-02 14:21:03,647:INFO:Starting cross validation
2025-06-02 14:21:03,651:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:21:30,214:INFO:Calculating mean and std
2025-06-02 14:21:30,218:INFO:Creating metrics dataframe
2025-06-02 14:21:30,223:INFO:Uploading results into container
2025-06-02 14:21:30,224:INFO:Uploading model into container now
2025-06-02 14:21:30,225:INFO:_master_model_container: 19
2025-06-02 14:21:30,225:INFO:_display_container: 2
2025-06-02 14:21:30,226:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6D8DA8850>
2025-06-02 14:21:30,226:INFO:create_model() successfully completed......................................
2025-06-02 14:21:31,509:INFO:SubProcess create_model() end ==================================
2025-06-02 14:21:31,510:INFO:Creating metrics dataframe
2025-06-02 14:21:31,537:INFO:Initializing Dummy Regressor
2025-06-02 14:21:31,537:INFO:Total runtime is 2.0318771719932553 minutes
2025-06-02 14:21:31,548:INFO:SubProcess create_model() called ==================================
2025-06-02 14:21:31,549:INFO:Initializing create_model()
2025-06-02 14:21:31,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D8DAF6A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:21:31,550:INFO:Checking exceptions
2025-06-02 14:21:31,550:INFO:Importing libraries
2025-06-02 14:21:31,550:INFO:Copying training dataset
2025-06-02 14:21:31,630:INFO:Defining folds
2025-06-02 14:21:31,630:INFO:Declaring metric variables
2025-06-02 14:21:31,647:INFO:Importing untrained model
2025-06-02 14:21:31,662:INFO:Dummy Regressor Imported successfully
2025-06-02 14:21:31,689:INFO:Starting cross validation
2025-06-02 14:21:31,694:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:21:32,929:INFO:Calculating mean and std
2025-06-02 14:21:32,932:INFO:Creating metrics dataframe
2025-06-02 14:21:32,936:INFO:Uploading results into container
2025-06-02 14:21:32,937:INFO:Uploading model into container now
2025-06-02 14:21:32,938:INFO:_master_model_container: 20
2025-06-02 14:21:32,938:INFO:_display_container: 2
2025-06-02 14:21:32,939:INFO:DummyRegressor()
2025-06-02 14:21:32,939:INFO:create_model() successfully completed......................................
2025-06-02 14:21:34,131:INFO:SubProcess create_model() end ==================================
2025-06-02 14:21:34,131:INFO:Creating metrics dataframe
2025-06-02 14:21:34,181:INFO:Initializing create_model()
2025-06-02 14:21:34,181:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:21:34,181:INFO:Checking exceptions
2025-06-02 14:21:34,191:INFO:Importing libraries
2025-06-02 14:21:34,192:INFO:Copying training dataset
2025-06-02 14:21:34,262:INFO:Defining folds
2025-06-02 14:21:34,262:INFO:Declaring metric variables
2025-06-02 14:21:34,263:INFO:Importing untrained model
2025-06-02 14:21:34,263:INFO:Declaring custom model
2025-06-02 14:21:34,265:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:21:34,268:INFO:Cross validation set to False
2025-06-02 14:21:34,268:INFO:Fitting Model
2025-06-02 14:21:34,762:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:21:34,773:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006955 seconds.
2025-06-02 14:21:34,773:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:21:34,774:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 14:21:34,783:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 14:21:34,786:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:21:34,996:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:21:34,997:INFO:create_model() successfully completed......................................
2025-06-02 14:21:36,307:INFO:_master_model_container: 20
2025-06-02 14:21:36,307:INFO:_display_container: 2
2025-06-02 14:21:36,308:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:21:36,309:INFO:compare_models() successfully completed......................................
2025-06-02 14:21:36,319:INFO:Initializing tune_model()
2025-06-02 14:21:36,320:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>)
2025-06-02 14:21:36,320:INFO:Checking exceptions
2025-06-02 14:21:36,320:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 14:21:36,435:INFO:Copying training dataset
2025-06-02 14:21:36,503:INFO:Checking base model
2025-06-02 14:21:36,504:INFO:Base model : Light Gradient Boosting Machine
2025-06-02 14:21:36,521:INFO:Declaring metric variables
2025-06-02 14:21:36,548:INFO:Defining Hyperparameters
2025-06-02 14:21:38,440:INFO:Tuning with n_jobs=-1
2025-06-02 14:21:38,458:INFO:Initializing skopt.BayesSearchCV
2025-06-02 14:21:58,834:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.8608120752388259), ('actual_estimator__bagging_freq', 1), ('actual_estimator__feature_fraction', 0.4284489606984907), ('actual_estimator__learning_rate', 0.016133245419918712), ('actual_estimator__min_child_samples', 95), ('actual_estimator__min_split_gain', 0.8209314243567916), ('actual_estimator__n_estimators', 239), ('actual_estimator__num_leaves', 183), ('actual_estimator__reg_alpha', 8.662569304197528e-07), ('actual_estimator__reg_lambda', 5.001062744294253e-06)])
2025-06-02 14:21:58,836:INFO:Hyperparameter search completed
2025-06-02 14:21:58,836:INFO:SubProcess create_model() called ==================================
2025-06-02 14:21:58,838:INFO:Initializing create_model()
2025-06-02 14:21:58,838:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D7F51660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.8608120752388259, 'bagging_freq': 1, 'feature_fraction': 0.4284489606984907, 'learning_rate': 0.016133245419918712, 'min_child_samples': 95, 'min_split_gain': 0.8209314243567916, 'n_estimators': 239, 'num_leaves': 183, 'reg_alpha': 8.662569304197528e-07, 'reg_lambda': 5.001062744294253e-06})
2025-06-02 14:21:58,840:INFO:Checking exceptions
2025-06-02 14:21:58,841:INFO:Importing libraries
2025-06-02 14:21:58,841:INFO:Copying training dataset
2025-06-02 14:21:58,909:INFO:Defining folds
2025-06-02 14:21:58,909:INFO:Declaring metric variables
2025-06-02 14:21:58,916:INFO:Importing untrained model
2025-06-02 14:21:58,916:INFO:Declaring custom model
2025-06-02 14:21:58,931:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:21:58,955:INFO:Starting cross validation
2025-06-02 14:21:58,959:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:22:00,928:INFO:Calculating mean and std
2025-06-02 14:22:00,931:INFO:Creating metrics dataframe
2025-06-02 14:22:00,948:INFO:Finalizing model
2025-06-02 14:22:01,360:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 14:22:01,360:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 14:22:01,360:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 14:22:01,387:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:22:01,389:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 14:22:01,389:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 14:22:01,389:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 14:22:01,398:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004615 seconds.
2025-06-02 14:22:01,398:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:22:01,399:INFO:[LightGBM] [Info] Total Bins 6220
2025-06-02 14:22:01,413:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 94
2025-06-02 14:22:01,414:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:22:01,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:22:01,706:INFO:Uploading results into container
2025-06-02 14:22:01,708:INFO:Uploading model into container now
2025-06-02 14:22:01,709:INFO:_master_model_container: 21
2025-06-02 14:22:01,710:INFO:_display_container: 3
2025-06-02 14:22:01,713:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06)
2025-06-02 14:22:01,713:INFO:create_model() successfully completed......................................
2025-06-02 14:22:02,915:INFO:SubProcess create_model() end ==================================
2025-06-02 14:22:02,916:INFO:choose_better activated
2025-06-02 14:22:02,924:INFO:SubProcess create_model() called ==================================
2025-06-02 14:22:02,926:INFO:Initializing create_model()
2025-06-02 14:22:02,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:22:02,926:INFO:Checking exceptions
2025-06-02 14:22:02,929:INFO:Importing libraries
2025-06-02 14:22:02,930:INFO:Copying training dataset
2025-06-02 14:22:02,996:INFO:Defining folds
2025-06-02 14:22:02,996:INFO:Declaring metric variables
2025-06-02 14:22:02,996:INFO:Importing untrained model
2025-06-02 14:22:02,997:INFO:Declaring custom model
2025-06-02 14:22:02,999:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:22:02,999:INFO:Starting cross validation
2025-06-02 14:22:03,003:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:22:04,580:INFO:Calculating mean and std
2025-06-02 14:22:04,581:INFO:Creating metrics dataframe
2025-06-02 14:22:04,586:INFO:Finalizing model
2025-06-02 14:22:04,969:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:22:04,975:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004022 seconds.
2025-06-02 14:22:04,975:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:22:04,976:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 14:22:04,976:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 14:22:04,977:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:22:05,155:INFO:Uploading results into container
2025-06-02 14:22:05,156:INFO:Uploading model into container now
2025-06-02 14:22:05,156:INFO:_master_model_container: 22
2025-06-02 14:22:05,157:INFO:_display_container: 4
2025-06-02 14:22:05,157:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:22:05,158:INFO:create_model() successfully completed......................................
2025-06-02 14:22:06,364:INFO:SubProcess create_model() end ==================================
2025-06-02 14:22:06,365:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8764
2025-06-02 14:22:06,366:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06) result for R2 is 0.8217
2025-06-02 14:22:06,367:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 14:22:06,367:INFO:choose_better completed
2025-06-02 14:22:06,367:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 14:22:06,382:INFO:_master_model_container: 22
2025-06-02 14:22:06,383:INFO:_display_container: 3
2025-06-02 14:22:06,385:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:22:06,385:INFO:tune_model() successfully completed......................................
2025-06-02 14:22:07,627:INFO:Initializing finalize_model()
2025-06-02 14:22:07,627:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 14:22:07,629:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:22:07,671:INFO:Initializing create_model()
2025-06-02 14:22:07,671:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:22:07,671:INFO:Checking exceptions
2025-06-02 14:22:07,673:INFO:Importing libraries
2025-06-02 14:22:07,673:INFO:Copying training dataset
2025-06-02 14:22:07,679:INFO:Defining folds
2025-06-02 14:22:07,679:INFO:Declaring metric variables
2025-06-02 14:22:07,679:INFO:Importing untrained model
2025-06-02 14:22:07,679:INFO:Declaring custom model
2025-06-02 14:22:07,681:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:22:07,684:INFO:Cross validation set to False
2025-06-02 14:22:07,684:INFO:Fitting Model
2025-06-02 14:22:08,105:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:22:08,110:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003102 seconds.
2025-06-02 14:22:08,110:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:22:08,111:INFO:[LightGBM] [Info] Total Bins 6237
2025-06-02 14:22:08,111:INFO:[LightGBM] [Info] Number of data points in the train set: 4478, number of used features: 95
2025-06-02 14:22:08,112:INFO:[LightGBM] [Info] Start training from score -0.483793
2025-06-02 14:22:08,367:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:22:08,367:INFO:create_model() successfully completed......................................
2025-06-02 14:22:09,601:INFO:_master_model_container: 22
2025-06-02 14:22:09,601:INFO:_display_container: 3
2025-06-02 14:22:09,618:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:22:09,618:INFO:finalize_model() successfully completed......................................
2025-06-02 14:22:10,872:INFO:Initializing save_model()
2025-06-02 14:22:10,872:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 14:22:10,873:INFO:Adding model into prep_pipe
2025-06-02 14:22:10,873:WARNING:Only Model saved as it was a pipeline.
2025-06-02 14:22:10,897:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 14:22:10,924:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:22:10,924:INFO:save_model() successfully completed......................................
2025-06-02 14:22:12,225:INFO:Initializing predict_model()
2025-06-02 14:22:12,226:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8CB6950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6D8CD6680>)
2025-06-02 14:22:12,226:INFO:Checking exceptions
2025-06-02 14:22:12,226:INFO:Preloading libraries
2025-06-02 14:24:32,889:INFO:PyCaret RegressionExperiment
2025-06-02 14:24:32,889:INFO:Logging name: reg-default-name
2025-06-02 14:24:32,890:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 14:24:32,890:INFO:version 3.3.2
2025-06-02 14:24:32,890:INFO:Initializing setup()
2025-06-02 14:24:32,890:INFO:self.USI: 2741
2025-06-02 14:24:32,890:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 14:24:32,890:INFO:Checking environment
2025-06-02 14:24:32,890:INFO:python_version: 3.10.16
2025-06-02 14:24:32,891:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 14:24:32,891:INFO:machine: AMD64
2025-06-02 14:24:32,891:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 14:24:32,900:INFO:Memory: svmem(total=6378008576, available=267153408, percent=95.8, used=6110855168, free=267153408)
2025-06-02 14:24:32,900:INFO:Physical Core: 4
2025-06-02 14:24:32,901:INFO:Logical Core: 8
2025-06-02 14:24:32,901:INFO:Checking libraries
2025-06-02 14:24:32,901:INFO:System:
2025-06-02 14:24:32,901:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 14:24:32,902:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 14:24:32,902:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 14:24:32,902:INFO:PyCaret required dependencies:
2025-06-02 14:24:32,902:INFO:                 pip: 25.1
2025-06-02 14:24:32,902:INFO:          setuptools: 78.1.1
2025-06-02 14:24:32,902:INFO:             pycaret: 3.3.2
2025-06-02 14:24:32,902:INFO:             IPython: 8.37.0
2025-06-02 14:24:32,902:INFO:          ipywidgets: 8.1.7
2025-06-02 14:24:32,903:INFO:                tqdm: 4.67.1
2025-06-02 14:24:32,903:INFO:               numpy: 1.26.4
2025-06-02 14:24:32,903:INFO:              pandas: 2.0.1
2025-06-02 14:24:32,903:INFO:              jinja2: 3.1.6
2025-06-02 14:24:32,903:INFO:               scipy: 1.10.1
2025-06-02 14:24:32,903:INFO:              joblib: 1.3.2
2025-06-02 14:24:32,903:INFO:             sklearn: 1.4.2
2025-06-02 14:24:32,903:INFO:                pyod: 2.0.5
2025-06-02 14:24:32,903:INFO:            imblearn: 0.13.0
2025-06-02 14:24:32,903:INFO:   category_encoders: 2.7.0
2025-06-02 14:24:32,903:INFO:            lightgbm: 4.6.0
2025-06-02 14:24:32,903:INFO:               numba: 0.61.0
2025-06-02 14:24:32,904:INFO:            requests: 2.32.3
2025-06-02 14:24:32,904:INFO:          matplotlib: 3.7.1
2025-06-02 14:24:32,904:INFO:          scikitplot: 0.3.7
2025-06-02 14:24:32,904:INFO:         yellowbrick: 1.5
2025-06-02 14:24:32,904:INFO:              plotly: 6.1.2
2025-06-02 14:24:32,904:INFO:    plotly-resampler: Not installed
2025-06-02 14:24:32,904:INFO:             kaleido: 0.2.1
2025-06-02 14:24:32,904:INFO:           schemdraw: 0.15
2025-06-02 14:24:32,904:INFO:         statsmodels: 0.14.4
2025-06-02 14:24:32,904:INFO:              sktime: 0.26.0
2025-06-02 14:24:32,904:INFO:               tbats: 1.1.3
2025-06-02 14:24:32,904:INFO:            pmdarima: 2.0.4
2025-06-02 14:24:32,905:INFO:              psutil: 7.0.0
2025-06-02 14:24:32,905:INFO:          markupsafe: 2.1.2
2025-06-02 14:24:32,905:INFO:             pickle5: Not installed
2025-06-02 14:24:32,905:INFO:         cloudpickle: 3.1.1
2025-06-02 14:24:32,905:INFO:         deprecation: 2.1.0
2025-06-02 14:24:32,905:INFO:              xxhash: 3.5.0
2025-06-02 14:24:32,905:INFO:           wurlitzer: Not installed
2025-06-02 14:24:32,905:INFO:PyCaret optional dependencies:
2025-06-02 14:24:32,905:INFO:                shap: 0.44.1
2025-06-02 14:24:32,905:INFO:           interpret: 0.6.9
2025-06-02 14:24:32,906:INFO:                umap: 0.5.7
2025-06-02 14:24:32,906:INFO:     ydata_profiling: 4.16.1
2025-06-02 14:24:32,906:INFO:  explainerdashboard: 0.4.8
2025-06-02 14:24:32,906:INFO:             autoviz: Not installed
2025-06-02 14:24:32,906:INFO:           fairlearn: 0.7.0
2025-06-02 14:24:32,906:INFO:          deepchecks: Not installed
2025-06-02 14:24:32,906:INFO:             xgboost: 3.0.2
2025-06-02 14:24:32,906:INFO:            catboost: 1.2.8
2025-06-02 14:24:32,906:INFO:              kmodes: 0.12.2
2025-06-02 14:24:32,906:INFO:             mlxtend: 0.23.4
2025-06-02 14:24:32,906:INFO:       statsforecast: 1.5.0
2025-06-02 14:24:32,906:INFO:        tune_sklearn: Not installed
2025-06-02 14:24:32,906:INFO:                 ray: Not installed
2025-06-02 14:24:32,907:INFO:            hyperopt: 0.2.7
2025-06-02 14:24:32,907:INFO:              optuna: 4.3.0
2025-06-02 14:24:32,907:INFO:               skopt: 0.10.2
2025-06-02 14:24:32,907:INFO:              mlflow: 2.22.0
2025-06-02 14:24:32,907:INFO:              gradio: 5.32.0
2025-06-02 14:24:32,907:INFO:             fastapi: 0.115.12
2025-06-02 14:24:32,907:INFO:             uvicorn: 0.34.3
2025-06-02 14:24:32,907:INFO:              m2cgen: 0.10.0
2025-06-02 14:24:32,907:INFO:           evidently: 0.4.40
2025-06-02 14:24:32,907:INFO:               fugue: 0.8.5
2025-06-02 14:24:32,907:INFO:           streamlit: Not installed
2025-06-02 14:24:32,907:INFO:             prophet: Not installed
2025-06-02 14:24:32,908:INFO:None
2025-06-02 14:24:32,908:INFO:Set up data.
2025-06-02 14:24:33,362:INFO:Set up folding strategy.
2025-06-02 14:24:33,362:INFO:Set up train/test split.
2025-06-02 14:24:33,470:INFO:Set up index.
2025-06-02 14:24:33,471:INFO:Assigning column types.
2025-06-02 14:24:33,578:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 14:24:33,584:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 14:24:33,598:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:24:33,612:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:24:33,838:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:24:33,952:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:24:33,954:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:24:33,962:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:24:33,964:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 14:24:33,976:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:24:33,987:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:24:34,196:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:24:34,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:24:34,303:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:24:34,311:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:24:34,312:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 14:24:34,325:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:24:34,338:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:24:34,529:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:24:34,636:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:24:34,638:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:24:34,645:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:24:34,661:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:24:34,677:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:24:34,865:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:24:34,954:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:24:34,955:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:24:34,959:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:24:34,961:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 14:24:34,977:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:24:35,140:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:24:35,229:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:24:35,229:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:24:35,235:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:24:35,259:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:24:35,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:24:35,504:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:24:35,505:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:24:35,509:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:24:35,510:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 14:24:35,681:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:24:35,768:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:24:35,770:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:24:35,774:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:24:35,956:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:24:36,040:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:24:36,041:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:24:36,046:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:24:36,047:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 14:24:36,232:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:24:36,329:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:24:36,334:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:24:36,514:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:24:36,590:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:24:36,594:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:24:36,596:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 14:24:36,828:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:24:36,832:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:24:37,065:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:24:37,070:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:24:37,073:INFO:Preparing preprocessing pipeline...
2025-06-02 14:24:37,073:INFO:Set up simple imputation.
2025-06-02 14:24:37,073:INFO:Set up removing multicollinearity.
2025-06-02 14:24:37,080:INFO:Set up column name cleaning.
2025-06-02 14:24:37,303:INFO:Finished creating preprocessing pipeline.
2025-06-02 14:24:37,315:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 14:24:37,315:INFO:Creating final display dataframe.
2025-06-02 14:24:37,716:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              2741
2025-06-02 14:24:37,966:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:24:37,970:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:24:38,194:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:24:38,199:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:24:38,201:INFO:setup() successfully completed in 5.32s...............
2025-06-02 14:24:38,202:INFO:Initializing compare_models()
2025-06-02 14:24:38,202:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 14:24:38,202:INFO:Checking exceptions
2025-06-02 14:24:38,231:INFO:Preparing display monitor
2025-06-02 14:24:38,291:INFO:Initializing Linear Regression
2025-06-02 14:24:38,291:INFO:Total runtime is 0.0 minutes
2025-06-02 14:24:38,302:INFO:SubProcess create_model() called ==================================
2025-06-02 14:24:38,303:INFO:Initializing create_model()
2025-06-02 14:24:38,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:24:38,303:INFO:Checking exceptions
2025-06-02 14:24:38,304:INFO:Importing libraries
2025-06-02 14:24:38,304:INFO:Copying training dataset
2025-06-02 14:24:38,391:INFO:Defining folds
2025-06-02 14:24:38,392:INFO:Declaring metric variables
2025-06-02 14:24:38,403:INFO:Importing untrained model
2025-06-02 14:24:38,413:INFO:Linear Regression Imported successfully
2025-06-02 14:24:38,438:INFO:Starting cross validation
2025-06-02 14:24:38,444:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:24:39,316:INFO:Calculating mean and std
2025-06-02 14:24:39,319:INFO:Creating metrics dataframe
2025-06-02 14:24:39,322:INFO:Uploading results into container
2025-06-02 14:24:39,324:INFO:Uploading model into container now
2025-06-02 14:24:39,325:INFO:_master_model_container: 1
2025-06-02 14:24:39,325:INFO:_display_container: 2
2025-06-02 14:24:39,326:INFO:LinearRegression(n_jobs=-1)
2025-06-02 14:24:39,326:INFO:create_model() successfully completed......................................
2025-06-02 14:24:40,812:INFO:SubProcess create_model() end ==================================
2025-06-02 14:24:40,812:INFO:Creating metrics dataframe
2025-06-02 14:24:40,827:INFO:Initializing Lasso Regression
2025-06-02 14:24:40,828:INFO:Total runtime is 0.042279871304829915 minutes
2025-06-02 14:24:40,836:INFO:SubProcess create_model() called ==================================
2025-06-02 14:24:40,837:INFO:Initializing create_model()
2025-06-02 14:24:40,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:24:40,837:INFO:Checking exceptions
2025-06-02 14:24:40,838:INFO:Importing libraries
2025-06-02 14:24:40,838:INFO:Copying training dataset
2025-06-02 14:24:40,979:INFO:Defining folds
2025-06-02 14:24:40,979:INFO:Declaring metric variables
2025-06-02 14:24:41,004:INFO:Importing untrained model
2025-06-02 14:24:41,024:INFO:Lasso Regression Imported successfully
2025-06-02 14:24:41,063:INFO:Starting cross validation
2025-06-02 14:24:41,067:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:24:41,907:INFO:Calculating mean and std
2025-06-02 14:24:41,910:INFO:Creating metrics dataframe
2025-06-02 14:24:41,914:INFO:Uploading results into container
2025-06-02 14:24:41,915:INFO:Uploading model into container now
2025-06-02 14:24:41,916:INFO:_master_model_container: 2
2025-06-02 14:24:41,916:INFO:_display_container: 2
2025-06-02 14:24:41,918:INFO:Lasso(random_state=123)
2025-06-02 14:24:41,918:INFO:create_model() successfully completed......................................
2025-06-02 14:24:43,163:INFO:SubProcess create_model() end ==================================
2025-06-02 14:24:43,163:INFO:Creating metrics dataframe
2025-06-02 14:24:43,174:INFO:Initializing Ridge Regression
2025-06-02 14:24:43,175:INFO:Total runtime is 0.08140094677607218 minutes
2025-06-02 14:24:43,182:INFO:SubProcess create_model() called ==================================
2025-06-02 14:24:43,183:INFO:Initializing create_model()
2025-06-02 14:24:43,184:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:24:43,184:INFO:Checking exceptions
2025-06-02 14:24:43,185:INFO:Importing libraries
2025-06-02 14:24:43,185:INFO:Copying training dataset
2025-06-02 14:24:43,260:INFO:Defining folds
2025-06-02 14:24:43,260:INFO:Declaring metric variables
2025-06-02 14:24:43,273:INFO:Importing untrained model
2025-06-02 14:24:43,283:INFO:Ridge Regression Imported successfully
2025-06-02 14:24:43,309:INFO:Starting cross validation
2025-06-02 14:24:43,313:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:24:44,012:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31073e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:24:44,018:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.24347e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:24:44,061:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.08754e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:24:44,623:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.75561e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:24:45,019:INFO:Calculating mean and std
2025-06-02 14:24:45,022:INFO:Creating metrics dataframe
2025-06-02 14:24:45,026:INFO:Uploading results into container
2025-06-02 14:24:45,027:INFO:Uploading model into container now
2025-06-02 14:24:45,029:INFO:_master_model_container: 3
2025-06-02 14:24:45,029:INFO:_display_container: 2
2025-06-02 14:24:45,030:INFO:Ridge(random_state=123)
2025-06-02 14:24:45,030:INFO:create_model() successfully completed......................................
2025-06-02 14:24:46,548:INFO:SubProcess create_model() end ==================================
2025-06-02 14:24:46,549:INFO:Creating metrics dataframe
2025-06-02 14:24:46,561:INFO:Initializing Elastic Net
2025-06-02 14:24:46,561:INFO:Total runtime is 0.13783443768819173 minutes
2025-06-02 14:24:46,571:INFO:SubProcess create_model() called ==================================
2025-06-02 14:24:46,572:INFO:Initializing create_model()
2025-06-02 14:24:46,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:24:46,572:INFO:Checking exceptions
2025-06-02 14:24:46,572:INFO:Importing libraries
2025-06-02 14:24:46,572:INFO:Copying training dataset
2025-06-02 14:24:46,642:INFO:Defining folds
2025-06-02 14:24:46,642:INFO:Declaring metric variables
2025-06-02 14:24:46,653:INFO:Importing untrained model
2025-06-02 14:24:46,663:INFO:Elastic Net Imported successfully
2025-06-02 14:24:46,689:INFO:Starting cross validation
2025-06-02 14:24:46,693:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:24:47,885:INFO:Calculating mean and std
2025-06-02 14:24:47,887:INFO:Creating metrics dataframe
2025-06-02 14:24:47,892:INFO:Uploading results into container
2025-06-02 14:24:47,894:INFO:Uploading model into container now
2025-06-02 14:24:47,895:INFO:_master_model_container: 4
2025-06-02 14:24:47,895:INFO:_display_container: 2
2025-06-02 14:24:47,896:INFO:ElasticNet(random_state=123)
2025-06-02 14:24:47,897:INFO:create_model() successfully completed......................................
2025-06-02 14:24:49,158:INFO:SubProcess create_model() end ==================================
2025-06-02 14:24:49,158:INFO:Creating metrics dataframe
2025-06-02 14:24:49,173:INFO:Initializing Least Angle Regression
2025-06-02 14:24:49,173:INFO:Total runtime is 0.18137283325195314 minutes
2025-06-02 14:24:49,181:INFO:SubProcess create_model() called ==================================
2025-06-02 14:24:49,181:INFO:Initializing create_model()
2025-06-02 14:24:49,182:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:24:49,182:INFO:Checking exceptions
2025-06-02 14:24:49,183:INFO:Importing libraries
2025-06-02 14:24:49,183:INFO:Copying training dataset
2025-06-02 14:24:49,253:INFO:Defining folds
2025-06-02 14:24:49,253:INFO:Declaring metric variables
2025-06-02 14:24:49,266:INFO:Importing untrained model
2025-06-02 14:24:49,277:INFO:Least Angle Regression Imported successfully
2025-06-02 14:24:49,299:INFO:Starting cross validation
2025-06-02 14:24:49,303:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:24:50,654:INFO:Calculating mean and std
2025-06-02 14:24:50,657:INFO:Creating metrics dataframe
2025-06-02 14:24:50,661:INFO:Uploading results into container
2025-06-02 14:24:50,662:INFO:Uploading model into container now
2025-06-02 14:24:50,664:INFO:_master_model_container: 5
2025-06-02 14:24:50,664:INFO:_display_container: 2
2025-06-02 14:24:50,666:INFO:Lars(random_state=123)
2025-06-02 14:24:50,666:INFO:create_model() successfully completed......................................
2025-06-02 14:24:52,003:INFO:SubProcess create_model() end ==================================
2025-06-02 14:24:52,003:INFO:Creating metrics dataframe
2025-06-02 14:24:52,021:INFO:Initializing Lasso Least Angle Regression
2025-06-02 14:24:52,021:INFO:Total runtime is 0.22882757981618246 minutes
2025-06-02 14:24:52,030:INFO:SubProcess create_model() called ==================================
2025-06-02 14:24:52,031:INFO:Initializing create_model()
2025-06-02 14:24:52,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:24:52,032:INFO:Checking exceptions
2025-06-02 14:24:52,032:INFO:Importing libraries
2025-06-02 14:24:52,032:INFO:Copying training dataset
2025-06-02 14:24:52,117:INFO:Defining folds
2025-06-02 14:24:52,118:INFO:Declaring metric variables
2025-06-02 14:24:52,132:INFO:Importing untrained model
2025-06-02 14:24:52,142:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 14:24:52,168:INFO:Starting cross validation
2025-06-02 14:24:52,173:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:24:53,018:INFO:Calculating mean and std
2025-06-02 14:24:53,021:INFO:Creating metrics dataframe
2025-06-02 14:24:53,026:INFO:Uploading results into container
2025-06-02 14:24:53,027:INFO:Uploading model into container now
2025-06-02 14:24:53,028:INFO:_master_model_container: 6
2025-06-02 14:24:53,028:INFO:_display_container: 2
2025-06-02 14:24:53,028:INFO:LassoLars(random_state=123)
2025-06-02 14:24:53,029:INFO:create_model() successfully completed......................................
2025-06-02 14:24:54,299:INFO:SubProcess create_model() end ==================================
2025-06-02 14:24:54,300:INFO:Creating metrics dataframe
2025-06-02 14:24:54,317:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 14:24:54,317:INFO:Total runtime is 0.2671029567718506 minutes
2025-06-02 14:24:54,327:INFO:SubProcess create_model() called ==================================
2025-06-02 14:24:54,328:INFO:Initializing create_model()
2025-06-02 14:24:54,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:24:54,329:INFO:Checking exceptions
2025-06-02 14:24:54,329:INFO:Importing libraries
2025-06-02 14:24:54,329:INFO:Copying training dataset
2025-06-02 14:24:54,390:INFO:Defining folds
2025-06-02 14:24:54,390:INFO:Declaring metric variables
2025-06-02 14:24:54,402:INFO:Importing untrained model
2025-06-02 14:24:54,413:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 14:24:54,436:INFO:Starting cross validation
2025-06-02 14:24:54,440:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:24:55,219:INFO:Calculating mean and std
2025-06-02 14:24:55,222:INFO:Creating metrics dataframe
2025-06-02 14:24:55,226:INFO:Uploading results into container
2025-06-02 14:24:55,227:INFO:Uploading model into container now
2025-06-02 14:24:55,228:INFO:_master_model_container: 7
2025-06-02 14:24:55,228:INFO:_display_container: 2
2025-06-02 14:24:55,229:INFO:OrthogonalMatchingPursuit()
2025-06-02 14:24:55,229:INFO:create_model() successfully completed......................................
2025-06-02 14:24:56,648:INFO:SubProcess create_model() end ==================================
2025-06-02 14:24:56,649:INFO:Creating metrics dataframe
2025-06-02 14:24:56,664:INFO:Initializing Bayesian Ridge
2025-06-02 14:24:56,664:INFO:Total runtime is 0.30621039470036826 minutes
2025-06-02 14:24:56,674:INFO:SubProcess create_model() called ==================================
2025-06-02 14:24:56,675:INFO:Initializing create_model()
2025-06-02 14:24:56,675:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:24:56,675:INFO:Checking exceptions
2025-06-02 14:24:56,676:INFO:Importing libraries
2025-06-02 14:24:56,676:INFO:Copying training dataset
2025-06-02 14:24:56,743:INFO:Defining folds
2025-06-02 14:24:56,744:INFO:Declaring metric variables
2025-06-02 14:24:56,756:INFO:Importing untrained model
2025-06-02 14:24:56,769:INFO:Bayesian Ridge Imported successfully
2025-06-02 14:24:56,796:INFO:Starting cross validation
2025-06-02 14:24:56,800:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:24:57,770:INFO:Calculating mean and std
2025-06-02 14:24:57,773:INFO:Creating metrics dataframe
2025-06-02 14:24:57,778:INFO:Uploading results into container
2025-06-02 14:24:57,779:INFO:Uploading model into container now
2025-06-02 14:24:57,780:INFO:_master_model_container: 8
2025-06-02 14:24:57,781:INFO:_display_container: 2
2025-06-02 14:24:57,781:INFO:BayesianRidge()
2025-06-02 14:24:57,782:INFO:create_model() successfully completed......................................
2025-06-02 14:24:59,087:INFO:SubProcess create_model() end ==================================
2025-06-02 14:24:59,088:INFO:Creating metrics dataframe
2025-06-02 14:24:59,109:INFO:Initializing Passive Aggressive Regressor
2025-06-02 14:24:59,110:INFO:Total runtime is 0.34698339700698855 minutes
2025-06-02 14:24:59,128:INFO:SubProcess create_model() called ==================================
2025-06-02 14:24:59,129:INFO:Initializing create_model()
2025-06-02 14:24:59,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:24:59,130:INFO:Checking exceptions
2025-06-02 14:24:59,131:INFO:Importing libraries
2025-06-02 14:24:59,131:INFO:Copying training dataset
2025-06-02 14:24:59,236:INFO:Defining folds
2025-06-02 14:24:59,237:INFO:Declaring metric variables
2025-06-02 14:24:59,258:INFO:Importing untrained model
2025-06-02 14:24:59,292:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 14:24:59,333:INFO:Starting cross validation
2025-06-02 14:24:59,339:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:25:02,110:INFO:Calculating mean and std
2025-06-02 14:25:02,113:INFO:Creating metrics dataframe
2025-06-02 14:25:02,120:INFO:Uploading results into container
2025-06-02 14:25:02,122:INFO:Uploading model into container now
2025-06-02 14:25:02,123:INFO:_master_model_container: 9
2025-06-02 14:25:02,124:INFO:_display_container: 2
2025-06-02 14:25:02,125:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 14:25:02,125:INFO:create_model() successfully completed......................................
2025-06-02 14:25:03,687:INFO:SubProcess create_model() end ==================================
2025-06-02 14:25:03,687:INFO:Creating metrics dataframe
2025-06-02 14:25:03,703:INFO:Initializing Huber Regressor
2025-06-02 14:25:03,703:INFO:Total runtime is 0.42352907260258993 minutes
2025-06-02 14:25:03,712:INFO:SubProcess create_model() called ==================================
2025-06-02 14:25:03,712:INFO:Initializing create_model()
2025-06-02 14:25:03,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:25:03,713:INFO:Checking exceptions
2025-06-02 14:25:03,713:INFO:Importing libraries
2025-06-02 14:25:03,714:INFO:Copying training dataset
2025-06-02 14:25:03,783:INFO:Defining folds
2025-06-02 14:25:03,784:INFO:Declaring metric variables
2025-06-02 14:25:03,795:INFO:Importing untrained model
2025-06-02 14:25:03,805:INFO:Huber Regressor Imported successfully
2025-06-02 14:25:03,829:INFO:Starting cross validation
2025-06-02 14:25:03,834:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:25:05,543:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:25:05,592:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:25:05,621:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:25:05,650:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:25:05,643:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:25:05,703:INFO:Calculating mean and std
2025-06-02 14:25:05,707:INFO:Creating metrics dataframe
2025-06-02 14:25:05,710:INFO:Uploading results into container
2025-06-02 14:25:05,711:INFO:Uploading model into container now
2025-06-02 14:25:05,712:INFO:_master_model_container: 10
2025-06-02 14:25:05,712:INFO:_display_container: 2
2025-06-02 14:25:05,713:INFO:HuberRegressor()
2025-06-02 14:25:05,713:INFO:create_model() successfully completed......................................
2025-06-02 14:25:07,086:INFO:SubProcess create_model() end ==================================
2025-06-02 14:25:07,087:INFO:Creating metrics dataframe
2025-06-02 14:25:07,121:INFO:Initializing K Neighbors Regressor
2025-06-02 14:25:07,121:INFO:Total runtime is 0.48050129413604736 minutes
2025-06-02 14:25:07,136:INFO:SubProcess create_model() called ==================================
2025-06-02 14:25:07,138:INFO:Initializing create_model()
2025-06-02 14:25:07,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:25:07,140:INFO:Checking exceptions
2025-06-02 14:25:07,141:INFO:Importing libraries
2025-06-02 14:25:07,141:INFO:Copying training dataset
2025-06-02 14:25:07,241:INFO:Defining folds
2025-06-02 14:25:07,241:INFO:Declaring metric variables
2025-06-02 14:25:07,254:INFO:Importing untrained model
2025-06-02 14:25:07,270:INFO:K Neighbors Regressor Imported successfully
2025-06-02 14:25:07,298:INFO:Starting cross validation
2025-06-02 14:25:07,303:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:25:08,477:INFO:Calculating mean and std
2025-06-02 14:25:08,480:INFO:Creating metrics dataframe
2025-06-02 14:25:08,483:INFO:Uploading results into container
2025-06-02 14:25:08,485:INFO:Uploading model into container now
2025-06-02 14:25:08,486:INFO:_master_model_container: 11
2025-06-02 14:25:08,486:INFO:_display_container: 2
2025-06-02 14:25:08,487:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 14:25:08,488:INFO:create_model() successfully completed......................................
2025-06-02 14:25:09,904:INFO:SubProcess create_model() end ==================================
2025-06-02 14:25:09,905:INFO:Creating metrics dataframe
2025-06-02 14:25:09,931:INFO:Initializing Decision Tree Regressor
2025-06-02 14:25:09,931:INFO:Total runtime is 0.5273389259974162 minutes
2025-06-02 14:25:09,944:INFO:SubProcess create_model() called ==================================
2025-06-02 14:25:09,945:INFO:Initializing create_model()
2025-06-02 14:25:09,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:25:09,946:INFO:Checking exceptions
2025-06-02 14:25:09,946:INFO:Importing libraries
2025-06-02 14:25:09,947:INFO:Copying training dataset
2025-06-02 14:25:10,036:INFO:Defining folds
2025-06-02 14:25:10,037:INFO:Declaring metric variables
2025-06-02 14:25:10,051:INFO:Importing untrained model
2025-06-02 14:25:10,063:INFO:Decision Tree Regressor Imported successfully
2025-06-02 14:25:10,092:INFO:Starting cross validation
2025-06-02 14:25:10,097:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:25:12,048:INFO:Calculating mean and std
2025-06-02 14:25:12,053:INFO:Creating metrics dataframe
2025-06-02 14:25:12,059:INFO:Uploading results into container
2025-06-02 14:25:12,060:INFO:Uploading model into container now
2025-06-02 14:25:12,062:INFO:_master_model_container: 12
2025-06-02 14:25:12,062:INFO:_display_container: 2
2025-06-02 14:25:12,063:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 14:25:12,064:INFO:create_model() successfully completed......................................
2025-06-02 14:25:13,539:INFO:SubProcess create_model() end ==================================
2025-06-02 14:25:13,539:INFO:Creating metrics dataframe
2025-06-02 14:25:13,563:INFO:Initializing Random Forest Regressor
2025-06-02 14:25:13,564:INFO:Total runtime is 0.5878857254981994 minutes
2025-06-02 14:25:13,575:INFO:SubProcess create_model() called ==================================
2025-06-02 14:25:13,576:INFO:Initializing create_model()
2025-06-02 14:25:13,576:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:25:13,576:INFO:Checking exceptions
2025-06-02 14:25:13,576:INFO:Importing libraries
2025-06-02 14:25:13,577:INFO:Copying training dataset
2025-06-02 14:25:13,658:INFO:Defining folds
2025-06-02 14:25:13,659:INFO:Declaring metric variables
2025-06-02 14:25:13,671:INFO:Importing untrained model
2025-06-02 14:25:13,687:INFO:Random Forest Regressor Imported successfully
2025-06-02 14:25:13,713:INFO:Starting cross validation
2025-06-02 14:25:13,718:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:25:26,271:INFO:Calculating mean and std
2025-06-02 14:25:26,275:INFO:Creating metrics dataframe
2025-06-02 14:25:26,286:INFO:Uploading results into container
2025-06-02 14:25:26,289:INFO:Uploading model into container now
2025-06-02 14:25:26,291:INFO:_master_model_container: 13
2025-06-02 14:25:26,292:INFO:_display_container: 2
2025-06-02 14:25:26,294:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:25:26,295:INFO:create_model() successfully completed......................................
2025-06-02 14:25:27,881:INFO:SubProcess create_model() end ==================================
2025-06-02 14:25:27,881:INFO:Creating metrics dataframe
2025-06-02 14:25:27,904:INFO:Initializing Extra Trees Regressor
2025-06-02 14:25:27,904:INFO:Total runtime is 0.8268851955731709 minutes
2025-06-02 14:25:27,913:INFO:SubProcess create_model() called ==================================
2025-06-02 14:25:27,914:INFO:Initializing create_model()
2025-06-02 14:25:27,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:25:27,914:INFO:Checking exceptions
2025-06-02 14:25:27,914:INFO:Importing libraries
2025-06-02 14:25:27,915:INFO:Copying training dataset
2025-06-02 14:25:27,989:INFO:Defining folds
2025-06-02 14:25:27,989:INFO:Declaring metric variables
2025-06-02 14:25:28,004:INFO:Importing untrained model
2025-06-02 14:25:28,016:INFO:Extra Trees Regressor Imported successfully
2025-06-02 14:25:28,042:INFO:Starting cross validation
2025-06-02 14:25:28,047:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:25:34,153:INFO:Calculating mean and std
2025-06-02 14:25:34,155:INFO:Creating metrics dataframe
2025-06-02 14:25:34,161:INFO:Uploading results into container
2025-06-02 14:25:34,162:INFO:Uploading model into container now
2025-06-02 14:25:34,163:INFO:_master_model_container: 14
2025-06-02 14:25:34,163:INFO:_display_container: 2
2025-06-02 14:25:34,164:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:25:34,165:INFO:create_model() successfully completed......................................
2025-06-02 14:25:35,432:INFO:SubProcess create_model() end ==================================
2025-06-02 14:25:35,432:INFO:Creating metrics dataframe
2025-06-02 14:25:35,453:INFO:Initializing AdaBoost Regressor
2025-06-02 14:25:35,454:INFO:Total runtime is 0.9527123729387919 minutes
2025-06-02 14:25:35,462:INFO:SubProcess create_model() called ==================================
2025-06-02 14:25:35,462:INFO:Initializing create_model()
2025-06-02 14:25:35,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:25:35,463:INFO:Checking exceptions
2025-06-02 14:25:35,463:INFO:Importing libraries
2025-06-02 14:25:35,464:INFO:Copying training dataset
2025-06-02 14:25:35,534:INFO:Defining folds
2025-06-02 14:25:35,534:INFO:Declaring metric variables
2025-06-02 14:25:35,547:INFO:Importing untrained model
2025-06-02 14:25:35,560:INFO:AdaBoost Regressor Imported successfully
2025-06-02 14:25:35,586:INFO:Starting cross validation
2025-06-02 14:25:35,590:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:25:38,024:INFO:Calculating mean and std
2025-06-02 14:25:38,027:INFO:Creating metrics dataframe
2025-06-02 14:25:38,030:INFO:Uploading results into container
2025-06-02 14:25:38,032:INFO:Uploading model into container now
2025-06-02 14:25:38,032:INFO:_master_model_container: 15
2025-06-02 14:25:38,033:INFO:_display_container: 2
2025-06-02 14:25:38,033:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 14:25:38,034:INFO:create_model() successfully completed......................................
2025-06-02 14:25:39,447:INFO:SubProcess create_model() end ==================================
2025-06-02 14:25:39,447:INFO:Creating metrics dataframe
2025-06-02 14:25:39,474:INFO:Initializing Gradient Boosting Regressor
2025-06-02 14:25:39,474:INFO:Total runtime is 1.019712730248769 minutes
2025-06-02 14:25:39,489:INFO:SubProcess create_model() called ==================================
2025-06-02 14:25:39,489:INFO:Initializing create_model()
2025-06-02 14:25:39,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:25:39,490:INFO:Checking exceptions
2025-06-02 14:25:39,490:INFO:Importing libraries
2025-06-02 14:25:39,490:INFO:Copying training dataset
2025-06-02 14:25:39,699:INFO:Defining folds
2025-06-02 14:25:39,702:INFO:Declaring metric variables
2025-06-02 14:25:39,727:INFO:Importing untrained model
2025-06-02 14:25:39,746:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 14:25:39,793:INFO:Starting cross validation
2025-06-02 14:25:39,799:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:25:44,720:INFO:Calculating mean and std
2025-06-02 14:25:44,723:INFO:Creating metrics dataframe
2025-06-02 14:25:44,726:INFO:Uploading results into container
2025-06-02 14:25:44,727:INFO:Uploading model into container now
2025-06-02 14:25:44,728:INFO:_master_model_container: 16
2025-06-02 14:25:44,728:INFO:_display_container: 2
2025-06-02 14:25:44,729:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 14:25:44,730:INFO:create_model() successfully completed......................................
2025-06-02 14:25:46,420:INFO:SubProcess create_model() end ==================================
2025-06-02 14:25:46,421:INFO:Creating metrics dataframe
2025-06-02 14:25:46,458:INFO:Initializing Extreme Gradient Boosting
2025-06-02 14:25:46,459:INFO:Total runtime is 1.1361280878384907 minutes
2025-06-02 14:25:46,473:INFO:SubProcess create_model() called ==================================
2025-06-02 14:25:46,474:INFO:Initializing create_model()
2025-06-02 14:25:46,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:25:46,475:INFO:Checking exceptions
2025-06-02 14:25:46,475:INFO:Importing libraries
2025-06-02 14:25:46,475:INFO:Copying training dataset
2025-06-02 14:25:46,727:INFO:Defining folds
2025-06-02 14:25:46,727:INFO:Declaring metric variables
2025-06-02 14:25:46,758:INFO:Importing untrained model
2025-06-02 14:25:46,793:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 14:25:46,861:INFO:Starting cross validation
2025-06-02 14:25:46,869:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:25:50,322:INFO:Calculating mean and std
2025-06-02 14:25:50,324:INFO:Creating metrics dataframe
2025-06-02 14:25:50,328:INFO:Uploading results into container
2025-06-02 14:25:50,329:INFO:Uploading model into container now
2025-06-02 14:25:50,330:INFO:_master_model_container: 17
2025-06-02 14:25:50,330:INFO:_display_container: 2
2025-06-02 14:25:50,335:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 14:25:50,336:INFO:create_model() successfully completed......................................
2025-06-02 14:25:52,054:INFO:SubProcess create_model() end ==================================
2025-06-02 14:25:52,055:INFO:Creating metrics dataframe
2025-06-02 14:25:52,095:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 14:25:52,096:INFO:Total runtime is 1.2300750017166138 minutes
2025-06-02 14:25:52,110:INFO:SubProcess create_model() called ==================================
2025-06-02 14:25:52,111:INFO:Initializing create_model()
2025-06-02 14:25:52,111:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:25:52,112:INFO:Checking exceptions
2025-06-02 14:25:52,112:INFO:Importing libraries
2025-06-02 14:25:52,113:INFO:Copying training dataset
2025-06-02 14:25:52,249:INFO:Defining folds
2025-06-02 14:25:52,250:INFO:Declaring metric variables
2025-06-02 14:25:52,269:INFO:Importing untrained model
2025-06-02 14:25:52,293:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:25:52,331:INFO:Starting cross validation
2025-06-02 14:25:52,336:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:25:55,118:INFO:Calculating mean and std
2025-06-02 14:25:55,121:INFO:Creating metrics dataframe
2025-06-02 14:25:55,126:INFO:Uploading results into container
2025-06-02 14:25:55,127:INFO:Uploading model into container now
2025-06-02 14:25:55,129:INFO:_master_model_container: 18
2025-06-02 14:25:55,129:INFO:_display_container: 2
2025-06-02 14:25:55,130:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:25:55,131:INFO:create_model() successfully completed......................................
2025-06-02 14:25:56,872:INFO:SubProcess create_model() end ==================================
2025-06-02 14:25:56,872:INFO:Creating metrics dataframe
2025-06-02 14:25:56,929:INFO:Initializing CatBoost Regressor
2025-06-02 14:25:56,930:INFO:Total runtime is 1.3106425563494364 minutes
2025-06-02 14:25:56,949:INFO:SubProcess create_model() called ==================================
2025-06-02 14:25:56,950:INFO:Initializing create_model()
2025-06-02 14:25:56,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:25:56,951:INFO:Checking exceptions
2025-06-02 14:25:56,952:INFO:Importing libraries
2025-06-02 14:25:56,953:INFO:Copying training dataset
2025-06-02 14:25:57,093:INFO:Defining folds
2025-06-02 14:25:57,094:INFO:Declaring metric variables
2025-06-02 14:25:57,121:INFO:Importing untrained model
2025-06-02 14:25:57,151:INFO:CatBoost Regressor Imported successfully
2025-06-02 14:25:57,186:INFO:Starting cross validation
2025-06-02 14:25:57,192:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:26:43,101:INFO:Calculating mean and std
2025-06-02 14:26:43,169:INFO:Creating metrics dataframe
2025-06-02 14:26:43,246:INFO:Uploading results into container
2025-06-02 14:26:43,258:INFO:Uploading model into container now
2025-06-02 14:26:43,267:INFO:_master_model_container: 19
2025-06-02 14:26:43,268:INFO:_display_container: 2
2025-06-02 14:26:43,269:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6D886A9B0>
2025-06-02 14:26:43,269:INFO:create_model() successfully completed......................................
2025-06-02 14:26:50,918:INFO:SubProcess create_model() end ==================================
2025-06-02 14:26:50,918:INFO:Creating metrics dataframe
2025-06-02 14:26:51,106:INFO:Initializing Dummy Regressor
2025-06-02 14:26:51,107:INFO:Total runtime is 2.2136040170987448 minutes
2025-06-02 14:26:51,152:INFO:SubProcess create_model() called ==================================
2025-06-02 14:26:51,155:INFO:Initializing create_model()
2025-06-02 14:26:51,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D86F6C20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:26:51,155:INFO:Checking exceptions
2025-06-02 14:26:51,156:INFO:Importing libraries
2025-06-02 14:26:51,157:INFO:Copying training dataset
2025-06-02 14:26:51,338:INFO:Defining folds
2025-06-02 14:26:51,338:INFO:Declaring metric variables
2025-06-02 14:26:51,358:INFO:Importing untrained model
2025-06-02 14:26:51,374:INFO:Dummy Regressor Imported successfully
2025-06-02 14:26:51,412:INFO:Starting cross validation
2025-06-02 14:26:51,419:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:26:53,009:INFO:Calculating mean and std
2025-06-02 14:26:53,014:INFO:Creating metrics dataframe
2025-06-02 14:26:53,021:INFO:Uploading results into container
2025-06-02 14:26:53,022:INFO:Uploading model into container now
2025-06-02 14:26:53,024:INFO:_master_model_container: 20
2025-06-02 14:26:53,025:INFO:_display_container: 2
2025-06-02 14:26:53,026:INFO:DummyRegressor()
2025-06-02 14:26:53,027:INFO:create_model() successfully completed......................................
2025-06-02 14:26:54,646:INFO:SubProcess create_model() end ==================================
2025-06-02 14:26:54,646:INFO:Creating metrics dataframe
2025-06-02 14:26:54,706:INFO:Initializing create_model()
2025-06-02 14:26:54,707:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:26:54,707:INFO:Checking exceptions
2025-06-02 14:26:54,724:INFO:Importing libraries
2025-06-02 14:26:54,725:INFO:Copying training dataset
2025-06-02 14:26:54,949:INFO:Defining folds
2025-06-02 14:26:54,949:INFO:Declaring metric variables
2025-06-02 14:26:54,950:INFO:Importing untrained model
2025-06-02 14:26:54,950:INFO:Declaring custom model
2025-06-02 14:26:54,954:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:26:54,958:INFO:Cross validation set to False
2025-06-02 14:26:54,958:INFO:Fitting Model
2025-06-02 14:26:55,678:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:26:55,698:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012516 seconds.
2025-06-02 14:26:55,698:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:26:55,699:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 14:26:55,715:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 14:26:55,719:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:26:56,224:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:26:56,224:INFO:create_model() successfully completed......................................
2025-06-02 14:26:57,979:INFO:_master_model_container: 20
2025-06-02 14:26:57,981:INFO:_display_container: 2
2025-06-02 14:26:57,982:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:26:57,983:INFO:compare_models() successfully completed......................................
2025-06-02 14:26:57,993:INFO:Initializing tune_model()
2025-06-02 14:26:57,993:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>)
2025-06-02 14:26:57,993:INFO:Checking exceptions
2025-06-02 14:26:57,993:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 14:26:58,093:INFO:Copying training dataset
2025-06-02 14:26:58,195:INFO:Checking base model
2025-06-02 14:26:58,196:INFO:Base model : Light Gradient Boosting Machine
2025-06-02 14:26:58,224:INFO:Declaring metric variables
2025-06-02 14:26:58,252:INFO:Defining Hyperparameters
2025-06-02 14:26:59,949:INFO:Tuning with n_jobs=-1
2025-06-02 14:26:59,966:INFO:Initializing skopt.BayesSearchCV
2025-06-02 14:27:27,953:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.8608120752388259), ('actual_estimator__bagging_freq', 1), ('actual_estimator__feature_fraction', 0.4284489606984907), ('actual_estimator__learning_rate', 0.016133245419918712), ('actual_estimator__min_child_samples', 95), ('actual_estimator__min_split_gain', 0.8209314243567916), ('actual_estimator__n_estimators', 239), ('actual_estimator__num_leaves', 183), ('actual_estimator__reg_alpha', 8.662569304197528e-07), ('actual_estimator__reg_lambda', 5.001062744294253e-06)])
2025-06-02 14:27:27,955:INFO:Hyperparameter search completed
2025-06-02 14:27:27,955:INFO:SubProcess create_model() called ==================================
2025-06-02 14:27:27,957:INFO:Initializing create_model()
2025-06-02 14:27:27,957:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D90354B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.8608120752388259, 'bagging_freq': 1, 'feature_fraction': 0.4284489606984907, 'learning_rate': 0.016133245419918712, 'min_child_samples': 95, 'min_split_gain': 0.8209314243567916, 'n_estimators': 239, 'num_leaves': 183, 'reg_alpha': 8.662569304197528e-07, 'reg_lambda': 5.001062744294253e-06})
2025-06-02 14:27:27,958:INFO:Checking exceptions
2025-06-02 14:27:27,959:INFO:Importing libraries
2025-06-02 14:27:27,959:INFO:Copying training dataset
2025-06-02 14:27:28,040:INFO:Defining folds
2025-06-02 14:27:28,041:INFO:Declaring metric variables
2025-06-02 14:27:28,050:INFO:Importing untrained model
2025-06-02 14:27:28,051:INFO:Declaring custom model
2025-06-02 14:27:28,070:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:27:28,105:INFO:Starting cross validation
2025-06-02 14:27:28,112:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:27:31,232:INFO:Calculating mean and std
2025-06-02 14:27:31,236:INFO:Creating metrics dataframe
2025-06-02 14:27:31,257:INFO:Finalizing model
2025-06-02 14:27:31,871:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 14:27:31,871:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 14:27:31,871:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 14:27:31,901:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:27:31,903:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 14:27:31,903:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 14:27:31,903:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 14:27:31,910:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004257 seconds.
2025-06-02 14:27:31,910:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:27:31,911:INFO:[LightGBM] [Info] Total Bins 6220
2025-06-02 14:27:31,929:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 94
2025-06-02 14:27:31,930:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:27:31,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:31,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:27:32,366:INFO:Uploading results into container
2025-06-02 14:27:32,369:INFO:Uploading model into container now
2025-06-02 14:27:32,371:INFO:_master_model_container: 21
2025-06-02 14:27:32,371:INFO:_display_container: 3
2025-06-02 14:27:32,375:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06)
2025-06-02 14:27:32,376:INFO:create_model() successfully completed......................................
2025-06-02 14:27:33,974:INFO:SubProcess create_model() end ==================================
2025-06-02 14:27:33,975:INFO:choose_better activated
2025-06-02 14:27:33,987:INFO:SubProcess create_model() called ==================================
2025-06-02 14:27:33,988:INFO:Initializing create_model()
2025-06-02 14:27:33,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:27:33,989:INFO:Checking exceptions
2025-06-02 14:27:33,994:INFO:Importing libraries
2025-06-02 14:27:33,994:INFO:Copying training dataset
2025-06-02 14:27:34,082:INFO:Defining folds
2025-06-02 14:27:34,083:INFO:Declaring metric variables
2025-06-02 14:27:34,083:INFO:Importing untrained model
2025-06-02 14:27:34,083:INFO:Declaring custom model
2025-06-02 14:27:34,086:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:27:34,087:INFO:Starting cross validation
2025-06-02 14:27:34,091:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:27:36,619:INFO:Calculating mean and std
2025-06-02 14:27:36,620:INFO:Creating metrics dataframe
2025-06-02 14:27:36,624:INFO:Finalizing model
2025-06-02 14:27:37,190:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:27:37,196:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003089 seconds.
2025-06-02 14:27:37,196:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:27:37,197:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 14:27:37,197:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 14:27:37,198:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:27:37,539:INFO:Uploading results into container
2025-06-02 14:27:37,541:INFO:Uploading model into container now
2025-06-02 14:27:37,542:INFO:_master_model_container: 22
2025-06-02 14:27:37,542:INFO:_display_container: 4
2025-06-02 14:27:37,543:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:27:37,543:INFO:create_model() successfully completed......................................
2025-06-02 14:27:39,123:INFO:SubProcess create_model() end ==================================
2025-06-02 14:27:39,125:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8764
2025-06-02 14:27:39,127:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06) result for R2 is 0.8217
2025-06-02 14:27:39,128:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 14:27:39,128:INFO:choose_better completed
2025-06-02 14:27:39,128:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 14:27:39,155:INFO:_master_model_container: 22
2025-06-02 14:27:39,156:INFO:_display_container: 3
2025-06-02 14:27:39,157:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:27:39,158:INFO:tune_model() successfully completed......................................
2025-06-02 14:27:40,652:INFO:Initializing finalize_model()
2025-06-02 14:27:40,653:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 14:27:40,654:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:27:40,716:INFO:Initializing create_model()
2025-06-02 14:27:40,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:27:40,716:INFO:Checking exceptions
2025-06-02 14:27:40,720:INFO:Importing libraries
2025-06-02 14:27:40,720:INFO:Copying training dataset
2025-06-02 14:27:40,729:INFO:Defining folds
2025-06-02 14:27:40,729:INFO:Declaring metric variables
2025-06-02 14:27:40,730:INFO:Importing untrained model
2025-06-02 14:27:40,730:INFO:Declaring custom model
2025-06-02 14:27:40,732:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:27:40,736:INFO:Cross validation set to False
2025-06-02 14:27:40,737:INFO:Fitting Model
2025-06-02 14:27:41,245:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:27:41,252:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005217 seconds.
2025-06-02 14:27:41,253:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:27:41,253:INFO:[LightGBM] [Info] Total Bins 6237
2025-06-02 14:27:41,254:INFO:[LightGBM] [Info] Number of data points in the train set: 4478, number of used features: 95
2025-06-02 14:27:41,255:INFO:[LightGBM] [Info] Start training from score -0.483793
2025-06-02 14:27:41,491:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:27:41,492:INFO:create_model() successfully completed......................................
2025-06-02 14:27:42,946:INFO:_master_model_container: 22
2025-06-02 14:27:42,946:INFO:_display_container: 3
2025-06-02 14:27:42,975:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:27:42,975:INFO:finalize_model() successfully completed......................................
2025-06-02 14:27:44,439:INFO:Initializing save_model()
2025-06-02 14:27:44,439:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 14:27:44,439:INFO:Adding model into prep_pipe
2025-06-02 14:27:44,439:WARNING:Only Model saved as it was a pipeline.
2025-06-02 14:27:44,463:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 14:27:44,488:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:27:44,489:INFO:save_model() successfully completed......................................
2025-06-02 14:27:45,905:INFO:Initializing get_config()
2025-06-02 14:27:45,906:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D93AB790>, variable=X_holdout)
2025-06-02 14:30:22,477:INFO:PyCaret RegressionExperiment
2025-06-02 14:30:22,479:INFO:Logging name: reg-default-name
2025-06-02 14:30:22,479:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 14:30:22,479:INFO:version 3.3.2
2025-06-02 14:30:22,480:INFO:Initializing setup()
2025-06-02 14:30:22,480:INFO:self.USI: 2a07
2025-06-02 14:30:22,480:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 14:30:22,480:INFO:Checking environment
2025-06-02 14:30:22,481:INFO:python_version: 3.10.16
2025-06-02 14:30:22,481:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 14:30:22,481:INFO:machine: AMD64
2025-06-02 14:30:22,482:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 14:30:22,491:INFO:Memory: svmem(total=6378008576, available=481484800, percent=92.5, used=5896523776, free=481484800)
2025-06-02 14:30:22,491:INFO:Physical Core: 4
2025-06-02 14:30:22,491:INFO:Logical Core: 8
2025-06-02 14:30:22,492:INFO:Checking libraries
2025-06-02 14:30:22,492:INFO:System:
2025-06-02 14:30:22,492:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 14:30:22,492:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 14:30:22,492:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 14:30:22,492:INFO:PyCaret required dependencies:
2025-06-02 14:30:22,493:INFO:                 pip: 25.1
2025-06-02 14:30:22,493:INFO:          setuptools: 78.1.1
2025-06-02 14:30:22,493:INFO:             pycaret: 3.3.2
2025-06-02 14:30:22,493:INFO:             IPython: 8.37.0
2025-06-02 14:30:22,493:INFO:          ipywidgets: 8.1.7
2025-06-02 14:30:22,493:INFO:                tqdm: 4.67.1
2025-06-02 14:30:22,494:INFO:               numpy: 1.26.4
2025-06-02 14:30:22,494:INFO:              pandas: 2.0.1
2025-06-02 14:30:22,494:INFO:              jinja2: 3.1.6
2025-06-02 14:30:22,494:INFO:               scipy: 1.10.1
2025-06-02 14:30:22,494:INFO:              joblib: 1.3.2
2025-06-02 14:30:22,494:INFO:             sklearn: 1.4.2
2025-06-02 14:30:22,494:INFO:                pyod: 2.0.5
2025-06-02 14:30:22,494:INFO:            imblearn: 0.13.0
2025-06-02 14:30:22,494:INFO:   category_encoders: 2.7.0
2025-06-02 14:30:22,494:INFO:            lightgbm: 4.6.0
2025-06-02 14:30:22,494:INFO:               numba: 0.61.0
2025-06-02 14:30:22,495:INFO:            requests: 2.32.3
2025-06-02 14:30:22,495:INFO:          matplotlib: 3.7.1
2025-06-02 14:30:22,495:INFO:          scikitplot: 0.3.7
2025-06-02 14:30:22,495:INFO:         yellowbrick: 1.5
2025-06-02 14:30:22,495:INFO:              plotly: 6.1.2
2025-06-02 14:30:22,495:INFO:    plotly-resampler: Not installed
2025-06-02 14:30:22,495:INFO:             kaleido: 0.2.1
2025-06-02 14:30:22,495:INFO:           schemdraw: 0.15
2025-06-02 14:30:22,495:INFO:         statsmodels: 0.14.4
2025-06-02 14:30:22,495:INFO:              sktime: 0.26.0
2025-06-02 14:30:22,495:INFO:               tbats: 1.1.3
2025-06-02 14:30:22,496:INFO:            pmdarima: 2.0.4
2025-06-02 14:30:22,496:INFO:              psutil: 7.0.0
2025-06-02 14:30:22,496:INFO:          markupsafe: 2.1.2
2025-06-02 14:30:22,496:INFO:             pickle5: Not installed
2025-06-02 14:30:22,496:INFO:         cloudpickle: 3.1.1
2025-06-02 14:30:22,496:INFO:         deprecation: 2.1.0
2025-06-02 14:30:22,496:INFO:              xxhash: 3.5.0
2025-06-02 14:30:22,496:INFO:           wurlitzer: Not installed
2025-06-02 14:30:22,496:INFO:PyCaret optional dependencies:
2025-06-02 14:30:22,496:INFO:                shap: 0.44.1
2025-06-02 14:30:22,496:INFO:           interpret: 0.6.9
2025-06-02 14:30:22,496:INFO:                umap: 0.5.7
2025-06-02 14:30:22,497:INFO:     ydata_profiling: 4.16.1
2025-06-02 14:30:22,497:INFO:  explainerdashboard: 0.4.8
2025-06-02 14:30:22,497:INFO:             autoviz: Not installed
2025-06-02 14:30:22,497:INFO:           fairlearn: 0.7.0
2025-06-02 14:30:22,497:INFO:          deepchecks: Not installed
2025-06-02 14:30:22,497:INFO:             xgboost: 3.0.2
2025-06-02 14:30:22,497:INFO:            catboost: 1.2.8
2025-06-02 14:30:22,497:INFO:              kmodes: 0.12.2
2025-06-02 14:30:22,497:INFO:             mlxtend: 0.23.4
2025-06-02 14:30:22,497:INFO:       statsforecast: 1.5.0
2025-06-02 14:30:22,497:INFO:        tune_sklearn: Not installed
2025-06-02 14:30:22,497:INFO:                 ray: Not installed
2025-06-02 14:30:22,497:INFO:            hyperopt: 0.2.7
2025-06-02 14:30:22,498:INFO:              optuna: 4.3.0
2025-06-02 14:30:22,498:INFO:               skopt: 0.10.2
2025-06-02 14:30:22,498:INFO:              mlflow: 2.22.0
2025-06-02 14:30:22,498:INFO:              gradio: 5.32.0
2025-06-02 14:30:22,498:INFO:             fastapi: 0.115.12
2025-06-02 14:30:22,498:INFO:             uvicorn: 0.34.3
2025-06-02 14:30:22,498:INFO:              m2cgen: 0.10.0
2025-06-02 14:30:22,498:INFO:           evidently: 0.4.40
2025-06-02 14:30:22,498:INFO:               fugue: 0.8.5
2025-06-02 14:30:22,498:INFO:           streamlit: Not installed
2025-06-02 14:30:22,498:INFO:             prophet: Not installed
2025-06-02 14:30:22,498:INFO:None
2025-06-02 14:30:22,498:INFO:Set up data.
2025-06-02 14:30:22,647:INFO:Set up folding strategy.
2025-06-02 14:30:22,648:INFO:Set up train/test split.
2025-06-02 14:30:22,765:INFO:Set up index.
2025-06-02 14:30:22,767:INFO:Assigning column types.
2025-06-02 14:30:22,838:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 14:30:22,840:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 14:30:22,851:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:30:22,860:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,030:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,119:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,121:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:30:23,126:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:30:23,127:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,136:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,148:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,312:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,396:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,397:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:30:23,402:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:30:23,404:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 14:30:23,413:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,423:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,602:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,689:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,690:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:30:23,695:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:30:23,709:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,718:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,876:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,993:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:30:23,994:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:30:24,001:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:30:24,003:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 14:30:24,019:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:30:24,191:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:30:24,290:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:30:24,291:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:30:24,295:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:30:24,316:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:30:24,457:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:30:24,543:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:30:24,544:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:30:24,548:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:30:24,550:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 14:30:24,771:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:30:24,880:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:30:24,881:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:30:24,888:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:30:25,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:30:25,192:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:30:25,193:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:30:25,197:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:30:25,198:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 14:30:25,404:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:30:25,513:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:30:25,520:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:30:25,758:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:30:25,892:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:30:25,898:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:30:25,900:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 14:30:26,228:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:30:26,235:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:30:26,570:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:30:26,577:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:30:26,582:INFO:Preparing preprocessing pipeline...
2025-06-02 14:30:26,582:INFO:Set up simple imputation.
2025-06-02 14:30:26,582:INFO:Set up removing multicollinearity.
2025-06-02 14:30:26,594:INFO:Set up column name cleaning.
2025-06-02 14:30:26,921:INFO:Finished creating preprocessing pipeline.
2025-06-02 14:30:26,937:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 14:30:26,937:INFO:Creating final display dataframe.
2025-06-02 14:30:27,532:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              2a07
2025-06-02 14:30:27,914:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:30:27,924:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:30:28,320:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:30:28,327:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:30:28,329:INFO:setup() successfully completed in 5.88s...............
2025-06-02 14:30:28,331:INFO:Initializing compare_models()
2025-06-02 14:30:28,331:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 14:30:28,331:INFO:Checking exceptions
2025-06-02 14:30:28,373:INFO:Preparing display monitor
2025-06-02 14:30:28,498:INFO:Initializing Linear Regression
2025-06-02 14:30:28,499:INFO:Total runtime is 1.6637643178304036e-05 minutes
2025-06-02 14:30:28,524:INFO:SubProcess create_model() called ==================================
2025-06-02 14:30:28,527:INFO:Initializing create_model()
2025-06-02 14:30:28,527:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:30:28,527:INFO:Checking exceptions
2025-06-02 14:30:28,528:INFO:Importing libraries
2025-06-02 14:30:28,528:INFO:Copying training dataset
2025-06-02 14:30:28,887:INFO:Defining folds
2025-06-02 14:30:28,887:INFO:Declaring metric variables
2025-06-02 14:30:28,929:INFO:Importing untrained model
2025-06-02 14:30:28,958:INFO:Linear Regression Imported successfully
2025-06-02 14:30:29,012:INFO:Starting cross validation
2025-06-02 14:30:29,020:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:30:30,295:INFO:Calculating mean and std
2025-06-02 14:30:30,298:INFO:Creating metrics dataframe
2025-06-02 14:30:30,304:INFO:Uploading results into container
2025-06-02 14:30:30,306:INFO:Uploading model into container now
2025-06-02 14:30:30,307:INFO:_master_model_container: 1
2025-06-02 14:30:30,307:INFO:_display_container: 2
2025-06-02 14:30:30,308:INFO:LinearRegression(n_jobs=-1)
2025-06-02 14:30:30,308:INFO:create_model() successfully completed......................................
2025-06-02 14:30:32,404:INFO:SubProcess create_model() end ==================================
2025-06-02 14:30:32,404:INFO:Creating metrics dataframe
2025-06-02 14:30:32,431:INFO:Initializing Lasso Regression
2025-06-02 14:30:32,431:INFO:Total runtime is 0.0655431310335795 minutes
2025-06-02 14:30:32,445:INFO:SubProcess create_model() called ==================================
2025-06-02 14:30:32,446:INFO:Initializing create_model()
2025-06-02 14:30:32,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:30:32,447:INFO:Checking exceptions
2025-06-02 14:30:32,448:INFO:Importing libraries
2025-06-02 14:30:32,448:INFO:Copying training dataset
2025-06-02 14:30:32,548:INFO:Defining folds
2025-06-02 14:30:32,549:INFO:Declaring metric variables
2025-06-02 14:30:32,569:INFO:Importing untrained model
2025-06-02 14:30:32,587:INFO:Lasso Regression Imported successfully
2025-06-02 14:30:32,623:INFO:Starting cross validation
2025-06-02 14:30:32,628:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:30:35,012:INFO:Calculating mean and std
2025-06-02 14:30:35,015:INFO:Creating metrics dataframe
2025-06-02 14:30:35,021:INFO:Uploading results into container
2025-06-02 14:30:35,022:INFO:Uploading model into container now
2025-06-02 14:30:35,023:INFO:_master_model_container: 2
2025-06-02 14:30:35,023:INFO:_display_container: 2
2025-06-02 14:30:35,024:INFO:Lasso(random_state=123)
2025-06-02 14:30:35,025:INFO:create_model() successfully completed......................................
2025-06-02 14:30:36,609:INFO:SubProcess create_model() end ==================================
2025-06-02 14:30:36,609:INFO:Creating metrics dataframe
2025-06-02 14:30:36,631:INFO:Initializing Ridge Regression
2025-06-02 14:30:36,631:INFO:Total runtime is 0.1355429212252299 minutes
2025-06-02 14:30:36,653:INFO:SubProcess create_model() called ==================================
2025-06-02 14:30:36,654:INFO:Initializing create_model()
2025-06-02 14:30:36,654:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:30:36,655:INFO:Checking exceptions
2025-06-02 14:30:36,656:INFO:Importing libraries
2025-06-02 14:30:36,656:INFO:Copying training dataset
2025-06-02 14:30:36,767:INFO:Defining folds
2025-06-02 14:30:36,768:INFO:Declaring metric variables
2025-06-02 14:30:36,786:INFO:Importing untrained model
2025-06-02 14:30:36,801:INFO:Ridge Regression Imported successfully
2025-06-02 14:30:36,831:INFO:Starting cross validation
2025-06-02 14:30:36,837:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:30:37,578:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.75561e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:30:37,612:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31073e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:30:37,685:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.24347e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:30:37,693:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.08754e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:30:37,829:INFO:Calculating mean and std
2025-06-02 14:30:37,833:INFO:Creating metrics dataframe
2025-06-02 14:30:37,842:INFO:Uploading results into container
2025-06-02 14:30:37,844:INFO:Uploading model into container now
2025-06-02 14:30:37,845:INFO:_master_model_container: 3
2025-06-02 14:30:37,846:INFO:_display_container: 2
2025-06-02 14:30:37,846:INFO:Ridge(random_state=123)
2025-06-02 14:30:37,847:INFO:create_model() successfully completed......................................
2025-06-02 14:30:39,334:INFO:SubProcess create_model() end ==================================
2025-06-02 14:30:39,335:INFO:Creating metrics dataframe
2025-06-02 14:30:39,356:INFO:Initializing Elastic Net
2025-06-02 14:30:39,356:INFO:Total runtime is 0.18095867236455282 minutes
2025-06-02 14:30:39,369:INFO:SubProcess create_model() called ==================================
2025-06-02 14:30:39,370:INFO:Initializing create_model()
2025-06-02 14:30:39,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:30:39,371:INFO:Checking exceptions
2025-06-02 14:30:39,372:INFO:Importing libraries
2025-06-02 14:30:39,372:INFO:Copying training dataset
2025-06-02 14:30:39,533:INFO:Defining folds
2025-06-02 14:30:39,534:INFO:Declaring metric variables
2025-06-02 14:30:39,547:INFO:Importing untrained model
2025-06-02 14:30:39,558:INFO:Elastic Net Imported successfully
2025-06-02 14:30:39,586:INFO:Starting cross validation
2025-06-02 14:30:39,591:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:30:40,707:INFO:Calculating mean and std
2025-06-02 14:30:40,710:INFO:Creating metrics dataframe
2025-06-02 14:30:40,715:INFO:Uploading results into container
2025-06-02 14:30:40,715:INFO:Uploading model into container now
2025-06-02 14:30:40,716:INFO:_master_model_container: 4
2025-06-02 14:30:40,717:INFO:_display_container: 2
2025-06-02 14:30:40,718:INFO:ElasticNet(random_state=123)
2025-06-02 14:30:40,718:INFO:create_model() successfully completed......................................
2025-06-02 14:30:42,272:INFO:SubProcess create_model() end ==================================
2025-06-02 14:30:42,272:INFO:Creating metrics dataframe
2025-06-02 14:30:42,295:INFO:Initializing Least Angle Regression
2025-06-02 14:30:42,295:INFO:Total runtime is 0.22995192607243856 minutes
2025-06-02 14:30:42,315:INFO:SubProcess create_model() called ==================================
2025-06-02 14:30:42,317:INFO:Initializing create_model()
2025-06-02 14:30:42,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:30:42,317:INFO:Checking exceptions
2025-06-02 14:30:42,318:INFO:Importing libraries
2025-06-02 14:30:42,318:INFO:Copying training dataset
2025-06-02 14:30:42,445:INFO:Defining folds
2025-06-02 14:30:42,445:INFO:Declaring metric variables
2025-06-02 14:30:42,466:INFO:Importing untrained model
2025-06-02 14:30:42,489:INFO:Least Angle Regression Imported successfully
2025-06-02 14:30:42,532:INFO:Starting cross validation
2025-06-02 14:30:42,540:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:30:44,124:INFO:Calculating mean and std
2025-06-02 14:30:44,126:INFO:Creating metrics dataframe
2025-06-02 14:30:44,130:INFO:Uploading results into container
2025-06-02 14:30:44,130:INFO:Uploading model into container now
2025-06-02 14:30:44,131:INFO:_master_model_container: 5
2025-06-02 14:30:44,132:INFO:_display_container: 2
2025-06-02 14:30:44,136:INFO:Lars(random_state=123)
2025-06-02 14:30:44,137:INFO:create_model() successfully completed......................................
2025-06-02 14:30:46,009:INFO:SubProcess create_model() end ==================================
2025-06-02 14:30:46,009:INFO:Creating metrics dataframe
2025-06-02 14:30:46,030:INFO:Initializing Lasso Least Angle Regression
2025-06-02 14:30:46,030:INFO:Total runtime is 0.2921962817509969 minutes
2025-06-02 14:30:46,044:INFO:SubProcess create_model() called ==================================
2025-06-02 14:30:46,045:INFO:Initializing create_model()
2025-06-02 14:30:46,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:30:46,045:INFO:Checking exceptions
2025-06-02 14:30:46,046:INFO:Importing libraries
2025-06-02 14:30:46,046:INFO:Copying training dataset
2025-06-02 14:30:46,143:INFO:Defining folds
2025-06-02 14:30:46,144:INFO:Declaring metric variables
2025-06-02 14:30:46,160:INFO:Importing untrained model
2025-06-02 14:30:46,176:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 14:30:46,212:INFO:Starting cross validation
2025-06-02 14:30:46,217:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:30:47,316:INFO:Calculating mean and std
2025-06-02 14:30:47,319:INFO:Creating metrics dataframe
2025-06-02 14:30:47,323:INFO:Uploading results into container
2025-06-02 14:30:47,324:INFO:Uploading model into container now
2025-06-02 14:30:47,325:INFO:_master_model_container: 6
2025-06-02 14:30:47,325:INFO:_display_container: 2
2025-06-02 14:30:47,326:INFO:LassoLars(random_state=123)
2025-06-02 14:30:47,326:INFO:create_model() successfully completed......................................
2025-06-02 14:30:48,965:INFO:SubProcess create_model() end ==================================
2025-06-02 14:30:48,966:INFO:Creating metrics dataframe
2025-06-02 14:30:48,986:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 14:30:48,986:INFO:Total runtime is 0.3414551496505737 minutes
2025-06-02 14:30:48,996:INFO:SubProcess create_model() called ==================================
2025-06-02 14:30:48,996:INFO:Initializing create_model()
2025-06-02 14:30:48,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:30:48,997:INFO:Checking exceptions
2025-06-02 14:30:48,998:INFO:Importing libraries
2025-06-02 14:30:48,998:INFO:Copying training dataset
2025-06-02 14:30:49,153:INFO:Defining folds
2025-06-02 14:30:49,153:INFO:Declaring metric variables
2025-06-02 14:30:49,164:INFO:Importing untrained model
2025-06-02 14:30:49,179:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 14:30:49,210:INFO:Starting cross validation
2025-06-02 14:30:49,214:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:30:50,155:INFO:Calculating mean and std
2025-06-02 14:30:50,157:INFO:Creating metrics dataframe
2025-06-02 14:30:50,161:INFO:Uploading results into container
2025-06-02 14:30:50,162:INFO:Uploading model into container now
2025-06-02 14:30:50,163:INFO:_master_model_container: 7
2025-06-02 14:30:50,163:INFO:_display_container: 2
2025-06-02 14:30:50,164:INFO:OrthogonalMatchingPursuit()
2025-06-02 14:30:50,164:INFO:create_model() successfully completed......................................
2025-06-02 14:30:51,617:INFO:SubProcess create_model() end ==================================
2025-06-02 14:30:51,618:INFO:Creating metrics dataframe
2025-06-02 14:30:51,637:INFO:Initializing Bayesian Ridge
2025-06-02 14:30:51,637:INFO:Total runtime is 0.38564244111378987 minutes
2025-06-02 14:30:51,646:INFO:SubProcess create_model() called ==================================
2025-06-02 14:30:51,647:INFO:Initializing create_model()
2025-06-02 14:30:51,648:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:30:51,648:INFO:Checking exceptions
2025-06-02 14:30:51,649:INFO:Importing libraries
2025-06-02 14:30:51,649:INFO:Copying training dataset
2025-06-02 14:30:51,763:INFO:Defining folds
2025-06-02 14:30:51,763:INFO:Declaring metric variables
2025-06-02 14:30:51,778:INFO:Importing untrained model
2025-06-02 14:30:51,806:INFO:Bayesian Ridge Imported successfully
2025-06-02 14:30:51,837:INFO:Starting cross validation
2025-06-02 14:30:51,841:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:30:52,863:INFO:Calculating mean and std
2025-06-02 14:30:52,866:INFO:Creating metrics dataframe
2025-06-02 14:30:52,872:INFO:Uploading results into container
2025-06-02 14:30:52,874:INFO:Uploading model into container now
2025-06-02 14:30:52,875:INFO:_master_model_container: 8
2025-06-02 14:30:52,875:INFO:_display_container: 2
2025-06-02 14:30:52,876:INFO:BayesianRidge()
2025-06-02 14:30:52,876:INFO:create_model() successfully completed......................................
2025-06-02 14:30:54,370:INFO:SubProcess create_model() end ==================================
2025-06-02 14:30:54,370:INFO:Creating metrics dataframe
2025-06-02 14:30:54,395:INFO:Initializing Passive Aggressive Regressor
2025-06-02 14:30:54,396:INFO:Total runtime is 0.4316213528315226 minutes
2025-06-02 14:30:54,410:INFO:SubProcess create_model() called ==================================
2025-06-02 14:30:54,411:INFO:Initializing create_model()
2025-06-02 14:30:54,411:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:30:54,411:INFO:Checking exceptions
2025-06-02 14:30:54,412:INFO:Importing libraries
2025-06-02 14:30:54,412:INFO:Copying training dataset
2025-06-02 14:30:54,534:INFO:Defining folds
2025-06-02 14:30:54,535:INFO:Declaring metric variables
2025-06-02 14:30:54,551:INFO:Importing untrained model
2025-06-02 14:30:54,574:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 14:30:54,604:INFO:Starting cross validation
2025-06-02 14:30:54,609:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:30:55,572:INFO:Calculating mean and std
2025-06-02 14:30:55,574:INFO:Creating metrics dataframe
2025-06-02 14:30:55,577:INFO:Uploading results into container
2025-06-02 14:30:55,578:INFO:Uploading model into container now
2025-06-02 14:30:55,579:INFO:_master_model_container: 9
2025-06-02 14:30:55,579:INFO:_display_container: 2
2025-06-02 14:30:55,580:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 14:30:55,581:INFO:create_model() successfully completed......................................
2025-06-02 14:30:57,013:INFO:SubProcess create_model() end ==================================
2025-06-02 14:30:57,014:INFO:Creating metrics dataframe
2025-06-02 14:30:57,037:INFO:Initializing Huber Regressor
2025-06-02 14:30:57,037:INFO:Total runtime is 0.4756466706593831 minutes
2025-06-02 14:30:57,050:INFO:SubProcess create_model() called ==================================
2025-06-02 14:30:57,052:INFO:Initializing create_model()
2025-06-02 14:30:57,052:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:30:57,053:INFO:Checking exceptions
2025-06-02 14:30:57,053:INFO:Importing libraries
2025-06-02 14:30:57,053:INFO:Copying training dataset
2025-06-02 14:30:57,142:INFO:Defining folds
2025-06-02 14:30:57,143:INFO:Declaring metric variables
2025-06-02 14:30:57,160:INFO:Importing untrained model
2025-06-02 14:30:57,175:INFO:Huber Regressor Imported successfully
2025-06-02 14:30:57,204:INFO:Starting cross validation
2025-06-02 14:30:57,210:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:30:59,595:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:30:59,631:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:30:59,722:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:30:59,772:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:30:59,809:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:30:59,889:INFO:Calculating mean and std
2025-06-02 14:30:59,891:INFO:Creating metrics dataframe
2025-06-02 14:30:59,895:INFO:Uploading results into container
2025-06-02 14:30:59,895:INFO:Uploading model into container now
2025-06-02 14:30:59,897:INFO:_master_model_container: 10
2025-06-02 14:30:59,897:INFO:_display_container: 2
2025-06-02 14:30:59,897:INFO:HuberRegressor()
2025-06-02 14:30:59,898:INFO:create_model() successfully completed......................................
2025-06-02 14:31:02,135:INFO:SubProcess create_model() end ==================================
2025-06-02 14:31:02,137:INFO:Creating metrics dataframe
2025-06-02 14:31:02,165:INFO:Initializing K Neighbors Regressor
2025-06-02 14:31:02,165:INFO:Total runtime is 0.5611038366953531 minutes
2025-06-02 14:31:02,178:INFO:SubProcess create_model() called ==================================
2025-06-02 14:31:02,180:INFO:Initializing create_model()
2025-06-02 14:31:02,181:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:31:02,182:INFO:Checking exceptions
2025-06-02 14:31:02,183:INFO:Importing libraries
2025-06-02 14:31:02,184:INFO:Copying training dataset
2025-06-02 14:31:02,377:INFO:Defining folds
2025-06-02 14:31:02,377:INFO:Declaring metric variables
2025-06-02 14:31:02,394:INFO:Importing untrained model
2025-06-02 14:31:02,423:INFO:K Neighbors Regressor Imported successfully
2025-06-02 14:31:02,497:INFO:Starting cross validation
2025-06-02 14:31:02,508:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:31:03,967:INFO:Calculating mean and std
2025-06-02 14:31:03,969:INFO:Creating metrics dataframe
2025-06-02 14:31:03,974:INFO:Uploading results into container
2025-06-02 14:31:03,976:INFO:Uploading model into container now
2025-06-02 14:31:03,977:INFO:_master_model_container: 11
2025-06-02 14:31:03,977:INFO:_display_container: 2
2025-06-02 14:31:03,978:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 14:31:03,978:INFO:create_model() successfully completed......................................
2025-06-02 14:31:05,602:INFO:SubProcess create_model() end ==================================
2025-06-02 14:31:05,603:INFO:Creating metrics dataframe
2025-06-02 14:31:05,643:INFO:Initializing Decision Tree Regressor
2025-06-02 14:31:05,643:INFO:Total runtime is 0.6190701882044474 minutes
2025-06-02 14:31:05,658:INFO:SubProcess create_model() called ==================================
2025-06-02 14:31:05,660:INFO:Initializing create_model()
2025-06-02 14:31:05,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:31:05,660:INFO:Checking exceptions
2025-06-02 14:31:05,661:INFO:Importing libraries
2025-06-02 14:31:05,661:INFO:Copying training dataset
2025-06-02 14:31:05,745:INFO:Defining folds
2025-06-02 14:31:05,746:INFO:Declaring metric variables
2025-06-02 14:31:05,764:INFO:Importing untrained model
2025-06-02 14:31:05,807:INFO:Decision Tree Regressor Imported successfully
2025-06-02 14:31:05,876:INFO:Starting cross validation
2025-06-02 14:31:05,883:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:31:07,506:INFO:Calculating mean and std
2025-06-02 14:31:07,508:INFO:Creating metrics dataframe
2025-06-02 14:31:07,513:INFO:Uploading results into container
2025-06-02 14:31:07,515:INFO:Uploading model into container now
2025-06-02 14:31:07,519:INFO:_master_model_container: 12
2025-06-02 14:31:07,519:INFO:_display_container: 2
2025-06-02 14:31:07,520:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 14:31:07,521:INFO:create_model() successfully completed......................................
2025-06-02 14:31:09,081:INFO:SubProcess create_model() end ==================================
2025-06-02 14:31:09,081:INFO:Creating metrics dataframe
2025-06-02 14:31:09,107:INFO:Initializing Random Forest Regressor
2025-06-02 14:31:09,108:INFO:Total runtime is 0.6768240372339884 minutes
2025-06-02 14:31:09,121:INFO:SubProcess create_model() called ==================================
2025-06-02 14:31:09,122:INFO:Initializing create_model()
2025-06-02 14:31:09,123:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:31:09,124:INFO:Checking exceptions
2025-06-02 14:31:09,125:INFO:Importing libraries
2025-06-02 14:31:09,125:INFO:Copying training dataset
2025-06-02 14:31:09,262:INFO:Defining folds
2025-06-02 14:31:09,263:INFO:Declaring metric variables
2025-06-02 14:31:09,286:INFO:Importing untrained model
2025-06-02 14:31:09,312:INFO:Random Forest Regressor Imported successfully
2025-06-02 14:31:09,348:INFO:Starting cross validation
2025-06-02 14:31:09,354:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:31:22,546:INFO:Calculating mean and std
2025-06-02 14:31:22,548:INFO:Creating metrics dataframe
2025-06-02 14:31:22,554:INFO:Uploading results into container
2025-06-02 14:31:22,555:INFO:Uploading model into container now
2025-06-02 14:31:22,555:INFO:_master_model_container: 13
2025-06-02 14:31:22,556:INFO:_display_container: 2
2025-06-02 14:31:22,556:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:31:22,557:INFO:create_model() successfully completed......................................
2025-06-02 14:31:24,702:INFO:SubProcess create_model() end ==================================
2025-06-02 14:31:24,702:INFO:Creating metrics dataframe
2025-06-02 14:31:24,732:INFO:Initializing Extra Trees Regressor
2025-06-02 14:31:24,732:INFO:Total runtime is 0.9372280359268188 minutes
2025-06-02 14:31:24,746:INFO:SubProcess create_model() called ==================================
2025-06-02 14:31:24,747:INFO:Initializing create_model()
2025-06-02 14:31:24,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:31:24,747:INFO:Checking exceptions
2025-06-02 14:31:24,748:INFO:Importing libraries
2025-06-02 14:31:24,748:INFO:Copying training dataset
2025-06-02 14:31:24,876:INFO:Defining folds
2025-06-02 14:31:24,877:INFO:Declaring metric variables
2025-06-02 14:31:24,898:INFO:Importing untrained model
2025-06-02 14:31:24,920:INFO:Extra Trees Regressor Imported successfully
2025-06-02 14:31:24,954:INFO:Starting cross validation
2025-06-02 14:31:24,960:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:31:34,474:INFO:Calculating mean and std
2025-06-02 14:31:34,476:INFO:Creating metrics dataframe
2025-06-02 14:31:34,479:INFO:Uploading results into container
2025-06-02 14:31:34,480:INFO:Uploading model into container now
2025-06-02 14:31:34,481:INFO:_master_model_container: 14
2025-06-02 14:31:34,481:INFO:_display_container: 2
2025-06-02 14:31:34,481:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:31:34,482:INFO:create_model() successfully completed......................................
2025-06-02 14:31:36,006:INFO:SubProcess create_model() end ==================================
2025-06-02 14:31:36,006:INFO:Creating metrics dataframe
2025-06-02 14:31:36,032:INFO:Initializing AdaBoost Regressor
2025-06-02 14:31:36,032:INFO:Total runtime is 1.125566029548645 minutes
2025-06-02 14:31:36,046:INFO:SubProcess create_model() called ==================================
2025-06-02 14:31:36,046:INFO:Initializing create_model()
2025-06-02 14:31:36,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:31:36,047:INFO:Checking exceptions
2025-06-02 14:31:36,048:INFO:Importing libraries
2025-06-02 14:31:36,048:INFO:Copying training dataset
2025-06-02 14:31:36,127:INFO:Defining folds
2025-06-02 14:31:36,131:INFO:Declaring metric variables
2025-06-02 14:31:36,153:INFO:Importing untrained model
2025-06-02 14:31:36,178:INFO:AdaBoost Regressor Imported successfully
2025-06-02 14:31:36,220:INFO:Starting cross validation
2025-06-02 14:31:36,224:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:31:38,512:INFO:Calculating mean and std
2025-06-02 14:31:38,514:INFO:Creating metrics dataframe
2025-06-02 14:31:38,519:INFO:Uploading results into container
2025-06-02 14:31:38,520:INFO:Uploading model into container now
2025-06-02 14:31:38,521:INFO:_master_model_container: 15
2025-06-02 14:31:38,521:INFO:_display_container: 2
2025-06-02 14:31:38,522:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 14:31:38,522:INFO:create_model() successfully completed......................................
2025-06-02 14:31:39,868:INFO:SubProcess create_model() end ==================================
2025-06-02 14:31:39,869:INFO:Creating metrics dataframe
2025-06-02 14:31:39,904:INFO:Initializing Gradient Boosting Regressor
2025-06-02 14:31:39,904:INFO:Total runtime is 1.1901012380917866 minutes
2025-06-02 14:31:39,916:INFO:SubProcess create_model() called ==================================
2025-06-02 14:31:39,917:INFO:Initializing create_model()
2025-06-02 14:31:39,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:31:39,918:INFO:Checking exceptions
2025-06-02 14:31:39,919:INFO:Importing libraries
2025-06-02 14:31:39,919:INFO:Copying training dataset
2025-06-02 14:31:40,028:INFO:Defining folds
2025-06-02 14:31:40,029:INFO:Declaring metric variables
2025-06-02 14:31:40,048:INFO:Importing untrained model
2025-06-02 14:31:40,085:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 14:31:40,113:INFO:Starting cross validation
2025-06-02 14:31:40,128:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:31:44,058:INFO:Calculating mean and std
2025-06-02 14:31:44,060:INFO:Creating metrics dataframe
2025-06-02 14:31:44,064:INFO:Uploading results into container
2025-06-02 14:31:44,065:INFO:Uploading model into container now
2025-06-02 14:31:44,066:INFO:_master_model_container: 16
2025-06-02 14:31:44,067:INFO:_display_container: 2
2025-06-02 14:31:44,068:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 14:31:44,068:INFO:create_model() successfully completed......................................
2025-06-02 14:31:45,391:INFO:SubProcess create_model() end ==================================
2025-06-02 14:31:45,392:INFO:Creating metrics dataframe
2025-06-02 14:31:45,417:INFO:Initializing Extreme Gradient Boosting
2025-06-02 14:31:45,417:INFO:Total runtime is 1.2819833795229594 minutes
2025-06-02 14:31:45,430:INFO:SubProcess create_model() called ==================================
2025-06-02 14:31:45,431:INFO:Initializing create_model()
2025-06-02 14:31:45,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:31:45,432:INFO:Checking exceptions
2025-06-02 14:31:45,432:INFO:Importing libraries
2025-06-02 14:31:45,433:INFO:Copying training dataset
2025-06-02 14:31:45,549:INFO:Defining folds
2025-06-02 14:31:45,550:INFO:Declaring metric variables
2025-06-02 14:31:45,586:INFO:Importing untrained model
2025-06-02 14:31:45,603:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 14:31:45,641:INFO:Starting cross validation
2025-06-02 14:31:45,645:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:31:47,845:INFO:Calculating mean and std
2025-06-02 14:31:47,847:INFO:Creating metrics dataframe
2025-06-02 14:31:47,851:INFO:Uploading results into container
2025-06-02 14:31:47,852:INFO:Uploading model into container now
2025-06-02 14:31:47,853:INFO:_master_model_container: 17
2025-06-02 14:31:47,853:INFO:_display_container: 2
2025-06-02 14:31:47,856:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 14:31:47,856:INFO:create_model() successfully completed......................................
2025-06-02 14:31:49,205:INFO:SubProcess create_model() end ==================================
2025-06-02 14:31:49,205:INFO:Creating metrics dataframe
2025-06-02 14:31:49,226:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 14:31:49,226:INFO:Total runtime is 1.3454580426216125 minutes
2025-06-02 14:31:49,236:INFO:SubProcess create_model() called ==================================
2025-06-02 14:31:49,237:INFO:Initializing create_model()
2025-06-02 14:31:49,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:31:49,238:INFO:Checking exceptions
2025-06-02 14:31:49,239:INFO:Importing libraries
2025-06-02 14:31:49,239:INFO:Copying training dataset
2025-06-02 14:31:49,311:INFO:Defining folds
2025-06-02 14:31:49,322:INFO:Declaring metric variables
2025-06-02 14:31:49,363:INFO:Importing untrained model
2025-06-02 14:31:49,382:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:31:49,415:INFO:Starting cross validation
2025-06-02 14:31:49,420:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:31:51,455:INFO:Calculating mean and std
2025-06-02 14:31:51,457:INFO:Creating metrics dataframe
2025-06-02 14:31:51,463:INFO:Uploading results into container
2025-06-02 14:31:51,465:INFO:Uploading model into container now
2025-06-02 14:31:51,466:INFO:_master_model_container: 18
2025-06-02 14:31:51,466:INFO:_display_container: 2
2025-06-02 14:31:51,468:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:31:51,468:INFO:create_model() successfully completed......................................
2025-06-02 14:31:52,720:INFO:SubProcess create_model() end ==================================
2025-06-02 14:31:52,721:INFO:Creating metrics dataframe
2025-06-02 14:31:52,740:INFO:Initializing CatBoost Regressor
2025-06-02 14:31:52,740:INFO:Total runtime is 1.4040365815162659 minutes
2025-06-02 14:31:52,748:INFO:SubProcess create_model() called ==================================
2025-06-02 14:31:52,749:INFO:Initializing create_model()
2025-06-02 14:31:52,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:31:52,751:INFO:Checking exceptions
2025-06-02 14:31:52,751:INFO:Importing libraries
2025-06-02 14:31:52,752:INFO:Copying training dataset
2025-06-02 14:31:52,886:INFO:Defining folds
2025-06-02 14:31:52,886:INFO:Declaring metric variables
2025-06-02 14:31:52,906:INFO:Importing untrained model
2025-06-02 14:31:52,939:INFO:CatBoost Regressor Imported successfully
2025-06-02 14:31:52,996:INFO:Starting cross validation
2025-06-02 14:31:53,004:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:32:24,236:INFO:Calculating mean and std
2025-06-02 14:32:24,240:INFO:Creating metrics dataframe
2025-06-02 14:32:24,248:INFO:Uploading results into container
2025-06-02 14:32:24,251:INFO:Uploading model into container now
2025-06-02 14:32:24,253:INFO:_master_model_container: 19
2025-06-02 14:32:24,253:INFO:_display_container: 2
2025-06-02 14:32:24,254:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6DA13F460>
2025-06-02 14:32:24,255:INFO:create_model() successfully completed......................................
2025-06-02 14:32:26,353:INFO:SubProcess create_model() end ==================================
2025-06-02 14:32:26,353:INFO:Creating metrics dataframe
2025-06-02 14:32:26,381:INFO:Initializing Dummy Regressor
2025-06-02 14:32:26,381:INFO:Total runtime is 1.964718214670817 minutes
2025-06-02 14:32:26,398:INFO:SubProcess create_model() called ==================================
2025-06-02 14:32:26,399:INFO:Initializing create_model()
2025-06-02 14:32:26,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DA13E110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:32:26,401:INFO:Checking exceptions
2025-06-02 14:32:26,401:INFO:Importing libraries
2025-06-02 14:32:26,402:INFO:Copying training dataset
2025-06-02 14:32:26,506:INFO:Defining folds
2025-06-02 14:32:26,507:INFO:Declaring metric variables
2025-06-02 14:32:26,522:INFO:Importing untrained model
2025-06-02 14:32:26,544:INFO:Dummy Regressor Imported successfully
2025-06-02 14:32:26,577:INFO:Starting cross validation
2025-06-02 14:32:26,581:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:32:27,727:INFO:Calculating mean and std
2025-06-02 14:32:27,729:INFO:Creating metrics dataframe
2025-06-02 14:32:27,735:INFO:Uploading results into container
2025-06-02 14:32:27,737:INFO:Uploading model into container now
2025-06-02 14:32:27,738:INFO:_master_model_container: 20
2025-06-02 14:32:27,738:INFO:_display_container: 2
2025-06-02 14:32:27,739:INFO:DummyRegressor()
2025-06-02 14:32:27,739:INFO:create_model() successfully completed......................................
2025-06-02 14:32:29,047:INFO:SubProcess create_model() end ==================================
2025-06-02 14:32:29,047:INFO:Creating metrics dataframe
2025-06-02 14:32:29,112:INFO:Initializing create_model()
2025-06-02 14:32:29,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:32:29,112:INFO:Checking exceptions
2025-06-02 14:32:29,115:INFO:Importing libraries
2025-06-02 14:32:29,115:INFO:Copying training dataset
2025-06-02 14:32:29,222:INFO:Defining folds
2025-06-02 14:32:29,222:INFO:Declaring metric variables
2025-06-02 14:32:29,223:INFO:Importing untrained model
2025-06-02 14:32:29,223:INFO:Declaring custom model
2025-06-02 14:32:29,225:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:32:29,227:INFO:Cross validation set to False
2025-06-02 14:32:29,227:INFO:Fitting Model
2025-06-02 14:32:29,927:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:32:29,936:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006096 seconds.
2025-06-02 14:32:29,937:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:32:29,937:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 14:32:29,940:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 14:32:29,942:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:32:30,182:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:32:30,182:INFO:create_model() successfully completed......................................
2025-06-02 14:32:31,820:INFO:_master_model_container: 20
2025-06-02 14:32:31,820:INFO:_display_container: 2
2025-06-02 14:32:31,822:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:32:31,822:INFO:compare_models() successfully completed......................................
2025-06-02 14:32:31,830:INFO:Initializing tune_model()
2025-06-02 14:32:31,830:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>)
2025-06-02 14:32:31,830:INFO:Checking exceptions
2025-06-02 14:32:31,830:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 14:32:31,908:INFO:Copying training dataset
2025-06-02 14:32:31,982:INFO:Checking base model
2025-06-02 14:32:31,983:INFO:Base model : Light Gradient Boosting Machine
2025-06-02 14:32:31,999:INFO:Declaring metric variables
2025-06-02 14:32:32,017:INFO:Defining Hyperparameters
2025-06-02 14:32:33,697:INFO:Tuning with n_jobs=-1
2025-06-02 14:32:33,729:INFO:Initializing skopt.BayesSearchCV
2025-06-02 14:32:56,405:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.8608120752388259), ('actual_estimator__bagging_freq', 1), ('actual_estimator__feature_fraction', 0.4284489606984907), ('actual_estimator__learning_rate', 0.016133245419918712), ('actual_estimator__min_child_samples', 95), ('actual_estimator__min_split_gain', 0.8209314243567916), ('actual_estimator__n_estimators', 239), ('actual_estimator__num_leaves', 183), ('actual_estimator__reg_alpha', 8.662569304197528e-07), ('actual_estimator__reg_lambda', 5.001062744294253e-06)])
2025-06-02 14:32:56,407:INFO:Hyperparameter search completed
2025-06-02 14:32:56,407:INFO:SubProcess create_model() called ==================================
2025-06-02 14:32:56,409:INFO:Initializing create_model()
2025-06-02 14:32:56,409:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC847D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.8608120752388259, 'bagging_freq': 1, 'feature_fraction': 0.4284489606984907, 'learning_rate': 0.016133245419918712, 'min_child_samples': 95, 'min_split_gain': 0.8209314243567916, 'n_estimators': 239, 'num_leaves': 183, 'reg_alpha': 8.662569304197528e-07, 'reg_lambda': 5.001062744294253e-06})
2025-06-02 14:32:56,409:INFO:Checking exceptions
2025-06-02 14:32:56,410:INFO:Importing libraries
2025-06-02 14:32:56,411:INFO:Copying training dataset
2025-06-02 14:32:56,497:INFO:Defining folds
2025-06-02 14:32:56,498:INFO:Declaring metric variables
2025-06-02 14:32:56,507:INFO:Importing untrained model
2025-06-02 14:32:56,507:INFO:Declaring custom model
2025-06-02 14:32:56,522:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:32:56,561:INFO:Starting cross validation
2025-06-02 14:32:56,566:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:32:58,821:INFO:Calculating mean and std
2025-06-02 14:32:58,822:INFO:Creating metrics dataframe
2025-06-02 14:32:58,842:INFO:Finalizing model
2025-06-02 14:32:59,597:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 14:32:59,597:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 14:32:59,597:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 14:32:59,625:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:32:59,626:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 14:32:59,626:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 14:32:59,627:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 14:32:59,639:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009350 seconds.
2025-06-02 14:32:59,639:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:32:59,640:INFO:[LightGBM] [Info] Total Bins 6220
2025-06-02 14:32:59,658:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 94
2025-06-02 14:32:59,660:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:32:59,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:32:59,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:33:00,794:INFO:Uploading results into container
2025-06-02 14:33:00,797:INFO:Uploading model into container now
2025-06-02 14:33:00,807:INFO:_master_model_container: 21
2025-06-02 14:33:00,811:INFO:_display_container: 3
2025-06-02 14:33:00,829:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06)
2025-06-02 14:33:00,831:INFO:create_model() successfully completed......................................
2025-06-02 14:33:04,102:INFO:SubProcess create_model() end ==================================
2025-06-02 14:33:04,102:INFO:choose_better activated
2025-06-02 14:33:04,112:INFO:SubProcess create_model() called ==================================
2025-06-02 14:33:04,113:INFO:Initializing create_model()
2025-06-02 14:33:04,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:33:04,114:INFO:Checking exceptions
2025-06-02 14:33:04,119:INFO:Importing libraries
2025-06-02 14:33:04,119:INFO:Copying training dataset
2025-06-02 14:33:04,219:INFO:Defining folds
2025-06-02 14:33:04,220:INFO:Declaring metric variables
2025-06-02 14:33:04,220:INFO:Importing untrained model
2025-06-02 14:33:04,221:INFO:Declaring custom model
2025-06-02 14:33:04,224:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:33:04,224:INFO:Starting cross validation
2025-06-02 14:33:04,229:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:33:06,341:INFO:Calculating mean and std
2025-06-02 14:33:06,342:INFO:Creating metrics dataframe
2025-06-02 14:33:06,346:INFO:Finalizing model
2025-06-02 14:33:06,940:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:33:06,949:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004887 seconds.
2025-06-02 14:33:06,949:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:33:06,950:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 14:33:06,951:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 14:33:06,953:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:33:07,165:INFO:Uploading results into container
2025-06-02 14:33:07,167:INFO:Uploading model into container now
2025-06-02 14:33:07,168:INFO:_master_model_container: 22
2025-06-02 14:33:07,169:INFO:_display_container: 4
2025-06-02 14:33:07,170:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:33:07,170:INFO:create_model() successfully completed......................................
2025-06-02 14:33:08,715:INFO:SubProcess create_model() end ==================================
2025-06-02 14:33:08,718:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8764
2025-06-02 14:33:08,724:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06) result for R2 is 0.8217
2025-06-02 14:33:08,726:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 14:33:08,726:INFO:choose_better completed
2025-06-02 14:33:08,726:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 14:33:08,765:INFO:_master_model_container: 22
2025-06-02 14:33:08,765:INFO:_display_container: 3
2025-06-02 14:33:08,769:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:33:08,770:INFO:tune_model() successfully completed......................................
2025-06-02 14:33:10,548:INFO:Initializing finalize_model()
2025-06-02 14:33:10,548:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 14:33:10,550:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:33:10,621:INFO:Initializing create_model()
2025-06-02 14:33:10,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:33:10,621:INFO:Checking exceptions
2025-06-02 14:33:10,624:INFO:Importing libraries
2025-06-02 14:33:10,625:INFO:Copying training dataset
2025-06-02 14:33:10,632:INFO:Defining folds
2025-06-02 14:33:10,633:INFO:Declaring metric variables
2025-06-02 14:33:10,634:INFO:Importing untrained model
2025-06-02 14:33:10,634:INFO:Declaring custom model
2025-06-02 14:33:10,639:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:33:10,647:INFO:Cross validation set to False
2025-06-02 14:33:10,648:INFO:Fitting Model
2025-06-02 14:33:11,422:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:33:11,433:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007153 seconds.
2025-06-02 14:33:11,434:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:33:11,435:INFO:[LightGBM] [Info] Total Bins 6237
2025-06-02 14:33:11,435:INFO:[LightGBM] [Info] Number of data points in the train set: 4478, number of used features: 95
2025-06-02 14:33:11,437:INFO:[LightGBM] [Info] Start training from score -0.483793
2025-06-02 14:33:11,696:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:33:11,696:INFO:create_model() successfully completed......................................
2025-06-02 14:33:13,422:INFO:_master_model_container: 22
2025-06-02 14:33:13,422:INFO:_display_container: 3
2025-06-02 14:33:13,458:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:33:13,458:INFO:finalize_model() successfully completed......................................
2025-06-02 14:33:15,389:INFO:Initializing save_model()
2025-06-02 14:33:15,389:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 14:33:15,389:INFO:Adding model into prep_pipe
2025-06-02 14:33:15,390:WARNING:Only Model saved as it was a pipeline.
2025-06-02 14:33:15,437:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 14:33:15,479:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:33:15,479:INFO:save_model() successfully completed......................................
2025-06-02 14:33:17,287:INFO:Initializing get_config()
2025-06-02 14:33:17,287:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, variable=X_test)
2025-06-02 14:33:17,288:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 14:33:17,289:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 14:33:17,390:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2059                       12.0                       13.0   
2652                       29.0                       31.0   
3768                       34.0                       65.0   
3686                        8.0                       14.0   
1037                       53.0                       83.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2059                      1.0               12.500000   
2652                      2.0               29.500000   
3768                     31.0               44.782608   
3686                      6.0               10.000000   
1037                     30.0               77.545456   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2059                   0.500000                    12.0   
2652                   0.750000                    29.0   
3768                  14.064272                    34.0   
3686                   2.666667                     8.0   
1037                   8.925620                    83.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2059                                68.0                                73.0   
2652                                64.0                                74.0   
3768                                29.0                                89.0   
3686                                78.0                                87.0   
1037                                86.0                                96.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2059                               5.0                        70.500000  ...   
2652                              10.0                        66.500000  ...   
3768                              60.0                        68.130432  ...   
3686                               9.0                        84.000000  ...   
1037                              10.0                        87.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2059                 4.0                   1            32.0   
2652                 4.0                   1            32.0   
3768                 7.0                   0             2.0   
3686                 7.0                   0             2.0   
1037                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2059                 False                     False   
2652                 False                     False   
3768                 False                     False   
3686                 False                     False   
1037                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2059                      False                        False   
2652                      False                        False   
3768                      False                        False   
3686                      False                        False   
1037                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2059                       True                     False   
2652                       True                     False   
3768                      False                      True   
3686                      False                      True   
1037                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2059                    False  
2652                    False  
3768                    False  
3686                    False  
1037                    False  

[1344 rows x 146 columns]
2025-06-02 14:33:17,392:INFO:get_config() successfully completed......................................
2025-06-02 14:33:17,406:INFO:Initializing get_config()
2025-06-02 14:33:17,406:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, variable=y_test)
2025-06-02 14:33:17,407:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 14:33:17,407:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 14:33:17,443:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2059    0.014339
2652   -0.098120
3768   -1.861921
3686   -3.207308
1037   -0.156411
Name: target, Length: 1344, dtype: float32
2025-06-02 14:33:17,443:INFO:get_config() successfully completed......................................
2025-06-02 14:33:17,479:INFO:Initializing predict_model()
2025-06-02 14:33:17,479:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D9582EC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6DA1E5900>)
2025-06-02 14:33:17,480:INFO:Checking exceptions
2025-06-02 14:33:17,480:INFO:Preloading libraries
2025-06-02 14:33:17,486:INFO:Set up data.
2025-06-02 14:33:17,639:INFO:Set up index.
2025-06-02 14:35:14,784:INFO:PyCaret RegressionExperiment
2025-06-02 14:35:14,785:INFO:Logging name: reg-default-name
2025-06-02 14:35:14,786:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 14:35:14,786:INFO:version 3.3.2
2025-06-02 14:35:14,786:INFO:Initializing setup()
2025-06-02 14:35:14,786:INFO:self.USI: 147d
2025-06-02 14:35:14,786:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 14:35:14,786:INFO:Checking environment
2025-06-02 14:35:14,787:INFO:python_version: 3.10.16
2025-06-02 14:35:14,787:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 14:35:14,788:INFO:machine: AMD64
2025-06-02 14:35:14,789:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 14:35:14,800:INFO:Memory: svmem(total=6378008576, available=419536896, percent=93.4, used=5958471680, free=419536896)
2025-06-02 14:35:14,801:INFO:Physical Core: 4
2025-06-02 14:35:14,802:INFO:Logical Core: 8
2025-06-02 14:35:14,802:INFO:Checking libraries
2025-06-02 14:35:14,803:INFO:System:
2025-06-02 14:35:14,803:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 14:35:14,804:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 14:35:14,804:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 14:35:14,805:INFO:PyCaret required dependencies:
2025-06-02 14:35:14,807:INFO:                 pip: 25.1
2025-06-02 14:35:14,808:INFO:          setuptools: 78.1.1
2025-06-02 14:35:14,808:INFO:             pycaret: 3.3.2
2025-06-02 14:35:14,809:INFO:             IPython: 8.37.0
2025-06-02 14:35:14,810:INFO:          ipywidgets: 8.1.7
2025-06-02 14:35:14,810:INFO:                tqdm: 4.67.1
2025-06-02 14:35:14,810:INFO:               numpy: 1.26.4
2025-06-02 14:35:14,810:INFO:              pandas: 2.0.1
2025-06-02 14:35:14,810:INFO:              jinja2: 3.1.6
2025-06-02 14:35:14,811:INFO:               scipy: 1.10.1
2025-06-02 14:35:14,811:INFO:              joblib: 1.3.2
2025-06-02 14:35:14,811:INFO:             sklearn: 1.4.2
2025-06-02 14:35:14,811:INFO:                pyod: 2.0.5
2025-06-02 14:35:14,811:INFO:            imblearn: 0.13.0
2025-06-02 14:35:14,811:INFO:   category_encoders: 2.7.0
2025-06-02 14:35:14,812:INFO:            lightgbm: 4.6.0
2025-06-02 14:35:14,812:INFO:               numba: 0.61.0
2025-06-02 14:35:14,812:INFO:            requests: 2.32.3
2025-06-02 14:35:14,812:INFO:          matplotlib: 3.7.1
2025-06-02 14:35:14,812:INFO:          scikitplot: 0.3.7
2025-06-02 14:35:14,812:INFO:         yellowbrick: 1.5
2025-06-02 14:35:14,812:INFO:              plotly: 6.1.2
2025-06-02 14:35:14,813:INFO:    plotly-resampler: Not installed
2025-06-02 14:35:14,813:INFO:             kaleido: 0.2.1
2025-06-02 14:35:14,813:INFO:           schemdraw: 0.15
2025-06-02 14:35:14,815:INFO:         statsmodels: 0.14.4
2025-06-02 14:35:14,815:INFO:              sktime: 0.26.0
2025-06-02 14:35:14,816:INFO:               tbats: 1.1.3
2025-06-02 14:35:14,824:INFO:            pmdarima: 2.0.4
2025-06-02 14:35:14,824:INFO:              psutil: 7.0.0
2025-06-02 14:35:14,829:INFO:          markupsafe: 2.1.2
2025-06-02 14:35:14,831:INFO:             pickle5: Not installed
2025-06-02 14:35:14,831:INFO:         cloudpickle: 3.1.1
2025-06-02 14:35:14,831:INFO:         deprecation: 2.1.0
2025-06-02 14:35:14,831:INFO:              xxhash: 3.5.0
2025-06-02 14:35:14,832:INFO:           wurlitzer: Not installed
2025-06-02 14:35:14,832:INFO:PyCaret optional dependencies:
2025-06-02 14:35:14,832:INFO:                shap: 0.44.1
2025-06-02 14:35:14,832:INFO:           interpret: 0.6.9
2025-06-02 14:35:14,841:INFO:                umap: 0.5.7
2025-06-02 14:35:14,842:INFO:     ydata_profiling: 4.16.1
2025-06-02 14:35:14,843:INFO:  explainerdashboard: 0.4.8
2025-06-02 14:35:14,843:INFO:             autoviz: Not installed
2025-06-02 14:35:14,843:INFO:           fairlearn: 0.7.0
2025-06-02 14:35:14,844:INFO:          deepchecks: Not installed
2025-06-02 14:35:14,844:INFO:             xgboost: 3.0.2
2025-06-02 14:35:14,844:INFO:            catboost: 1.2.8
2025-06-02 14:35:14,844:INFO:              kmodes: 0.12.2
2025-06-02 14:35:14,844:INFO:             mlxtend: 0.23.4
2025-06-02 14:35:14,845:INFO:       statsforecast: 1.5.0
2025-06-02 14:35:14,845:INFO:        tune_sklearn: Not installed
2025-06-02 14:35:14,845:INFO:                 ray: Not installed
2025-06-02 14:35:14,845:INFO:            hyperopt: 0.2.7
2025-06-02 14:35:14,846:INFO:              optuna: 4.3.0
2025-06-02 14:35:14,846:INFO:               skopt: 0.10.2
2025-06-02 14:35:14,847:INFO:              mlflow: 2.22.0
2025-06-02 14:35:14,847:INFO:              gradio: 5.32.0
2025-06-02 14:35:14,847:INFO:             fastapi: 0.115.12
2025-06-02 14:35:14,847:INFO:             uvicorn: 0.34.3
2025-06-02 14:35:14,849:INFO:              m2cgen: 0.10.0
2025-06-02 14:35:14,850:INFO:           evidently: 0.4.40
2025-06-02 14:35:14,850:INFO:               fugue: 0.8.5
2025-06-02 14:35:14,850:INFO:           streamlit: Not installed
2025-06-02 14:35:14,853:INFO:             prophet: Not installed
2025-06-02 14:35:14,854:INFO:None
2025-06-02 14:35:14,855:INFO:Set up data.
2025-06-02 14:35:15,375:INFO:Set up folding strategy.
2025-06-02 14:35:15,375:INFO:Set up train/test split.
2025-06-02 14:35:17,595:INFO:Set up index.
2025-06-02 14:35:17,597:INFO:Assigning column types.
2025-06-02 14:35:17,736:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 14:35:17,737:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 14:35:17,754:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:35:17,768:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:35:18,116:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:35:18,313:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:35:18,315:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:35:18,326:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:35:18,329:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 14:35:18,346:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:35:18,362:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:35:18,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:35:18,934:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:35:18,938:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:35:18,946:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:35:18,950:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 14:35:18,967:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:35:18,986:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:35:19,284:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:35:19,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:35:19,391:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:35:19,402:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:35:19,422:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:35:19,443:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:35:19,760:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:35:19,937:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:35:19,940:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:35:19,948:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:35:19,949:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 14:35:19,991:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:35:20,263:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:35:20,418:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:35:20,420:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:35:20,428:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:35:20,467:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:35:20,855:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:35:20,978:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:35:20,979:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:35:20,987:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:35:20,988:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 14:35:21,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:35:21,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:35:21,412:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:35:21,423:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:35:21,807:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:35:22,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:35:22,010:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:35:22,018:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:35:22,022:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 14:35:22,414:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:35:22,576:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:35:22,586:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:35:22,894:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:35:23,076:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:35:23,087:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:35:23,089:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 14:35:23,559:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:35:23,576:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:35:24,087:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:35:24,094:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:35:24,099:INFO:Preparing preprocessing pipeline...
2025-06-02 14:35:24,099:INFO:Set up simple imputation.
2025-06-02 14:35:24,099:INFO:Set up removing multicollinearity.
2025-06-02 14:35:24,114:INFO:Set up column name cleaning.
2025-06-02 14:35:24,595:INFO:Finished creating preprocessing pipeline.
2025-06-02 14:35:24,609:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 14:35:24,609:INFO:Creating final display dataframe.
2025-06-02 14:35:25,445:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              147d
2025-06-02 14:35:25,916:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:35:25,928:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:35:26,530:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:35:26,538:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:35:26,542:INFO:setup() successfully completed in 11.78s...............
2025-06-02 14:35:26,560:INFO:Initializing compare_models()
2025-06-02 14:35:26,561:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 14:35:26,562:INFO:Checking exceptions
2025-06-02 14:35:26,610:INFO:Preparing display monitor
2025-06-02 14:35:26,728:INFO:Initializing Linear Regression
2025-06-02 14:35:26,728:INFO:Total runtime is 0.0 minutes
2025-06-02 14:35:26,754:INFO:SubProcess create_model() called ==================================
2025-06-02 14:35:26,756:INFO:Initializing create_model()
2025-06-02 14:35:26,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:35:26,758:INFO:Checking exceptions
2025-06-02 14:35:26,758:INFO:Importing libraries
2025-06-02 14:35:26,759:INFO:Copying training dataset
2025-06-02 14:35:26,882:INFO:Defining folds
2025-06-02 14:35:26,882:INFO:Declaring metric variables
2025-06-02 14:35:26,897:INFO:Importing untrained model
2025-06-02 14:35:26,913:INFO:Linear Regression Imported successfully
2025-06-02 14:35:26,974:INFO:Starting cross validation
2025-06-02 14:35:26,986:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:35:28,457:INFO:Calculating mean and std
2025-06-02 14:35:28,459:INFO:Creating metrics dataframe
2025-06-02 14:35:28,464:INFO:Uploading results into container
2025-06-02 14:35:28,465:INFO:Uploading model into container now
2025-06-02 14:35:28,467:INFO:_master_model_container: 1
2025-06-02 14:35:28,469:INFO:_display_container: 2
2025-06-02 14:35:28,471:INFO:LinearRegression(n_jobs=-1)
2025-06-02 14:35:28,471:INFO:create_model() successfully completed......................................
2025-06-02 14:35:30,632:INFO:SubProcess create_model() end ==================================
2025-06-02 14:35:30,632:INFO:Creating metrics dataframe
2025-06-02 14:35:30,647:INFO:Initializing Lasso Regression
2025-06-02 14:35:30,649:INFO:Total runtime is 0.06535133918126425 minutes
2025-06-02 14:35:30,663:INFO:SubProcess create_model() called ==================================
2025-06-02 14:35:30,664:INFO:Initializing create_model()
2025-06-02 14:35:30,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:35:30,665:INFO:Checking exceptions
2025-06-02 14:35:30,668:INFO:Importing libraries
2025-06-02 14:35:30,670:INFO:Copying training dataset
2025-06-02 14:35:30,791:INFO:Defining folds
2025-06-02 14:35:30,791:INFO:Declaring metric variables
2025-06-02 14:35:30,812:INFO:Importing untrained model
2025-06-02 14:35:30,830:INFO:Lasso Regression Imported successfully
2025-06-02 14:35:30,874:INFO:Starting cross validation
2025-06-02 14:35:30,880:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:35:31,980:INFO:Calculating mean and std
2025-06-02 14:35:31,983:INFO:Creating metrics dataframe
2025-06-02 14:35:31,988:INFO:Uploading results into container
2025-06-02 14:35:31,990:INFO:Uploading model into container now
2025-06-02 14:35:31,991:INFO:_master_model_container: 2
2025-06-02 14:35:31,991:INFO:_display_container: 2
2025-06-02 14:35:31,992:INFO:Lasso(random_state=123)
2025-06-02 14:35:31,993:INFO:create_model() successfully completed......................................
2025-06-02 14:35:33,986:INFO:SubProcess create_model() end ==================================
2025-06-02 14:35:33,988:INFO:Creating metrics dataframe
2025-06-02 14:35:34,026:INFO:Initializing Ridge Regression
2025-06-02 14:35:34,027:INFO:Total runtime is 0.12164798974990845 minutes
2025-06-02 14:35:34,057:INFO:SubProcess create_model() called ==================================
2025-06-02 14:35:34,058:INFO:Initializing create_model()
2025-06-02 14:35:34,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:35:34,060:INFO:Checking exceptions
2025-06-02 14:35:34,060:INFO:Importing libraries
2025-06-02 14:35:34,061:INFO:Copying training dataset
2025-06-02 14:35:34,233:INFO:Defining folds
2025-06-02 14:35:34,234:INFO:Declaring metric variables
2025-06-02 14:35:34,307:INFO:Importing untrained model
2025-06-02 14:35:34,356:INFO:Ridge Regression Imported successfully
2025-06-02 14:35:34,443:INFO:Starting cross validation
2025-06-02 14:35:34,453:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:35:35,421:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.75561e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:35:35,496:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31073e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:35:35,563:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.08754e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:35:36,583:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.24347e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:35:36,653:INFO:Calculating mean and std
2025-06-02 14:35:36,655:INFO:Creating metrics dataframe
2025-06-02 14:35:36,661:INFO:Uploading results into container
2025-06-02 14:35:36,662:INFO:Uploading model into container now
2025-06-02 14:35:36,663:INFO:_master_model_container: 3
2025-06-02 14:35:36,663:INFO:_display_container: 2
2025-06-02 14:35:36,665:INFO:Ridge(random_state=123)
2025-06-02 14:35:36,667:INFO:create_model() successfully completed......................................
2025-06-02 14:35:38,691:INFO:SubProcess create_model() end ==================================
2025-06-02 14:35:38,692:INFO:Creating metrics dataframe
2025-06-02 14:35:38,722:INFO:Initializing Elastic Net
2025-06-02 14:35:38,723:INFO:Total runtime is 0.19992659489313763 minutes
2025-06-02 14:35:38,749:INFO:SubProcess create_model() called ==================================
2025-06-02 14:35:38,751:INFO:Initializing create_model()
2025-06-02 14:35:38,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:35:38,753:INFO:Checking exceptions
2025-06-02 14:35:38,754:INFO:Importing libraries
2025-06-02 14:35:38,754:INFO:Copying training dataset
2025-06-02 14:35:38,908:INFO:Defining folds
2025-06-02 14:35:38,908:INFO:Declaring metric variables
2025-06-02 14:35:38,929:INFO:Importing untrained model
2025-06-02 14:35:38,947:INFO:Elastic Net Imported successfully
2025-06-02 14:35:38,985:INFO:Starting cross validation
2025-06-02 14:35:38,993:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:35:40,193:INFO:Calculating mean and std
2025-06-02 14:35:40,195:INFO:Creating metrics dataframe
2025-06-02 14:35:40,201:INFO:Uploading results into container
2025-06-02 14:35:40,203:INFO:Uploading model into container now
2025-06-02 14:35:40,204:INFO:_master_model_container: 4
2025-06-02 14:35:40,204:INFO:_display_container: 2
2025-06-02 14:35:40,205:INFO:ElasticNet(random_state=123)
2025-06-02 14:35:40,206:INFO:create_model() successfully completed......................................
2025-06-02 14:35:42,239:INFO:SubProcess create_model() end ==================================
2025-06-02 14:35:42,240:INFO:Creating metrics dataframe
2025-06-02 14:35:42,278:INFO:Initializing Least Angle Regression
2025-06-02 14:35:42,279:INFO:Total runtime is 0.25918150742848717 minutes
2025-06-02 14:35:42,306:INFO:SubProcess create_model() called ==================================
2025-06-02 14:35:42,308:INFO:Initializing create_model()
2025-06-02 14:35:42,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:35:42,309:INFO:Checking exceptions
2025-06-02 14:35:42,309:INFO:Importing libraries
2025-06-02 14:35:42,310:INFO:Copying training dataset
2025-06-02 14:35:42,470:INFO:Defining folds
2025-06-02 14:35:42,471:INFO:Declaring metric variables
2025-06-02 14:35:42,490:INFO:Importing untrained model
2025-06-02 14:35:42,513:INFO:Least Angle Regression Imported successfully
2025-06-02 14:35:42,556:INFO:Starting cross validation
2025-06-02 14:35:42,562:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:35:43,749:INFO:Calculating mean and std
2025-06-02 14:35:43,752:INFO:Creating metrics dataframe
2025-06-02 14:35:43,758:INFO:Uploading results into container
2025-06-02 14:35:43,759:INFO:Uploading model into container now
2025-06-02 14:35:43,760:INFO:_master_model_container: 5
2025-06-02 14:35:43,760:INFO:_display_container: 2
2025-06-02 14:35:43,763:INFO:Lars(random_state=123)
2025-06-02 14:35:43,763:INFO:create_model() successfully completed......................................
2025-06-02 14:35:45,804:INFO:SubProcess create_model() end ==================================
2025-06-02 14:35:45,804:INFO:Creating metrics dataframe
2025-06-02 14:35:45,840:INFO:Initializing Lasso Least Angle Regression
2025-06-02 14:35:45,840:INFO:Total runtime is 0.3185410300890605 minutes
2025-06-02 14:35:45,860:INFO:SubProcess create_model() called ==================================
2025-06-02 14:35:45,861:INFO:Initializing create_model()
2025-06-02 14:35:45,862:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:35:45,863:INFO:Checking exceptions
2025-06-02 14:35:45,863:INFO:Importing libraries
2025-06-02 14:35:45,864:INFO:Copying training dataset
2025-06-02 14:35:45,996:INFO:Defining folds
2025-06-02 14:35:45,996:INFO:Declaring metric variables
2025-06-02 14:35:46,013:INFO:Importing untrained model
2025-06-02 14:35:46,035:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 14:35:46,071:INFO:Starting cross validation
2025-06-02 14:35:46,078:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:35:47,346:INFO:Calculating mean and std
2025-06-02 14:35:47,349:INFO:Creating metrics dataframe
2025-06-02 14:35:47,359:INFO:Uploading results into container
2025-06-02 14:35:47,360:INFO:Uploading model into container now
2025-06-02 14:35:47,361:INFO:_master_model_container: 6
2025-06-02 14:35:47,361:INFO:_display_container: 2
2025-06-02 14:35:47,362:INFO:LassoLars(random_state=123)
2025-06-02 14:35:47,362:INFO:create_model() successfully completed......................................
2025-06-02 14:35:49,506:INFO:SubProcess create_model() end ==================================
2025-06-02 14:35:49,508:INFO:Creating metrics dataframe
2025-06-02 14:35:49,541:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 14:35:49,542:INFO:Total runtime is 0.3802445371945699 minutes
2025-06-02 14:35:49,559:INFO:SubProcess create_model() called ==================================
2025-06-02 14:35:49,560:INFO:Initializing create_model()
2025-06-02 14:35:49,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:35:49,561:INFO:Checking exceptions
2025-06-02 14:35:49,563:INFO:Importing libraries
2025-06-02 14:35:49,563:INFO:Copying training dataset
2025-06-02 14:35:49,675:INFO:Defining folds
2025-06-02 14:35:49,676:INFO:Declaring metric variables
2025-06-02 14:35:49,699:INFO:Importing untrained model
2025-06-02 14:35:49,720:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 14:35:49,759:INFO:Starting cross validation
2025-06-02 14:35:49,765:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:35:50,869:INFO:Calculating mean and std
2025-06-02 14:35:50,872:INFO:Creating metrics dataframe
2025-06-02 14:35:50,876:INFO:Uploading results into container
2025-06-02 14:35:50,877:INFO:Uploading model into container now
2025-06-02 14:35:50,878:INFO:_master_model_container: 7
2025-06-02 14:35:50,878:INFO:_display_container: 2
2025-06-02 14:35:50,879:INFO:OrthogonalMatchingPursuit()
2025-06-02 14:35:50,879:INFO:create_model() successfully completed......................................
2025-06-02 14:35:53,026:INFO:SubProcess create_model() end ==================================
2025-06-02 14:35:53,026:INFO:Creating metrics dataframe
2025-06-02 14:35:53,062:INFO:Initializing Bayesian Ridge
2025-06-02 14:35:53,062:INFO:Total runtime is 0.43890950282414753 minutes
2025-06-02 14:35:53,084:INFO:SubProcess create_model() called ==================================
2025-06-02 14:35:53,085:INFO:Initializing create_model()
2025-06-02 14:35:53,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:35:53,088:INFO:Checking exceptions
2025-06-02 14:35:53,089:INFO:Importing libraries
2025-06-02 14:35:53,089:INFO:Copying training dataset
2025-06-02 14:35:53,255:INFO:Defining folds
2025-06-02 14:35:53,261:INFO:Declaring metric variables
2025-06-02 14:35:53,299:INFO:Importing untrained model
2025-06-02 14:35:53,336:INFO:Bayesian Ridge Imported successfully
2025-06-02 14:35:53,386:INFO:Starting cross validation
2025-06-02 14:35:53,394:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:35:54,567:INFO:Calculating mean and std
2025-06-02 14:35:54,569:INFO:Creating metrics dataframe
2025-06-02 14:35:54,572:INFO:Uploading results into container
2025-06-02 14:35:54,573:INFO:Uploading model into container now
2025-06-02 14:35:54,574:INFO:_master_model_container: 8
2025-06-02 14:35:54,574:INFO:_display_container: 2
2025-06-02 14:35:54,575:INFO:BayesianRidge()
2025-06-02 14:35:54,576:INFO:create_model() successfully completed......................................
2025-06-02 14:35:56,693:INFO:SubProcess create_model() end ==================================
2025-06-02 14:35:56,693:INFO:Creating metrics dataframe
2025-06-02 14:35:56,730:INFO:Initializing Passive Aggressive Regressor
2025-06-02 14:35:56,731:INFO:Total runtime is 0.500052257378896 minutes
2025-06-02 14:35:56,754:INFO:SubProcess create_model() called ==================================
2025-06-02 14:35:56,756:INFO:Initializing create_model()
2025-06-02 14:35:56,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:35:56,757:INFO:Checking exceptions
2025-06-02 14:35:56,758:INFO:Importing libraries
2025-06-02 14:35:56,759:INFO:Copying training dataset
2025-06-02 14:35:56,921:INFO:Defining folds
2025-06-02 14:35:56,922:INFO:Declaring metric variables
2025-06-02 14:35:56,939:INFO:Importing untrained model
2025-06-02 14:35:56,958:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 14:35:56,991:INFO:Starting cross validation
2025-06-02 14:35:56,996:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:35:59,570:INFO:Calculating mean and std
2025-06-02 14:35:59,572:INFO:Creating metrics dataframe
2025-06-02 14:35:59,575:INFO:Uploading results into container
2025-06-02 14:35:59,577:INFO:Uploading model into container now
2025-06-02 14:35:59,578:INFO:_master_model_container: 9
2025-06-02 14:35:59,578:INFO:_display_container: 2
2025-06-02 14:35:59,579:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 14:35:59,579:INFO:create_model() successfully completed......................................
2025-06-02 14:36:01,726:INFO:SubProcess create_model() end ==================================
2025-06-02 14:36:01,727:INFO:Creating metrics dataframe
2025-06-02 14:36:01,759:INFO:Initializing Huber Regressor
2025-06-02 14:36:01,759:INFO:Total runtime is 0.5838632663091023 minutes
2025-06-02 14:36:01,777:INFO:SubProcess create_model() called ==================================
2025-06-02 14:36:01,778:INFO:Initializing create_model()
2025-06-02 14:36:01,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:36:01,779:INFO:Checking exceptions
2025-06-02 14:36:01,779:INFO:Importing libraries
2025-06-02 14:36:01,779:INFO:Copying training dataset
2025-06-02 14:36:01,930:INFO:Defining folds
2025-06-02 14:36:01,931:INFO:Declaring metric variables
2025-06-02 14:36:01,955:INFO:Importing untrained model
2025-06-02 14:36:01,976:INFO:Huber Regressor Imported successfully
2025-06-02 14:36:02,022:INFO:Starting cross validation
2025-06-02 14:36:02,030:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:36:04,928:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:36:05,063:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:36:05,099:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:36:05,150:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:36:05,143:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:36:05,234:INFO:Calculating mean and std
2025-06-02 14:36:05,237:INFO:Creating metrics dataframe
2025-06-02 14:36:05,242:INFO:Uploading results into container
2025-06-02 14:36:05,244:INFO:Uploading model into container now
2025-06-02 14:36:05,245:INFO:_master_model_container: 10
2025-06-02 14:36:05,245:INFO:_display_container: 2
2025-06-02 14:36:05,246:INFO:HuberRegressor()
2025-06-02 14:36:05,246:INFO:create_model() successfully completed......................................
2025-06-02 14:36:07,237:INFO:SubProcess create_model() end ==================================
2025-06-02 14:36:07,238:INFO:Creating metrics dataframe
2025-06-02 14:36:07,274:INFO:Initializing K Neighbors Regressor
2025-06-02 14:36:07,274:INFO:Total runtime is 0.675777796904246 minutes
2025-06-02 14:36:07,291:INFO:SubProcess create_model() called ==================================
2025-06-02 14:36:07,292:INFO:Initializing create_model()
2025-06-02 14:36:07,293:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:36:07,294:INFO:Checking exceptions
2025-06-02 14:36:07,294:INFO:Importing libraries
2025-06-02 14:36:07,295:INFO:Copying training dataset
2025-06-02 14:36:07,410:INFO:Defining folds
2025-06-02 14:36:07,411:INFO:Declaring metric variables
2025-06-02 14:36:07,426:INFO:Importing untrained model
2025-06-02 14:36:07,441:INFO:K Neighbors Regressor Imported successfully
2025-06-02 14:36:07,479:INFO:Starting cross validation
2025-06-02 14:36:07,486:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:36:08,896:INFO:Calculating mean and std
2025-06-02 14:36:08,898:INFO:Creating metrics dataframe
2025-06-02 14:36:08,905:INFO:Uploading results into container
2025-06-02 14:36:08,907:INFO:Uploading model into container now
2025-06-02 14:36:08,908:INFO:_master_model_container: 11
2025-06-02 14:36:08,908:INFO:_display_container: 2
2025-06-02 14:36:08,908:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 14:36:08,910:INFO:create_model() successfully completed......................................
2025-06-02 14:36:10,945:INFO:SubProcess create_model() end ==================================
2025-06-02 14:36:10,946:INFO:Creating metrics dataframe
2025-06-02 14:36:10,998:INFO:Initializing Decision Tree Regressor
2025-06-02 14:36:10,998:INFO:Total runtime is 0.7378375093142191 minutes
2025-06-02 14:36:11,021:INFO:SubProcess create_model() called ==================================
2025-06-02 14:36:11,023:INFO:Initializing create_model()
2025-06-02 14:36:11,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:36:11,024:INFO:Checking exceptions
2025-06-02 14:36:11,024:INFO:Importing libraries
2025-06-02 14:36:11,025:INFO:Copying training dataset
2025-06-02 14:36:11,177:INFO:Defining folds
2025-06-02 14:36:11,178:INFO:Declaring metric variables
2025-06-02 14:36:11,199:INFO:Importing untrained model
2025-06-02 14:36:11,220:INFO:Decision Tree Regressor Imported successfully
2025-06-02 14:36:11,278:INFO:Starting cross validation
2025-06-02 14:36:11,289:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:36:12,860:INFO:Calculating mean and std
2025-06-02 14:36:12,862:INFO:Creating metrics dataframe
2025-06-02 14:36:12,865:INFO:Uploading results into container
2025-06-02 14:36:12,867:INFO:Uploading model into container now
2025-06-02 14:36:12,869:INFO:_master_model_container: 12
2025-06-02 14:36:12,870:INFO:_display_container: 2
2025-06-02 14:36:12,872:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 14:36:12,873:INFO:create_model() successfully completed......................................
2025-06-02 14:36:14,832:INFO:SubProcess create_model() end ==================================
2025-06-02 14:36:14,832:INFO:Creating metrics dataframe
2025-06-02 14:36:14,870:INFO:Initializing Random Forest Regressor
2025-06-02 14:36:14,871:INFO:Total runtime is 0.8023824175198873 minutes
2025-06-02 14:36:14,888:INFO:SubProcess create_model() called ==================================
2025-06-02 14:36:14,889:INFO:Initializing create_model()
2025-06-02 14:36:14,890:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:36:14,890:INFO:Checking exceptions
2025-06-02 14:36:14,891:INFO:Importing libraries
2025-06-02 14:36:14,891:INFO:Copying training dataset
2025-06-02 14:36:15,015:INFO:Defining folds
2025-06-02 14:36:15,016:INFO:Declaring metric variables
2025-06-02 14:36:15,041:INFO:Importing untrained model
2025-06-02 14:36:15,063:INFO:Random Forest Regressor Imported successfully
2025-06-02 14:36:15,105:INFO:Starting cross validation
2025-06-02 14:36:15,111:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:36:28,224:INFO:Calculating mean and std
2025-06-02 14:36:28,226:INFO:Creating metrics dataframe
2025-06-02 14:36:28,231:INFO:Uploading results into container
2025-06-02 14:36:28,234:INFO:Uploading model into container now
2025-06-02 14:36:28,236:INFO:_master_model_container: 13
2025-06-02 14:36:28,236:INFO:_display_container: 2
2025-06-02 14:36:28,239:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:36:28,239:INFO:create_model() successfully completed......................................
2025-06-02 14:36:30,359:INFO:SubProcess create_model() end ==================================
2025-06-02 14:36:30,359:INFO:Creating metrics dataframe
2025-06-02 14:36:30,387:INFO:Initializing Extra Trees Regressor
2025-06-02 14:36:30,387:INFO:Total runtime is 1.0609899878501892 minutes
2025-06-02 14:36:30,400:INFO:SubProcess create_model() called ==================================
2025-06-02 14:36:30,403:INFO:Initializing create_model()
2025-06-02 14:36:30,403:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:36:30,404:INFO:Checking exceptions
2025-06-02 14:36:30,404:INFO:Importing libraries
2025-06-02 14:36:30,405:INFO:Copying training dataset
2025-06-02 14:36:30,532:INFO:Defining folds
2025-06-02 14:36:30,534:INFO:Declaring metric variables
2025-06-02 14:36:30,552:INFO:Importing untrained model
2025-06-02 14:36:30,571:INFO:Extra Trees Regressor Imported successfully
2025-06-02 14:36:30,610:INFO:Starting cross validation
2025-06-02 14:36:30,615:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:36:40,287:INFO:Calculating mean and std
2025-06-02 14:36:40,290:INFO:Creating metrics dataframe
2025-06-02 14:36:40,294:INFO:Uploading results into container
2025-06-02 14:36:40,295:INFO:Uploading model into container now
2025-06-02 14:36:40,296:INFO:_master_model_container: 14
2025-06-02 14:36:40,296:INFO:_display_container: 2
2025-06-02 14:36:40,297:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:36:40,297:INFO:create_model() successfully completed......................................
2025-06-02 14:36:42,390:INFO:SubProcess create_model() end ==================================
2025-06-02 14:36:42,391:INFO:Creating metrics dataframe
2025-06-02 14:36:42,414:INFO:Initializing AdaBoost Regressor
2025-06-02 14:36:42,414:INFO:Total runtime is 1.2614342808723449 minutes
2025-06-02 14:36:42,430:INFO:SubProcess create_model() called ==================================
2025-06-02 14:36:42,431:INFO:Initializing create_model()
2025-06-02 14:36:42,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:36:42,433:INFO:Checking exceptions
2025-06-02 14:36:42,433:INFO:Importing libraries
2025-06-02 14:36:42,434:INFO:Copying training dataset
2025-06-02 14:36:42,560:INFO:Defining folds
2025-06-02 14:36:42,561:INFO:Declaring metric variables
2025-06-02 14:36:42,579:INFO:Importing untrained model
2025-06-02 14:36:42,597:INFO:AdaBoost Regressor Imported successfully
2025-06-02 14:36:42,643:INFO:Starting cross validation
2025-06-02 14:36:42,651:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:36:46,306:INFO:Calculating mean and std
2025-06-02 14:36:46,309:INFO:Creating metrics dataframe
2025-06-02 14:36:46,315:INFO:Uploading results into container
2025-06-02 14:36:46,317:INFO:Uploading model into container now
2025-06-02 14:36:46,319:INFO:_master_model_container: 15
2025-06-02 14:36:46,320:INFO:_display_container: 2
2025-06-02 14:36:46,321:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 14:36:46,323:INFO:create_model() successfully completed......................................
2025-06-02 14:36:48,337:INFO:SubProcess create_model() end ==================================
2025-06-02 14:36:48,338:INFO:Creating metrics dataframe
2025-06-02 14:36:48,387:INFO:Initializing Gradient Boosting Regressor
2025-06-02 14:36:48,388:INFO:Total runtime is 1.3610124667485555 minutes
2025-06-02 14:36:48,411:INFO:SubProcess create_model() called ==================================
2025-06-02 14:36:48,412:INFO:Initializing create_model()
2025-06-02 14:36:48,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:36:48,414:INFO:Checking exceptions
2025-06-02 14:36:48,415:INFO:Importing libraries
2025-06-02 14:36:48,417:INFO:Copying training dataset
2025-06-02 14:36:48,563:INFO:Defining folds
2025-06-02 14:36:48,563:INFO:Declaring metric variables
2025-06-02 14:36:48,582:INFO:Importing untrained model
2025-06-02 14:36:48,608:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 14:36:48,647:INFO:Starting cross validation
2025-06-02 14:36:48,654:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:36:53,469:INFO:Calculating mean and std
2025-06-02 14:36:53,471:INFO:Creating metrics dataframe
2025-06-02 14:36:53,475:INFO:Uploading results into container
2025-06-02 14:36:53,477:INFO:Uploading model into container now
2025-06-02 14:36:53,478:INFO:_master_model_container: 16
2025-06-02 14:36:53,479:INFO:_display_container: 2
2025-06-02 14:36:53,480:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 14:36:53,480:INFO:create_model() successfully completed......................................
2025-06-02 14:36:55,409:INFO:SubProcess create_model() end ==================================
2025-06-02 14:36:55,410:INFO:Creating metrics dataframe
2025-06-02 14:36:55,464:INFO:Initializing Extreme Gradient Boosting
2025-06-02 14:36:55,465:INFO:Total runtime is 1.4789578994115193 minutes
2025-06-02 14:36:55,490:INFO:SubProcess create_model() called ==================================
2025-06-02 14:36:55,491:INFO:Initializing create_model()
2025-06-02 14:36:55,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:36:55,493:INFO:Checking exceptions
2025-06-02 14:36:55,493:INFO:Importing libraries
2025-06-02 14:36:55,493:INFO:Copying training dataset
2025-06-02 14:36:55,678:INFO:Defining folds
2025-06-02 14:36:55,679:INFO:Declaring metric variables
2025-06-02 14:36:55,705:INFO:Importing untrained model
2025-06-02 14:36:55,748:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 14:36:55,787:INFO:Starting cross validation
2025-06-02 14:36:55,792:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:36:58,476:INFO:Calculating mean and std
2025-06-02 14:36:58,479:INFO:Creating metrics dataframe
2025-06-02 14:36:58,483:INFO:Uploading results into container
2025-06-02 14:36:58,485:INFO:Uploading model into container now
2025-06-02 14:36:58,486:INFO:_master_model_container: 17
2025-06-02 14:36:58,487:INFO:_display_container: 2
2025-06-02 14:36:58,488:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 14:36:58,489:INFO:create_model() successfully completed......................................
2025-06-02 14:37:00,304:INFO:SubProcess create_model() end ==================================
2025-06-02 14:37:00,305:INFO:Creating metrics dataframe
2025-06-02 14:37:00,348:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 14:37:00,349:INFO:Total runtime is 1.5603596647580464 minutes
2025-06-02 14:37:00,373:INFO:SubProcess create_model() called ==================================
2025-06-02 14:37:00,375:INFO:Initializing create_model()
2025-06-02 14:37:00,375:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:37:00,377:INFO:Checking exceptions
2025-06-02 14:37:00,377:INFO:Importing libraries
2025-06-02 14:37:00,377:INFO:Copying training dataset
2025-06-02 14:37:00,576:INFO:Defining folds
2025-06-02 14:37:00,577:INFO:Declaring metric variables
2025-06-02 14:37:00,645:INFO:Importing untrained model
2025-06-02 14:37:00,671:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:37:00,741:INFO:Starting cross validation
2025-06-02 14:37:00,746:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:37:03,760:INFO:Calculating mean and std
2025-06-02 14:37:03,763:INFO:Creating metrics dataframe
2025-06-02 14:37:03,771:INFO:Uploading results into container
2025-06-02 14:37:03,772:INFO:Uploading model into container now
2025-06-02 14:37:03,773:INFO:_master_model_container: 18
2025-06-02 14:37:03,773:INFO:_display_container: 2
2025-06-02 14:37:03,775:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:37:03,775:INFO:create_model() successfully completed......................................
2025-06-02 14:37:05,744:INFO:SubProcess create_model() end ==================================
2025-06-02 14:37:05,745:INFO:Creating metrics dataframe
2025-06-02 14:37:05,800:INFO:Initializing CatBoost Regressor
2025-06-02 14:37:05,801:INFO:Total runtime is 1.6512271960576375 minutes
2025-06-02 14:37:05,826:INFO:SubProcess create_model() called ==================================
2025-06-02 14:37:05,827:INFO:Initializing create_model()
2025-06-02 14:37:05,827:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:37:05,828:INFO:Checking exceptions
2025-06-02 14:37:05,829:INFO:Importing libraries
2025-06-02 14:37:05,829:INFO:Copying training dataset
2025-06-02 14:37:06,138:INFO:Defining folds
2025-06-02 14:37:06,139:INFO:Declaring metric variables
2025-06-02 14:37:06,156:INFO:Importing untrained model
2025-06-02 14:37:06,180:INFO:CatBoost Regressor Imported successfully
2025-06-02 14:37:06,231:INFO:Starting cross validation
2025-06-02 14:37:06,236:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:37:38,428:INFO:Calculating mean and std
2025-06-02 14:37:38,431:INFO:Creating metrics dataframe
2025-06-02 14:37:38,437:INFO:Uploading results into container
2025-06-02 14:37:38,438:INFO:Uploading model into container now
2025-06-02 14:37:38,439:INFO:_master_model_container: 19
2025-06-02 14:37:38,439:INFO:_display_container: 2
2025-06-02 14:37:38,439:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6DAAD9720>
2025-06-02 14:37:38,440:INFO:create_model() successfully completed......................................
2025-06-02 14:37:40,295:INFO:SubProcess create_model() end ==================================
2025-06-02 14:37:40,295:INFO:Creating metrics dataframe
2025-06-02 14:37:40,348:INFO:Initializing Dummy Regressor
2025-06-02 14:37:40,348:INFO:Total runtime is 2.2270133018493654 minutes
2025-06-02 14:37:40,369:INFO:SubProcess create_model() called ==================================
2025-06-02 14:37:40,371:INFO:Initializing create_model()
2025-06-02 14:37:40,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F9ED40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:37:40,372:INFO:Checking exceptions
2025-06-02 14:37:40,372:INFO:Importing libraries
2025-06-02 14:37:40,372:INFO:Copying training dataset
2025-06-02 14:37:40,574:INFO:Defining folds
2025-06-02 14:37:40,574:INFO:Declaring metric variables
2025-06-02 14:37:40,609:INFO:Importing untrained model
2025-06-02 14:37:40,671:INFO:Dummy Regressor Imported successfully
2025-06-02 14:37:40,710:INFO:Starting cross validation
2025-06-02 14:37:40,716:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:37:41,787:INFO:Calculating mean and std
2025-06-02 14:37:41,790:INFO:Creating metrics dataframe
2025-06-02 14:37:41,796:INFO:Uploading results into container
2025-06-02 14:37:41,798:INFO:Uploading model into container now
2025-06-02 14:37:41,799:INFO:_master_model_container: 20
2025-06-02 14:37:41,799:INFO:_display_container: 2
2025-06-02 14:37:41,801:INFO:DummyRegressor()
2025-06-02 14:37:41,801:INFO:create_model() successfully completed......................................
2025-06-02 14:37:43,553:INFO:SubProcess create_model() end ==================================
2025-06-02 14:37:43,553:INFO:Creating metrics dataframe
2025-06-02 14:37:43,667:INFO:Initializing create_model()
2025-06-02 14:37:43,668:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:37:43,668:INFO:Checking exceptions
2025-06-02 14:37:43,678:INFO:Importing libraries
2025-06-02 14:37:43,678:INFO:Copying training dataset
2025-06-02 14:37:43,803:INFO:Defining folds
2025-06-02 14:37:43,804:INFO:Declaring metric variables
2025-06-02 14:37:43,804:INFO:Importing untrained model
2025-06-02 14:37:43,804:INFO:Declaring custom model
2025-06-02 14:37:43,808:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:37:43,812:INFO:Cross validation set to False
2025-06-02 14:37:43,813:INFO:Fitting Model
2025-06-02 14:37:44,614:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:37:44,625:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008134 seconds.
2025-06-02 14:37:44,625:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:37:44,626:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 14:37:44,630:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 14:37:44,631:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:37:45,148:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:37:45,148:INFO:create_model() successfully completed......................................
2025-06-02 14:37:46,864:INFO:_master_model_container: 20
2025-06-02 14:37:46,864:INFO:_display_container: 2
2025-06-02 14:37:46,865:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:37:46,865:INFO:compare_models() successfully completed......................................
2025-06-02 14:37:46,875:INFO:Initializing tune_model()
2025-06-02 14:37:46,876:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>)
2025-06-02 14:37:46,876:INFO:Checking exceptions
2025-06-02 14:37:46,876:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 14:37:46,947:INFO:Copying training dataset
2025-06-02 14:37:47,029:INFO:Checking base model
2025-06-02 14:37:47,029:INFO:Base model : Light Gradient Boosting Machine
2025-06-02 14:37:47,046:INFO:Declaring metric variables
2025-06-02 14:37:47,064:INFO:Defining Hyperparameters
2025-06-02 14:37:48,979:INFO:Tuning with n_jobs=-1
2025-06-02 14:37:49,015:INFO:Initializing skopt.BayesSearchCV
2025-06-02 14:38:14,497:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.8608120752388259), ('actual_estimator__bagging_freq', 1), ('actual_estimator__feature_fraction', 0.4284489606984907), ('actual_estimator__learning_rate', 0.016133245419918712), ('actual_estimator__min_child_samples', 95), ('actual_estimator__min_split_gain', 0.8209314243567916), ('actual_estimator__n_estimators', 239), ('actual_estimator__num_leaves', 183), ('actual_estimator__reg_alpha', 8.662569304197528e-07), ('actual_estimator__reg_lambda', 5.001062744294253e-06)])
2025-06-02 14:38:14,516:INFO:Hyperparameter search completed
2025-06-02 14:38:14,516:INFO:SubProcess create_model() called ==================================
2025-06-02 14:38:14,525:INFO:Initializing create_model()
2025-06-02 14:38:14,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC8A5C90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.8608120752388259, 'bagging_freq': 1, 'feature_fraction': 0.4284489606984907, 'learning_rate': 0.016133245419918712, 'min_child_samples': 95, 'min_split_gain': 0.8209314243567916, 'n_estimators': 239, 'num_leaves': 183, 'reg_alpha': 8.662569304197528e-07, 'reg_lambda': 5.001062744294253e-06})
2025-06-02 14:38:14,526:INFO:Checking exceptions
2025-06-02 14:38:14,527:INFO:Importing libraries
2025-06-02 14:38:14,528:INFO:Copying training dataset
2025-06-02 14:38:14,883:INFO:Defining folds
2025-06-02 14:38:14,884:INFO:Declaring metric variables
2025-06-02 14:38:14,945:INFO:Importing untrained model
2025-06-02 14:38:14,948:INFO:Declaring custom model
2025-06-02 14:38:14,980:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:38:15,029:INFO:Starting cross validation
2025-06-02 14:38:15,039:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:38:20,110:INFO:Calculating mean and std
2025-06-02 14:38:20,113:INFO:Creating metrics dataframe
2025-06-02 14:38:20,146:INFO:Finalizing model
2025-06-02 14:38:20,837:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 14:38:20,837:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 14:38:20,837:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 14:38:20,878:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:38:20,879:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 14:38:20,880:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 14:38:20,880:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 14:38:20,891:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007131 seconds.
2025-06-02 14:38:20,892:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:38:20,893:INFO:[LightGBM] [Info] Total Bins 6220
2025-06-02 14:38:20,908:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 94
2025-06-02 14:38:20,909:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:38:20,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:20,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:38:21,505:INFO:Uploading results into container
2025-06-02 14:38:21,507:INFO:Uploading model into container now
2025-06-02 14:38:21,509:INFO:_master_model_container: 21
2025-06-02 14:38:21,509:INFO:_display_container: 3
2025-06-02 14:38:21,513:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06)
2025-06-02 14:38:21,514:INFO:create_model() successfully completed......................................
2025-06-02 14:38:24,910:INFO:SubProcess create_model() end ==================================
2025-06-02 14:38:24,912:INFO:choose_better activated
2025-06-02 14:38:24,968:INFO:SubProcess create_model() called ==================================
2025-06-02 14:38:24,998:INFO:Initializing create_model()
2025-06-02 14:38:25,003:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:38:25,004:INFO:Checking exceptions
2025-06-02 14:38:25,821:INFO:Importing libraries
2025-06-02 14:38:25,822:INFO:Copying training dataset
2025-06-02 14:38:26,260:INFO:Defining folds
2025-06-02 14:38:26,260:INFO:Declaring metric variables
2025-06-02 14:38:26,262:INFO:Importing untrained model
2025-06-02 14:38:26,262:INFO:Declaring custom model
2025-06-02 14:38:26,271:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:38:26,272:INFO:Starting cross validation
2025-06-02 14:38:26,278:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:38:35,205:INFO:Calculating mean and std
2025-06-02 14:38:35,207:INFO:Creating metrics dataframe
2025-06-02 14:38:35,213:INFO:Finalizing model
2025-06-02 14:38:36,128:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:38:36,145:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013690 seconds.
2025-06-02 14:38:36,146:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:38:36,147:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 14:38:36,150:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 14:38:36,153:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:38:37,858:INFO:Uploading results into container
2025-06-02 14:38:37,859:INFO:Uploading model into container now
2025-06-02 14:38:37,861:INFO:_master_model_container: 22
2025-06-02 14:38:37,861:INFO:_display_container: 4
2025-06-02 14:38:37,862:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:38:37,862:INFO:create_model() successfully completed......................................
2025-06-02 14:38:39,808:INFO:SubProcess create_model() end ==================================
2025-06-02 14:38:39,809:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8764
2025-06-02 14:38:39,810:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06) result for R2 is 0.8217
2025-06-02 14:38:39,811:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 14:38:39,811:INFO:choose_better completed
2025-06-02 14:38:39,811:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 14:38:39,840:INFO:_master_model_container: 22
2025-06-02 14:38:39,840:INFO:_display_container: 3
2025-06-02 14:38:39,842:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:38:39,842:INFO:tune_model() successfully completed......................................
2025-06-02 14:38:41,398:INFO:Initializing finalize_model()
2025-06-02 14:38:41,398:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 14:38:41,401:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:38:41,735:INFO:Initializing create_model()
2025-06-02 14:38:41,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:38:41,735:INFO:Checking exceptions
2025-06-02 14:38:41,741:INFO:Importing libraries
2025-06-02 14:38:41,741:INFO:Copying training dataset
2025-06-02 14:38:41,750:INFO:Defining folds
2025-06-02 14:38:41,750:INFO:Declaring metric variables
2025-06-02 14:38:41,751:INFO:Importing untrained model
2025-06-02 14:38:41,751:INFO:Declaring custom model
2025-06-02 14:38:41,753:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:38:41,756:INFO:Cross validation set to False
2025-06-02 14:38:41,757:INFO:Fitting Model
2025-06-02 14:38:42,362:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:38:42,372:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007106 seconds.
2025-06-02 14:38:42,373:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:38:42,373:INFO:[LightGBM] [Info] Total Bins 6237
2025-06-02 14:38:42,375:INFO:[LightGBM] [Info] Number of data points in the train set: 4478, number of used features: 95
2025-06-02 14:38:42,376:INFO:[LightGBM] [Info] Start training from score -0.483793
2025-06-02 14:38:42,801:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:38:42,801:INFO:create_model() successfully completed......................................
2025-06-02 14:38:44,181:INFO:_master_model_container: 22
2025-06-02 14:38:44,181:INFO:_display_container: 3
2025-06-02 14:38:44,196:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:38:44,196:INFO:finalize_model() successfully completed......................................
2025-06-02 14:38:45,463:INFO:Initializing save_model()
2025-06-02 14:38:45,463:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 14:38:45,464:INFO:Adding model into prep_pipe
2025-06-02 14:38:45,464:WARNING:Only Model saved as it was a pipeline.
2025-06-02 14:38:45,486:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 14:38:45,511:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:38:45,512:INFO:save_model() successfully completed......................................
2025-06-02 14:38:46,770:INFO:Initializing get_config()
2025-06-02 14:38:46,771:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, variable=X_test)
2025-06-02 14:38:46,771:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 14:38:46,771:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 14:38:46,822:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2059                       12.0                       13.0   
2652                       29.0                       31.0   
3768                       34.0                       65.0   
3686                        8.0                       14.0   
1037                       53.0                       83.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2059                      1.0               12.500000   
2652                      2.0               29.500000   
3768                     31.0               44.782608   
3686                      6.0               10.000000   
1037                     30.0               77.545456   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2059                   0.500000                    12.0   
2652                   0.750000                    29.0   
3768                  14.064272                    34.0   
3686                   2.666667                     8.0   
1037                   8.925620                    83.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2059                                68.0                                73.0   
2652                                64.0                                74.0   
3768                                29.0                                89.0   
3686                                78.0                                87.0   
1037                                86.0                                96.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2059                               5.0                        70.500000  ...   
2652                              10.0                        66.500000  ...   
3768                              60.0                        68.130432  ...   
3686                               9.0                        84.000000  ...   
1037                              10.0                        87.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2059                 4.0                   1            32.0   
2652                 4.0                   1            32.0   
3768                 7.0                   0             2.0   
3686                 7.0                   0             2.0   
1037                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2059                 False                     False   
2652                 False                     False   
3768                 False                     False   
3686                 False                     False   
1037                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2059                      False                        False   
2652                      False                        False   
3768                      False                        False   
3686                      False                        False   
1037                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2059                       True                     False   
2652                       True                     False   
3768                      False                      True   
3686                      False                      True   
1037                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2059                    False  
2652                    False  
3768                    False  
3686                    False  
1037                    False  

[1344 rows x 146 columns]
2025-06-02 14:38:46,823:INFO:get_config() successfully completed......................................
2025-06-02 14:38:46,826:INFO:Initializing get_config()
2025-06-02 14:38:46,827:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, variable=y_test)
2025-06-02 14:38:46,827:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 14:38:46,827:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 14:38:46,842:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2059    0.014339
2652   -0.098120
3768   -1.861921
3686   -3.207308
1037   -0.156411
Name: target, Length: 1344, dtype: float32
2025-06-02 14:38:46,842:INFO:get_config() successfully completed......................................
2025-06-02 14:38:46,862:INFO:Initializing predict_model()
2025-06-02 14:38:46,863:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DA996B00>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6DAB91EA0>)
2025-06-02 14:38:46,863:INFO:Checking exceptions
2025-06-02 14:38:46,863:INFO:Preloading libraries
2025-06-02 14:38:46,867:INFO:Set up data.
2025-06-02 14:38:46,939:INFO:Set up index.
2025-06-02 14:46:56,990:INFO:PyCaret RegressionExperiment
2025-06-02 14:46:56,992:INFO:Logging name: reg-default-name
2025-06-02 14:46:56,992:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 14:46:56,992:INFO:version 3.3.2
2025-06-02 14:46:56,992:INFO:Initializing setup()
2025-06-02 14:46:56,992:INFO:self.USI: 7429
2025-06-02 14:46:56,994:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 14:46:56,994:INFO:Checking environment
2025-06-02 14:46:56,995:INFO:python_version: 3.10.16
2025-06-02 14:46:56,995:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 14:46:56,995:INFO:machine: AMD64
2025-06-02 14:46:56,995:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 14:46:57,003:INFO:Memory: svmem(total=6378008576, available=1183522816, percent=81.4, used=5194485760, free=1183522816)
2025-06-02 14:46:57,004:INFO:Physical Core: 4
2025-06-02 14:46:57,004:INFO:Logical Core: 8
2025-06-02 14:46:57,004:INFO:Checking libraries
2025-06-02 14:46:57,005:INFO:System:
2025-06-02 14:46:57,005:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 14:46:57,005:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 14:46:57,005:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 14:46:57,005:INFO:PyCaret required dependencies:
2025-06-02 14:46:57,009:INFO:                 pip: 25.1
2025-06-02 14:46:57,009:INFO:          setuptools: 78.1.1
2025-06-02 14:46:57,009:INFO:             pycaret: 3.3.2
2025-06-02 14:46:57,009:INFO:             IPython: 8.37.0
2025-06-02 14:46:57,009:INFO:          ipywidgets: 8.1.7
2025-06-02 14:46:57,009:INFO:                tqdm: 4.67.1
2025-06-02 14:46:57,009:INFO:               numpy: 1.26.4
2025-06-02 14:46:57,009:INFO:              pandas: 2.0.1
2025-06-02 14:46:57,009:INFO:              jinja2: 3.1.6
2025-06-02 14:46:57,009:INFO:               scipy: 1.10.1
2025-06-02 14:46:57,010:INFO:              joblib: 1.3.2
2025-06-02 14:46:57,010:INFO:             sklearn: 1.4.2
2025-06-02 14:46:57,010:INFO:                pyod: 2.0.5
2025-06-02 14:46:57,010:INFO:            imblearn: 0.13.0
2025-06-02 14:46:57,010:INFO:   category_encoders: 2.7.0
2025-06-02 14:46:57,010:INFO:            lightgbm: 4.6.0
2025-06-02 14:46:57,010:INFO:               numba: 0.61.0
2025-06-02 14:46:57,010:INFO:            requests: 2.32.3
2025-06-02 14:46:57,010:INFO:          matplotlib: 3.7.1
2025-06-02 14:46:57,010:INFO:          scikitplot: 0.3.7
2025-06-02 14:46:57,010:INFO:         yellowbrick: 1.5
2025-06-02 14:46:57,010:INFO:              plotly: 6.1.2
2025-06-02 14:46:57,010:INFO:    plotly-resampler: Not installed
2025-06-02 14:46:57,010:INFO:             kaleido: 0.2.1
2025-06-02 14:46:57,010:INFO:           schemdraw: 0.15
2025-06-02 14:46:57,011:INFO:         statsmodels: 0.14.4
2025-06-02 14:46:57,011:INFO:              sktime: 0.26.0
2025-06-02 14:46:57,011:INFO:               tbats: 1.1.3
2025-06-02 14:46:57,011:INFO:            pmdarima: 2.0.4
2025-06-02 14:46:57,011:INFO:              psutil: 7.0.0
2025-06-02 14:46:57,011:INFO:          markupsafe: 2.1.2
2025-06-02 14:46:57,011:INFO:             pickle5: Not installed
2025-06-02 14:46:57,011:INFO:         cloudpickle: 3.1.1
2025-06-02 14:46:57,011:INFO:         deprecation: 2.1.0
2025-06-02 14:46:57,011:INFO:              xxhash: 3.5.0
2025-06-02 14:46:57,011:INFO:           wurlitzer: Not installed
2025-06-02 14:46:57,011:INFO:PyCaret optional dependencies:
2025-06-02 14:46:57,012:INFO:                shap: 0.44.1
2025-06-02 14:46:57,012:INFO:           interpret: 0.6.9
2025-06-02 14:46:57,012:INFO:                umap: 0.5.7
2025-06-02 14:46:57,012:INFO:     ydata_profiling: 4.16.1
2025-06-02 14:46:57,012:INFO:  explainerdashboard: 0.4.8
2025-06-02 14:46:57,012:INFO:             autoviz: Not installed
2025-06-02 14:46:57,012:INFO:           fairlearn: 0.7.0
2025-06-02 14:46:57,012:INFO:          deepchecks: Not installed
2025-06-02 14:46:57,012:INFO:             xgboost: 3.0.2
2025-06-02 14:46:57,012:INFO:            catboost: 1.2.8
2025-06-02 14:46:57,013:INFO:              kmodes: 0.12.2
2025-06-02 14:46:57,013:INFO:             mlxtend: 0.23.4
2025-06-02 14:46:57,013:INFO:       statsforecast: 1.5.0
2025-06-02 14:46:57,013:INFO:        tune_sklearn: Not installed
2025-06-02 14:46:57,013:INFO:                 ray: Not installed
2025-06-02 14:46:57,013:INFO:            hyperopt: 0.2.7
2025-06-02 14:46:57,013:INFO:              optuna: 4.3.0
2025-06-02 14:46:57,013:INFO:               skopt: 0.10.2
2025-06-02 14:46:57,013:INFO:              mlflow: 2.22.0
2025-06-02 14:46:57,013:INFO:              gradio: 5.32.0
2025-06-02 14:46:57,013:INFO:             fastapi: 0.115.12
2025-06-02 14:46:57,013:INFO:             uvicorn: 0.34.3
2025-06-02 14:46:57,013:INFO:              m2cgen: 0.10.0
2025-06-02 14:46:57,013:INFO:           evidently: 0.4.40
2025-06-02 14:46:57,013:INFO:               fugue: 0.8.5
2025-06-02 14:46:57,014:INFO:           streamlit: Not installed
2025-06-02 14:46:57,014:INFO:             prophet: Not installed
2025-06-02 14:46:57,014:INFO:None
2025-06-02 14:46:57,014:INFO:Set up data.
2025-06-02 14:46:57,181:INFO:Set up folding strategy.
2025-06-02 14:46:57,183:INFO:Set up train/test split.
2025-06-02 14:46:57,274:INFO:Set up index.
2025-06-02 14:46:57,277:INFO:Assigning column types.
2025-06-02 14:46:57,351:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 14:46:57,359:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 14:46:57,371:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:46:57,381:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:46:57,573:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:46:57,665:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:46:57,672:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:46:57,685:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:46:57,687:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 14:46:57,695:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:46:57,704:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:46:57,844:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:46:57,935:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:46:57,936:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:46:57,940:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:46:57,941:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 14:46:57,948:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:46:57,961:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:46:58,109:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:46:58,211:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:46:58,211:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:46:58,215:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:46:58,224:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 14:46:58,231:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:46:58,364:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:46:58,453:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:46:58,454:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:46:58,458:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:46:58,459:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 14:46:58,474:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:46:58,609:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:46:58,710:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:46:58,710:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:46:58,715:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:46:58,731:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 14:46:58,875:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:46:58,968:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:46:58,968:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:46:58,972:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:46:58,973:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 14:46:59,129:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:46:59,204:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:46:59,205:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:46:59,209:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:46:59,358:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:46:59,439:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 14:46:59,440:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:46:59,445:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:46:59,446:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 14:46:59,599:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:46:59,684:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:46:59,691:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:46:59,875:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 14:46:59,955:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:46:59,959:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:46:59,960:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 14:47:00,256:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:47:00,261:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:47:00,547:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:47:00,554:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:47:00,573:INFO:Preparing preprocessing pipeline...
2025-06-02 14:47:00,573:INFO:Set up simple imputation.
2025-06-02 14:47:00,575:INFO:Set up removing multicollinearity.
2025-06-02 14:47:00,585:INFO:Set up column name cleaning.
2025-06-02 14:47:00,898:INFO:Finished creating preprocessing pipeline.
2025-06-02 14:47:00,915:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 14:47:00,916:INFO:Creating final display dataframe.
2025-06-02 14:47:01,386:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              7429
2025-06-02 14:47:01,713:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:47:01,718:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:47:01,942:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 14:47:01,946:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 14:47:01,951:INFO:setup() successfully completed in 5.09s...............
2025-06-02 14:47:01,993:INFO:Initializing compare_models()
2025-06-02 14:47:01,993:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 14:47:01,993:INFO:Checking exceptions
2025-06-02 14:47:02,017:INFO:Preparing display monitor
2025-06-02 14:47:02,110:INFO:Initializing Linear Regression
2025-06-02 14:47:02,111:INFO:Total runtime is 1.6661485036214194e-05 minutes
2025-06-02 14:47:02,135:INFO:SubProcess create_model() called ==================================
2025-06-02 14:47:02,140:INFO:Initializing create_model()
2025-06-02 14:47:02,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:47:02,141:INFO:Checking exceptions
2025-06-02 14:47:02,142:INFO:Importing libraries
2025-06-02 14:47:02,143:INFO:Copying training dataset
2025-06-02 14:47:02,389:INFO:Defining folds
2025-06-02 14:47:02,390:INFO:Declaring metric variables
2025-06-02 14:47:02,403:INFO:Importing untrained model
2025-06-02 14:47:02,479:INFO:Linear Regression Imported successfully
2025-06-02 14:47:02,514:INFO:Starting cross validation
2025-06-02 14:47:02,526:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:47:17,597:INFO:Calculating mean and std
2025-06-02 14:47:17,619:INFO:Creating metrics dataframe
2025-06-02 14:47:17,641:INFO:Uploading results into container
2025-06-02 14:47:17,646:INFO:Uploading model into container now
2025-06-02 14:47:17,652:INFO:_master_model_container: 1
2025-06-02 14:47:17,653:INFO:_display_container: 2
2025-06-02 14:47:17,655:INFO:LinearRegression(n_jobs=-1)
2025-06-02 14:47:17,655:INFO:create_model() successfully completed......................................
2025-06-02 14:47:29,584:INFO:SubProcess create_model() end ==================================
2025-06-02 14:47:29,585:INFO:Creating metrics dataframe
2025-06-02 14:47:29,618:INFO:Initializing Lasso Regression
2025-06-02 14:47:29,618:INFO:Total runtime is 0.45846011638641354 minutes
2025-06-02 14:47:29,632:INFO:SubProcess create_model() called ==================================
2025-06-02 14:47:29,633:INFO:Initializing create_model()
2025-06-02 14:47:29,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:47:29,634:INFO:Checking exceptions
2025-06-02 14:47:29,634:INFO:Importing libraries
2025-06-02 14:47:29,636:INFO:Copying training dataset
2025-06-02 14:47:29,773:INFO:Defining folds
2025-06-02 14:47:29,774:INFO:Declaring metric variables
2025-06-02 14:47:29,787:INFO:Importing untrained model
2025-06-02 14:47:29,798:INFO:Lasso Regression Imported successfully
2025-06-02 14:47:29,822:INFO:Starting cross validation
2025-06-02 14:47:29,827:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:47:40,147:INFO:Calculating mean and std
2025-06-02 14:47:40,155:INFO:Creating metrics dataframe
2025-06-02 14:47:40,174:INFO:Uploading results into container
2025-06-02 14:47:40,175:INFO:Uploading model into container now
2025-06-02 14:47:40,177:INFO:_master_model_container: 2
2025-06-02 14:47:40,178:INFO:_display_container: 2
2025-06-02 14:47:40,184:INFO:Lasso(random_state=123)
2025-06-02 14:47:40,185:INFO:create_model() successfully completed......................................
2025-06-02 14:47:41,868:INFO:SubProcess create_model() end ==================================
2025-06-02 14:47:41,868:INFO:Creating metrics dataframe
2025-06-02 14:47:41,889:INFO:Initializing Ridge Regression
2025-06-02 14:47:41,889:INFO:Total runtime is 0.6629843473434448 minutes
2025-06-02 14:47:41,899:INFO:SubProcess create_model() called ==================================
2025-06-02 14:47:41,900:INFO:Initializing create_model()
2025-06-02 14:47:41,900:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:47:41,900:INFO:Checking exceptions
2025-06-02 14:47:41,900:INFO:Importing libraries
2025-06-02 14:47:41,901:INFO:Copying training dataset
2025-06-02 14:47:41,971:INFO:Defining folds
2025-06-02 14:47:41,971:INFO:Declaring metric variables
2025-06-02 14:47:41,986:INFO:Importing untrained model
2025-06-02 14:47:41,998:INFO:Ridge Regression Imported successfully
2025-06-02 14:47:42,023:INFO:Starting cross validation
2025-06-02 14:47:42,026:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:47:42,620:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.75561e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:47:42,661:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.24347e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:47:42,664:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31073e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:47:42,783:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.08754e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 14:47:43,166:INFO:Calculating mean and std
2025-06-02 14:47:43,169:INFO:Creating metrics dataframe
2025-06-02 14:47:43,172:INFO:Uploading results into container
2025-06-02 14:47:43,173:INFO:Uploading model into container now
2025-06-02 14:47:43,174:INFO:_master_model_container: 3
2025-06-02 14:47:43,175:INFO:_display_container: 2
2025-06-02 14:47:43,175:INFO:Ridge(random_state=123)
2025-06-02 14:47:43,176:INFO:create_model() successfully completed......................................
2025-06-02 14:47:44,439:INFO:SubProcess create_model() end ==================================
2025-06-02 14:47:44,439:INFO:Creating metrics dataframe
2025-06-02 14:47:44,459:INFO:Initializing Elastic Net
2025-06-02 14:47:44,459:INFO:Total runtime is 0.7058162331581116 minutes
2025-06-02 14:47:44,473:INFO:SubProcess create_model() called ==================================
2025-06-02 14:47:44,474:INFO:Initializing create_model()
2025-06-02 14:47:44,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:47:44,474:INFO:Checking exceptions
2025-06-02 14:47:44,475:INFO:Importing libraries
2025-06-02 14:47:44,475:INFO:Copying training dataset
2025-06-02 14:47:44,584:INFO:Defining folds
2025-06-02 14:47:44,585:INFO:Declaring metric variables
2025-06-02 14:47:44,602:INFO:Importing untrained model
2025-06-02 14:47:44,619:INFO:Elastic Net Imported successfully
2025-06-02 14:47:44,653:INFO:Starting cross validation
2025-06-02 14:47:44,658:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:47:45,903:INFO:Calculating mean and std
2025-06-02 14:47:45,907:INFO:Creating metrics dataframe
2025-06-02 14:47:45,911:INFO:Uploading results into container
2025-06-02 14:47:45,913:INFO:Uploading model into container now
2025-06-02 14:47:45,914:INFO:_master_model_container: 4
2025-06-02 14:47:45,914:INFO:_display_container: 2
2025-06-02 14:47:45,915:INFO:ElasticNet(random_state=123)
2025-06-02 14:47:45,916:INFO:create_model() successfully completed......................................
2025-06-02 14:47:47,188:INFO:SubProcess create_model() end ==================================
2025-06-02 14:47:47,189:INFO:Creating metrics dataframe
2025-06-02 14:47:47,209:INFO:Initializing Least Angle Regression
2025-06-02 14:47:47,210:INFO:Total runtime is 0.7516600410143535 minutes
2025-06-02 14:47:47,219:INFO:SubProcess create_model() called ==================================
2025-06-02 14:47:47,220:INFO:Initializing create_model()
2025-06-02 14:47:47,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:47:47,221:INFO:Checking exceptions
2025-06-02 14:47:47,221:INFO:Importing libraries
2025-06-02 14:47:47,222:INFO:Copying training dataset
2025-06-02 14:47:47,291:INFO:Defining folds
2025-06-02 14:47:47,292:INFO:Declaring metric variables
2025-06-02 14:47:47,303:INFO:Importing untrained model
2025-06-02 14:47:47,316:INFO:Least Angle Regression Imported successfully
2025-06-02 14:47:47,340:INFO:Starting cross validation
2025-06-02 14:47:47,345:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:47:48,487:INFO:Calculating mean and std
2025-06-02 14:47:48,489:INFO:Creating metrics dataframe
2025-06-02 14:47:48,493:INFO:Uploading results into container
2025-06-02 14:47:48,494:INFO:Uploading model into container now
2025-06-02 14:47:48,494:INFO:_master_model_container: 5
2025-06-02 14:47:48,495:INFO:_display_container: 2
2025-06-02 14:47:48,496:INFO:Lars(random_state=123)
2025-06-02 14:47:48,497:INFO:create_model() successfully completed......................................
2025-06-02 14:47:49,724:INFO:SubProcess create_model() end ==================================
2025-06-02 14:47:49,726:INFO:Creating metrics dataframe
2025-06-02 14:47:49,751:INFO:Initializing Lasso Least Angle Regression
2025-06-02 14:47:49,751:INFO:Total runtime is 0.7940057436625163 minutes
2025-06-02 14:47:49,762:INFO:SubProcess create_model() called ==================================
2025-06-02 14:47:49,763:INFO:Initializing create_model()
2025-06-02 14:47:49,763:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:47:49,763:INFO:Checking exceptions
2025-06-02 14:47:49,763:INFO:Importing libraries
2025-06-02 14:47:49,764:INFO:Copying training dataset
2025-06-02 14:47:49,838:INFO:Defining folds
2025-06-02 14:47:49,838:INFO:Declaring metric variables
2025-06-02 14:47:49,849:INFO:Importing untrained model
2025-06-02 14:47:49,860:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 14:47:49,882:INFO:Starting cross validation
2025-06-02 14:47:49,888:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:47:51,021:INFO:Calculating mean and std
2025-06-02 14:47:51,023:INFO:Creating metrics dataframe
2025-06-02 14:47:51,025:INFO:Uploading results into container
2025-06-02 14:47:51,026:INFO:Uploading model into container now
2025-06-02 14:47:51,027:INFO:_master_model_container: 6
2025-06-02 14:47:51,027:INFO:_display_container: 2
2025-06-02 14:47:51,028:INFO:LassoLars(random_state=123)
2025-06-02 14:47:51,028:INFO:create_model() successfully completed......................................
2025-06-02 14:47:52,260:INFO:SubProcess create_model() end ==================================
2025-06-02 14:47:52,260:INFO:Creating metrics dataframe
2025-06-02 14:47:52,280:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 14:47:52,280:INFO:Total runtime is 0.8361584544181824 minutes
2025-06-02 14:47:52,289:INFO:SubProcess create_model() called ==================================
2025-06-02 14:47:52,290:INFO:Initializing create_model()
2025-06-02 14:47:52,290:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:47:52,290:INFO:Checking exceptions
2025-06-02 14:47:52,291:INFO:Importing libraries
2025-06-02 14:47:52,291:INFO:Copying training dataset
2025-06-02 14:47:52,370:INFO:Defining folds
2025-06-02 14:47:52,370:INFO:Declaring metric variables
2025-06-02 14:47:52,382:INFO:Importing untrained model
2025-06-02 14:47:52,394:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 14:47:52,419:INFO:Starting cross validation
2025-06-02 14:47:52,423:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:47:54,367:INFO:Calculating mean and std
2025-06-02 14:47:54,369:INFO:Creating metrics dataframe
2025-06-02 14:47:54,373:INFO:Uploading results into container
2025-06-02 14:47:54,374:INFO:Uploading model into container now
2025-06-02 14:47:54,375:INFO:_master_model_container: 7
2025-06-02 14:47:54,375:INFO:_display_container: 2
2025-06-02 14:47:54,376:INFO:OrthogonalMatchingPursuit()
2025-06-02 14:47:54,376:INFO:create_model() successfully completed......................................
2025-06-02 14:47:55,695:INFO:SubProcess create_model() end ==================================
2025-06-02 14:47:55,695:INFO:Creating metrics dataframe
2025-06-02 14:47:55,714:INFO:Initializing Bayesian Ridge
2025-06-02 14:47:55,714:INFO:Total runtime is 0.8934003909428915 minutes
2025-06-02 14:47:55,723:INFO:SubProcess create_model() called ==================================
2025-06-02 14:47:55,724:INFO:Initializing create_model()
2025-06-02 14:47:55,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:47:55,725:INFO:Checking exceptions
2025-06-02 14:47:55,725:INFO:Importing libraries
2025-06-02 14:47:55,726:INFO:Copying training dataset
2025-06-02 14:47:55,795:INFO:Defining folds
2025-06-02 14:47:55,795:INFO:Declaring metric variables
2025-06-02 14:47:55,810:INFO:Importing untrained model
2025-06-02 14:47:55,821:INFO:Bayesian Ridge Imported successfully
2025-06-02 14:47:55,847:INFO:Starting cross validation
2025-06-02 14:47:55,852:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:47:56,680:INFO:Calculating mean and std
2025-06-02 14:47:56,682:INFO:Creating metrics dataframe
2025-06-02 14:47:56,685:INFO:Uploading results into container
2025-06-02 14:47:56,686:INFO:Uploading model into container now
2025-06-02 14:47:56,687:INFO:_master_model_container: 8
2025-06-02 14:47:56,687:INFO:_display_container: 2
2025-06-02 14:47:56,688:INFO:BayesianRidge()
2025-06-02 14:47:56,688:INFO:create_model() successfully completed......................................
2025-06-02 14:47:57,934:INFO:SubProcess create_model() end ==================================
2025-06-02 14:47:57,934:INFO:Creating metrics dataframe
2025-06-02 14:47:57,955:INFO:Initializing Passive Aggressive Regressor
2025-06-02 14:47:57,955:INFO:Total runtime is 0.9307439128557842 minutes
2025-06-02 14:47:57,969:INFO:SubProcess create_model() called ==================================
2025-06-02 14:47:57,970:INFO:Initializing create_model()
2025-06-02 14:47:57,971:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:47:57,971:INFO:Checking exceptions
2025-06-02 14:47:57,972:INFO:Importing libraries
2025-06-02 14:47:57,972:INFO:Copying training dataset
2025-06-02 14:47:58,062:INFO:Defining folds
2025-06-02 14:47:58,063:INFO:Declaring metric variables
2025-06-02 14:47:58,078:INFO:Importing untrained model
2025-06-02 14:47:58,091:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 14:47:58,119:INFO:Starting cross validation
2025-06-02 14:47:58,123:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:47:59,026:INFO:Calculating mean and std
2025-06-02 14:47:59,029:INFO:Creating metrics dataframe
2025-06-02 14:47:59,033:INFO:Uploading results into container
2025-06-02 14:47:59,034:INFO:Uploading model into container now
2025-06-02 14:47:59,036:INFO:_master_model_container: 9
2025-06-02 14:47:59,036:INFO:_display_container: 2
2025-06-02 14:47:59,037:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 14:47:59,037:INFO:create_model() successfully completed......................................
2025-06-02 14:48:00,328:INFO:SubProcess create_model() end ==================================
2025-06-02 14:48:00,329:INFO:Creating metrics dataframe
2025-06-02 14:48:00,354:INFO:Initializing Huber Regressor
2025-06-02 14:48:00,354:INFO:Total runtime is 0.970729931195577 minutes
2025-06-02 14:48:00,365:INFO:SubProcess create_model() called ==================================
2025-06-02 14:48:00,366:INFO:Initializing create_model()
2025-06-02 14:48:00,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:48:00,367:INFO:Checking exceptions
2025-06-02 14:48:00,367:INFO:Importing libraries
2025-06-02 14:48:00,368:INFO:Copying training dataset
2025-06-02 14:48:00,460:INFO:Defining folds
2025-06-02 14:48:00,461:INFO:Declaring metric variables
2025-06-02 14:48:00,475:INFO:Importing untrained model
2025-06-02 14:48:00,487:INFO:Huber Regressor Imported successfully
2025-06-02 14:48:00,514:INFO:Starting cross validation
2025-06-02 14:48:00,518:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:48:02,846:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:48:02,880:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:48:02,925:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:48:02,948:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:48:02,981:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 14:48:03,039:INFO:Calculating mean and std
2025-06-02 14:48:03,041:INFO:Creating metrics dataframe
2025-06-02 14:48:03,044:INFO:Uploading results into container
2025-06-02 14:48:03,045:INFO:Uploading model into container now
2025-06-02 14:48:03,046:INFO:_master_model_container: 10
2025-06-02 14:48:03,046:INFO:_display_container: 2
2025-06-02 14:48:03,047:INFO:HuberRegressor()
2025-06-02 14:48:03,047:INFO:create_model() successfully completed......................................
2025-06-02 14:48:04,278:INFO:SubProcess create_model() end ==================================
2025-06-02 14:48:04,278:INFO:Creating metrics dataframe
2025-06-02 14:48:04,297:INFO:Initializing K Neighbors Regressor
2025-06-02 14:48:04,297:INFO:Total runtime is 1.0364471594492595 minutes
2025-06-02 14:48:04,306:INFO:SubProcess create_model() called ==================================
2025-06-02 14:48:04,307:INFO:Initializing create_model()
2025-06-02 14:48:04,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:48:04,308:INFO:Checking exceptions
2025-06-02 14:48:04,308:INFO:Importing libraries
2025-06-02 14:48:04,308:INFO:Copying training dataset
2025-06-02 14:48:04,398:INFO:Defining folds
2025-06-02 14:48:04,399:INFO:Declaring metric variables
2025-06-02 14:48:04,414:INFO:Importing untrained model
2025-06-02 14:48:04,428:INFO:K Neighbors Regressor Imported successfully
2025-06-02 14:48:04,461:INFO:Starting cross validation
2025-06-02 14:48:04,467:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:48:05,381:INFO:Calculating mean and std
2025-06-02 14:48:05,383:INFO:Creating metrics dataframe
2025-06-02 14:48:05,386:INFO:Uploading results into container
2025-06-02 14:48:05,387:INFO:Uploading model into container now
2025-06-02 14:48:05,388:INFO:_master_model_container: 11
2025-06-02 14:48:05,388:INFO:_display_container: 2
2025-06-02 14:48:05,389:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 14:48:05,389:INFO:create_model() successfully completed......................................
2025-06-02 14:48:06,641:INFO:SubProcess create_model() end ==================================
2025-06-02 14:48:06,641:INFO:Creating metrics dataframe
2025-06-02 14:48:06,664:INFO:Initializing Decision Tree Regressor
2025-06-02 14:48:06,664:INFO:Total runtime is 1.075886634985606 minutes
2025-06-02 14:48:06,675:INFO:SubProcess create_model() called ==================================
2025-06-02 14:48:06,676:INFO:Initializing create_model()
2025-06-02 14:48:06,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:48:06,677:INFO:Checking exceptions
2025-06-02 14:48:06,677:INFO:Importing libraries
2025-06-02 14:48:06,678:INFO:Copying training dataset
2025-06-02 14:48:06,753:INFO:Defining folds
2025-06-02 14:48:06,754:INFO:Declaring metric variables
2025-06-02 14:48:06,767:INFO:Importing untrained model
2025-06-02 14:48:06,780:INFO:Decision Tree Regressor Imported successfully
2025-06-02 14:48:06,806:INFO:Starting cross validation
2025-06-02 14:48:06,810:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:48:08,020:INFO:Calculating mean and std
2025-06-02 14:48:08,022:INFO:Creating metrics dataframe
2025-06-02 14:48:08,026:INFO:Uploading results into container
2025-06-02 14:48:08,027:INFO:Uploading model into container now
2025-06-02 14:48:08,028:INFO:_master_model_container: 12
2025-06-02 14:48:08,028:INFO:_display_container: 2
2025-06-02 14:48:08,028:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 14:48:08,029:INFO:create_model() successfully completed......................................
2025-06-02 14:48:09,341:INFO:SubProcess create_model() end ==================================
2025-06-02 14:48:09,342:INFO:Creating metrics dataframe
2025-06-02 14:48:09,364:INFO:Initializing Random Forest Regressor
2025-06-02 14:48:09,364:INFO:Total runtime is 1.1208850741386416 minutes
2025-06-02 14:48:09,375:INFO:SubProcess create_model() called ==================================
2025-06-02 14:48:09,376:INFO:Initializing create_model()
2025-06-02 14:48:09,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:48:09,377:INFO:Checking exceptions
2025-06-02 14:48:09,377:INFO:Importing libraries
2025-06-02 14:48:09,377:INFO:Copying training dataset
2025-06-02 14:48:09,446:INFO:Defining folds
2025-06-02 14:48:09,446:INFO:Declaring metric variables
2025-06-02 14:48:09,461:INFO:Importing untrained model
2025-06-02 14:48:09,473:INFO:Random Forest Regressor Imported successfully
2025-06-02 14:48:09,498:INFO:Starting cross validation
2025-06-02 14:48:09,502:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:48:19,373:INFO:Calculating mean and std
2025-06-02 14:48:19,376:INFO:Creating metrics dataframe
2025-06-02 14:48:19,380:INFO:Uploading results into container
2025-06-02 14:48:19,381:INFO:Uploading model into container now
2025-06-02 14:48:19,383:INFO:_master_model_container: 13
2025-06-02 14:48:19,383:INFO:_display_container: 2
2025-06-02 14:48:19,384:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:48:19,385:INFO:create_model() successfully completed......................................
2025-06-02 14:48:20,744:INFO:SubProcess create_model() end ==================================
2025-06-02 14:48:20,744:INFO:Creating metrics dataframe
2025-06-02 14:48:20,772:INFO:Initializing Extra Trees Regressor
2025-06-02 14:48:20,773:INFO:Total runtime is 1.3110443433125816 minutes
2025-06-02 14:48:20,783:INFO:SubProcess create_model() called ==================================
2025-06-02 14:48:20,784:INFO:Initializing create_model()
2025-06-02 14:48:20,784:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:48:20,785:INFO:Checking exceptions
2025-06-02 14:48:20,786:INFO:Importing libraries
2025-06-02 14:48:20,787:INFO:Copying training dataset
2025-06-02 14:48:20,869:INFO:Defining folds
2025-06-02 14:48:20,870:INFO:Declaring metric variables
2025-06-02 14:48:20,887:INFO:Importing untrained model
2025-06-02 14:48:20,903:INFO:Extra Trees Regressor Imported successfully
2025-06-02 14:48:20,935:INFO:Starting cross validation
2025-06-02 14:48:20,941:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:48:28,900:INFO:Calculating mean and std
2025-06-02 14:48:28,903:INFO:Creating metrics dataframe
2025-06-02 14:48:28,907:INFO:Uploading results into container
2025-06-02 14:48:28,909:INFO:Uploading model into container now
2025-06-02 14:48:28,910:INFO:_master_model_container: 14
2025-06-02 14:48:28,910:INFO:_display_container: 2
2025-06-02 14:48:28,911:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:48:28,911:INFO:create_model() successfully completed......................................
2025-06-02 14:48:30,221:INFO:SubProcess create_model() end ==================================
2025-06-02 14:48:30,221:INFO:Creating metrics dataframe
2025-06-02 14:48:30,249:INFO:Initializing AdaBoost Regressor
2025-06-02 14:48:30,249:INFO:Total runtime is 1.468970561027527 minutes
2025-06-02 14:48:30,263:INFO:SubProcess create_model() called ==================================
2025-06-02 14:48:30,264:INFO:Initializing create_model()
2025-06-02 14:48:30,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:48:30,264:INFO:Checking exceptions
2025-06-02 14:48:30,265:INFO:Importing libraries
2025-06-02 14:48:30,265:INFO:Copying training dataset
2025-06-02 14:48:30,350:INFO:Defining folds
2025-06-02 14:48:30,351:INFO:Declaring metric variables
2025-06-02 14:48:30,367:INFO:Importing untrained model
2025-06-02 14:48:30,381:INFO:AdaBoost Regressor Imported successfully
2025-06-02 14:48:30,411:INFO:Starting cross validation
2025-06-02 14:48:30,416:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:48:32,844:INFO:Calculating mean and std
2025-06-02 14:48:32,847:INFO:Creating metrics dataframe
2025-06-02 14:48:32,851:INFO:Uploading results into container
2025-06-02 14:48:32,852:INFO:Uploading model into container now
2025-06-02 14:48:32,853:INFO:_master_model_container: 15
2025-06-02 14:48:32,853:INFO:_display_container: 2
2025-06-02 14:48:32,854:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 14:48:32,854:INFO:create_model() successfully completed......................................
2025-06-02 14:48:34,088:INFO:SubProcess create_model() end ==================================
2025-06-02 14:48:34,088:INFO:Creating metrics dataframe
2025-06-02 14:48:34,115:INFO:Initializing Gradient Boosting Regressor
2025-06-02 14:48:34,115:INFO:Total runtime is 1.5334156711896263 minutes
2025-06-02 14:48:34,126:INFO:SubProcess create_model() called ==================================
2025-06-02 14:48:34,127:INFO:Initializing create_model()
2025-06-02 14:48:34,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:48:34,128:INFO:Checking exceptions
2025-06-02 14:48:34,128:INFO:Importing libraries
2025-06-02 14:48:34,128:INFO:Copying training dataset
2025-06-02 14:48:34,201:INFO:Defining folds
2025-06-02 14:48:34,202:INFO:Declaring metric variables
2025-06-02 14:48:34,219:INFO:Importing untrained model
2025-06-02 14:48:34,236:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 14:48:34,264:INFO:Starting cross validation
2025-06-02 14:48:34,269:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:48:37,760:INFO:Calculating mean and std
2025-06-02 14:48:37,762:INFO:Creating metrics dataframe
2025-06-02 14:48:37,767:INFO:Uploading results into container
2025-06-02 14:48:37,768:INFO:Uploading model into container now
2025-06-02 14:48:37,769:INFO:_master_model_container: 16
2025-06-02 14:48:37,770:INFO:_display_container: 2
2025-06-02 14:48:37,771:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 14:48:37,772:INFO:create_model() successfully completed......................................
2025-06-02 14:48:39,068:INFO:SubProcess create_model() end ==================================
2025-06-02 14:48:39,068:INFO:Creating metrics dataframe
2025-06-02 14:48:39,094:INFO:Initializing Extreme Gradient Boosting
2025-06-02 14:48:39,095:INFO:Total runtime is 1.6164155324300133 minutes
2025-06-02 14:48:39,106:INFO:SubProcess create_model() called ==================================
2025-06-02 14:48:39,107:INFO:Initializing create_model()
2025-06-02 14:48:39,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:48:39,107:INFO:Checking exceptions
2025-06-02 14:48:39,107:INFO:Importing libraries
2025-06-02 14:48:39,108:INFO:Copying training dataset
2025-06-02 14:48:39,186:INFO:Defining folds
2025-06-02 14:48:39,186:INFO:Declaring metric variables
2025-06-02 14:48:39,201:INFO:Importing untrained model
2025-06-02 14:48:39,218:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 14:48:39,246:INFO:Starting cross validation
2025-06-02 14:48:39,250:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:48:41,750:INFO:Calculating mean and std
2025-06-02 14:48:41,753:INFO:Creating metrics dataframe
2025-06-02 14:48:41,759:INFO:Uploading results into container
2025-06-02 14:48:41,761:INFO:Uploading model into container now
2025-06-02 14:48:41,762:INFO:_master_model_container: 17
2025-06-02 14:48:41,762:INFO:_display_container: 2
2025-06-02 14:48:41,767:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 14:48:41,768:INFO:create_model() successfully completed......................................
2025-06-02 14:48:43,004:INFO:SubProcess create_model() end ==================================
2025-06-02 14:48:43,005:INFO:Creating metrics dataframe
2025-06-02 14:48:43,026:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 14:48:43,026:INFO:Total runtime is 1.6819280227025353 minutes
2025-06-02 14:48:43,038:INFO:SubProcess create_model() called ==================================
2025-06-02 14:48:43,039:INFO:Initializing create_model()
2025-06-02 14:48:43,039:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:48:43,039:INFO:Checking exceptions
2025-06-02 14:48:43,040:INFO:Importing libraries
2025-06-02 14:48:43,040:INFO:Copying training dataset
2025-06-02 14:48:43,121:INFO:Defining folds
2025-06-02 14:48:43,121:INFO:Declaring metric variables
2025-06-02 14:48:43,137:INFO:Importing untrained model
2025-06-02 14:48:43,151:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:48:43,177:INFO:Starting cross validation
2025-06-02 14:48:43,181:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:48:45,237:INFO:Calculating mean and std
2025-06-02 14:48:45,239:INFO:Creating metrics dataframe
2025-06-02 14:48:45,244:INFO:Uploading results into container
2025-06-02 14:48:45,246:INFO:Uploading model into container now
2025-06-02 14:48:45,247:INFO:_master_model_container: 18
2025-06-02 14:48:45,247:INFO:_display_container: 2
2025-06-02 14:48:45,248:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:48:45,249:INFO:create_model() successfully completed......................................
2025-06-02 14:48:46,579:INFO:SubProcess create_model() end ==================================
2025-06-02 14:48:46,579:INFO:Creating metrics dataframe
2025-06-02 14:48:46,609:INFO:Initializing CatBoost Regressor
2025-06-02 14:48:46,609:INFO:Total runtime is 1.7416429877281192 minutes
2025-06-02 14:48:46,623:INFO:SubProcess create_model() called ==================================
2025-06-02 14:48:46,624:INFO:Initializing create_model()
2025-06-02 14:48:46,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:48:46,624:INFO:Checking exceptions
2025-06-02 14:48:46,625:INFO:Importing libraries
2025-06-02 14:48:46,625:INFO:Copying training dataset
2025-06-02 14:48:46,698:INFO:Defining folds
2025-06-02 14:48:46,699:INFO:Declaring metric variables
2025-06-02 14:48:46,714:INFO:Importing untrained model
2025-06-02 14:48:46,739:INFO:CatBoost Regressor Imported successfully
2025-06-02 14:48:46,765:INFO:Starting cross validation
2025-06-02 14:48:46,769:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:49:14,043:INFO:Calculating mean and std
2025-06-02 14:49:14,046:INFO:Creating metrics dataframe
2025-06-02 14:49:14,050:INFO:Uploading results into container
2025-06-02 14:49:14,051:INFO:Uploading model into container now
2025-06-02 14:49:14,052:INFO:_master_model_container: 19
2025-06-02 14:49:14,053:INFO:_display_container: 2
2025-06-02 14:49:14,053:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6DB5546A0>
2025-06-02 14:49:14,054:INFO:create_model() successfully completed......................................
2025-06-02 14:49:15,390:INFO:SubProcess create_model() end ==================================
2025-06-02 14:49:15,390:INFO:Creating metrics dataframe
2025-06-02 14:49:15,418:INFO:Initializing Dummy Regressor
2025-06-02 14:49:15,418:INFO:Total runtime is 2.221791978677114 minutes
2025-06-02 14:49:15,432:INFO:SubProcess create_model() called ==================================
2025-06-02 14:49:15,433:INFO:Initializing create_model()
2025-06-02 14:49:15,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9201870>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:49:15,434:INFO:Checking exceptions
2025-06-02 14:49:15,434:INFO:Importing libraries
2025-06-02 14:49:15,435:INFO:Copying training dataset
2025-06-02 14:49:15,493:INFO:Defining folds
2025-06-02 14:49:15,493:INFO:Declaring metric variables
2025-06-02 14:49:15,503:INFO:Importing untrained model
2025-06-02 14:49:15,514:INFO:Dummy Regressor Imported successfully
2025-06-02 14:49:15,537:INFO:Starting cross validation
2025-06-02 14:49:15,541:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:49:16,263:INFO:Calculating mean and std
2025-06-02 14:49:16,266:INFO:Creating metrics dataframe
2025-06-02 14:49:16,269:INFO:Uploading results into container
2025-06-02 14:49:16,270:INFO:Uploading model into container now
2025-06-02 14:49:16,271:INFO:_master_model_container: 20
2025-06-02 14:49:16,271:INFO:_display_container: 2
2025-06-02 14:49:16,272:INFO:DummyRegressor()
2025-06-02 14:49:16,272:INFO:create_model() successfully completed......................................
2025-06-02 14:49:17,502:INFO:SubProcess create_model() end ==================================
2025-06-02 14:49:17,502:INFO:Creating metrics dataframe
2025-06-02 14:49:17,561:INFO:Initializing create_model()
2025-06-02 14:49:17,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:49:17,562:INFO:Checking exceptions
2025-06-02 14:49:17,571:INFO:Importing libraries
2025-06-02 14:49:17,571:INFO:Copying training dataset
2025-06-02 14:49:17,640:INFO:Defining folds
2025-06-02 14:49:17,641:INFO:Declaring metric variables
2025-06-02 14:49:17,641:INFO:Importing untrained model
2025-06-02 14:49:17,641:INFO:Declaring custom model
2025-06-02 14:49:17,644:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:49:17,648:INFO:Cross validation set to False
2025-06-02 14:49:17,648:INFO:Fitting Model
2025-06-02 14:49:18,060:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:49:18,079:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013501 seconds.
2025-06-02 14:49:18,079:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:49:18,079:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 14:49:18,085:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 14:49:18,087:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:49:18,262:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:49:18,262:INFO:create_model() successfully completed......................................
2025-06-02 14:49:19,578:INFO:_master_model_container: 20
2025-06-02 14:49:19,579:INFO:_display_container: 2
2025-06-02 14:49:19,581:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:49:19,582:INFO:compare_models() successfully completed......................................
2025-06-02 14:49:19,592:INFO:Initializing tune_model()
2025-06-02 14:49:19,592:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>)
2025-06-02 14:49:19,592:INFO:Checking exceptions
2025-06-02 14:49:19,592:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 14:49:19,674:INFO:Copying training dataset
2025-06-02 14:49:19,736:INFO:Checking base model
2025-06-02 14:49:19,737:INFO:Base model : Light Gradient Boosting Machine
2025-06-02 14:49:19,754:INFO:Declaring metric variables
2025-06-02 14:49:19,767:INFO:Defining Hyperparameters
2025-06-02 14:49:21,371:INFO:Tuning with n_jobs=-1
2025-06-02 14:49:21,402:INFO:Initializing skopt.BayesSearchCV
2025-06-02 14:49:38,578:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.8608120752388259), ('actual_estimator__bagging_freq', 1), ('actual_estimator__feature_fraction', 0.4284489606984907), ('actual_estimator__learning_rate', 0.016133245419918712), ('actual_estimator__min_child_samples', 95), ('actual_estimator__min_split_gain', 0.8209314243567916), ('actual_estimator__n_estimators', 239), ('actual_estimator__num_leaves', 183), ('actual_estimator__reg_alpha', 8.662569304197528e-07), ('actual_estimator__reg_lambda', 5.001062744294253e-06)])
2025-06-02 14:49:38,580:INFO:Hyperparameter search completed
2025-06-02 14:49:38,580:INFO:SubProcess create_model() called ==================================
2025-06-02 14:49:38,581:INFO:Initializing create_model()
2025-06-02 14:49:38,582:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DAAE8A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.8608120752388259, 'bagging_freq': 1, 'feature_fraction': 0.4284489606984907, 'learning_rate': 0.016133245419918712, 'min_child_samples': 95, 'min_split_gain': 0.8209314243567916, 'n_estimators': 239, 'num_leaves': 183, 'reg_alpha': 8.662569304197528e-07, 'reg_lambda': 5.001062744294253e-06})
2025-06-02 14:49:38,583:INFO:Checking exceptions
2025-06-02 14:49:38,584:INFO:Importing libraries
2025-06-02 14:49:38,584:INFO:Copying training dataset
2025-06-02 14:49:38,674:INFO:Defining folds
2025-06-02 14:49:38,674:INFO:Declaring metric variables
2025-06-02 14:49:38,683:INFO:Importing untrained model
2025-06-02 14:49:38,683:INFO:Declaring custom model
2025-06-02 14:49:38,696:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:49:38,726:INFO:Starting cross validation
2025-06-02 14:49:38,729:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:49:40,187:INFO:Calculating mean and std
2025-06-02 14:49:40,188:INFO:Creating metrics dataframe
2025-06-02 14:49:40,201:INFO:Finalizing model
2025-06-02 14:49:40,547:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 14:49:40,547:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 14:49:40,547:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 14:49:40,573:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:49:40,574:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 14:49:40,574:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 14:49:40,574:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 14:49:40,581:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003804 seconds.
2025-06-02 14:49:40,581:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:49:40,582:INFO:[LightGBM] [Info] Total Bins 6220
2025-06-02 14:49:40,603:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 94
2025-06-02 14:49:40,604:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:49:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 14:49:40,866:INFO:Uploading results into container
2025-06-02 14:49:40,868:INFO:Uploading model into container now
2025-06-02 14:49:40,870:INFO:_master_model_container: 21
2025-06-02 14:49:40,870:INFO:_display_container: 3
2025-06-02 14:49:40,874:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06)
2025-06-02 14:49:40,874:INFO:create_model() successfully completed......................................
2025-06-02 14:49:42,520:INFO:SubProcess create_model() end ==================================
2025-06-02 14:49:42,521:INFO:choose_better activated
2025-06-02 14:49:42,532:INFO:SubProcess create_model() called ==================================
2025-06-02 14:49:42,534:INFO:Initializing create_model()
2025-06-02 14:49:42,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:49:42,535:INFO:Checking exceptions
2025-06-02 14:49:42,537:INFO:Importing libraries
2025-06-02 14:49:42,538:INFO:Copying training dataset
2025-06-02 14:49:42,620:INFO:Defining folds
2025-06-02 14:49:42,621:INFO:Declaring metric variables
2025-06-02 14:49:42,622:INFO:Importing untrained model
2025-06-02 14:49:42,622:INFO:Declaring custom model
2025-06-02 14:49:42,628:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:49:42,629:INFO:Starting cross validation
2025-06-02 14:49:42,632:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 14:49:44,513:INFO:Calculating mean and std
2025-06-02 14:49:44,514:INFO:Creating metrics dataframe
2025-06-02 14:49:44,519:INFO:Finalizing model
2025-06-02 14:49:45,007:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:49:45,012:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002984 seconds.
2025-06-02 14:49:45,012:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:49:45,013:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 14:49:45,013:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 14:49:45,015:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 14:49:45,316:INFO:Uploading results into container
2025-06-02 14:49:45,318:INFO:Uploading model into container now
2025-06-02 14:49:45,319:INFO:_master_model_container: 22
2025-06-02 14:49:45,319:INFO:_display_container: 4
2025-06-02 14:49:45,320:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:49:45,320:INFO:create_model() successfully completed......................................
2025-06-02 14:49:46,705:INFO:SubProcess create_model() end ==================================
2025-06-02 14:49:46,706:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8764
2025-06-02 14:49:46,709:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06) result for R2 is 0.8217
2025-06-02 14:49:46,710:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 14:49:46,710:INFO:choose_better completed
2025-06-02 14:49:46,710:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 14:49:46,731:INFO:_master_model_container: 22
2025-06-02 14:49:46,731:INFO:_display_container: 3
2025-06-02 14:49:46,733:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:49:46,734:INFO:tune_model() successfully completed......................................
2025-06-02 14:49:47,974:INFO:Initializing finalize_model()
2025-06-02 14:49:47,974:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 14:49:47,975:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 14:49:48,019:INFO:Initializing create_model()
2025-06-02 14:49:48,019:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 14:49:48,019:INFO:Checking exceptions
2025-06-02 14:49:48,021:INFO:Importing libraries
2025-06-02 14:49:48,022:INFO:Copying training dataset
2025-06-02 14:49:48,028:INFO:Defining folds
2025-06-02 14:49:48,028:INFO:Declaring metric variables
2025-06-02 14:49:48,028:INFO:Importing untrained model
2025-06-02 14:49:48,028:INFO:Declaring custom model
2025-06-02 14:49:48,030:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 14:49:48,033:INFO:Cross validation set to False
2025-06-02 14:49:48,033:INFO:Fitting Model
2025-06-02 14:49:48,483:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 14:49:48,490:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005185 seconds.
2025-06-02 14:49:48,490:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 14:49:48,491:INFO:[LightGBM] [Info] Total Bins 6237
2025-06-02 14:49:48,491:INFO:[LightGBM] [Info] Number of data points in the train set: 4478, number of used features: 95
2025-06-02 14:49:48,493:INFO:[LightGBM] [Info] Start training from score -0.483793
2025-06-02 14:49:48,693:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:49:48,693:INFO:create_model() successfully completed......................................
2025-06-02 14:49:49,932:INFO:_master_model_container: 22
2025-06-02 14:49:49,932:INFO:_display_container: 3
2025-06-02 14:49:49,952:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:49:49,952:INFO:finalize_model() successfully completed......................................
2025-06-02 14:49:51,230:INFO:Initializing save_model()
2025-06-02 14:49:51,230:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 14:49:51,230:INFO:Adding model into prep_pipe
2025-06-02 14:49:51,230:WARNING:Only Model saved as it was a pipeline.
2025-06-02 14:49:51,254:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 14:49:51,278:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 14:49:51,278:INFO:save_model() successfully completed......................................
2025-06-02 14:57:14,208:INFO:Initializing load_model()
2025-06-02 14:57:14,215:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 14:57:14,460:INFO:Initializing get_config()
2025-06-02 14:57:14,460:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, variable=X_test)
2025-06-02 14:57:14,465:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 14:57:14,468:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 14:57:14,617:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2059                       12.0                       13.0   
2652                       29.0                       31.0   
3768                       34.0                       65.0   
3686                        8.0                       14.0   
1037                       53.0                       83.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2059                      1.0               12.500000   
2652                      2.0               29.500000   
3768                     31.0               44.782608   
3686                      6.0               10.000000   
1037                     30.0               77.545456   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2059                   0.500000                    12.0   
2652                   0.750000                    29.0   
3768                  14.064272                    34.0   
3686                   2.666667                     8.0   
1037                   8.925620                    83.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2059                                68.0                                73.0   
2652                                64.0                                74.0   
3768                                29.0                                89.0   
3686                                78.0                                87.0   
1037                                86.0                                96.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2059                               5.0                        70.500000  ...   
2652                              10.0                        66.500000  ...   
3768                              60.0                        68.130432  ...   
3686                               9.0                        84.000000  ...   
1037                              10.0                        87.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2059                 4.0                   1            32.0   
2652                 4.0                   1            32.0   
3768                 7.0                   0             2.0   
3686                 7.0                   0             2.0   
1037                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2059                 False                     False   
2652                 False                     False   
3768                 False                     False   
3686                 False                     False   
1037                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2059                      False                        False   
2652                      False                        False   
3768                      False                        False   
3686                      False                        False   
1037                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2059                       True                     False   
2652                       True                     False   
3768                      False                      True   
3686                      False                      True   
1037                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2059                    False  
2652                    False  
3768                    False  
3686                    False  
1037                    False  

[1344 rows x 146 columns]
2025-06-02 14:57:14,617:INFO:get_config() successfully completed......................................
2025-06-02 14:57:14,635:INFO:Initializing get_config()
2025-06-02 14:57:14,635:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, variable=y_test)
2025-06-02 14:57:14,636:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 14:57:14,636:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 14:57:14,662:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2059    0.014339
2652   -0.098120
3768   -1.861921
3686   -3.207308
1037   -0.156411
Name: target, Length: 1344, dtype: float32
2025-06-02 14:57:14,663:INFO:get_config() successfully completed......................................
2025-06-02 14:57:14,698:INFO:Initializing predict_model()
2025-06-02 14:57:14,698:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6DB93BD90>)
2025-06-02 14:57:14,698:INFO:Checking exceptions
2025-06-02 14:57:14,699:INFO:Preloading libraries
2025-06-02 14:57:14,719:INFO:Set up data.
2025-06-02 14:57:14,804:INFO:Set up index.
2025-06-02 14:57:56,423:INFO:Initializing load_model()
2025-06-02 14:57:56,424:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 14:57:56,463:INFO:Initializing get_config()
2025-06-02 14:57:56,463:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, variable=X_test)
2025-06-02 14:57:56,463:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 14:57:56,464:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 14:57:56,553:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2059                       12.0                       13.0   
2652                       29.0                       31.0   
3768                       34.0                       65.0   
3686                        8.0                       14.0   
1037                       53.0                       83.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2059                      1.0               12.500000   
2652                      2.0               29.500000   
3768                     31.0               44.782608   
3686                      6.0               10.000000   
1037                     30.0               77.545456   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2059                   0.500000                    12.0   
2652                   0.750000                    29.0   
3768                  14.064272                    34.0   
3686                   2.666667                     8.0   
1037                   8.925620                    83.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2059                                68.0                                73.0   
2652                                64.0                                74.0   
3768                                29.0                                89.0   
3686                                78.0                                87.0   
1037                                86.0                                96.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2059                               5.0                        70.500000  ...   
2652                              10.0                        66.500000  ...   
3768                              60.0                        68.130432  ...   
3686                               9.0                        84.000000  ...   
1037                              10.0                        87.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2059                 4.0                   1            32.0   
2652                 4.0                   1            32.0   
3768                 7.0                   0             2.0   
3686                 7.0                   0             2.0   
1037                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2059                 False                     False   
2652                 False                     False   
3768                 False                     False   
3686                 False                     False   
1037                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2059                      False                        False   
2652                      False                        False   
3768                      False                        False   
3686                      False                        False   
1037                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2059                       True                     False   
2652                       True                     False   
3768                      False                      True   
3686                      False                      True   
1037                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2059                    False  
2652                    False  
3768                    False  
3686                    False  
1037                    False  

[1344 rows x 146 columns]
2025-06-02 14:57:56,554:INFO:get_config() successfully completed......................................
2025-06-02 14:57:56,556:INFO:Initializing get_config()
2025-06-02 14:57:56,556:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, variable=y_test)
2025-06-02 14:57:56,557:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 14:57:56,557:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 14:57:56,574:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2059    0.014339
2652   -0.098120
3768   -1.861921
3686   -3.207308
1037   -0.156411
Name: target, Length: 1344, dtype: float32
2025-06-02 14:57:56,574:INFO:get_config() successfully completed......................................
2025-06-02 14:57:56,595:INFO:Initializing predict_model()
2025-06-02 14:57:56,595:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6DAAFCDC0>)
2025-06-02 14:57:56,595:INFO:Checking exceptions
2025-06-02 14:57:56,595:INFO:Preloading libraries
2025-06-02 14:57:56,602:INFO:Set up data.
2025-06-02 14:57:56,772:INFO:Set up index.
2025-06-02 15:00:17,779:INFO:Initializing load_model()
2025-06-02 15:00:17,780:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 15:00:17,794:INFO:Initializing get_config()
2025-06-02 15:00:17,795:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, variable=X_test)
2025-06-02 15:00:17,796:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 15:00:17,796:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 15:00:17,843:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2059                       12.0                       13.0   
2652                       29.0                       31.0   
3768                       34.0                       65.0   
3686                        8.0                       14.0   
1037                       53.0                       83.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2059                      1.0               12.500000   
2652                      2.0               29.500000   
3768                     31.0               44.782608   
3686                      6.0               10.000000   
1037                     30.0               77.545456   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2059                   0.500000                    12.0   
2652                   0.750000                    29.0   
3768                  14.064272                    34.0   
3686                   2.666667                     8.0   
1037                   8.925620                    83.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2059                                68.0                                73.0   
2652                                64.0                                74.0   
3768                                29.0                                89.0   
3686                                78.0                                87.0   
1037                                86.0                                96.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2059                               5.0                        70.500000  ...   
2652                              10.0                        66.500000  ...   
3768                              60.0                        68.130432  ...   
3686                               9.0                        84.000000  ...   
1037                              10.0                        87.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2059                 4.0                   1            32.0   
2652                 4.0                   1            32.0   
3768                 7.0                   0             2.0   
3686                 7.0                   0             2.0   
1037                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2059                 False                     False   
2652                 False                     False   
3768                 False                     False   
3686                 False                     False   
1037                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2059                      False                        False   
2652                      False                        False   
3768                      False                        False   
3686                      False                        False   
1037                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2059                       True                     False   
2652                       True                     False   
3768                      False                      True   
3686                      False                      True   
1037                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2059                    False  
2652                    False  
3768                    False  
3686                    False  
1037                    False  

[1344 rows x 146 columns]
2025-06-02 15:00:17,843:INFO:get_config() successfully completed......................................
2025-06-02 15:00:17,844:INFO:Initializing get_config()
2025-06-02 15:00:17,844:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, variable=y_test)
2025-06-02 15:00:17,846:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 15:00:17,846:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 15:00:17,865:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2059    0.014339
2652   -0.098120
3768   -1.861921
3686   -3.207308
1037   -0.156411
Name: target, Length: 1344, dtype: float32
2025-06-02 15:00:17,865:INFO:get_config() successfully completed......................................
2025-06-02 15:00:17,889:INFO:Initializing predict_model()
2025-06-02 15:00:17,890:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6D8C7AA10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6DBC5A950>)
2025-06-02 15:00:17,890:INFO:Checking exceptions
2025-06-02 15:00:17,890:INFO:Preloading libraries
2025-06-02 15:00:17,893:INFO:Set up data.
2025-06-02 15:00:17,969:INFO:Set up index.
2025-06-02 15:00:59,620:INFO:PyCaret RegressionExperiment
2025-06-02 15:00:59,620:INFO:Logging name: reg-default-name
2025-06-02 15:00:59,620:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 15:00:59,620:INFO:version 3.3.2
2025-06-02 15:00:59,620:INFO:Initializing setup()
2025-06-02 15:00:59,621:INFO:self.USI: b752
2025-06-02 15:00:59,621:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 15:00:59,621:INFO:Checking environment
2025-06-02 15:00:59,621:INFO:python_version: 3.10.16
2025-06-02 15:00:59,621:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 15:00:59,621:INFO:machine: AMD64
2025-06-02 15:00:59,621:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 15:00:59,626:INFO:Memory: svmem(total=6378008576, available=821551104, percent=87.1, used=5556457472, free=821551104)
2025-06-02 15:00:59,627:INFO:Physical Core: 4
2025-06-02 15:00:59,627:INFO:Logical Core: 8
2025-06-02 15:00:59,628:INFO:Checking libraries
2025-06-02 15:00:59,628:INFO:System:
2025-06-02 15:00:59,628:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 15:00:59,628:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 15:00:59,628:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 15:00:59,628:INFO:PyCaret required dependencies:
2025-06-02 15:00:59,628:INFO:                 pip: 25.1
2025-06-02 15:00:59,628:INFO:          setuptools: 78.1.1
2025-06-02 15:00:59,628:INFO:             pycaret: 3.3.2
2025-06-02 15:00:59,628:INFO:             IPython: 8.37.0
2025-06-02 15:00:59,629:INFO:          ipywidgets: 8.1.7
2025-06-02 15:00:59,629:INFO:                tqdm: 4.67.1
2025-06-02 15:00:59,629:INFO:               numpy: 1.26.4
2025-06-02 15:00:59,629:INFO:              pandas: 2.0.1
2025-06-02 15:00:59,629:INFO:              jinja2: 3.1.6
2025-06-02 15:00:59,629:INFO:               scipy: 1.10.1
2025-06-02 15:00:59,629:INFO:              joblib: 1.3.2
2025-06-02 15:00:59,629:INFO:             sklearn: 1.4.2
2025-06-02 15:00:59,629:INFO:                pyod: 2.0.5
2025-06-02 15:00:59,629:INFO:            imblearn: 0.13.0
2025-06-02 15:00:59,629:INFO:   category_encoders: 2.7.0
2025-06-02 15:00:59,629:INFO:            lightgbm: 4.6.0
2025-06-02 15:00:59,630:INFO:               numba: 0.61.0
2025-06-02 15:00:59,630:INFO:            requests: 2.32.3
2025-06-02 15:00:59,630:INFO:          matplotlib: 3.7.1
2025-06-02 15:00:59,630:INFO:          scikitplot: 0.3.7
2025-06-02 15:00:59,630:INFO:         yellowbrick: 1.5
2025-06-02 15:00:59,630:INFO:              plotly: 6.1.2
2025-06-02 15:00:59,630:INFO:    plotly-resampler: Not installed
2025-06-02 15:00:59,630:INFO:             kaleido: 0.2.1
2025-06-02 15:00:59,630:INFO:           schemdraw: 0.15
2025-06-02 15:00:59,630:INFO:         statsmodels: 0.14.4
2025-06-02 15:00:59,630:INFO:              sktime: 0.26.0
2025-06-02 15:00:59,630:INFO:               tbats: 1.1.3
2025-06-02 15:00:59,630:INFO:            pmdarima: 2.0.4
2025-06-02 15:00:59,631:INFO:              psutil: 7.0.0
2025-06-02 15:00:59,631:INFO:          markupsafe: 2.1.2
2025-06-02 15:00:59,631:INFO:             pickle5: Not installed
2025-06-02 15:00:59,631:INFO:         cloudpickle: 3.1.1
2025-06-02 15:00:59,631:INFO:         deprecation: 2.1.0
2025-06-02 15:00:59,631:INFO:              xxhash: 3.5.0
2025-06-02 15:00:59,631:INFO:           wurlitzer: Not installed
2025-06-02 15:00:59,631:INFO:PyCaret optional dependencies:
2025-06-02 15:00:59,631:INFO:                shap: 0.44.1
2025-06-02 15:00:59,631:INFO:           interpret: 0.6.9
2025-06-02 15:00:59,631:INFO:                umap: 0.5.7
2025-06-02 15:00:59,631:INFO:     ydata_profiling: 4.16.1
2025-06-02 15:00:59,631:INFO:  explainerdashboard: 0.4.8
2025-06-02 15:00:59,632:INFO:             autoviz: Not installed
2025-06-02 15:00:59,632:INFO:           fairlearn: 0.7.0
2025-06-02 15:00:59,632:INFO:          deepchecks: Not installed
2025-06-02 15:00:59,632:INFO:             xgboost: 3.0.2
2025-06-02 15:00:59,632:INFO:            catboost: 1.2.8
2025-06-02 15:00:59,632:INFO:              kmodes: 0.12.2
2025-06-02 15:00:59,632:INFO:             mlxtend: 0.23.4
2025-06-02 15:00:59,632:INFO:       statsforecast: 1.5.0
2025-06-02 15:00:59,632:INFO:        tune_sklearn: Not installed
2025-06-02 15:00:59,632:INFO:                 ray: Not installed
2025-06-02 15:00:59,632:INFO:            hyperopt: 0.2.7
2025-06-02 15:00:59,632:INFO:              optuna: 4.3.0
2025-06-02 15:00:59,632:INFO:               skopt: 0.10.2
2025-06-02 15:00:59,632:INFO:              mlflow: 2.22.0
2025-06-02 15:00:59,633:INFO:              gradio: 5.32.0
2025-06-02 15:00:59,633:INFO:             fastapi: 0.115.12
2025-06-02 15:00:59,633:INFO:             uvicorn: 0.34.3
2025-06-02 15:00:59,633:INFO:              m2cgen: 0.10.0
2025-06-02 15:00:59,633:INFO:           evidently: 0.4.40
2025-06-02 15:00:59,633:INFO:               fugue: 0.8.5
2025-06-02 15:00:59,633:INFO:           streamlit: Not installed
2025-06-02 15:00:59,633:INFO:             prophet: Not installed
2025-06-02 15:00:59,633:INFO:None
2025-06-02 15:00:59,633:INFO:Set up data.
2025-06-02 15:00:59,747:INFO:Set up folding strategy.
2025-06-02 15:00:59,747:INFO:Set up train/test split.
2025-06-02 15:00:59,839:INFO:Set up index.
2025-06-02 15:00:59,840:INFO:Assigning column types.
2025-06-02 15:00:59,906:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 15:00:59,907:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 15:00:59,917:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 15:00:59,928:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:01:00,103:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:01:00,197:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:01:00,200:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:01:00,206:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:01:00,208:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 15:01:00,220:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 15:01:00,228:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:01:00,420:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:01:00,507:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:01:00,508:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:01:00,512:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:01:00,513:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 15:01:00,520:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 15:01:00,527:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:01:00,675:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:01:00,757:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:01:00,758:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:01:00,766:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:01:00,776:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 15:01:00,784:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:01:00,933:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:01:01,011:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:01:01,012:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:01:01,016:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:01:01,017:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 15:01:01,032:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:01:01,161:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:01:01,235:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:01:01,236:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:01:01,244:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:01:01,263:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:01:01,400:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:01:01,483:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:01:01,484:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:01:01,488:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:01:01,489:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 15:01:01,651:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:01:01,722:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:01:01,723:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:01:01,727:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:01:01,874:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:01:01,955:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:01:01,955:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:01:01,960:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:01:01,961:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 15:01:02,101:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:01:02,184:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:01:02,188:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:01:02,329:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:01:02,400:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:01:02,405:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:01:02,406:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 15:01:02,630:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:01:02,635:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:01:02,859:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:01:02,863:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:01:02,866:INFO:Preparing preprocessing pipeline...
2025-06-02 15:01:02,866:INFO:Set up simple imputation.
2025-06-02 15:01:02,866:INFO:Set up removing multicollinearity.
2025-06-02 15:01:02,874:INFO:Set up column name cleaning.
2025-06-02 15:01:03,110:INFO:Finished creating preprocessing pipeline.
2025-06-02 15:01:03,122:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 15:01:03,122:INFO:Creating final display dataframe.
2025-06-02 15:01:03,530:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              b752
2025-06-02 15:01:03,763:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:01:03,767:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:01:03,991:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:01:03,996:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:01:03,997:INFO:setup() successfully completed in 4.39s...............
2025-06-02 15:01:04,017:INFO:Initializing compare_models()
2025-06-02 15:01:04,017:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 15:01:04,017:INFO:Checking exceptions
2025-06-02 15:01:04,039:INFO:Preparing display monitor
2025-06-02 15:01:04,097:INFO:Initializing Linear Regression
2025-06-02 15:01:04,098:INFO:Total runtime is 1.6689300537109375e-05 minutes
2025-06-02 15:01:04,109:INFO:SubProcess create_model() called ==================================
2025-06-02 15:01:04,110:INFO:Initializing create_model()
2025-06-02 15:01:04,111:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:01:04,111:INFO:Checking exceptions
2025-06-02 15:01:04,111:INFO:Importing libraries
2025-06-02 15:01:04,112:INFO:Copying training dataset
2025-06-02 15:01:04,196:INFO:Defining folds
2025-06-02 15:01:04,197:INFO:Declaring metric variables
2025-06-02 15:01:04,210:INFO:Importing untrained model
2025-06-02 15:01:04,222:INFO:Linear Regression Imported successfully
2025-06-02 15:01:04,247:INFO:Starting cross validation
2025-06-02 15:01:04,253:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:01:19,123:INFO:Calculating mean and std
2025-06-02 15:01:19,244:INFO:Creating metrics dataframe
2025-06-02 15:01:19,274:INFO:Uploading results into container
2025-06-02 15:01:19,279:INFO:Uploading model into container now
2025-06-02 15:01:19,286:INFO:_master_model_container: 1
2025-06-02 15:01:19,286:INFO:_display_container: 2
2025-06-02 15:01:19,289:INFO:LinearRegression(n_jobs=-1)
2025-06-02 15:01:19,289:INFO:create_model() successfully completed......................................
2025-06-02 15:01:25,189:INFO:SubProcess create_model() end ==================================
2025-06-02 15:01:25,190:INFO:Creating metrics dataframe
2025-06-02 15:01:25,223:INFO:Initializing Lasso Regression
2025-06-02 15:01:25,224:INFO:Total runtime is 0.3521134972572327 minutes
2025-06-02 15:01:25,239:INFO:SubProcess create_model() called ==================================
2025-06-02 15:01:25,240:INFO:Initializing create_model()
2025-06-02 15:01:25,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:01:25,240:INFO:Checking exceptions
2025-06-02 15:01:25,241:INFO:Importing libraries
2025-06-02 15:01:25,242:INFO:Copying training dataset
2025-06-02 15:01:25,336:INFO:Defining folds
2025-06-02 15:01:25,337:INFO:Declaring metric variables
2025-06-02 15:01:25,347:INFO:Importing untrained model
2025-06-02 15:01:25,357:INFO:Lasso Regression Imported successfully
2025-06-02 15:01:25,374:INFO:Starting cross validation
2025-06-02 15:01:25,379:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:01:36,126:INFO:Calculating mean and std
2025-06-02 15:01:36,134:INFO:Creating metrics dataframe
2025-06-02 15:01:36,147:INFO:Uploading results into container
2025-06-02 15:01:36,150:INFO:Uploading model into container now
2025-06-02 15:01:36,152:INFO:_master_model_container: 2
2025-06-02 15:01:36,152:INFO:_display_container: 2
2025-06-02 15:01:36,154:INFO:Lasso(random_state=123)
2025-06-02 15:01:36,154:INFO:create_model() successfully completed......................................
2025-06-02 15:01:37,505:INFO:SubProcess create_model() end ==================================
2025-06-02 15:01:37,505:INFO:Creating metrics dataframe
2025-06-02 15:01:37,526:INFO:Initializing Ridge Regression
2025-06-02 15:01:37,526:INFO:Total runtime is 0.55714404185613 minutes
2025-06-02 15:01:37,537:INFO:SubProcess create_model() called ==================================
2025-06-02 15:01:37,539:INFO:Initializing create_model()
2025-06-02 15:01:37,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:01:37,539:INFO:Checking exceptions
2025-06-02 15:01:37,539:INFO:Importing libraries
2025-06-02 15:01:37,540:INFO:Copying training dataset
2025-06-02 15:01:37,617:INFO:Defining folds
2025-06-02 15:01:37,617:INFO:Declaring metric variables
2025-06-02 15:01:37,628:INFO:Importing untrained model
2025-06-02 15:01:37,638:INFO:Ridge Regression Imported successfully
2025-06-02 15:01:37,659:INFO:Starting cross validation
2025-06-02 15:01:37,662:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:01:38,680:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.75561e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 15:01:38,745:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31073e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 15:01:38,796:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.24347e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 15:01:38,830:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.08754e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 15:01:38,959:INFO:Calculating mean and std
2025-06-02 15:01:38,962:INFO:Creating metrics dataframe
2025-06-02 15:01:38,967:INFO:Uploading results into container
2025-06-02 15:01:38,969:INFO:Uploading model into container now
2025-06-02 15:01:38,970:INFO:_master_model_container: 3
2025-06-02 15:01:38,971:INFO:_display_container: 2
2025-06-02 15:01:38,972:INFO:Ridge(random_state=123)
2025-06-02 15:01:38,972:INFO:create_model() successfully completed......................................
2025-06-02 15:01:40,478:INFO:SubProcess create_model() end ==================================
2025-06-02 15:01:40,478:INFO:Creating metrics dataframe
2025-06-02 15:01:40,494:INFO:Initializing Elastic Net
2025-06-02 15:01:40,494:INFO:Total runtime is 0.6066181381543477 minutes
2025-06-02 15:01:40,505:INFO:SubProcess create_model() called ==================================
2025-06-02 15:01:40,505:INFO:Initializing create_model()
2025-06-02 15:01:40,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:01:40,507:INFO:Checking exceptions
2025-06-02 15:01:40,507:INFO:Importing libraries
2025-06-02 15:01:40,508:INFO:Copying training dataset
2025-06-02 15:01:40,589:INFO:Defining folds
2025-06-02 15:01:40,590:INFO:Declaring metric variables
2025-06-02 15:01:40,602:INFO:Importing untrained model
2025-06-02 15:01:40,615:INFO:Elastic Net Imported successfully
2025-06-02 15:01:40,639:INFO:Starting cross validation
2025-06-02 15:01:40,644:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:01:41,462:INFO:Calculating mean and std
2025-06-02 15:01:41,464:INFO:Creating metrics dataframe
2025-06-02 15:01:41,468:INFO:Uploading results into container
2025-06-02 15:01:41,469:INFO:Uploading model into container now
2025-06-02 15:01:41,470:INFO:_master_model_container: 4
2025-06-02 15:01:41,471:INFO:_display_container: 2
2025-06-02 15:01:41,472:INFO:ElasticNet(random_state=123)
2025-06-02 15:01:41,472:INFO:create_model() successfully completed......................................
2025-06-02 15:01:42,732:INFO:SubProcess create_model() end ==================================
2025-06-02 15:01:42,732:INFO:Creating metrics dataframe
2025-06-02 15:01:42,748:INFO:Initializing Least Angle Regression
2025-06-02 15:01:42,749:INFO:Total runtime is 0.6441961208979289 minutes
2025-06-02 15:01:42,758:INFO:SubProcess create_model() called ==================================
2025-06-02 15:01:42,759:INFO:Initializing create_model()
2025-06-02 15:01:42,760:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:01:42,761:INFO:Checking exceptions
2025-06-02 15:01:42,761:INFO:Importing libraries
2025-06-02 15:01:42,762:INFO:Copying training dataset
2025-06-02 15:01:42,850:INFO:Defining folds
2025-06-02 15:01:42,851:INFO:Declaring metric variables
2025-06-02 15:01:42,865:INFO:Importing untrained model
2025-06-02 15:01:42,884:INFO:Least Angle Regression Imported successfully
2025-06-02 15:01:42,908:INFO:Starting cross validation
2025-06-02 15:01:42,913:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:01:43,796:INFO:Calculating mean and std
2025-06-02 15:01:43,799:INFO:Creating metrics dataframe
2025-06-02 15:01:43,804:INFO:Uploading results into container
2025-06-02 15:01:43,805:INFO:Uploading model into container now
2025-06-02 15:01:43,806:INFO:_master_model_container: 5
2025-06-02 15:01:43,807:INFO:_display_container: 2
2025-06-02 15:01:43,809:INFO:Lars(random_state=123)
2025-06-02 15:01:43,809:INFO:create_model() successfully completed......................................
2025-06-02 15:01:45,135:INFO:SubProcess create_model() end ==================================
2025-06-02 15:01:45,135:INFO:Creating metrics dataframe
2025-06-02 15:01:45,155:INFO:Initializing Lasso Least Angle Regression
2025-06-02 15:01:45,155:INFO:Total runtime is 0.6843006094296773 minutes
2025-06-02 15:01:45,163:INFO:SubProcess create_model() called ==================================
2025-06-02 15:01:45,164:INFO:Initializing create_model()
2025-06-02 15:01:45,164:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:01:45,165:INFO:Checking exceptions
2025-06-02 15:01:45,165:INFO:Importing libraries
2025-06-02 15:01:45,166:INFO:Copying training dataset
2025-06-02 15:01:45,240:INFO:Defining folds
2025-06-02 15:01:45,241:INFO:Declaring metric variables
2025-06-02 15:01:45,255:INFO:Importing untrained model
2025-06-02 15:01:45,268:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 15:01:45,294:INFO:Starting cross validation
2025-06-02 15:01:45,299:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:01:46,297:INFO:Calculating mean and std
2025-06-02 15:01:46,300:INFO:Creating metrics dataframe
2025-06-02 15:01:46,305:INFO:Uploading results into container
2025-06-02 15:01:46,307:INFO:Uploading model into container now
2025-06-02 15:01:46,308:INFO:_master_model_container: 6
2025-06-02 15:01:46,308:INFO:_display_container: 2
2025-06-02 15:01:46,309:INFO:LassoLars(random_state=123)
2025-06-02 15:01:46,310:INFO:create_model() successfully completed......................................
2025-06-02 15:01:47,618:INFO:SubProcess create_model() end ==================================
2025-06-02 15:01:47,619:INFO:Creating metrics dataframe
2025-06-02 15:01:47,636:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 15:01:47,636:INFO:Total runtime is 0.7256400386492411 minutes
2025-06-02 15:01:47,645:INFO:SubProcess create_model() called ==================================
2025-06-02 15:01:47,646:INFO:Initializing create_model()
2025-06-02 15:01:47,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:01:47,646:INFO:Checking exceptions
2025-06-02 15:01:47,647:INFO:Importing libraries
2025-06-02 15:01:47,647:INFO:Copying training dataset
2025-06-02 15:01:47,719:INFO:Defining folds
2025-06-02 15:01:47,719:INFO:Declaring metric variables
2025-06-02 15:01:47,733:INFO:Importing untrained model
2025-06-02 15:01:47,746:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 15:01:47,772:INFO:Starting cross validation
2025-06-02 15:01:47,777:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:01:48,569:INFO:Calculating mean and std
2025-06-02 15:01:48,573:INFO:Creating metrics dataframe
2025-06-02 15:01:48,577:INFO:Uploading results into container
2025-06-02 15:01:48,578:INFO:Uploading model into container now
2025-06-02 15:01:48,579:INFO:_master_model_container: 7
2025-06-02 15:01:48,579:INFO:_display_container: 2
2025-06-02 15:01:48,580:INFO:OrthogonalMatchingPursuit()
2025-06-02 15:01:48,581:INFO:create_model() successfully completed......................................
2025-06-02 15:01:49,818:INFO:SubProcess create_model() end ==================================
2025-06-02 15:01:49,818:INFO:Creating metrics dataframe
2025-06-02 15:01:49,841:INFO:Initializing Bayesian Ridge
2025-06-02 15:01:49,841:INFO:Total runtime is 0.762401533126831 minutes
2025-06-02 15:01:49,851:INFO:SubProcess create_model() called ==================================
2025-06-02 15:01:49,851:INFO:Initializing create_model()
2025-06-02 15:01:49,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:01:49,852:INFO:Checking exceptions
2025-06-02 15:01:49,852:INFO:Importing libraries
2025-06-02 15:01:49,853:INFO:Copying training dataset
2025-06-02 15:01:49,918:INFO:Defining folds
2025-06-02 15:01:49,918:INFO:Declaring metric variables
2025-06-02 15:01:49,932:INFO:Importing untrained model
2025-06-02 15:01:49,945:INFO:Bayesian Ridge Imported successfully
2025-06-02 15:01:49,973:INFO:Starting cross validation
2025-06-02 15:01:49,977:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:01:50,772:INFO:Calculating mean and std
2025-06-02 15:01:50,775:INFO:Creating metrics dataframe
2025-06-02 15:01:50,778:INFO:Uploading results into container
2025-06-02 15:01:50,779:INFO:Uploading model into container now
2025-06-02 15:01:50,780:INFO:_master_model_container: 8
2025-06-02 15:01:50,780:INFO:_display_container: 2
2025-06-02 15:01:50,781:INFO:BayesianRidge()
2025-06-02 15:01:50,781:INFO:create_model() successfully completed......................................
2025-06-02 15:01:52,028:INFO:SubProcess create_model() end ==================================
2025-06-02 15:01:52,028:INFO:Creating metrics dataframe
2025-06-02 15:01:52,043:INFO:Initializing Passive Aggressive Regressor
2025-06-02 15:01:52,043:INFO:Total runtime is 0.7990966320037841 minutes
2025-06-02 15:01:52,053:INFO:SubProcess create_model() called ==================================
2025-06-02 15:01:52,053:INFO:Initializing create_model()
2025-06-02 15:01:52,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:01:52,054:INFO:Checking exceptions
2025-06-02 15:01:52,055:INFO:Importing libraries
2025-06-02 15:01:52,055:INFO:Copying training dataset
2025-06-02 15:01:52,125:INFO:Defining folds
2025-06-02 15:01:52,125:INFO:Declaring metric variables
2025-06-02 15:01:52,137:INFO:Importing untrained model
2025-06-02 15:01:52,149:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 15:01:52,179:INFO:Starting cross validation
2025-06-02 15:01:52,184:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:01:53,244:INFO:Calculating mean and std
2025-06-02 15:01:53,247:INFO:Creating metrics dataframe
2025-06-02 15:01:53,252:INFO:Uploading results into container
2025-06-02 15:01:53,254:INFO:Uploading model into container now
2025-06-02 15:01:53,255:INFO:_master_model_container: 9
2025-06-02 15:01:53,255:INFO:_display_container: 2
2025-06-02 15:01:53,256:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 15:01:53,256:INFO:create_model() successfully completed......................................
2025-06-02 15:01:54,536:INFO:SubProcess create_model() end ==================================
2025-06-02 15:01:54,537:INFO:Creating metrics dataframe
2025-06-02 15:01:54,558:INFO:Initializing Huber Regressor
2025-06-02 15:01:54,559:INFO:Total runtime is 0.841035791238149 minutes
2025-06-02 15:01:54,568:INFO:SubProcess create_model() called ==================================
2025-06-02 15:01:54,569:INFO:Initializing create_model()
2025-06-02 15:01:54,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:01:54,569:INFO:Checking exceptions
2025-06-02 15:01:54,570:INFO:Importing libraries
2025-06-02 15:01:54,570:INFO:Copying training dataset
2025-06-02 15:01:54,637:INFO:Defining folds
2025-06-02 15:01:54,637:INFO:Declaring metric variables
2025-06-02 15:01:54,648:INFO:Importing untrained model
2025-06-02 15:01:54,662:INFO:Huber Regressor Imported successfully
2025-06-02 15:01:54,687:INFO:Starting cross validation
2025-06-02 15:01:54,692:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:01:56,278:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:01:56,299:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:01:56,336:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:01:56,368:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:01:56,415:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:01:56,456:INFO:Calculating mean and std
2025-06-02 15:01:56,459:INFO:Creating metrics dataframe
2025-06-02 15:01:56,463:INFO:Uploading results into container
2025-06-02 15:01:56,464:INFO:Uploading model into container now
2025-06-02 15:01:56,465:INFO:_master_model_container: 10
2025-06-02 15:01:56,466:INFO:_display_container: 2
2025-06-02 15:01:56,467:INFO:HuberRegressor()
2025-06-02 15:01:56,467:INFO:create_model() successfully completed......................................
2025-06-02 15:01:57,694:INFO:SubProcess create_model() end ==================================
2025-06-02 15:01:57,695:INFO:Creating metrics dataframe
2025-06-02 15:01:57,719:INFO:Initializing K Neighbors Regressor
2025-06-02 15:01:57,719:INFO:Total runtime is 0.8937027454376221 minutes
2025-06-02 15:01:57,729:INFO:SubProcess create_model() called ==================================
2025-06-02 15:01:57,730:INFO:Initializing create_model()
2025-06-02 15:01:57,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:01:57,731:INFO:Checking exceptions
2025-06-02 15:01:57,731:INFO:Importing libraries
2025-06-02 15:01:57,732:INFO:Copying training dataset
2025-06-02 15:01:57,805:INFO:Defining folds
2025-06-02 15:01:57,806:INFO:Declaring metric variables
2025-06-02 15:01:57,818:INFO:Importing untrained model
2025-06-02 15:01:57,828:INFO:K Neighbors Regressor Imported successfully
2025-06-02 15:01:57,853:INFO:Starting cross validation
2025-06-02 15:01:57,857:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:01:58,725:INFO:Calculating mean and std
2025-06-02 15:01:58,728:INFO:Creating metrics dataframe
2025-06-02 15:01:58,731:INFO:Uploading results into container
2025-06-02 15:01:58,732:INFO:Uploading model into container now
2025-06-02 15:01:58,733:INFO:_master_model_container: 11
2025-06-02 15:01:58,734:INFO:_display_container: 2
2025-06-02 15:01:58,734:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 15:01:58,735:INFO:create_model() successfully completed......................................
2025-06-02 15:01:59,993:INFO:SubProcess create_model() end ==================================
2025-06-02 15:01:59,993:INFO:Creating metrics dataframe
2025-06-02 15:02:00,011:INFO:Initializing Decision Tree Regressor
2025-06-02 15:02:00,012:INFO:Total runtime is 0.9319138050079345 minutes
2025-06-02 15:02:00,028:INFO:SubProcess create_model() called ==================================
2025-06-02 15:02:00,029:INFO:Initializing create_model()
2025-06-02 15:02:00,029:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:02:00,030:INFO:Checking exceptions
2025-06-02 15:02:00,030:INFO:Importing libraries
2025-06-02 15:02:00,031:INFO:Copying training dataset
2025-06-02 15:02:00,114:INFO:Defining folds
2025-06-02 15:02:00,114:INFO:Declaring metric variables
2025-06-02 15:02:00,134:INFO:Importing untrained model
2025-06-02 15:02:00,156:INFO:Decision Tree Regressor Imported successfully
2025-06-02 15:02:00,211:INFO:Starting cross validation
2025-06-02 15:02:00,216:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:02:01,881:INFO:Calculating mean and std
2025-06-02 15:02:01,891:INFO:Creating metrics dataframe
2025-06-02 15:02:01,897:INFO:Uploading results into container
2025-06-02 15:02:01,898:INFO:Uploading model into container now
2025-06-02 15:02:01,901:INFO:_master_model_container: 12
2025-06-02 15:02:01,901:INFO:_display_container: 2
2025-06-02 15:02:01,903:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 15:02:01,903:INFO:create_model() successfully completed......................................
2025-06-02 15:02:03,453:INFO:SubProcess create_model() end ==================================
2025-06-02 15:02:03,454:INFO:Creating metrics dataframe
2025-06-02 15:02:03,488:INFO:Initializing Random Forest Regressor
2025-06-02 15:02:03,488:INFO:Total runtime is 0.9898532708485921 minutes
2025-06-02 15:02:03,504:INFO:SubProcess create_model() called ==================================
2025-06-02 15:02:03,504:INFO:Initializing create_model()
2025-06-02 15:02:03,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:02:03,505:INFO:Checking exceptions
2025-06-02 15:02:03,505:INFO:Importing libraries
2025-06-02 15:02:03,505:INFO:Copying training dataset
2025-06-02 15:02:03,589:INFO:Defining folds
2025-06-02 15:02:03,589:INFO:Declaring metric variables
2025-06-02 15:02:03,603:INFO:Importing untrained model
2025-06-02 15:02:03,618:INFO:Random Forest Regressor Imported successfully
2025-06-02 15:02:03,643:INFO:Starting cross validation
2025-06-02 15:02:03,647:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:02:12,362:INFO:Calculating mean and std
2025-06-02 15:02:12,365:INFO:Creating metrics dataframe
2025-06-02 15:02:12,368:INFO:Uploading results into container
2025-06-02 15:02:12,369:INFO:Uploading model into container now
2025-06-02 15:02:12,370:INFO:_master_model_container: 13
2025-06-02 15:02:12,370:INFO:_display_container: 2
2025-06-02 15:02:12,371:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:02:12,372:INFO:create_model() successfully completed......................................
2025-06-02 15:02:13,628:INFO:SubProcess create_model() end ==================================
2025-06-02 15:02:13,629:INFO:Creating metrics dataframe
2025-06-02 15:02:13,648:INFO:Initializing Extra Trees Regressor
2025-06-02 15:02:13,649:INFO:Total runtime is 1.1591933886210124 minutes
2025-06-02 15:02:13,658:INFO:SubProcess create_model() called ==================================
2025-06-02 15:02:13,659:INFO:Initializing create_model()
2025-06-02 15:02:13,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:02:13,659:INFO:Checking exceptions
2025-06-02 15:02:13,659:INFO:Importing libraries
2025-06-02 15:02:13,659:INFO:Copying training dataset
2025-06-02 15:02:13,737:INFO:Defining folds
2025-06-02 15:02:13,738:INFO:Declaring metric variables
2025-06-02 15:02:13,750:INFO:Importing untrained model
2025-06-02 15:02:13,761:INFO:Extra Trees Regressor Imported successfully
2025-06-02 15:02:13,790:INFO:Starting cross validation
2025-06-02 15:02:13,796:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:02:19,747:INFO:Calculating mean and std
2025-06-02 15:02:19,751:INFO:Creating metrics dataframe
2025-06-02 15:02:19,755:INFO:Uploading results into container
2025-06-02 15:02:19,756:INFO:Uploading model into container now
2025-06-02 15:02:19,757:INFO:_master_model_container: 14
2025-06-02 15:02:19,758:INFO:_display_container: 2
2025-06-02 15:02:19,759:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:02:19,759:INFO:create_model() successfully completed......................................
2025-06-02 15:02:21,076:INFO:SubProcess create_model() end ==================================
2025-06-02 15:02:21,077:INFO:Creating metrics dataframe
2025-06-02 15:02:21,103:INFO:Initializing AdaBoost Regressor
2025-06-02 15:02:21,103:INFO:Total runtime is 1.2834339221318563 minutes
2025-06-02 15:02:21,113:INFO:SubProcess create_model() called ==================================
2025-06-02 15:02:21,114:INFO:Initializing create_model()
2025-06-02 15:02:21,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:02:21,114:INFO:Checking exceptions
2025-06-02 15:02:21,114:INFO:Importing libraries
2025-06-02 15:02:21,115:INFO:Copying training dataset
2025-06-02 15:02:21,185:INFO:Defining folds
2025-06-02 15:02:21,185:INFO:Declaring metric variables
2025-06-02 15:02:21,198:INFO:Importing untrained model
2025-06-02 15:02:21,212:INFO:AdaBoost Regressor Imported successfully
2025-06-02 15:02:21,237:INFO:Starting cross validation
2025-06-02 15:02:21,242:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:02:23,613:INFO:Calculating mean and std
2025-06-02 15:02:23,615:INFO:Creating metrics dataframe
2025-06-02 15:02:23,618:INFO:Uploading results into container
2025-06-02 15:02:23,619:INFO:Uploading model into container now
2025-06-02 15:02:23,620:INFO:_master_model_container: 15
2025-06-02 15:02:23,620:INFO:_display_container: 2
2025-06-02 15:02:23,621:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 15:02:23,621:INFO:create_model() successfully completed......................................
2025-06-02 15:02:24,877:INFO:SubProcess create_model() end ==================================
2025-06-02 15:02:24,878:INFO:Creating metrics dataframe
2025-06-02 15:02:24,908:INFO:Initializing Gradient Boosting Regressor
2025-06-02 15:02:24,908:INFO:Total runtime is 1.3468384544054668 minutes
2025-06-02 15:02:24,919:INFO:SubProcess create_model() called ==================================
2025-06-02 15:02:24,919:INFO:Initializing create_model()
2025-06-02 15:02:24,919:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:02:24,920:INFO:Checking exceptions
2025-06-02 15:02:24,920:INFO:Importing libraries
2025-06-02 15:02:24,920:INFO:Copying training dataset
2025-06-02 15:02:24,980:INFO:Defining folds
2025-06-02 15:02:24,981:INFO:Declaring metric variables
2025-06-02 15:02:24,994:INFO:Importing untrained model
2025-06-02 15:02:25,009:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 15:02:25,037:INFO:Starting cross validation
2025-06-02 15:02:25,043:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:02:28,510:INFO:Calculating mean and std
2025-06-02 15:02:28,513:INFO:Creating metrics dataframe
2025-06-02 15:02:28,517:INFO:Uploading results into container
2025-06-02 15:02:28,518:INFO:Uploading model into container now
2025-06-02 15:02:28,519:INFO:_master_model_container: 16
2025-06-02 15:02:28,519:INFO:_display_container: 2
2025-06-02 15:02:28,520:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 15:02:28,521:INFO:create_model() successfully completed......................................
2025-06-02 15:02:29,780:INFO:SubProcess create_model() end ==================================
2025-06-02 15:02:29,780:INFO:Creating metrics dataframe
2025-06-02 15:02:29,804:INFO:Initializing Extreme Gradient Boosting
2025-06-02 15:02:29,805:INFO:Total runtime is 1.428466804822286 minutes
2025-06-02 15:02:29,814:INFO:SubProcess create_model() called ==================================
2025-06-02 15:02:29,815:INFO:Initializing create_model()
2025-06-02 15:02:29,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:02:29,816:INFO:Checking exceptions
2025-06-02 15:02:29,816:INFO:Importing libraries
2025-06-02 15:02:29,816:INFO:Copying training dataset
2025-06-02 15:02:29,881:INFO:Defining folds
2025-06-02 15:02:29,882:INFO:Declaring metric variables
2025-06-02 15:02:29,893:INFO:Importing untrained model
2025-06-02 15:02:29,905:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 15:02:29,931:INFO:Starting cross validation
2025-06-02 15:02:29,935:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:02:32,293:INFO:Calculating mean and std
2025-06-02 15:02:32,295:INFO:Creating metrics dataframe
2025-06-02 15:02:32,298:INFO:Uploading results into container
2025-06-02 15:02:32,299:INFO:Uploading model into container now
2025-06-02 15:02:32,300:INFO:_master_model_container: 17
2025-06-02 15:02:32,300:INFO:_display_container: 2
2025-06-02 15:02:32,303:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 15:02:32,303:INFO:create_model() successfully completed......................................
2025-06-02 15:02:33,571:INFO:SubProcess create_model() end ==================================
2025-06-02 15:02:33,571:INFO:Creating metrics dataframe
2025-06-02 15:02:33,594:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 15:02:33,594:INFO:Total runtime is 1.4916110197703043 minutes
2025-06-02 15:02:33,604:INFO:SubProcess create_model() called ==================================
2025-06-02 15:02:33,604:INFO:Initializing create_model()
2025-06-02 15:02:33,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:02:33,605:INFO:Checking exceptions
2025-06-02 15:02:33,605:INFO:Importing libraries
2025-06-02 15:02:33,605:INFO:Copying training dataset
2025-06-02 15:02:33,674:INFO:Defining folds
2025-06-02 15:02:33,674:INFO:Declaring metric variables
2025-06-02 15:02:33,687:INFO:Importing untrained model
2025-06-02 15:02:33,703:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 15:02:33,733:INFO:Starting cross validation
2025-06-02 15:02:33,739:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:02:35,639:INFO:Calculating mean and std
2025-06-02 15:02:35,641:INFO:Creating metrics dataframe
2025-06-02 15:02:35,646:INFO:Uploading results into container
2025-06-02 15:02:35,647:INFO:Uploading model into container now
2025-06-02 15:02:35,649:INFO:_master_model_container: 18
2025-06-02 15:02:35,649:INFO:_display_container: 2
2025-06-02 15:02:35,650:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:02:35,651:INFO:create_model() successfully completed......................................
2025-06-02 15:02:36,926:INFO:SubProcess create_model() end ==================================
2025-06-02 15:02:36,926:INFO:Creating metrics dataframe
2025-06-02 15:02:36,952:INFO:Initializing CatBoost Regressor
2025-06-02 15:02:36,952:INFO:Total runtime is 1.54757452805837 minutes
2025-06-02 15:02:36,961:INFO:SubProcess create_model() called ==================================
2025-06-02 15:02:36,961:INFO:Initializing create_model()
2025-06-02 15:02:36,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:02:36,962:INFO:Checking exceptions
2025-06-02 15:02:36,962:INFO:Importing libraries
2025-06-02 15:02:36,962:INFO:Copying training dataset
2025-06-02 15:02:37,028:INFO:Defining folds
2025-06-02 15:02:37,028:INFO:Declaring metric variables
2025-06-02 15:02:37,041:INFO:Importing untrained model
2025-06-02 15:02:37,063:INFO:CatBoost Regressor Imported successfully
2025-06-02 15:02:37,092:INFO:Starting cross validation
2025-06-02 15:02:37,096:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:03:04,357:INFO:Calculating mean and std
2025-06-02 15:03:04,361:INFO:Creating metrics dataframe
2025-06-02 15:03:04,369:INFO:Uploading results into container
2025-06-02 15:03:04,370:INFO:Uploading model into container now
2025-06-02 15:03:04,372:INFO:_master_model_container: 19
2025-06-02 15:03:04,372:INFO:_display_container: 2
2025-06-02 15:03:04,372:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6DC179510>
2025-06-02 15:03:04,373:INFO:create_model() successfully completed......................................
2025-06-02 15:03:05,788:INFO:SubProcess create_model() end ==================================
2025-06-02 15:03:05,788:INFO:Creating metrics dataframe
2025-06-02 15:03:05,810:INFO:Initializing Dummy Regressor
2025-06-02 15:03:05,810:INFO:Total runtime is 2.0285456657409666 minutes
2025-06-02 15:03:05,820:INFO:SubProcess create_model() called ==================================
2025-06-02 15:03:05,821:INFO:Initializing create_model()
2025-06-02 15:03:05,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BC4E6140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:03:05,821:INFO:Checking exceptions
2025-06-02 15:03:05,821:INFO:Importing libraries
2025-06-02 15:03:05,821:INFO:Copying training dataset
2025-06-02 15:03:05,891:INFO:Defining folds
2025-06-02 15:03:05,891:INFO:Declaring metric variables
2025-06-02 15:03:05,905:INFO:Importing untrained model
2025-06-02 15:03:05,918:INFO:Dummy Regressor Imported successfully
2025-06-02 15:03:05,940:INFO:Starting cross validation
2025-06-02 15:03:05,944:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:03:06,775:INFO:Calculating mean and std
2025-06-02 15:03:06,778:INFO:Creating metrics dataframe
2025-06-02 15:03:06,783:INFO:Uploading results into container
2025-06-02 15:03:06,785:INFO:Uploading model into container now
2025-06-02 15:03:06,786:INFO:_master_model_container: 20
2025-06-02 15:03:06,786:INFO:_display_container: 2
2025-06-02 15:03:06,786:INFO:DummyRegressor()
2025-06-02 15:03:06,787:INFO:create_model() successfully completed......................................
2025-06-02 15:03:08,079:INFO:SubProcess create_model() end ==================================
2025-06-02 15:03:08,080:INFO:Creating metrics dataframe
2025-06-02 15:03:08,130:INFO:Initializing create_model()
2025-06-02 15:03:08,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:03:08,131:INFO:Checking exceptions
2025-06-02 15:03:08,144:INFO:Importing libraries
2025-06-02 15:03:08,144:INFO:Copying training dataset
2025-06-02 15:03:08,213:INFO:Defining folds
2025-06-02 15:03:08,213:INFO:Declaring metric variables
2025-06-02 15:03:08,214:INFO:Importing untrained model
2025-06-02 15:03:08,214:INFO:Declaring custom model
2025-06-02 15:03:08,216:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 15:03:08,219:INFO:Cross validation set to False
2025-06-02 15:03:08,219:INFO:Fitting Model
2025-06-02 15:03:08,867:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 15:03:08,880:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007127 seconds.
2025-06-02 15:03:08,880:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 15:03:08,881:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 15:03:08,887:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 15:03:08,888:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 15:03:09,070:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:03:09,070:INFO:create_model() successfully completed......................................
2025-06-02 15:03:10,390:INFO:_master_model_container: 20
2025-06-02 15:03:10,390:INFO:_display_container: 2
2025-06-02 15:03:10,391:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:03:10,392:INFO:compare_models() successfully completed......................................
2025-06-02 15:03:10,403:INFO:Initializing tune_model()
2025-06-02 15:03:10,403:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>)
2025-06-02 15:03:10,403:INFO:Checking exceptions
2025-06-02 15:03:10,403:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 15:03:10,467:INFO:Copying training dataset
2025-06-02 15:03:10,531:INFO:Checking base model
2025-06-02 15:03:10,532:INFO:Base model : Light Gradient Boosting Machine
2025-06-02 15:03:10,545:INFO:Declaring metric variables
2025-06-02 15:03:10,562:INFO:Defining Hyperparameters
2025-06-02 15:03:12,216:INFO:Tuning with n_jobs=-1
2025-06-02 15:03:12,231:INFO:Initializing skopt.BayesSearchCV
2025-06-02 15:03:29,576:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.8608120752388259), ('actual_estimator__bagging_freq', 1), ('actual_estimator__feature_fraction', 0.4284489606984907), ('actual_estimator__learning_rate', 0.016133245419918712), ('actual_estimator__min_child_samples', 95), ('actual_estimator__min_split_gain', 0.8209314243567916), ('actual_estimator__n_estimators', 239), ('actual_estimator__num_leaves', 183), ('actual_estimator__reg_alpha', 8.662569304197528e-07), ('actual_estimator__reg_lambda', 5.001062744294253e-06)])
2025-06-02 15:03:29,577:INFO:Hyperparameter search completed
2025-06-02 15:03:29,578:INFO:SubProcess create_model() called ==================================
2025-06-02 15:03:29,580:INFO:Initializing create_model()
2025-06-02 15:03:29,580:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB26CE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.8608120752388259, 'bagging_freq': 1, 'feature_fraction': 0.4284489606984907, 'learning_rate': 0.016133245419918712, 'min_child_samples': 95, 'min_split_gain': 0.8209314243567916, 'n_estimators': 239, 'num_leaves': 183, 'reg_alpha': 8.662569304197528e-07, 'reg_lambda': 5.001062744294253e-06})
2025-06-02 15:03:29,581:INFO:Checking exceptions
2025-06-02 15:03:29,581:INFO:Importing libraries
2025-06-02 15:03:29,582:INFO:Copying training dataset
2025-06-02 15:03:29,664:INFO:Defining folds
2025-06-02 15:03:29,664:INFO:Declaring metric variables
2025-06-02 15:03:29,672:INFO:Importing untrained model
2025-06-02 15:03:29,673:INFO:Declaring custom model
2025-06-02 15:03:29,687:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 15:03:29,716:INFO:Starting cross validation
2025-06-02 15:03:29,720:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:03:31,462:INFO:Calculating mean and std
2025-06-02 15:03:31,463:INFO:Creating metrics dataframe
2025-06-02 15:03:31,477:INFO:Finalizing model
2025-06-02 15:03:31,850:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 15:03:31,851:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 15:03:31,851:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 15:03:31,872:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 15:03:31,873:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 15:03:31,873:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 15:03:31,873:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 15:03:31,880:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004038 seconds.
2025-06-02 15:03:31,880:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 15:03:31,881:INFO:[LightGBM] [Info] Total Bins 6220
2025-06-02 15:03:31,899:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 94
2025-06-02 15:03:31,900:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 15:03:31,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:31,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 15:03:32,155:INFO:Uploading results into container
2025-06-02 15:03:32,158:INFO:Uploading model into container now
2025-06-02 15:03:32,158:INFO:_master_model_container: 21
2025-06-02 15:03:32,159:INFO:_display_container: 3
2025-06-02 15:03:32,162:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06)
2025-06-02 15:03:32,162:INFO:create_model() successfully completed......................................
2025-06-02 15:03:33,420:INFO:SubProcess create_model() end ==================================
2025-06-02 15:03:33,422:INFO:choose_better activated
2025-06-02 15:03:33,432:INFO:SubProcess create_model() called ==================================
2025-06-02 15:03:33,433:INFO:Initializing create_model()
2025-06-02 15:03:33,434:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:03:33,434:INFO:Checking exceptions
2025-06-02 15:03:33,438:INFO:Importing libraries
2025-06-02 15:03:33,438:INFO:Copying training dataset
2025-06-02 15:03:33,496:INFO:Defining folds
2025-06-02 15:03:33,496:INFO:Declaring metric variables
2025-06-02 15:03:33,496:INFO:Importing untrained model
2025-06-02 15:03:33,496:INFO:Declaring custom model
2025-06-02 15:03:33,499:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 15:03:33,500:INFO:Starting cross validation
2025-06-02 15:03:33,503:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:03:35,044:INFO:Calculating mean and std
2025-06-02 15:03:35,045:INFO:Creating metrics dataframe
2025-06-02 15:03:35,048:INFO:Finalizing model
2025-06-02 15:03:35,436:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 15:03:35,441:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003273 seconds.
2025-06-02 15:03:35,442:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 15:03:35,442:INFO:[LightGBM] [Info] Total Bins 6231
2025-06-02 15:03:35,443:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 15:03:35,444:INFO:[LightGBM] [Info] Start training from score -0.490332
2025-06-02 15:03:35,621:INFO:Uploading results into container
2025-06-02 15:03:35,623:INFO:Uploading model into container now
2025-06-02 15:03:35,623:INFO:_master_model_container: 22
2025-06-02 15:03:35,624:INFO:_display_container: 4
2025-06-02 15:03:35,625:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:03:35,625:INFO:create_model() successfully completed......................................
2025-06-02 15:03:36,866:INFO:SubProcess create_model() end ==================================
2025-06-02 15:03:36,868:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8764
2025-06-02 15:03:36,870:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06) result for R2 is 0.8217
2025-06-02 15:03:36,872:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 15:03:36,872:INFO:choose_better completed
2025-06-02 15:03:36,872:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 15:03:36,887:INFO:_master_model_container: 22
2025-06-02 15:03:36,887:INFO:_display_container: 3
2025-06-02 15:03:36,888:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:03:36,889:INFO:tune_model() successfully completed......................................
2025-06-02 15:03:38,153:INFO:Initializing finalize_model()
2025-06-02 15:03:38,153:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 15:03:38,154:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:03:38,204:INFO:Initializing create_model()
2025-06-02 15:03:38,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:03:38,205:INFO:Checking exceptions
2025-06-02 15:03:38,207:INFO:Importing libraries
2025-06-02 15:03:38,207:INFO:Copying training dataset
2025-06-02 15:03:38,212:INFO:Defining folds
2025-06-02 15:03:38,212:INFO:Declaring metric variables
2025-06-02 15:03:38,213:INFO:Importing untrained model
2025-06-02 15:03:38,213:INFO:Declaring custom model
2025-06-02 15:03:38,215:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 15:03:38,218:INFO:Cross validation set to False
2025-06-02 15:03:38,218:INFO:Fitting Model
2025-06-02 15:03:38,627:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 15:03:38,633:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003649 seconds.
2025-06-02 15:03:38,633:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 15:03:38,634:INFO:[LightGBM] [Info] Total Bins 6237
2025-06-02 15:03:38,634:INFO:[LightGBM] [Info] Number of data points in the train set: 4478, number of used features: 95
2025-06-02 15:03:38,635:INFO:[LightGBM] [Info] Start training from score -0.483793
2025-06-02 15:03:38,850:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 15:03:38,850:INFO:create_model() successfully completed......................................
2025-06-02 15:03:40,124:INFO:_master_model_container: 22
2025-06-02 15:03:40,124:INFO:_display_container: 3
2025-06-02 15:03:40,139:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 15:03:40,140:INFO:finalize_model() successfully completed......................................
2025-06-02 15:03:41,409:INFO:Initializing save_model()
2025-06-02 15:03:41,409:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 15:03:41,409:INFO:Adding model into prep_pipe
2025-06-02 15:03:41,409:WARNING:Only Model saved as it was a pipeline.
2025-06-02 15:03:41,429:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 15:03:41,452:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 15:03:41,452:INFO:save_model() successfully completed......................................
2025-06-02 15:06:17,932:INFO:Initializing load_model()
2025-06-02 15:06:17,933:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 15:06:18,063:INFO:Initializing get_config()
2025-06-02 15:06:18,064:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, variable=X_test)
2025-06-02 15:06:18,065:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 15:06:18,066:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 15:06:18,184:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2059                       12.0                       13.0   
2652                       29.0                       31.0   
3768                       34.0                       65.0   
3686                        8.0                       14.0   
1037                       53.0                       83.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2059                      1.0               12.500000   
2652                      2.0               29.500000   
3768                     31.0               44.782608   
3686                      6.0               10.000000   
1037                     30.0               77.545456   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2059                   0.500000                    12.0   
2652                   0.750000                    29.0   
3768                  14.064272                    34.0   
3686                   2.666667                     8.0   
1037                   8.925620                    83.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2059                                68.0                                73.0   
2652                                64.0                                74.0   
3768                                29.0                                89.0   
3686                                78.0                                87.0   
1037                                86.0                                96.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2059                               5.0                        70.500000  ...   
2652                              10.0                        66.500000  ...   
3768                              60.0                        68.130432  ...   
3686                               9.0                        84.000000  ...   
1037                              10.0                        87.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2059                 4.0                   1            32.0   
2652                 4.0                   1            32.0   
3768                 7.0                   0             2.0   
3686                 7.0                   0             2.0   
1037                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2059                 False                     False   
2652                 False                     False   
3768                 False                     False   
3686                 False                     False   
1037                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2059                      False                        False   
2652                      False                        False   
3768                      False                        False   
3686                      False                        False   
1037                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2059                       True                     False   
2652                       True                     False   
3768                      False                      True   
3686                      False                      True   
1037                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2059                    False  
2652                    False  
3768                    False  
3686                    False  
1037                    False  

[1344 rows x 146 columns]
2025-06-02 15:06:18,185:INFO:get_config() successfully completed......................................
2025-06-02 15:06:18,195:INFO:Initializing get_config()
2025-06-02 15:06:18,195:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, variable=y_test)
2025-06-02 15:06:18,195:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 15:06:18,196:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 15:06:18,224:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2059    0.014339
2652   -0.098120
3768   -1.861921
3686   -3.207308
1037   -0.156411
Name: target, Length: 1344, dtype: float32
2025-06-02 15:06:18,225:INFO:get_config() successfully completed......................................
2025-06-02 15:06:18,272:INFO:Initializing predict_model()
2025-06-02 15:06:18,274:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC677790>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6DCD1EA70>)
2025-06-02 15:06:18,274:INFO:Checking exceptions
2025-06-02 15:06:18,274:INFO:Preloading libraries
2025-06-02 15:06:18,285:INFO:Set up data.
2025-06-02 15:06:18,453:INFO:Set up index.
2025-06-02 15:17:20,243:INFO:PyCaret RegressionExperiment
2025-06-02 15:17:20,246:INFO:Logging name: reg-default-name
2025-06-02 15:17:20,246:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 15:17:20,246:INFO:version 3.3.2
2025-06-02 15:17:20,247:INFO:Initializing setup()
2025-06-02 15:17:20,247:INFO:self.USI: 4659
2025-06-02 15:17:20,247:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 15:17:20,247:INFO:Checking environment
2025-06-02 15:17:20,248:INFO:python_version: 3.10.16
2025-06-02 15:17:20,248:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 15:17:20,249:INFO:machine: AMD64
2025-06-02 15:17:20,249:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 15:17:20,260:INFO:Memory: svmem(total=6378008576, available=1022066688, percent=84.0, used=5355941888, free=1022066688)
2025-06-02 15:17:20,260:INFO:Physical Core: 4
2025-06-02 15:17:20,260:INFO:Logical Core: 8
2025-06-02 15:17:20,262:INFO:Checking libraries
2025-06-02 15:17:20,262:INFO:System:
2025-06-02 15:17:20,262:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 15:17:20,263:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 15:17:20,263:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 15:17:20,263:INFO:PyCaret required dependencies:
2025-06-02 15:17:20,265:INFO:                 pip: 25.1
2025-06-02 15:17:20,266:INFO:          setuptools: 78.1.1
2025-06-02 15:17:20,266:INFO:             pycaret: 3.3.2
2025-06-02 15:17:20,266:INFO:             IPython: 8.37.0
2025-06-02 15:17:20,266:INFO:          ipywidgets: 8.1.7
2025-06-02 15:17:20,266:INFO:                tqdm: 4.67.1
2025-06-02 15:17:20,266:INFO:               numpy: 1.26.4
2025-06-02 15:17:20,266:INFO:              pandas: 2.0.1
2025-06-02 15:17:20,266:INFO:              jinja2: 3.1.6
2025-06-02 15:17:20,266:INFO:               scipy: 1.10.1
2025-06-02 15:17:20,266:INFO:              joblib: 1.3.2
2025-06-02 15:17:20,266:INFO:             sklearn: 1.4.2
2025-06-02 15:17:20,267:INFO:                pyod: 2.0.5
2025-06-02 15:17:20,267:INFO:            imblearn: 0.13.0
2025-06-02 15:17:20,267:INFO:   category_encoders: 2.7.0
2025-06-02 15:17:20,267:INFO:            lightgbm: 4.6.0
2025-06-02 15:17:20,267:INFO:               numba: 0.61.0
2025-06-02 15:17:20,267:INFO:            requests: 2.32.3
2025-06-02 15:17:20,267:INFO:          matplotlib: 3.7.1
2025-06-02 15:17:20,267:INFO:          scikitplot: 0.3.7
2025-06-02 15:17:20,267:INFO:         yellowbrick: 1.5
2025-06-02 15:17:20,267:INFO:              plotly: 6.1.2
2025-06-02 15:17:20,267:INFO:    plotly-resampler: Not installed
2025-06-02 15:17:20,267:INFO:             kaleido: 0.2.1
2025-06-02 15:17:20,268:INFO:           schemdraw: 0.15
2025-06-02 15:17:20,268:INFO:         statsmodels: 0.14.4
2025-06-02 15:17:20,268:INFO:              sktime: 0.26.0
2025-06-02 15:17:20,268:INFO:               tbats: 1.1.3
2025-06-02 15:17:20,268:INFO:            pmdarima: 2.0.4
2025-06-02 15:17:20,268:INFO:              psutil: 7.0.0
2025-06-02 15:17:20,268:INFO:          markupsafe: 2.1.2
2025-06-02 15:17:20,268:INFO:             pickle5: Not installed
2025-06-02 15:17:20,268:INFO:         cloudpickle: 3.1.1
2025-06-02 15:17:20,268:INFO:         deprecation: 2.1.0
2025-06-02 15:17:20,268:INFO:              xxhash: 3.5.0
2025-06-02 15:17:20,268:INFO:           wurlitzer: Not installed
2025-06-02 15:17:20,268:INFO:PyCaret optional dependencies:
2025-06-02 15:17:20,270:INFO:                shap: 0.44.1
2025-06-02 15:17:20,270:INFO:           interpret: 0.6.9
2025-06-02 15:17:20,270:INFO:                umap: 0.5.7
2025-06-02 15:17:20,270:INFO:     ydata_profiling: 4.16.1
2025-06-02 15:17:20,270:INFO:  explainerdashboard: 0.4.8
2025-06-02 15:17:20,270:INFO:             autoviz: Not installed
2025-06-02 15:17:20,270:INFO:           fairlearn: 0.7.0
2025-06-02 15:17:20,270:INFO:          deepchecks: Not installed
2025-06-02 15:17:20,270:INFO:             xgboost: 3.0.2
2025-06-02 15:17:20,270:INFO:            catboost: 1.2.8
2025-06-02 15:17:20,270:INFO:              kmodes: 0.12.2
2025-06-02 15:17:20,270:INFO:             mlxtend: 0.23.4
2025-06-02 15:17:20,271:INFO:       statsforecast: 1.5.0
2025-06-02 15:17:20,271:INFO:        tune_sklearn: Not installed
2025-06-02 15:17:20,271:INFO:                 ray: Not installed
2025-06-02 15:17:20,271:INFO:            hyperopt: 0.2.7
2025-06-02 15:17:20,271:INFO:              optuna: 4.3.0
2025-06-02 15:17:20,271:INFO:               skopt: 0.10.2
2025-06-02 15:17:20,271:INFO:              mlflow: 2.22.0
2025-06-02 15:17:20,271:INFO:              gradio: 5.32.0
2025-06-02 15:17:20,271:INFO:             fastapi: 0.115.12
2025-06-02 15:17:20,271:INFO:             uvicorn: 0.34.3
2025-06-02 15:17:20,271:INFO:              m2cgen: 0.10.0
2025-06-02 15:17:20,271:INFO:           evidently: 0.4.40
2025-06-02 15:17:20,271:INFO:               fugue: 0.8.5
2025-06-02 15:17:20,271:INFO:           streamlit: Not installed
2025-06-02 15:17:20,272:INFO:             prophet: Not installed
2025-06-02 15:17:20,272:INFO:None
2025-06-02 15:17:20,272:INFO:Set up data.
2025-06-02 15:17:20,465:INFO:Set up folding strategy.
2025-06-02 15:17:20,466:INFO:Set up train/test split.
2025-06-02 15:17:20,539:INFO:Set up index.
2025-06-02 15:17:20,541:INFO:Assigning column types.
2025-06-02 15:17:20,604:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 15:17:20,608:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 15:17:20,617:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 15:17:20,625:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:17:20,773:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:17:20,857:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:17:20,861:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:17:20,871:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:17:20,873:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 15:17:20,884:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 15:17:20,894:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:17:21,049:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:17:21,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:17:21,128:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:17:21,132:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:17:21,133:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 15:17:21,140:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 15:17:21,148:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:17:21,295:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:17:21,381:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:17:21,382:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:17:21,386:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:17:21,394:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 15:17:21,402:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:17:21,543:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:17:21,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:17:21,633:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:17:21,637:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:17:21,639:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 15:17:21,653:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:17:21,782:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:17:21,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:17:21,870:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:17:21,874:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:17:21,891:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:17:22,023:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:17:22,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:17:22,099:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:17:22,103:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:17:22,104:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 15:17:22,250:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:17:22,328:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:17:22,329:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:17:22,333:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:17:22,497:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:17:22,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:17:22,586:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:17:22,591:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:17:22,592:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 15:17:22,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:17:22,831:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:17:22,836:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:17:22,988:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:17:23,063:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:17:23,067:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:17:23,069:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 15:17:23,300:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:17:23,304:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:17:23,536:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:17:23,540:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:17:23,552:INFO:Preparing preprocessing pipeline...
2025-06-02 15:17:23,552:INFO:Set up simple imputation.
2025-06-02 15:17:23,552:INFO:Set up removing multicollinearity.
2025-06-02 15:17:23,561:INFO:Set up column name cleaning.
2025-06-02 15:17:23,810:INFO:Finished creating preprocessing pipeline.
2025-06-02 15:17:23,826:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 15:17:23,826:INFO:Creating final display dataframe.
2025-06-02 15:17:24,254:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              4659
2025-06-02 15:17:24,519:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:17:24,523:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:17:24,754:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:17:24,758:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:17:24,760:INFO:setup() successfully completed in 4.6s...............
2025-06-02 15:17:24,799:INFO:Initializing compare_models()
2025-06-02 15:17:24,800:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 15:17:24,800:INFO:Checking exceptions
2025-06-02 15:17:24,823:INFO:Preparing display monitor
2025-06-02 15:17:24,914:INFO:Initializing Linear Regression
2025-06-02 15:17:24,915:INFO:Total runtime is 1.6681353251139323e-05 minutes
2025-06-02 15:17:24,929:INFO:SubProcess create_model() called ==================================
2025-06-02 15:17:24,931:INFO:Initializing create_model()
2025-06-02 15:17:24,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:17:24,933:INFO:Checking exceptions
2025-06-02 15:17:24,933:INFO:Importing libraries
2025-06-02 15:17:24,934:INFO:Copying training dataset
2025-06-02 15:17:25,037:INFO:Defining folds
2025-06-02 15:17:25,038:INFO:Declaring metric variables
2025-06-02 15:17:25,060:INFO:Importing untrained model
2025-06-02 15:17:25,074:INFO:Linear Regression Imported successfully
2025-06-02 15:17:25,107:INFO:Starting cross validation
2025-06-02 15:17:25,116:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:17:40,076:INFO:Calculating mean and std
2025-06-02 15:17:40,085:INFO:Creating metrics dataframe
2025-06-02 15:17:40,106:INFO:Uploading results into container
2025-06-02 15:17:40,109:INFO:Uploading model into container now
2025-06-02 15:17:40,112:INFO:_master_model_container: 1
2025-06-02 15:17:40,112:INFO:_display_container: 2
2025-06-02 15:17:40,113:INFO:LinearRegression(n_jobs=-1)
2025-06-02 15:17:40,114:INFO:create_model() successfully completed......................................
2025-06-02 15:17:52,043:INFO:SubProcess create_model() end ==================================
2025-06-02 15:17:52,045:INFO:Creating metrics dataframe
2025-06-02 15:17:52,079:INFO:Initializing Lasso Regression
2025-06-02 15:17:52,080:INFO:Total runtime is 0.4527722557385762 minutes
2025-06-02 15:17:52,096:INFO:SubProcess create_model() called ==================================
2025-06-02 15:17:52,096:INFO:Initializing create_model()
2025-06-02 15:17:52,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:17:52,097:INFO:Checking exceptions
2025-06-02 15:17:52,098:INFO:Importing libraries
2025-06-02 15:17:52,099:INFO:Copying training dataset
2025-06-02 15:17:52,210:INFO:Defining folds
2025-06-02 15:17:52,211:INFO:Declaring metric variables
2025-06-02 15:17:52,223:INFO:Importing untrained model
2025-06-02 15:17:52,235:INFO:Lasso Regression Imported successfully
2025-06-02 15:17:52,276:INFO:Starting cross validation
2025-06-02 15:17:52,281:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:03,013:INFO:Calculating mean and std
2025-06-02 15:18:03,056:INFO:Creating metrics dataframe
2025-06-02 15:18:03,103:INFO:Uploading results into container
2025-06-02 15:18:03,108:INFO:Uploading model into container now
2025-06-02 15:18:03,112:INFO:_master_model_container: 2
2025-06-02 15:18:03,112:INFO:_display_container: 2
2025-06-02 15:18:03,119:INFO:Lasso(random_state=123)
2025-06-02 15:18:03,121:INFO:create_model() successfully completed......................................
2025-06-02 15:18:06,987:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:06,987:INFO:Creating metrics dataframe
2025-06-02 15:18:07,011:INFO:Initializing Ridge Regression
2025-06-02 15:18:07,011:INFO:Total runtime is 0.701626165707906 minutes
2025-06-02 15:18:07,025:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:07,025:INFO:Initializing create_model()
2025-06-02 15:18:07,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:07,027:INFO:Checking exceptions
2025-06-02 15:18:07,027:INFO:Importing libraries
2025-06-02 15:18:07,028:INFO:Copying training dataset
2025-06-02 15:18:07,127:INFO:Defining folds
2025-06-02 15:18:07,128:INFO:Declaring metric variables
2025-06-02 15:18:07,141:INFO:Importing untrained model
2025-06-02 15:18:07,156:INFO:Ridge Regression Imported successfully
2025-06-02 15:18:07,181:INFO:Starting cross validation
2025-06-02 15:18:07,186:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:07,927:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.75561e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 15:18:07,938:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31073e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 15:18:07,979:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.24347e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 15:18:08,020:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.08754e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 15:18:08,161:INFO:Calculating mean and std
2025-06-02 15:18:08,164:INFO:Creating metrics dataframe
2025-06-02 15:18:08,170:INFO:Uploading results into container
2025-06-02 15:18:08,171:INFO:Uploading model into container now
2025-06-02 15:18:08,173:INFO:_master_model_container: 3
2025-06-02 15:18:08,173:INFO:_display_container: 2
2025-06-02 15:18:08,175:INFO:Ridge(random_state=123)
2025-06-02 15:18:08,175:INFO:create_model() successfully completed......................................
2025-06-02 15:18:09,882:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:09,882:INFO:Creating metrics dataframe
2025-06-02 15:18:09,900:INFO:Initializing Elastic Net
2025-06-02 15:18:09,901:INFO:Total runtime is 0.7497879385948181 minutes
2025-06-02 15:18:09,911:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:09,911:INFO:Initializing create_model()
2025-06-02 15:18:09,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:09,913:INFO:Checking exceptions
2025-06-02 15:18:09,913:INFO:Importing libraries
2025-06-02 15:18:09,914:INFO:Copying training dataset
2025-06-02 15:18:09,977:INFO:Defining folds
2025-06-02 15:18:09,978:INFO:Declaring metric variables
2025-06-02 15:18:09,992:INFO:Importing untrained model
2025-06-02 15:18:10,002:INFO:Elastic Net Imported successfully
2025-06-02 15:18:10,024:INFO:Starting cross validation
2025-06-02 15:18:10,028:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:10,900:INFO:Calculating mean and std
2025-06-02 15:18:10,903:INFO:Creating metrics dataframe
2025-06-02 15:18:10,908:INFO:Uploading results into container
2025-06-02 15:18:10,909:INFO:Uploading model into container now
2025-06-02 15:18:10,910:INFO:_master_model_container: 4
2025-06-02 15:18:10,911:INFO:_display_container: 2
2025-06-02 15:18:10,912:INFO:ElasticNet(random_state=123)
2025-06-02 15:18:10,913:INFO:create_model() successfully completed......................................
2025-06-02 15:18:12,287:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:12,287:INFO:Creating metrics dataframe
2025-06-02 15:18:12,303:INFO:Initializing Least Angle Regression
2025-06-02 15:18:12,303:INFO:Total runtime is 0.7898245175679525 minutes
2025-06-02 15:18:12,313:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:12,313:INFO:Initializing create_model()
2025-06-02 15:18:12,314:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:12,314:INFO:Checking exceptions
2025-06-02 15:18:12,315:INFO:Importing libraries
2025-06-02 15:18:12,315:INFO:Copying training dataset
2025-06-02 15:18:12,388:INFO:Defining folds
2025-06-02 15:18:12,389:INFO:Declaring metric variables
2025-06-02 15:18:12,402:INFO:Importing untrained model
2025-06-02 15:18:12,414:INFO:Least Angle Regression Imported successfully
2025-06-02 15:18:12,437:INFO:Starting cross validation
2025-06-02 15:18:12,441:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:13,285:INFO:Calculating mean and std
2025-06-02 15:18:13,287:INFO:Creating metrics dataframe
2025-06-02 15:18:13,290:INFO:Uploading results into container
2025-06-02 15:18:13,291:INFO:Uploading model into container now
2025-06-02 15:18:13,292:INFO:_master_model_container: 5
2025-06-02 15:18:13,292:INFO:_display_container: 2
2025-06-02 15:18:13,294:INFO:Lars(random_state=123)
2025-06-02 15:18:13,295:INFO:create_model() successfully completed......................................
2025-06-02 15:18:14,543:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:14,543:INFO:Creating metrics dataframe
2025-06-02 15:18:14,563:INFO:Initializing Lasso Least Angle Regression
2025-06-02 15:18:14,564:INFO:Total runtime is 0.827503788471222 minutes
2025-06-02 15:18:14,574:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:14,575:INFO:Initializing create_model()
2025-06-02 15:18:14,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:14,576:INFO:Checking exceptions
2025-06-02 15:18:14,576:INFO:Importing libraries
2025-06-02 15:18:14,576:INFO:Copying training dataset
2025-06-02 15:18:14,638:INFO:Defining folds
2025-06-02 15:18:14,638:INFO:Declaring metric variables
2025-06-02 15:18:14,652:INFO:Importing untrained model
2025-06-02 15:18:14,665:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 15:18:14,690:INFO:Starting cross validation
2025-06-02 15:18:14,694:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:16,000:INFO:Calculating mean and std
2025-06-02 15:18:16,003:INFO:Creating metrics dataframe
2025-06-02 15:18:16,007:INFO:Uploading results into container
2025-06-02 15:18:16,009:INFO:Uploading model into container now
2025-06-02 15:18:16,009:INFO:_master_model_container: 6
2025-06-02 15:18:16,010:INFO:_display_container: 2
2025-06-02 15:18:16,010:INFO:LassoLars(random_state=123)
2025-06-02 15:18:16,011:INFO:create_model() successfully completed......................................
2025-06-02 15:18:17,444:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:17,444:INFO:Creating metrics dataframe
2025-06-02 15:18:17,463:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 15:18:17,463:INFO:Total runtime is 0.8758274912834167 minutes
2025-06-02 15:18:17,474:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:17,475:INFO:Initializing create_model()
2025-06-02 15:18:17,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:17,475:INFO:Checking exceptions
2025-06-02 15:18:17,476:INFO:Importing libraries
2025-06-02 15:18:17,476:INFO:Copying training dataset
2025-06-02 15:18:17,544:INFO:Defining folds
2025-06-02 15:18:17,544:INFO:Declaring metric variables
2025-06-02 15:18:17,556:INFO:Importing untrained model
2025-06-02 15:18:17,566:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 15:18:17,593:INFO:Starting cross validation
2025-06-02 15:18:17,596:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:18,356:INFO:Calculating mean and std
2025-06-02 15:18:18,359:INFO:Creating metrics dataframe
2025-06-02 15:18:18,362:INFO:Uploading results into container
2025-06-02 15:18:18,363:INFO:Uploading model into container now
2025-06-02 15:18:18,364:INFO:_master_model_container: 7
2025-06-02 15:18:18,364:INFO:_display_container: 2
2025-06-02 15:18:18,364:INFO:OrthogonalMatchingPursuit()
2025-06-02 15:18:18,365:INFO:create_model() successfully completed......................................
2025-06-02 15:18:19,633:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:19,634:INFO:Creating metrics dataframe
2025-06-02 15:18:19,650:INFO:Initializing Bayesian Ridge
2025-06-02 15:18:19,650:INFO:Total runtime is 0.9122756679852804 minutes
2025-06-02 15:18:19,659:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:19,659:INFO:Initializing create_model()
2025-06-02 15:18:19,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:19,660:INFO:Checking exceptions
2025-06-02 15:18:19,661:INFO:Importing libraries
2025-06-02 15:18:19,661:INFO:Copying training dataset
2025-06-02 15:18:19,731:INFO:Defining folds
2025-06-02 15:18:19,731:INFO:Declaring metric variables
2025-06-02 15:18:19,743:INFO:Importing untrained model
2025-06-02 15:18:19,755:INFO:Bayesian Ridge Imported successfully
2025-06-02 15:18:19,778:INFO:Starting cross validation
2025-06-02 15:18:19,783:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:20,605:INFO:Calculating mean and std
2025-06-02 15:18:20,607:INFO:Creating metrics dataframe
2025-06-02 15:18:20,610:INFO:Uploading results into container
2025-06-02 15:18:20,611:INFO:Uploading model into container now
2025-06-02 15:18:20,612:INFO:_master_model_container: 8
2025-06-02 15:18:20,612:INFO:_display_container: 2
2025-06-02 15:18:20,613:INFO:BayesianRidge()
2025-06-02 15:18:20,613:INFO:create_model() successfully completed......................................
2025-06-02 15:18:21,877:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:21,878:INFO:Creating metrics dataframe
2025-06-02 15:18:21,898:INFO:Initializing Passive Aggressive Regressor
2025-06-02 15:18:21,898:INFO:Total runtime is 0.9497421423594157 minutes
2025-06-02 15:18:21,909:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:21,910:INFO:Initializing create_model()
2025-06-02 15:18:21,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:21,911:INFO:Checking exceptions
2025-06-02 15:18:21,911:INFO:Importing libraries
2025-06-02 15:18:21,912:INFO:Copying training dataset
2025-06-02 15:18:21,986:INFO:Defining folds
2025-06-02 15:18:21,989:INFO:Declaring metric variables
2025-06-02 15:18:22,004:INFO:Importing untrained model
2025-06-02 15:18:22,015:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 15:18:22,039:INFO:Starting cross validation
2025-06-02 15:18:22,043:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:22,849:INFO:Calculating mean and std
2025-06-02 15:18:22,851:INFO:Creating metrics dataframe
2025-06-02 15:18:22,855:INFO:Uploading results into container
2025-06-02 15:18:22,856:INFO:Uploading model into container now
2025-06-02 15:18:22,857:INFO:_master_model_container: 9
2025-06-02 15:18:22,857:INFO:_display_container: 2
2025-06-02 15:18:22,858:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 15:18:22,858:INFO:create_model() successfully completed......................................
2025-06-02 15:18:24,154:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:24,154:INFO:Creating metrics dataframe
2025-06-02 15:18:24,171:INFO:Initializing Huber Regressor
2025-06-02 15:18:24,171:INFO:Total runtime is 0.9876148223876953 minutes
2025-06-02 15:18:24,180:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:24,181:INFO:Initializing create_model()
2025-06-02 15:18:24,182:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:24,182:INFO:Checking exceptions
2025-06-02 15:18:24,183:INFO:Importing libraries
2025-06-02 15:18:24,183:INFO:Copying training dataset
2025-06-02 15:18:24,280:INFO:Defining folds
2025-06-02 15:18:24,281:INFO:Declaring metric variables
2025-06-02 15:18:24,300:INFO:Importing untrained model
2025-06-02 15:18:24,323:INFO:Huber Regressor Imported successfully
2025-06-02 15:18:24,376:INFO:Starting cross validation
2025-06-02 15:18:24,381:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:26,587:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:18:26,729:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:18:26,784:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:18:26,785:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:18:26,803:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:18:26,870:INFO:Calculating mean and std
2025-06-02 15:18:26,873:INFO:Creating metrics dataframe
2025-06-02 15:18:26,877:INFO:Uploading results into container
2025-06-02 15:18:26,879:INFO:Uploading model into container now
2025-06-02 15:18:26,880:INFO:_master_model_container: 10
2025-06-02 15:18:26,880:INFO:_display_container: 2
2025-06-02 15:18:26,881:INFO:HuberRegressor()
2025-06-02 15:18:26,882:INFO:create_model() successfully completed......................................
2025-06-02 15:18:28,233:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:28,233:INFO:Creating metrics dataframe
2025-06-02 15:18:28,253:INFO:Initializing K Neighbors Regressor
2025-06-02 15:18:28,253:INFO:Total runtime is 1.055650250116984 minutes
2025-06-02 15:18:28,262:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:28,263:INFO:Initializing create_model()
2025-06-02 15:18:28,263:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:28,264:INFO:Checking exceptions
2025-06-02 15:18:28,264:INFO:Importing libraries
2025-06-02 15:18:28,266:INFO:Copying training dataset
2025-06-02 15:18:28,342:INFO:Defining folds
2025-06-02 15:18:28,342:INFO:Declaring metric variables
2025-06-02 15:18:28,354:INFO:Importing untrained model
2025-06-02 15:18:28,367:INFO:K Neighbors Regressor Imported successfully
2025-06-02 15:18:28,389:INFO:Starting cross validation
2025-06-02 15:18:28,393:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:29,220:INFO:Calculating mean and std
2025-06-02 15:18:29,222:INFO:Creating metrics dataframe
2025-06-02 15:18:29,225:INFO:Uploading results into container
2025-06-02 15:18:29,226:INFO:Uploading model into container now
2025-06-02 15:18:29,228:INFO:_master_model_container: 11
2025-06-02 15:18:29,228:INFO:_display_container: 2
2025-06-02 15:18:29,229:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 15:18:29,229:INFO:create_model() successfully completed......................................
2025-06-02 15:18:30,475:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:30,475:INFO:Creating metrics dataframe
2025-06-02 15:18:30,495:INFO:Initializing Decision Tree Regressor
2025-06-02 15:18:30,495:INFO:Total runtime is 1.093020208676656 minutes
2025-06-02 15:18:30,506:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:30,506:INFO:Initializing create_model()
2025-06-02 15:18:30,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:30,507:INFO:Checking exceptions
2025-06-02 15:18:30,507:INFO:Importing libraries
2025-06-02 15:18:30,508:INFO:Copying training dataset
2025-06-02 15:18:30,579:INFO:Defining folds
2025-06-02 15:18:30,579:INFO:Declaring metric variables
2025-06-02 15:18:30,589:INFO:Importing untrained model
2025-06-02 15:18:30,601:INFO:Decision Tree Regressor Imported successfully
2025-06-02 15:18:30,625:INFO:Starting cross validation
2025-06-02 15:18:30,629:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:31,594:INFO:Calculating mean and std
2025-06-02 15:18:31,597:INFO:Creating metrics dataframe
2025-06-02 15:18:31,600:INFO:Uploading results into container
2025-06-02 15:18:31,601:INFO:Uploading model into container now
2025-06-02 15:18:31,602:INFO:_master_model_container: 12
2025-06-02 15:18:31,602:INFO:_display_container: 2
2025-06-02 15:18:31,602:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 15:18:31,602:INFO:create_model() successfully completed......................................
2025-06-02 15:18:32,912:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:32,913:INFO:Creating metrics dataframe
2025-06-02 15:18:32,935:INFO:Initializing Random Forest Regressor
2025-06-02 15:18:32,935:INFO:Total runtime is 1.133692701657613 minutes
2025-06-02 15:18:32,944:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:32,945:INFO:Initializing create_model()
2025-06-02 15:18:32,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:32,946:INFO:Checking exceptions
2025-06-02 15:18:32,946:INFO:Importing libraries
2025-06-02 15:18:32,946:INFO:Copying training dataset
2025-06-02 15:18:33,020:INFO:Defining folds
2025-06-02 15:18:33,021:INFO:Declaring metric variables
2025-06-02 15:18:33,033:INFO:Importing untrained model
2025-06-02 15:18:33,043:INFO:Random Forest Regressor Imported successfully
2025-06-02 15:18:33,066:INFO:Starting cross validation
2025-06-02 15:18:33,071:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:42,079:INFO:Calculating mean and std
2025-06-02 15:18:42,082:INFO:Creating metrics dataframe
2025-06-02 15:18:42,085:INFO:Uploading results into container
2025-06-02 15:18:42,086:INFO:Uploading model into container now
2025-06-02 15:18:42,087:INFO:_master_model_container: 13
2025-06-02 15:18:42,088:INFO:_display_container: 2
2025-06-02 15:18:42,088:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:18:42,089:INFO:create_model() successfully completed......................................
2025-06-02 15:18:43,406:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:43,406:INFO:Creating metrics dataframe
2025-06-02 15:18:43,436:INFO:Initializing Extra Trees Regressor
2025-06-02 15:18:43,436:INFO:Total runtime is 1.3087099989255269 minutes
2025-06-02 15:18:43,445:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:43,445:INFO:Initializing create_model()
2025-06-02 15:18:43,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:43,446:INFO:Checking exceptions
2025-06-02 15:18:43,446:INFO:Importing libraries
2025-06-02 15:18:43,447:INFO:Copying training dataset
2025-06-02 15:18:43,520:INFO:Defining folds
2025-06-02 15:18:43,520:INFO:Declaring metric variables
2025-06-02 15:18:43,533:INFO:Importing untrained model
2025-06-02 15:18:43,544:INFO:Extra Trees Regressor Imported successfully
2025-06-02 15:18:43,572:INFO:Starting cross validation
2025-06-02 15:18:43,575:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:49,250:INFO:Calculating mean and std
2025-06-02 15:18:49,253:INFO:Creating metrics dataframe
2025-06-02 15:18:49,256:INFO:Uploading results into container
2025-06-02 15:18:49,257:INFO:Uploading model into container now
2025-06-02 15:18:49,259:INFO:_master_model_container: 14
2025-06-02 15:18:49,259:INFO:_display_container: 2
2025-06-02 15:18:49,260:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:18:49,261:INFO:create_model() successfully completed......................................
2025-06-02 15:18:50,553:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:50,553:INFO:Creating metrics dataframe
2025-06-02 15:18:50,588:INFO:Initializing AdaBoost Regressor
2025-06-02 15:18:50,588:INFO:Total runtime is 1.427901522318522 minutes
2025-06-02 15:18:50,598:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:50,599:INFO:Initializing create_model()
2025-06-02 15:18:50,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:50,599:INFO:Checking exceptions
2025-06-02 15:18:50,600:INFO:Importing libraries
2025-06-02 15:18:50,600:INFO:Copying training dataset
2025-06-02 15:18:50,662:INFO:Defining folds
2025-06-02 15:18:50,664:INFO:Declaring metric variables
2025-06-02 15:18:50,680:INFO:Importing untrained model
2025-06-02 15:18:50,691:INFO:AdaBoost Regressor Imported successfully
2025-06-02 15:18:50,716:INFO:Starting cross validation
2025-06-02 15:18:50,720:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:52,882:INFO:Calculating mean and std
2025-06-02 15:18:52,884:INFO:Creating metrics dataframe
2025-06-02 15:18:52,889:INFO:Uploading results into container
2025-06-02 15:18:52,890:INFO:Uploading model into container now
2025-06-02 15:18:52,891:INFO:_master_model_container: 15
2025-06-02 15:18:52,891:INFO:_display_container: 2
2025-06-02 15:18:52,891:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 15:18:52,891:INFO:create_model() successfully completed......................................
2025-06-02 15:18:54,164:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:54,164:INFO:Creating metrics dataframe
2025-06-02 15:18:54,189:INFO:Initializing Gradient Boosting Regressor
2025-06-02 15:18:54,189:INFO:Total runtime is 1.4879290461540222 minutes
2025-06-02 15:18:54,201:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:54,202:INFO:Initializing create_model()
2025-06-02 15:18:54,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:54,203:INFO:Checking exceptions
2025-06-02 15:18:54,203:INFO:Importing libraries
2025-06-02 15:18:54,204:INFO:Copying training dataset
2025-06-02 15:18:54,274:INFO:Defining folds
2025-06-02 15:18:54,275:INFO:Declaring metric variables
2025-06-02 15:18:54,289:INFO:Importing untrained model
2025-06-02 15:18:54,300:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 15:18:54,324:INFO:Starting cross validation
2025-06-02 15:18:54,329:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:18:57,716:INFO:Calculating mean and std
2025-06-02 15:18:57,718:INFO:Creating metrics dataframe
2025-06-02 15:18:57,721:INFO:Uploading results into container
2025-06-02 15:18:57,722:INFO:Uploading model into container now
2025-06-02 15:18:57,723:INFO:_master_model_container: 16
2025-06-02 15:18:57,723:INFO:_display_container: 2
2025-06-02 15:18:57,723:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 15:18:57,724:INFO:create_model() successfully completed......................................
2025-06-02 15:18:59,001:INFO:SubProcess create_model() end ==================================
2025-06-02 15:18:59,001:INFO:Creating metrics dataframe
2025-06-02 15:18:59,025:INFO:Initializing Extreme Gradient Boosting
2025-06-02 15:18:59,026:INFO:Total runtime is 1.56854008436203 minutes
2025-06-02 15:18:59,039:INFO:SubProcess create_model() called ==================================
2025-06-02 15:18:59,040:INFO:Initializing create_model()
2025-06-02 15:18:59,040:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:18:59,041:INFO:Checking exceptions
2025-06-02 15:18:59,041:INFO:Importing libraries
2025-06-02 15:18:59,041:INFO:Copying training dataset
2025-06-02 15:18:59,111:INFO:Defining folds
2025-06-02 15:18:59,111:INFO:Declaring metric variables
2025-06-02 15:18:59,125:INFO:Importing untrained model
2025-06-02 15:18:59,139:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 15:18:59,161:INFO:Starting cross validation
2025-06-02 15:18:59,166:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:19:01,880:INFO:Calculating mean and std
2025-06-02 15:19:01,883:INFO:Creating metrics dataframe
2025-06-02 15:19:01,887:INFO:Uploading results into container
2025-06-02 15:19:01,888:INFO:Uploading model into container now
2025-06-02 15:19:01,889:INFO:_master_model_container: 17
2025-06-02 15:19:01,889:INFO:_display_container: 2
2025-06-02 15:19:01,894:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 15:19:01,894:INFO:create_model() successfully completed......................................
2025-06-02 15:19:03,217:INFO:SubProcess create_model() end ==================================
2025-06-02 15:19:03,217:INFO:Creating metrics dataframe
2025-06-02 15:19:03,241:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 15:19:03,241:INFO:Total runtime is 1.6387911518414815 minutes
2025-06-02 15:19:03,251:INFO:SubProcess create_model() called ==================================
2025-06-02 15:19:03,251:INFO:Initializing create_model()
2025-06-02 15:19:03,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:19:03,252:INFO:Checking exceptions
2025-06-02 15:19:03,252:INFO:Importing libraries
2025-06-02 15:19:03,252:INFO:Copying training dataset
2025-06-02 15:19:03,309:INFO:Defining folds
2025-06-02 15:19:03,310:INFO:Declaring metric variables
2025-06-02 15:19:03,319:INFO:Importing untrained model
2025-06-02 15:19:03,328:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 15:19:03,346:INFO:Starting cross validation
2025-06-02 15:19:03,350:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:19:06,532:INFO:Calculating mean and std
2025-06-02 15:19:06,535:INFO:Creating metrics dataframe
2025-06-02 15:19:06,540:INFO:Uploading results into container
2025-06-02 15:19:06,541:INFO:Uploading model into container now
2025-06-02 15:19:06,541:INFO:_master_model_container: 18
2025-06-02 15:19:06,542:INFO:_display_container: 2
2025-06-02 15:19:06,543:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:19:06,543:INFO:create_model() successfully completed......................................
2025-06-02 15:19:07,880:INFO:SubProcess create_model() end ==================================
2025-06-02 15:19:07,881:INFO:Creating metrics dataframe
2025-06-02 15:19:07,905:INFO:Initializing CatBoost Regressor
2025-06-02 15:19:07,905:INFO:Total runtime is 1.7165254672368366 minutes
2025-06-02 15:19:07,916:INFO:SubProcess create_model() called ==================================
2025-06-02 15:19:07,916:INFO:Initializing create_model()
2025-06-02 15:19:07,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:19:07,917:INFO:Checking exceptions
2025-06-02 15:19:07,918:INFO:Importing libraries
2025-06-02 15:19:07,918:INFO:Copying training dataset
2025-06-02 15:19:07,979:INFO:Defining folds
2025-06-02 15:19:07,980:INFO:Declaring metric variables
2025-06-02 15:19:07,994:INFO:Importing untrained model
2025-06-02 15:19:08,019:INFO:CatBoost Regressor Imported successfully
2025-06-02 15:19:08,044:INFO:Starting cross validation
2025-06-02 15:19:08,048:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:19:33,314:INFO:Calculating mean and std
2025-06-02 15:19:33,317:INFO:Creating metrics dataframe
2025-06-02 15:19:33,321:INFO:Uploading results into container
2025-06-02 15:19:33,322:INFO:Uploading model into container now
2025-06-02 15:19:33,323:INFO:_master_model_container: 19
2025-06-02 15:19:33,323:INFO:_display_container: 2
2025-06-02 15:19:33,323:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6DC955F00>
2025-06-02 15:19:33,324:INFO:create_model() successfully completed......................................
2025-06-02 15:19:34,697:INFO:SubProcess create_model() end ==================================
2025-06-02 15:19:34,698:INFO:Creating metrics dataframe
2025-06-02 15:19:34,726:INFO:Initializing Dummy Regressor
2025-06-02 15:19:34,727:INFO:Total runtime is 2.16355341275533 minutes
2025-06-02 15:19:34,738:INFO:SubProcess create_model() called ==================================
2025-06-02 15:19:34,739:INFO:Initializing create_model()
2025-06-02 15:19:34,739:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6D9F83370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:19:34,740:INFO:Checking exceptions
2025-06-02 15:19:34,740:INFO:Importing libraries
2025-06-02 15:19:34,741:INFO:Copying training dataset
2025-06-02 15:19:34,806:INFO:Defining folds
2025-06-02 15:19:34,806:INFO:Declaring metric variables
2025-06-02 15:19:34,817:INFO:Importing untrained model
2025-06-02 15:19:34,831:INFO:Dummy Regressor Imported successfully
2025-06-02 15:19:34,858:INFO:Starting cross validation
2025-06-02 15:19:34,862:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:19:35,805:INFO:Calculating mean and std
2025-06-02 15:19:35,808:INFO:Creating metrics dataframe
2025-06-02 15:19:35,811:INFO:Uploading results into container
2025-06-02 15:19:35,812:INFO:Uploading model into container now
2025-06-02 15:19:35,813:INFO:_master_model_container: 20
2025-06-02 15:19:35,814:INFO:_display_container: 2
2025-06-02 15:19:35,815:INFO:DummyRegressor()
2025-06-02 15:19:35,816:INFO:create_model() successfully completed......................................
2025-06-02 15:19:37,142:INFO:SubProcess create_model() end ==================================
2025-06-02 15:19:37,143:INFO:Creating metrics dataframe
2025-06-02 15:19:37,198:INFO:Initializing create_model()
2025-06-02 15:19:37,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:19:37,199:INFO:Checking exceptions
2025-06-02 15:19:37,212:INFO:Importing libraries
2025-06-02 15:19:37,213:INFO:Copying training dataset
2025-06-02 15:19:37,289:INFO:Defining folds
2025-06-02 15:19:37,290:INFO:Declaring metric variables
2025-06-02 15:19:37,290:INFO:Importing untrained model
2025-06-02 15:19:37,290:INFO:Declaring custom model
2025-06-02 15:19:37,291:INFO:Extra Trees Regressor Imported successfully
2025-06-02 15:19:37,294:INFO:Cross validation set to False
2025-06-02 15:19:37,294:INFO:Fitting Model
2025-06-02 15:19:38,995:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:19:38,995:INFO:create_model() successfully completed......................................
2025-06-02 15:19:40,470:INFO:_master_model_container: 20
2025-06-02 15:19:40,470:INFO:_display_container: 2
2025-06-02 15:19:40,471:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:19:40,472:INFO:compare_models() successfully completed......................................
2025-06-02 15:19:40,490:INFO:Initializing tune_model()
2025-06-02 15:19:40,491:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>)
2025-06-02 15:19:40,491:INFO:Checking exceptions
2025-06-02 15:19:40,491:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 15:19:40,559:INFO:Copying training dataset
2025-06-02 15:19:40,630:INFO:Checking base model
2025-06-02 15:19:40,631:INFO:Base model : Extra Trees Regressor
2025-06-02 15:19:40,666:INFO:Declaring metric variables
2025-06-02 15:19:40,690:INFO:Defining Hyperparameters
2025-06-02 15:19:42,629:INFO:Tuning with n_jobs=-1
2025-06-02 15:19:42,651:INFO:Initializing skopt.BayesSearchCV
2025-06-02 15:23:00,411:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', False), ('actual_estimator__criterion', 'absolute_error'), ('actual_estimator__max_depth', 11), ('actual_estimator__max_features', 0.4556655086335653), ('actual_estimator__min_impurity_decrease', 0.00012891733508622256), ('actual_estimator__min_samples_leaf', 1), ('actual_estimator__min_samples_split', 9), ('actual_estimator__n_estimators', 11)])
2025-06-02 15:23:00,421:INFO:Hyperparameter search completed
2025-06-02 15:23:00,422:INFO:SubProcess create_model() called ==================================
2025-06-02 15:23:00,428:INFO:Initializing create_model()
2025-06-02 15:23:00,428:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB30E140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bootstrap': False, 'criterion': 'absolute_error', 'max_depth': 11, 'max_features': 0.4556655086335653, 'min_impurity_decrease': 0.00012891733508622256, 'min_samples_leaf': 1, 'min_samples_split': 9, 'n_estimators': 11})
2025-06-02 15:23:00,428:INFO:Checking exceptions
2025-06-02 15:23:00,429:INFO:Importing libraries
2025-06-02 15:23:00,430:INFO:Copying training dataset
2025-06-02 15:23:00,540:INFO:Defining folds
2025-06-02 15:23:00,542:INFO:Declaring metric variables
2025-06-02 15:23:00,577:INFO:Importing untrained model
2025-06-02 15:23:00,578:INFO:Declaring custom model
2025-06-02 15:23:00,603:INFO:Extra Trees Regressor Imported successfully
2025-06-02 15:23:00,628:INFO:Starting cross validation
2025-06-02 15:23:00,634:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:23:08,417:INFO:Calculating mean and std
2025-06-02 15:23:08,420:INFO:Creating metrics dataframe
2025-06-02 15:23:08,435:INFO:Finalizing model
2025-06-02 15:23:11,509:INFO:Uploading results into container
2025-06-02 15:23:11,511:INFO:Uploading model into container now
2025-06-02 15:23:11,514:INFO:_master_model_container: 21
2025-06-02 15:23:11,514:INFO:_display_container: 3
2025-06-02 15:23:11,516:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=11,
                    max_features=0.4556655086335653,
                    min_impurity_decrease=0.00012891733508622256,
                    min_samples_split=9, n_estimators=11, n_jobs=-1,
                    random_state=123)
2025-06-02 15:23:11,517:INFO:create_model() successfully completed......................................
2025-06-02 15:23:13,317:INFO:SubProcess create_model() end ==================================
2025-06-02 15:23:13,326:INFO:choose_better activated
2025-06-02 15:23:13,335:INFO:SubProcess create_model() called ==================================
2025-06-02 15:23:13,336:INFO:Initializing create_model()
2025-06-02 15:23:13,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:23:13,337:INFO:Checking exceptions
2025-06-02 15:23:13,340:INFO:Importing libraries
2025-06-02 15:23:13,341:INFO:Copying training dataset
2025-06-02 15:23:13,413:INFO:Defining folds
2025-06-02 15:23:13,413:INFO:Declaring metric variables
2025-06-02 15:23:13,413:INFO:Importing untrained model
2025-06-02 15:23:13,413:INFO:Declaring custom model
2025-06-02 15:23:13,415:INFO:Extra Trees Regressor Imported successfully
2025-06-02 15:23:13,415:INFO:Starting cross validation
2025-06-02 15:23:13,418:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:23:19,096:INFO:Calculating mean and std
2025-06-02 15:23:19,098:INFO:Creating metrics dataframe
2025-06-02 15:23:19,101:INFO:Finalizing model
2025-06-02 15:23:20,698:INFO:Uploading results into container
2025-06-02 15:23:20,699:INFO:Uploading model into container now
2025-06-02 15:23:20,700:INFO:_master_model_container: 22
2025-06-02 15:23:20,700:INFO:_display_container: 4
2025-06-02 15:23:20,701:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:23:20,701:INFO:create_model() successfully completed......................................
2025-06-02 15:23:21,953:INFO:SubProcess create_model() end ==================================
2025-06-02 15:23:21,954:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 0.1708
2025-06-02 15:23:21,956:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=11,
                    max_features=0.4556655086335653,
                    min_impurity_decrease=0.00012891733508622256,
                    min_samples_split=9, n_estimators=11, n_jobs=-1,
                    random_state=123) result for MAE is 0.1994
2025-06-02 15:23:21,956:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 15:23:21,956:INFO:choose_better completed
2025-06-02 15:23:21,957:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 15:23:21,998:INFO:_master_model_container: 22
2025-06-02 15:23:21,998:INFO:_display_container: 3
2025-06-02 15:23:21,999:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:23:22,000:INFO:tune_model() successfully completed......................................
2025-06-02 15:23:23,303:INFO:Initializing finalize_model()
2025-06-02 15:23:23,303:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 15:23:23,304:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:23:23,353:INFO:Initializing create_model()
2025-06-02 15:23:23,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC7FCFD0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:23:23,354:INFO:Checking exceptions
2025-06-02 15:23:23,356:INFO:Importing libraries
2025-06-02 15:23:23,356:INFO:Copying training dataset
2025-06-02 15:23:23,362:INFO:Defining folds
2025-06-02 15:23:23,362:INFO:Declaring metric variables
2025-06-02 15:23:23,363:INFO:Importing untrained model
2025-06-02 15:23:23,363:INFO:Declaring custom model
2025-06-02 15:23:23,364:INFO:Extra Trees Regressor Imported successfully
2025-06-02 15:23:23,367:INFO:Cross validation set to False
2025-06-02 15:23:23,367:INFO:Fitting Model
2025-06-02 15:23:25,435:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 15:23:25,436:INFO:create_model() successfully completed......................................
2025-06-02 15:23:26,695:INFO:_master_model_container: 22
2025-06-02 15:23:26,695:INFO:_display_container: 3
2025-06-02 15:23:26,714:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 15:23:26,714:INFO:finalize_model() successfully completed......................................
2025-06-02 15:23:27,996:INFO:Initializing save_model()
2025-06-02 15:23:27,996:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 15:23:27,996:INFO:Adding model into prep_pipe
2025-06-02 15:23:27,996:WARNING:Only Model saved as it was a pipeline.
2025-06-02 15:23:28,133:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 15:23:28,148:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 15:23:28,148:INFO:save_model() successfully completed......................................
2025-06-02 15:28:35,928:INFO:PyCaret RegressionExperiment
2025-06-02 15:28:35,929:INFO:Logging name: reg-default-name
2025-06-02 15:28:35,930:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 15:28:35,931:INFO:version 3.3.2
2025-06-02 15:28:35,931:INFO:Initializing setup()
2025-06-02 15:28:35,932:INFO:self.USI: 4dbf
2025-06-02 15:28:35,933:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 15:28:35,934:INFO:Checking environment
2025-06-02 15:28:35,934:INFO:python_version: 3.10.16
2025-06-02 15:28:35,935:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 15:28:35,935:INFO:machine: AMD64
2025-06-02 15:28:35,936:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 15:28:35,944:INFO:Memory: svmem(total=6378008576, available=896520192, percent=85.9, used=5481488384, free=896520192)
2025-06-02 15:28:35,945:INFO:Physical Core: 4
2025-06-02 15:28:35,945:INFO:Logical Core: 8
2025-06-02 15:28:35,946:INFO:Checking libraries
2025-06-02 15:28:35,947:INFO:System:
2025-06-02 15:28:35,947:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 15:28:35,948:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 15:28:35,948:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 15:28:35,948:INFO:PyCaret required dependencies:
2025-06-02 15:28:35,951:INFO:                 pip: 25.1
2025-06-02 15:28:35,951:INFO:          setuptools: 78.1.1
2025-06-02 15:28:35,951:INFO:             pycaret: 3.3.2
2025-06-02 15:28:35,951:INFO:             IPython: 8.37.0
2025-06-02 15:28:35,951:INFO:          ipywidgets: 8.1.7
2025-06-02 15:28:35,952:INFO:                tqdm: 4.67.1
2025-06-02 15:28:35,952:INFO:               numpy: 1.26.4
2025-06-02 15:28:35,952:INFO:              pandas: 2.0.1
2025-06-02 15:28:35,952:INFO:              jinja2: 3.1.6
2025-06-02 15:28:35,952:INFO:               scipy: 1.10.1
2025-06-02 15:28:35,952:INFO:              joblib: 1.3.2
2025-06-02 15:28:35,952:INFO:             sklearn: 1.4.2
2025-06-02 15:28:35,952:INFO:                pyod: 2.0.5
2025-06-02 15:28:35,952:INFO:            imblearn: 0.13.0
2025-06-02 15:28:35,952:INFO:   category_encoders: 2.7.0
2025-06-02 15:28:35,953:INFO:            lightgbm: 4.6.0
2025-06-02 15:28:35,953:INFO:               numba: 0.61.0
2025-06-02 15:28:35,953:INFO:            requests: 2.32.3
2025-06-02 15:28:35,953:INFO:          matplotlib: 3.7.1
2025-06-02 15:28:35,953:INFO:          scikitplot: 0.3.7
2025-06-02 15:28:35,953:INFO:         yellowbrick: 1.5
2025-06-02 15:28:35,953:INFO:              plotly: 6.1.2
2025-06-02 15:28:35,953:INFO:    plotly-resampler: Not installed
2025-06-02 15:28:35,953:INFO:             kaleido: 0.2.1
2025-06-02 15:28:35,953:INFO:           schemdraw: 0.15
2025-06-02 15:28:35,953:INFO:         statsmodels: 0.14.4
2025-06-02 15:28:35,954:INFO:              sktime: 0.26.0
2025-06-02 15:28:35,954:INFO:               tbats: 1.1.3
2025-06-02 15:28:35,954:INFO:            pmdarima: 2.0.4
2025-06-02 15:28:35,954:INFO:              psutil: 7.0.0
2025-06-02 15:28:35,954:INFO:          markupsafe: 2.1.2
2025-06-02 15:28:35,954:INFO:             pickle5: Not installed
2025-06-02 15:28:35,954:INFO:         cloudpickle: 3.1.1
2025-06-02 15:28:35,954:INFO:         deprecation: 2.1.0
2025-06-02 15:28:35,954:INFO:              xxhash: 3.5.0
2025-06-02 15:28:35,954:INFO:           wurlitzer: Not installed
2025-06-02 15:28:35,954:INFO:PyCaret optional dependencies:
2025-06-02 15:28:35,955:INFO:                shap: 0.44.1
2025-06-02 15:28:35,955:INFO:           interpret: 0.6.9
2025-06-02 15:28:35,955:INFO:                umap: 0.5.7
2025-06-02 15:28:35,955:INFO:     ydata_profiling: 4.16.1
2025-06-02 15:28:35,955:INFO:  explainerdashboard: 0.4.8
2025-06-02 15:28:35,955:INFO:             autoviz: Not installed
2025-06-02 15:28:35,955:INFO:           fairlearn: 0.7.0
2025-06-02 15:28:35,956:INFO:          deepchecks: Not installed
2025-06-02 15:28:35,956:INFO:             xgboost: 3.0.2
2025-06-02 15:28:35,956:INFO:            catboost: 1.2.8
2025-06-02 15:28:35,956:INFO:              kmodes: 0.12.2
2025-06-02 15:28:35,956:INFO:             mlxtend: 0.23.4
2025-06-02 15:28:35,956:INFO:       statsforecast: 1.5.0
2025-06-02 15:28:35,956:INFO:        tune_sklearn: Not installed
2025-06-02 15:28:35,957:INFO:                 ray: Not installed
2025-06-02 15:28:35,957:INFO:            hyperopt: 0.2.7
2025-06-02 15:28:35,957:INFO:              optuna: 4.3.0
2025-06-02 15:28:35,957:INFO:               skopt: 0.10.2
2025-06-02 15:28:35,957:INFO:              mlflow: 2.22.0
2025-06-02 15:28:35,957:INFO:              gradio: 5.32.0
2025-06-02 15:28:35,957:INFO:             fastapi: 0.115.12
2025-06-02 15:28:35,958:INFO:             uvicorn: 0.34.3
2025-06-02 15:28:35,958:INFO:              m2cgen: 0.10.0
2025-06-02 15:28:35,958:INFO:           evidently: 0.4.40
2025-06-02 15:28:35,958:INFO:               fugue: 0.8.5
2025-06-02 15:28:35,958:INFO:           streamlit: Not installed
2025-06-02 15:28:35,958:INFO:             prophet: Not installed
2025-06-02 15:28:35,958:INFO:None
2025-06-02 15:28:35,958:INFO:Set up data.
2025-06-02 15:28:36,180:INFO:Set up folding strategy.
2025-06-02 15:28:36,180:INFO:Set up train/test split.
2025-06-02 15:28:36,302:INFO:Set up index.
2025-06-02 15:28:36,324:INFO:Assigning column types.
2025-06-02 15:28:36,397:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 15:28:36,400:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 15:28:36,410:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 15:28:36,420:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:28:36,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:28:36,656:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:28:36,658:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:28:36,665:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:28:36,666:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 15:28:36,674:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 15:28:36,682:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:28:36,823:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:28:36,905:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:28:36,906:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:28:36,910:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:28:36,911:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 15:28:36,920:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 15:28:36,928:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:28:37,074:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:28:37,148:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:28:37,149:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:28:37,153:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:28:37,161:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 15:28:37,169:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:28:37,315:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:28:37,404:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:28:37,405:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:28:37,412:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:28:37,413:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 15:28:37,433:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:28:37,600:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:28:37,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:28:37,687:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:28:37,691:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:28:37,707:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 15:28:37,852:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:28:37,932:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:28:37,933:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:28:37,937:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:28:37,938:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 15:28:38,097:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:28:38,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:28:38,178:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:28:38,184:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:28:38,353:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:28:38,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 15:28:38,438:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:28:38,446:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:28:38,447:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 15:28:38,588:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:28:38,662:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:28:38,666:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:28:38,817:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 15:28:38,895:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:28:38,902:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:28:38,904:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 15:28:39,138:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:28:39,142:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:28:39,360:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:28:39,365:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:28:39,372:INFO:Preparing preprocessing pipeline...
2025-06-02 15:28:39,373:INFO:Set up simple imputation.
2025-06-02 15:28:39,373:INFO:Set up removing multicollinearity.
2025-06-02 15:28:39,380:INFO:Set up column name cleaning.
2025-06-02 15:28:39,626:INFO:Finished creating preprocessing pipeline.
2025-06-02 15:28:39,642:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 15:28:39,643:INFO:Creating final display dataframe.
2025-06-02 15:28:40,058:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              4dbf
2025-06-02 15:28:40,321:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:28:40,326:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:28:40,558:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 15:28:40,563:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 15:28:40,565:INFO:setup() successfully completed in 4.71s...............
2025-06-02 15:28:40,585:INFO:Initializing compare_models()
2025-06-02 15:28:40,585:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 15:28:40,585:INFO:Checking exceptions
2025-06-02 15:28:40,606:INFO:Preparing display monitor
2025-06-02 15:28:40,675:INFO:Initializing Linear Regression
2025-06-02 15:28:40,675:INFO:Total runtime is 0.0 minutes
2025-06-02 15:28:40,687:INFO:SubProcess create_model() called ==================================
2025-06-02 15:28:40,688:INFO:Initializing create_model()
2025-06-02 15:28:40,688:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:28:40,688:INFO:Checking exceptions
2025-06-02 15:28:40,689:INFO:Importing libraries
2025-06-02 15:28:40,689:INFO:Copying training dataset
2025-06-02 15:28:40,786:INFO:Defining folds
2025-06-02 15:28:40,786:INFO:Declaring metric variables
2025-06-02 15:28:40,796:INFO:Importing untrained model
2025-06-02 15:28:40,815:INFO:Linear Regression Imported successfully
2025-06-02 15:28:40,864:INFO:Starting cross validation
2025-06-02 15:28:40,871:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:28:55,539:INFO:Calculating mean and std
2025-06-02 15:28:55,556:INFO:Creating metrics dataframe
2025-06-02 15:28:55,575:INFO:Uploading results into container
2025-06-02 15:28:55,582:INFO:Uploading model into container now
2025-06-02 15:28:55,585:INFO:_master_model_container: 1
2025-06-02 15:28:55,585:INFO:_display_container: 2
2025-06-02 15:28:55,586:INFO:LinearRegression(n_jobs=-1)
2025-06-02 15:28:55,586:INFO:create_model() successfully completed......................................
2025-06-02 15:29:06,891:INFO:SubProcess create_model() end ==================================
2025-06-02 15:29:06,892:INFO:Creating metrics dataframe
2025-06-02 15:29:06,922:INFO:Initializing Lasso Regression
2025-06-02 15:29:06,922:INFO:Total runtime is 0.43745596408843995 minutes
2025-06-02 15:29:06,937:INFO:SubProcess create_model() called ==================================
2025-06-02 15:29:06,937:INFO:Initializing create_model()
2025-06-02 15:29:06,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:29:06,938:INFO:Checking exceptions
2025-06-02 15:29:06,939:INFO:Importing libraries
2025-06-02 15:29:06,939:INFO:Copying training dataset
2025-06-02 15:29:07,040:INFO:Defining folds
2025-06-02 15:29:07,041:INFO:Declaring metric variables
2025-06-02 15:29:07,053:INFO:Importing untrained model
2025-06-02 15:29:07,065:INFO:Lasso Regression Imported successfully
2025-06-02 15:29:07,089:INFO:Starting cross validation
2025-06-02 15:29:07,093:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:29:17,442:INFO:Calculating mean and std
2025-06-02 15:29:17,451:INFO:Creating metrics dataframe
2025-06-02 15:29:17,461:INFO:Uploading results into container
2025-06-02 15:29:17,463:INFO:Uploading model into container now
2025-06-02 15:29:17,465:INFO:_master_model_container: 2
2025-06-02 15:29:17,465:INFO:_display_container: 2
2025-06-02 15:29:17,470:INFO:Lasso(random_state=123)
2025-06-02 15:29:17,470:INFO:create_model() successfully completed......................................
2025-06-02 15:29:20,122:INFO:SubProcess create_model() end ==================================
2025-06-02 15:29:20,123:INFO:Creating metrics dataframe
2025-06-02 15:29:20,144:INFO:Initializing Ridge Regression
2025-06-02 15:29:20,144:INFO:Total runtime is 0.6578240513801574 minutes
2025-06-02 15:29:20,157:INFO:SubProcess create_model() called ==================================
2025-06-02 15:29:20,157:INFO:Initializing create_model()
2025-06-02 15:29:20,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:29:20,158:INFO:Checking exceptions
2025-06-02 15:29:20,158:INFO:Importing libraries
2025-06-02 15:29:20,158:INFO:Copying training dataset
2025-06-02 15:29:20,246:INFO:Defining folds
2025-06-02 15:29:20,247:INFO:Declaring metric variables
2025-06-02 15:29:20,263:INFO:Importing untrained model
2025-06-02 15:29:20,275:INFO:Ridge Regression Imported successfully
2025-06-02 15:29:20,302:INFO:Starting cross validation
2025-06-02 15:29:20,308:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:29:20,930:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.75561e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 15:29:20,962:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31073e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 15:29:20,993:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.24347e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 15:29:21,032:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.08754e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 15:29:21,163:INFO:Calculating mean and std
2025-06-02 15:29:21,167:INFO:Creating metrics dataframe
2025-06-02 15:29:21,173:INFO:Uploading results into container
2025-06-02 15:29:21,174:INFO:Uploading model into container now
2025-06-02 15:29:21,175:INFO:_master_model_container: 3
2025-06-02 15:29:21,175:INFO:_display_container: 2
2025-06-02 15:29:21,177:INFO:Ridge(random_state=123)
2025-06-02 15:29:21,177:INFO:create_model() successfully completed......................................
2025-06-02 15:29:22,495:INFO:SubProcess create_model() end ==================================
2025-06-02 15:29:22,495:INFO:Creating metrics dataframe
2025-06-02 15:29:22,512:INFO:Initializing Elastic Net
2025-06-02 15:29:22,512:INFO:Total runtime is 0.6972888112068176 minutes
2025-06-02 15:29:22,522:INFO:SubProcess create_model() called ==================================
2025-06-02 15:29:22,523:INFO:Initializing create_model()
2025-06-02 15:29:22,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:29:22,523:INFO:Checking exceptions
2025-06-02 15:29:22,524:INFO:Importing libraries
2025-06-02 15:29:22,524:INFO:Copying training dataset
2025-06-02 15:29:22,585:INFO:Defining folds
2025-06-02 15:29:22,586:INFO:Declaring metric variables
2025-06-02 15:29:22,600:INFO:Importing untrained model
2025-06-02 15:29:22,616:INFO:Elastic Net Imported successfully
2025-06-02 15:29:22,643:INFO:Starting cross validation
2025-06-02 15:29:22,647:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:29:23,470:INFO:Calculating mean and std
2025-06-02 15:29:23,472:INFO:Creating metrics dataframe
2025-06-02 15:29:23,475:INFO:Uploading results into container
2025-06-02 15:29:23,476:INFO:Uploading model into container now
2025-06-02 15:29:23,476:INFO:_master_model_container: 4
2025-06-02 15:29:23,477:INFO:_display_container: 2
2025-06-02 15:29:23,477:INFO:ElasticNet(random_state=123)
2025-06-02 15:29:23,477:INFO:create_model() successfully completed......................................
2025-06-02 15:29:24,814:INFO:SubProcess create_model() end ==================================
2025-06-02 15:29:24,814:INFO:Creating metrics dataframe
2025-06-02 15:29:24,830:INFO:Initializing Least Angle Regression
2025-06-02 15:29:24,830:INFO:Total runtime is 0.7359206755956014 minutes
2025-06-02 15:29:24,841:INFO:SubProcess create_model() called ==================================
2025-06-02 15:29:24,843:INFO:Initializing create_model()
2025-06-02 15:29:24,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:29:24,843:INFO:Checking exceptions
2025-06-02 15:29:24,843:INFO:Importing libraries
2025-06-02 15:29:24,844:INFO:Copying training dataset
2025-06-02 15:29:24,911:INFO:Defining folds
2025-06-02 15:29:24,911:INFO:Declaring metric variables
2025-06-02 15:29:24,925:INFO:Importing untrained model
2025-06-02 15:29:24,936:INFO:Least Angle Regression Imported successfully
2025-06-02 15:29:24,960:INFO:Starting cross validation
2025-06-02 15:29:24,967:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:29:26,417:INFO:Calculating mean and std
2025-06-02 15:29:26,420:INFO:Creating metrics dataframe
2025-06-02 15:29:26,425:INFO:Uploading results into container
2025-06-02 15:29:26,426:INFO:Uploading model into container now
2025-06-02 15:29:26,427:INFO:_master_model_container: 5
2025-06-02 15:29:26,427:INFO:_display_container: 2
2025-06-02 15:29:26,434:INFO:Lars(random_state=123)
2025-06-02 15:29:26,436:INFO:create_model() successfully completed......................................
2025-06-02 15:29:28,730:INFO:SubProcess create_model() end ==================================
2025-06-02 15:29:28,732:INFO:Creating metrics dataframe
2025-06-02 15:29:28,753:INFO:Initializing Lasso Least Angle Regression
2025-06-02 15:29:28,753:INFO:Total runtime is 0.8012945373853048 minutes
2025-06-02 15:29:28,764:INFO:SubProcess create_model() called ==================================
2025-06-02 15:29:28,764:INFO:Initializing create_model()
2025-06-02 15:29:28,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:29:28,765:INFO:Checking exceptions
2025-06-02 15:29:28,766:INFO:Importing libraries
2025-06-02 15:29:28,767:INFO:Copying training dataset
2025-06-02 15:29:28,840:INFO:Defining folds
2025-06-02 15:29:28,840:INFO:Declaring metric variables
2025-06-02 15:29:28,854:INFO:Importing untrained model
2025-06-02 15:29:28,867:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 15:29:28,894:INFO:Starting cross validation
2025-06-02 15:29:28,899:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:29:29,722:INFO:Calculating mean and std
2025-06-02 15:29:29,725:INFO:Creating metrics dataframe
2025-06-02 15:29:29,729:INFO:Uploading results into container
2025-06-02 15:29:29,730:INFO:Uploading model into container now
2025-06-02 15:29:29,731:INFO:_master_model_container: 6
2025-06-02 15:29:29,731:INFO:_display_container: 2
2025-06-02 15:29:29,732:INFO:LassoLars(random_state=123)
2025-06-02 15:29:29,733:INFO:create_model() successfully completed......................................
2025-06-02 15:29:31,025:INFO:SubProcess create_model() end ==================================
2025-06-02 15:29:31,025:INFO:Creating metrics dataframe
2025-06-02 15:29:31,041:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 15:29:31,041:INFO:Total runtime is 0.8394260565439859 minutes
2025-06-02 15:29:31,052:INFO:SubProcess create_model() called ==================================
2025-06-02 15:29:31,053:INFO:Initializing create_model()
2025-06-02 15:29:31,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:29:31,054:INFO:Checking exceptions
2025-06-02 15:29:31,054:INFO:Importing libraries
2025-06-02 15:29:31,055:INFO:Copying training dataset
2025-06-02 15:29:31,124:INFO:Defining folds
2025-06-02 15:29:31,125:INFO:Declaring metric variables
2025-06-02 15:29:31,138:INFO:Importing untrained model
2025-06-02 15:29:31,149:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 15:29:31,175:INFO:Starting cross validation
2025-06-02 15:29:31,179:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:29:31,955:INFO:Calculating mean and std
2025-06-02 15:29:31,958:INFO:Creating metrics dataframe
2025-06-02 15:29:31,961:INFO:Uploading results into container
2025-06-02 15:29:31,962:INFO:Uploading model into container now
2025-06-02 15:29:31,963:INFO:_master_model_container: 7
2025-06-02 15:29:31,963:INFO:_display_container: 2
2025-06-02 15:29:31,963:INFO:OrthogonalMatchingPursuit()
2025-06-02 15:29:31,964:INFO:create_model() successfully completed......................................
2025-06-02 15:29:33,247:INFO:SubProcess create_model() end ==================================
2025-06-02 15:29:33,248:INFO:Creating metrics dataframe
2025-06-02 15:29:33,267:INFO:Initializing Bayesian Ridge
2025-06-02 15:29:33,267:INFO:Total runtime is 0.8765329639116922 minutes
2025-06-02 15:29:33,276:INFO:SubProcess create_model() called ==================================
2025-06-02 15:29:33,276:INFO:Initializing create_model()
2025-06-02 15:29:33,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:29:33,277:INFO:Checking exceptions
2025-06-02 15:29:33,277:INFO:Importing libraries
2025-06-02 15:29:33,278:INFO:Copying training dataset
2025-06-02 15:29:33,340:INFO:Defining folds
2025-06-02 15:29:33,340:INFO:Declaring metric variables
2025-06-02 15:29:33,354:INFO:Importing untrained model
2025-06-02 15:29:33,368:INFO:Bayesian Ridge Imported successfully
2025-06-02 15:29:33,391:INFO:Starting cross validation
2025-06-02 15:29:33,395:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:29:34,207:INFO:Calculating mean and std
2025-06-02 15:29:34,209:INFO:Creating metrics dataframe
2025-06-02 15:29:34,213:INFO:Uploading results into container
2025-06-02 15:29:34,215:INFO:Uploading model into container now
2025-06-02 15:29:34,215:INFO:_master_model_container: 8
2025-06-02 15:29:34,216:INFO:_display_container: 2
2025-06-02 15:29:34,216:INFO:BayesianRidge()
2025-06-02 15:29:34,217:INFO:create_model() successfully completed......................................
2025-06-02 15:29:35,513:INFO:SubProcess create_model() end ==================================
2025-06-02 15:29:35,513:INFO:Creating metrics dataframe
2025-06-02 15:29:35,531:INFO:Initializing Passive Aggressive Regressor
2025-06-02 15:29:35,531:INFO:Total runtime is 0.9142725706100463 minutes
2025-06-02 15:29:35,541:INFO:SubProcess create_model() called ==================================
2025-06-02 15:29:35,542:INFO:Initializing create_model()
2025-06-02 15:29:35,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:29:35,542:INFO:Checking exceptions
2025-06-02 15:29:35,543:INFO:Importing libraries
2025-06-02 15:29:35,543:INFO:Copying training dataset
2025-06-02 15:29:35,618:INFO:Defining folds
2025-06-02 15:29:35,619:INFO:Declaring metric variables
2025-06-02 15:29:35,629:INFO:Importing untrained model
2025-06-02 15:29:35,642:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 15:29:35,667:INFO:Starting cross validation
2025-06-02 15:29:35,671:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:29:36,773:INFO:Calculating mean and std
2025-06-02 15:29:36,775:INFO:Creating metrics dataframe
2025-06-02 15:29:36,778:INFO:Uploading results into container
2025-06-02 15:29:36,779:INFO:Uploading model into container now
2025-06-02 15:29:36,780:INFO:_master_model_container: 9
2025-06-02 15:29:36,781:INFO:_display_container: 2
2025-06-02 15:29:36,781:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 15:29:36,782:INFO:create_model() successfully completed......................................
2025-06-02 15:29:38,062:INFO:SubProcess create_model() end ==================================
2025-06-02 15:29:38,063:INFO:Creating metrics dataframe
2025-06-02 15:29:38,082:INFO:Initializing Huber Regressor
2025-06-02 15:29:38,082:INFO:Total runtime is 0.9567888935407002 minutes
2025-06-02 15:29:38,096:INFO:SubProcess create_model() called ==================================
2025-06-02 15:29:38,096:INFO:Initializing create_model()
2025-06-02 15:29:38,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:29:38,097:INFO:Checking exceptions
2025-06-02 15:29:38,098:INFO:Importing libraries
2025-06-02 15:29:38,098:INFO:Copying training dataset
2025-06-02 15:29:38,178:INFO:Defining folds
2025-06-02 15:29:38,179:INFO:Declaring metric variables
2025-06-02 15:29:38,193:INFO:Importing untrained model
2025-06-02 15:29:38,206:INFO:Huber Regressor Imported successfully
2025-06-02 15:29:38,232:INFO:Starting cross validation
2025-06-02 15:29:38,238:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:29:40,541:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:29:40,595:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:29:40,648:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:29:40,760:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:29:40,795:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 15:29:40,863:INFO:Calculating mean and std
2025-06-02 15:29:40,866:INFO:Creating metrics dataframe
2025-06-02 15:29:40,870:INFO:Uploading results into container
2025-06-02 15:29:40,871:INFO:Uploading model into container now
2025-06-02 15:29:40,872:INFO:_master_model_container: 10
2025-06-02 15:29:40,873:INFO:_display_container: 2
2025-06-02 15:29:40,873:INFO:HuberRegressor()
2025-06-02 15:29:40,874:INFO:create_model() successfully completed......................................
2025-06-02 15:29:42,691:INFO:SubProcess create_model() end ==================================
2025-06-02 15:29:42,691:INFO:Creating metrics dataframe
2025-06-02 15:29:42,709:INFO:Initializing K Neighbors Regressor
2025-06-02 15:29:42,710:INFO:Total runtime is 1.033918535709381 minutes
2025-06-02 15:29:42,722:INFO:SubProcess create_model() called ==================================
2025-06-02 15:29:42,723:INFO:Initializing create_model()
2025-06-02 15:29:42,723:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:29:42,724:INFO:Checking exceptions
2025-06-02 15:29:42,724:INFO:Importing libraries
2025-06-02 15:29:42,725:INFO:Copying training dataset
2025-06-02 15:29:42,804:INFO:Defining folds
2025-06-02 15:29:42,804:INFO:Declaring metric variables
2025-06-02 15:29:42,818:INFO:Importing untrained model
2025-06-02 15:29:42,834:INFO:K Neighbors Regressor Imported successfully
2025-06-02 15:29:42,865:INFO:Starting cross validation
2025-06-02 15:29:42,871:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:29:43,774:INFO:Calculating mean and std
2025-06-02 15:29:43,776:INFO:Creating metrics dataframe
2025-06-02 15:29:43,780:INFO:Uploading results into container
2025-06-02 15:29:43,781:INFO:Uploading model into container now
2025-06-02 15:29:43,782:INFO:_master_model_container: 11
2025-06-02 15:29:43,782:INFO:_display_container: 2
2025-06-02 15:29:43,783:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 15:29:43,784:INFO:create_model() successfully completed......................................
2025-06-02 15:29:45,081:INFO:SubProcess create_model() end ==================================
2025-06-02 15:29:45,081:INFO:Creating metrics dataframe
2025-06-02 15:29:45,104:INFO:Initializing Decision Tree Regressor
2025-06-02 15:29:45,104:INFO:Total runtime is 1.0738187432289121 minutes
2025-06-02 15:29:45,115:INFO:SubProcess create_model() called ==================================
2025-06-02 15:29:45,116:INFO:Initializing create_model()
2025-06-02 15:29:45,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:29:45,117:INFO:Checking exceptions
2025-06-02 15:29:45,117:INFO:Importing libraries
2025-06-02 15:29:45,118:INFO:Copying training dataset
2025-06-02 15:29:45,180:INFO:Defining folds
2025-06-02 15:29:45,180:INFO:Declaring metric variables
2025-06-02 15:29:45,193:INFO:Importing untrained model
2025-06-02 15:29:45,205:INFO:Decision Tree Regressor Imported successfully
2025-06-02 15:29:45,231:INFO:Starting cross validation
2025-06-02 15:29:45,235:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:29:46,433:INFO:Calculating mean and std
2025-06-02 15:29:46,436:INFO:Creating metrics dataframe
2025-06-02 15:29:46,440:INFO:Uploading results into container
2025-06-02 15:29:46,440:INFO:Uploading model into container now
2025-06-02 15:29:46,441:INFO:_master_model_container: 12
2025-06-02 15:29:46,441:INFO:_display_container: 2
2025-06-02 15:29:46,442:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 15:29:46,442:INFO:create_model() successfully completed......................................
2025-06-02 15:29:47,756:INFO:SubProcess create_model() end ==================================
2025-06-02 15:29:47,757:INFO:Creating metrics dataframe
2025-06-02 15:29:47,778:INFO:Initializing Random Forest Regressor
2025-06-02 15:29:47,779:INFO:Total runtime is 1.1184046586354572 minutes
2025-06-02 15:29:47,794:INFO:SubProcess create_model() called ==================================
2025-06-02 15:29:47,794:INFO:Initializing create_model()
2025-06-02 15:29:47,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:29:47,795:INFO:Checking exceptions
2025-06-02 15:29:47,796:INFO:Importing libraries
2025-06-02 15:29:47,796:INFO:Copying training dataset
2025-06-02 15:29:47,867:INFO:Defining folds
2025-06-02 15:29:47,868:INFO:Declaring metric variables
2025-06-02 15:29:47,883:INFO:Importing untrained model
2025-06-02 15:29:47,895:INFO:Random Forest Regressor Imported successfully
2025-06-02 15:29:47,924:INFO:Starting cross validation
2025-06-02 15:29:47,928:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:29:56,822:INFO:Calculating mean and std
2025-06-02 15:29:56,825:INFO:Creating metrics dataframe
2025-06-02 15:29:56,829:INFO:Uploading results into container
2025-06-02 15:29:56,830:INFO:Uploading model into container now
2025-06-02 15:29:56,831:INFO:_master_model_container: 13
2025-06-02 15:29:56,832:INFO:_display_container: 2
2025-06-02 15:29:56,833:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:29:56,834:INFO:create_model() successfully completed......................................
2025-06-02 15:29:58,318:INFO:SubProcess create_model() end ==================================
2025-06-02 15:29:58,319:INFO:Creating metrics dataframe
2025-06-02 15:29:58,344:INFO:Initializing Extra Trees Regressor
2025-06-02 15:29:58,344:INFO:Total runtime is 1.2944800774256386 minutes
2025-06-02 15:29:58,359:INFO:SubProcess create_model() called ==================================
2025-06-02 15:29:58,360:INFO:Initializing create_model()
2025-06-02 15:29:58,360:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:29:58,360:INFO:Checking exceptions
2025-06-02 15:29:58,361:INFO:Importing libraries
2025-06-02 15:29:58,361:INFO:Copying training dataset
2025-06-02 15:29:58,450:INFO:Defining folds
2025-06-02 15:29:58,451:INFO:Declaring metric variables
2025-06-02 15:29:58,464:INFO:Importing untrained model
2025-06-02 15:29:58,477:INFO:Extra Trees Regressor Imported successfully
2025-06-02 15:29:58,508:INFO:Starting cross validation
2025-06-02 15:29:58,511:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:30:05,193:INFO:Calculating mean and std
2025-06-02 15:30:05,196:INFO:Creating metrics dataframe
2025-06-02 15:30:05,202:INFO:Uploading results into container
2025-06-02 15:30:05,203:INFO:Uploading model into container now
2025-06-02 15:30:05,205:INFO:_master_model_container: 14
2025-06-02 15:30:05,205:INFO:_display_container: 2
2025-06-02 15:30:05,206:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:30:05,206:INFO:create_model() successfully completed......................................
2025-06-02 15:30:06,677:INFO:SubProcess create_model() end ==================================
2025-06-02 15:30:06,678:INFO:Creating metrics dataframe
2025-06-02 15:30:06,705:INFO:Initializing AdaBoost Regressor
2025-06-02 15:30:06,706:INFO:Total runtime is 1.4338440020879109 minutes
2025-06-02 15:30:06,717:INFO:SubProcess create_model() called ==================================
2025-06-02 15:30:06,718:INFO:Initializing create_model()
2025-06-02 15:30:06,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:30:06,718:INFO:Checking exceptions
2025-06-02 15:30:06,719:INFO:Importing libraries
2025-06-02 15:30:06,719:INFO:Copying training dataset
2025-06-02 15:30:06,795:INFO:Defining folds
2025-06-02 15:30:06,796:INFO:Declaring metric variables
2025-06-02 15:30:06,811:INFO:Importing untrained model
2025-06-02 15:30:06,824:INFO:AdaBoost Regressor Imported successfully
2025-06-02 15:30:06,850:INFO:Starting cross validation
2025-06-02 15:30:06,854:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:30:09,202:INFO:Calculating mean and std
2025-06-02 15:30:09,204:INFO:Creating metrics dataframe
2025-06-02 15:30:09,207:INFO:Uploading results into container
2025-06-02 15:30:09,208:INFO:Uploading model into container now
2025-06-02 15:30:09,209:INFO:_master_model_container: 15
2025-06-02 15:30:09,210:INFO:_display_container: 2
2025-06-02 15:30:09,211:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 15:30:09,211:INFO:create_model() successfully completed......................................
2025-06-02 15:30:10,507:INFO:SubProcess create_model() end ==================================
2025-06-02 15:30:10,507:INFO:Creating metrics dataframe
2025-06-02 15:30:10,538:INFO:Initializing Gradient Boosting Regressor
2025-06-02 15:30:10,539:INFO:Total runtime is 1.497735551993052 minutes
2025-06-02 15:30:10,549:INFO:SubProcess create_model() called ==================================
2025-06-02 15:30:10,550:INFO:Initializing create_model()
2025-06-02 15:30:10,550:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:30:10,550:INFO:Checking exceptions
2025-06-02 15:30:10,551:INFO:Importing libraries
2025-06-02 15:30:10,551:INFO:Copying training dataset
2025-06-02 15:30:10,612:INFO:Defining folds
2025-06-02 15:30:10,612:INFO:Declaring metric variables
2025-06-02 15:30:10,626:INFO:Importing untrained model
2025-06-02 15:30:10,638:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 15:30:10,664:INFO:Starting cross validation
2025-06-02 15:30:10,668:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:30:14,155:INFO:Calculating mean and std
2025-06-02 15:30:14,159:INFO:Creating metrics dataframe
2025-06-02 15:30:14,162:INFO:Uploading results into container
2025-06-02 15:30:14,164:INFO:Uploading model into container now
2025-06-02 15:30:14,167:INFO:_master_model_container: 16
2025-06-02 15:30:14,168:INFO:_display_container: 2
2025-06-02 15:30:14,169:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 15:30:14,169:INFO:create_model() successfully completed......................................
2025-06-02 15:30:15,467:INFO:SubProcess create_model() end ==================================
2025-06-02 15:30:15,468:INFO:Creating metrics dataframe
2025-06-02 15:30:15,492:INFO:Initializing Extreme Gradient Boosting
2025-06-02 15:30:15,492:INFO:Total runtime is 1.5802823146184284 minutes
2025-06-02 15:30:15,502:INFO:SubProcess create_model() called ==================================
2025-06-02 15:30:15,503:INFO:Initializing create_model()
2025-06-02 15:30:15,503:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:30:15,503:INFO:Checking exceptions
2025-06-02 15:30:15,504:INFO:Importing libraries
2025-06-02 15:30:15,504:INFO:Copying training dataset
2025-06-02 15:30:15,571:INFO:Defining folds
2025-06-02 15:30:15,572:INFO:Declaring metric variables
2025-06-02 15:30:15,586:INFO:Importing untrained model
2025-06-02 15:30:15,601:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 15:30:15,629:INFO:Starting cross validation
2025-06-02 15:30:15,634:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:30:18,069:INFO:Calculating mean and std
2025-06-02 15:30:18,072:INFO:Creating metrics dataframe
2025-06-02 15:30:18,076:INFO:Uploading results into container
2025-06-02 15:30:18,077:INFO:Uploading model into container now
2025-06-02 15:30:18,078:INFO:_master_model_container: 17
2025-06-02 15:30:18,078:INFO:_display_container: 2
2025-06-02 15:30:18,083:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 15:30:18,083:INFO:create_model() successfully completed......................................
2025-06-02 15:30:19,387:INFO:SubProcess create_model() end ==================================
2025-06-02 15:30:19,387:INFO:Creating metrics dataframe
2025-06-02 15:30:19,409:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 15:30:19,409:INFO:Total runtime is 1.6455724636713662 minutes
2025-06-02 15:30:19,419:INFO:SubProcess create_model() called ==================================
2025-06-02 15:30:19,420:INFO:Initializing create_model()
2025-06-02 15:30:19,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:30:19,420:INFO:Checking exceptions
2025-06-02 15:30:19,421:INFO:Importing libraries
2025-06-02 15:30:19,421:INFO:Copying training dataset
2025-06-02 15:30:19,488:INFO:Defining folds
2025-06-02 15:30:19,488:INFO:Declaring metric variables
2025-06-02 15:30:19,503:INFO:Importing untrained model
2025-06-02 15:30:19,517:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 15:30:19,540:INFO:Starting cross validation
2025-06-02 15:30:19,544:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:30:21,348:INFO:Calculating mean and std
2025-06-02 15:30:21,351:INFO:Creating metrics dataframe
2025-06-02 15:30:21,355:INFO:Uploading results into container
2025-06-02 15:30:21,356:INFO:Uploading model into container now
2025-06-02 15:30:21,357:INFO:_master_model_container: 18
2025-06-02 15:30:21,358:INFO:_display_container: 2
2025-06-02 15:30:21,359:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:30:21,359:INFO:create_model() successfully completed......................................
2025-06-02 15:30:22,646:INFO:SubProcess create_model() end ==================================
2025-06-02 15:30:22,646:INFO:Creating metrics dataframe
2025-06-02 15:30:22,670:INFO:Initializing CatBoost Regressor
2025-06-02 15:30:22,670:INFO:Total runtime is 1.6999204357465107 minutes
2025-06-02 15:30:22,678:INFO:SubProcess create_model() called ==================================
2025-06-02 15:30:22,679:INFO:Initializing create_model()
2025-06-02 15:30:22,680:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:30:22,680:INFO:Checking exceptions
2025-06-02 15:30:22,680:INFO:Importing libraries
2025-06-02 15:30:22,681:INFO:Copying training dataset
2025-06-02 15:30:22,763:INFO:Defining folds
2025-06-02 15:30:22,763:INFO:Declaring metric variables
2025-06-02 15:30:22,776:INFO:Importing untrained model
2025-06-02 15:30:22,800:INFO:CatBoost Regressor Imported successfully
2025-06-02 15:30:22,823:INFO:Starting cross validation
2025-06-02 15:30:22,828:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:30:49,258:INFO:Calculating mean and std
2025-06-02 15:30:49,261:INFO:Creating metrics dataframe
2025-06-02 15:30:49,266:INFO:Uploading results into container
2025-06-02 15:30:49,268:INFO:Uploading model into container now
2025-06-02 15:30:49,269:INFO:_master_model_container: 19
2025-06-02 15:30:49,269:INFO:_display_container: 2
2025-06-02 15:30:49,269:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6E404CC70>
2025-06-02 15:30:49,270:INFO:create_model() successfully completed......................................
2025-06-02 15:30:50,797:INFO:SubProcess create_model() end ==================================
2025-06-02 15:30:50,798:INFO:Creating metrics dataframe
2025-06-02 15:30:50,821:INFO:Initializing Dummy Regressor
2025-06-02 15:30:50,821:INFO:Total runtime is 2.169105799992879 minutes
2025-06-02 15:30:50,831:INFO:SubProcess create_model() called ==================================
2025-06-02 15:30:50,831:INFO:Initializing create_model()
2025-06-02 15:30:50,832:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC119150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:30:50,832:INFO:Checking exceptions
2025-06-02 15:30:50,832:INFO:Importing libraries
2025-06-02 15:30:50,833:INFO:Copying training dataset
2025-06-02 15:30:50,905:INFO:Defining folds
2025-06-02 15:30:50,906:INFO:Declaring metric variables
2025-06-02 15:30:50,921:INFO:Importing untrained model
2025-06-02 15:30:50,933:INFO:Dummy Regressor Imported successfully
2025-06-02 15:30:50,960:INFO:Starting cross validation
2025-06-02 15:30:50,964:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:30:51,844:INFO:Calculating mean and std
2025-06-02 15:30:51,847:INFO:Creating metrics dataframe
2025-06-02 15:30:51,852:INFO:Uploading results into container
2025-06-02 15:30:51,854:INFO:Uploading model into container now
2025-06-02 15:30:51,855:INFO:_master_model_container: 20
2025-06-02 15:30:51,855:INFO:_display_container: 2
2025-06-02 15:30:51,856:INFO:DummyRegressor()
2025-06-02 15:30:51,856:INFO:create_model() successfully completed......................................
2025-06-02 15:30:53,294:INFO:SubProcess create_model() end ==================================
2025-06-02 15:30:53,294:INFO:Creating metrics dataframe
2025-06-02 15:30:53,343:INFO:Initializing create_model()
2025-06-02 15:30:53,344:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:30:53,344:INFO:Checking exceptions
2025-06-02 15:30:53,356:INFO:Importing libraries
2025-06-02 15:30:53,357:INFO:Copying training dataset
2025-06-02 15:30:53,428:INFO:Defining folds
2025-06-02 15:30:53,428:INFO:Declaring metric variables
2025-06-02 15:30:53,428:INFO:Importing untrained model
2025-06-02 15:30:53,428:INFO:Declaring custom model
2025-06-02 15:30:53,429:INFO:Extra Trees Regressor Imported successfully
2025-06-02 15:30:53,433:INFO:Cross validation set to False
2025-06-02 15:30:53,434:INFO:Fitting Model
2025-06-02 15:30:55,188:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:30:55,188:INFO:create_model() successfully completed......................................
2025-06-02 15:30:56,770:INFO:_master_model_container: 20
2025-06-02 15:30:56,770:INFO:_display_container: 2
2025-06-02 15:30:56,771:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:30:56,772:INFO:compare_models() successfully completed......................................
2025-06-02 15:30:56,855:INFO:Initializing tune_model()
2025-06-02 15:30:56,855:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>)
2025-06-02 15:30:56,855:INFO:Checking exceptions
2025-06-02 15:30:56,856:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 15:30:56,910:INFO:Copying training dataset
2025-06-02 15:30:56,970:INFO:Checking base model
2025-06-02 15:30:56,971:INFO:Base model : Extra Trees Regressor
2025-06-02 15:30:56,985:INFO:Declaring metric variables
2025-06-02 15:30:56,998:INFO:Defining Hyperparameters
2025-06-02 15:30:58,546:INFO:Tuning with n_jobs=-1
2025-06-02 15:30:58,567:INFO:Initializing skopt.BayesSearchCV
2025-06-02 15:34:21,794:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', False), ('actual_estimator__criterion', 'absolute_error'), ('actual_estimator__max_depth', 11), ('actual_estimator__max_features', 0.4556655086335653), ('actual_estimator__min_impurity_decrease', 0.00012891733508622256), ('actual_estimator__min_samples_leaf', 1), ('actual_estimator__min_samples_split', 9), ('actual_estimator__n_estimators', 11)])
2025-06-02 15:34:21,796:INFO:Hyperparameter search completed
2025-06-02 15:34:21,797:INFO:SubProcess create_model() called ==================================
2025-06-02 15:34:21,799:INFO:Initializing create_model()
2025-06-02 15:34:21,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6BB929240>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bootstrap': False, 'criterion': 'absolute_error', 'max_depth': 11, 'max_features': 0.4556655086335653, 'min_impurity_decrease': 0.00012891733508622256, 'min_samples_leaf': 1, 'min_samples_split': 9, 'n_estimators': 11})
2025-06-02 15:34:21,800:INFO:Checking exceptions
2025-06-02 15:34:21,800:INFO:Importing libraries
2025-06-02 15:34:21,801:INFO:Copying training dataset
2025-06-02 15:34:21,884:INFO:Defining folds
2025-06-02 15:34:21,885:INFO:Declaring metric variables
2025-06-02 15:34:21,896:INFO:Importing untrained model
2025-06-02 15:34:21,896:INFO:Declaring custom model
2025-06-02 15:34:21,911:INFO:Extra Trees Regressor Imported successfully
2025-06-02 15:34:21,935:INFO:Starting cross validation
2025-06-02 15:34:21,939:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:34:30,002:INFO:Calculating mean and std
2025-06-02 15:34:30,003:INFO:Creating metrics dataframe
2025-06-02 15:34:30,015:INFO:Finalizing model
2025-06-02 15:34:33,219:INFO:Uploading results into container
2025-06-02 15:34:33,221:INFO:Uploading model into container now
2025-06-02 15:34:33,222:INFO:_master_model_container: 21
2025-06-02 15:34:33,222:INFO:_display_container: 3
2025-06-02 15:34:33,223:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=11,
                    max_features=0.4556655086335653,
                    min_impurity_decrease=0.00012891733508622256,
                    min_samples_split=9, n_estimators=11, n_jobs=-1,
                    random_state=123)
2025-06-02 15:34:33,224:INFO:create_model() successfully completed......................................
2025-06-02 15:34:34,791:INFO:SubProcess create_model() end ==================================
2025-06-02 15:34:34,792:INFO:choose_better activated
2025-06-02 15:34:34,801:INFO:SubProcess create_model() called ==================================
2025-06-02 15:34:34,802:INFO:Initializing create_model()
2025-06-02 15:34:34,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:34:34,803:INFO:Checking exceptions
2025-06-02 15:34:34,807:INFO:Importing libraries
2025-06-02 15:34:34,807:INFO:Copying training dataset
2025-06-02 15:34:34,872:INFO:Defining folds
2025-06-02 15:34:34,872:INFO:Declaring metric variables
2025-06-02 15:34:34,873:INFO:Importing untrained model
2025-06-02 15:34:34,873:INFO:Declaring custom model
2025-06-02 15:34:34,874:INFO:Extra Trees Regressor Imported successfully
2025-06-02 15:34:34,874:INFO:Starting cross validation
2025-06-02 15:34:34,877:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 15:34:41,233:INFO:Calculating mean and std
2025-06-02 15:34:41,234:INFO:Creating metrics dataframe
2025-06-02 15:34:41,237:INFO:Finalizing model
2025-06-02 15:34:42,918:INFO:Uploading results into container
2025-06-02 15:34:42,919:INFO:Uploading model into container now
2025-06-02 15:34:42,920:INFO:_master_model_container: 22
2025-06-02 15:34:42,920:INFO:_display_container: 4
2025-06-02 15:34:42,921:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:34:42,921:INFO:create_model() successfully completed......................................
2025-06-02 15:34:44,235:INFO:SubProcess create_model() end ==================================
2025-06-02 15:34:44,236:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 0.1708
2025-06-02 15:34:44,237:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=11,
                    max_features=0.4556655086335653,
                    min_impurity_decrease=0.00012891733508622256,
                    min_samples_split=9, n_estimators=11, n_jobs=-1,
                    random_state=123) result for MAE is 0.1994
2025-06-02 15:34:44,237:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 15:34:44,237:INFO:choose_better completed
2025-06-02 15:34:44,237:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 15:34:44,257:INFO:_master_model_container: 22
2025-06-02 15:34:44,258:INFO:_display_container: 3
2025-06-02 15:34:44,259:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:34:44,259:INFO:tune_model() successfully completed......................................
2025-06-02 15:34:45,623:INFO:Initializing finalize_model()
2025-06-02 15:34:45,623:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 15:34:45,624:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 15:34:45,667:INFO:Initializing create_model()
2025-06-02 15:34:45,667:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 15:34:45,667:INFO:Checking exceptions
2025-06-02 15:34:45,670:INFO:Importing libraries
2025-06-02 15:34:45,670:INFO:Copying training dataset
2025-06-02 15:34:45,675:INFO:Defining folds
2025-06-02 15:34:45,676:INFO:Declaring metric variables
2025-06-02 15:34:45,676:INFO:Importing untrained model
2025-06-02 15:34:45,676:INFO:Declaring custom model
2025-06-02 15:34:45,677:INFO:Extra Trees Regressor Imported successfully
2025-06-02 15:34:45,679:INFO:Cross validation set to False
2025-06-02 15:34:45,680:INFO:Fitting Model
2025-06-02 15:34:47,838:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 15:34:47,838:INFO:create_model() successfully completed......................................
2025-06-02 15:34:49,133:INFO:_master_model_container: 22
2025-06-02 15:34:49,133:INFO:_display_container: 3
2025-06-02 15:34:49,152:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 15:34:49,152:INFO:finalize_model() successfully completed......................................
2025-06-02 15:34:50,472:INFO:Initializing save_model()
2025-06-02 15:34:50,472:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model_mae, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 15:34:50,472:INFO:Adding model into prep_pipe
2025-06-02 15:34:50,472:WARNING:Only Model saved as it was a pipeline.
2025-06-02 15:34:50,612:INFO:formation_energy_final_model_mae.pkl saved in current working directory
2025-06-02 15:34:50,627:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 15:34:50,628:INFO:save_model() successfully completed......................................
2025-06-02 15:52:43,698:INFO:Initializing load_model()
2025-06-02 15:52:43,701:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 15:52:44,355:INFO:Initializing get_config()
2025-06-02 15:52:44,356:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, variable=X_test)
2025-06-02 15:52:44,360:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 15:52:44,363:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 15:52:44,477:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2059                       12.0                       13.0   
2652                       29.0                       31.0   
3768                       34.0                       65.0   
3686                        8.0                       14.0   
1037                       53.0                       83.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2059                      1.0               12.500000   
2652                      2.0               29.500000   
3768                     31.0               44.782608   
3686                      6.0               10.000000   
1037                     30.0               77.545456   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2059                   0.500000                    12.0   
2652                   0.750000                    29.0   
3768                  14.064272                    34.0   
3686                   2.666667                     8.0   
1037                   8.925620                    83.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2059                                68.0                                73.0   
2652                                64.0                                74.0   
3768                                29.0                                89.0   
3686                                78.0                                87.0   
1037                                86.0                                96.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2059                               5.0                        70.500000  ...   
2652                              10.0                        66.500000  ...   
3768                              60.0                        68.130432  ...   
3686                               9.0                        84.000000  ...   
1037                              10.0                        87.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2059                 4.0                   1            32.0   
2652                 4.0                   1            32.0   
3768                 7.0                   0             2.0   
3686                 7.0                   0             2.0   
1037                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2059                 False                     False   
2652                 False                     False   
3768                 False                     False   
3686                 False                     False   
1037                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2059                      False                        False   
2652                      False                        False   
3768                      False                        False   
3686                      False                        False   
1037                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2059                       True                     False   
2652                       True                     False   
3768                      False                      True   
3686                      False                      True   
1037                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2059                    False  
2652                    False  
3768                    False  
3686                    False  
1037                    False  

[1344 rows x 146 columns]
2025-06-02 15:52:44,478:INFO:get_config() successfully completed......................................
2025-06-02 15:52:44,486:INFO:Initializing get_config()
2025-06-02 15:52:44,486:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, variable=y_test)
2025-06-02 15:52:44,486:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 15:52:44,486:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 15:52:44,501:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2059    0.014339
2652   -0.098120
3768   -1.861921
3686   -3.207308
1037   -0.156411
Name: target, Length: 1344, dtype: float32
2025-06-02 15:52:44,501:INFO:get_config() successfully completed......................................
2025-06-02 15:52:44,524:INFO:Initializing predict_model()
2025-06-02 15:52:44,526:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6E50104C0>)
2025-06-02 15:52:44,526:INFO:Checking exceptions
2025-06-02 15:52:44,526:INFO:Preloading libraries
2025-06-02 15:52:44,556:INFO:Set up data.
2025-06-02 15:52:44,661:INFO:Set up index.
2025-06-02 15:56:46,987:INFO:Initializing load_model()
2025-06-02 15:56:46,990:INFO:load_model(model_name=formation_energy_final_model_mae, platform=None, authentication=None, verbose=True)
2025-06-02 15:56:47,582:INFO:Initializing get_config()
2025-06-02 15:56:47,583:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, variable=X_test)
2025-06-02 15:56:47,584:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 15:56:47,585:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 15:56:47,733:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2059                       12.0                       13.0   
2652                       29.0                       31.0   
3768                       34.0                       65.0   
3686                        8.0                       14.0   
1037                       53.0                       83.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2059                      1.0               12.500000   
2652                      2.0               29.500000   
3768                     31.0               44.782608   
3686                      6.0               10.000000   
1037                     30.0               77.545456   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2059                   0.500000                    12.0   
2652                   0.750000                    29.0   
3768                  14.064272                    34.0   
3686                   2.666667                     8.0   
1037                   8.925620                    83.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2059                                68.0                                73.0   
2652                                64.0                                74.0   
3768                                29.0                                89.0   
3686                                78.0                                87.0   
1037                                86.0                                96.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2059                               5.0                        70.500000  ...   
2652                              10.0                        66.500000  ...   
3768                              60.0                        68.130432  ...   
3686                               9.0                        84.000000  ...   
1037                              10.0                        87.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2059                 4.0                   1            32.0   
2652                 4.0                   1            32.0   
3768                 7.0                   0             2.0   
3686                 7.0                   0             2.0   
1037                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2059                 False                     False   
2652                 False                     False   
3768                 False                     False   
3686                 False                     False   
1037                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2059                      False                        False   
2652                      False                        False   
3768                      False                        False   
3686                      False                        False   
1037                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2059                       True                     False   
2652                       True                     False   
3768                      False                      True   
3686                      False                      True   
1037                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2059                    False  
2652                    False  
3768                    False  
3686                    False  
1037                    False  

[1344 rows x 146 columns]
2025-06-02 15:56:47,733:INFO:get_config() successfully completed......................................
2025-06-02 15:56:47,734:INFO:Initializing get_config()
2025-06-02 15:56:47,734:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, variable=y_test)
2025-06-02 15:56:47,734:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 15:56:47,734:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 15:56:47,752:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2059    0.014339
2652   -0.098120
3768   -1.861921
3686   -3.207308
1037   -0.156411
Name: target, Length: 1344, dtype: float32
2025-06-02 15:56:47,753:INFO:get_config() successfully completed......................................
2025-06-02 15:56:47,776:INFO:Initializing predict_model()
2025-06-02 15:56:47,777:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DCC36CB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6E50103A0>)
2025-06-02 15:56:47,777:INFO:Checking exceptions
2025-06-02 15:56:47,778:INFO:Preloading libraries
2025-06-02 15:56:47,798:INFO:Set up data.
2025-06-02 15:56:47,897:INFO:Set up index.
2025-06-02 16:14:55,264:INFO:PyCaret RegressionExperiment
2025-06-02 16:14:55,267:INFO:Logging name: reg-default-name
2025-06-02 16:14:55,268:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 16:14:55,268:INFO:version 3.3.2
2025-06-02 16:14:55,268:INFO:Initializing setup()
2025-06-02 16:14:55,268:INFO:self.USI: 14e3
2025-06-02 16:14:55,268:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 16:14:55,268:INFO:Checking environment
2025-06-02 16:14:55,270:INFO:python_version: 3.10.16
2025-06-02 16:14:55,270:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 16:14:55,270:INFO:machine: AMD64
2025-06-02 16:14:55,270:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 16:14:55,277:INFO:Memory: svmem(total=6378008576, available=1033584640, percent=83.8, used=5344423936, free=1033584640)
2025-06-02 16:14:55,279:INFO:Physical Core: 4
2025-06-02 16:14:55,279:INFO:Logical Core: 8
2025-06-02 16:14:55,279:INFO:Checking libraries
2025-06-02 16:14:55,279:INFO:System:
2025-06-02 16:14:55,280:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 16:14:55,280:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 16:14:55,280:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 16:14:55,280:INFO:PyCaret required dependencies:
2025-06-02 16:14:55,282:INFO:                 pip: 25.1
2025-06-02 16:14:55,282:INFO:          setuptools: 78.1.1
2025-06-02 16:14:55,282:INFO:             pycaret: 3.3.2
2025-06-02 16:14:55,282:INFO:             IPython: 8.37.0
2025-06-02 16:14:55,282:INFO:          ipywidgets: 8.1.7
2025-06-02 16:14:55,282:INFO:                tqdm: 4.67.1
2025-06-02 16:14:55,282:INFO:               numpy: 1.26.4
2025-06-02 16:14:55,282:INFO:              pandas: 2.0.1
2025-06-02 16:14:55,282:INFO:              jinja2: 3.1.6
2025-06-02 16:14:55,282:INFO:               scipy: 1.10.1
2025-06-02 16:14:55,282:INFO:              joblib: 1.3.2
2025-06-02 16:14:55,282:INFO:             sklearn: 1.4.2
2025-06-02 16:14:55,283:INFO:                pyod: 2.0.5
2025-06-02 16:14:55,283:INFO:            imblearn: 0.13.0
2025-06-02 16:14:55,283:INFO:   category_encoders: 2.7.0
2025-06-02 16:14:55,283:INFO:            lightgbm: 4.6.0
2025-06-02 16:14:55,283:INFO:               numba: 0.61.0
2025-06-02 16:14:55,283:INFO:            requests: 2.32.3
2025-06-02 16:14:55,283:INFO:          matplotlib: 3.7.1
2025-06-02 16:14:55,283:INFO:          scikitplot: 0.3.7
2025-06-02 16:14:55,283:INFO:         yellowbrick: 1.5
2025-06-02 16:14:55,283:INFO:              plotly: 6.1.2
2025-06-02 16:14:55,283:INFO:    plotly-resampler: Not installed
2025-06-02 16:14:55,283:INFO:             kaleido: 0.2.1
2025-06-02 16:14:55,283:INFO:           schemdraw: 0.15
2025-06-02 16:14:55,283:INFO:         statsmodels: 0.14.4
2025-06-02 16:14:55,283:INFO:              sktime: 0.26.0
2025-06-02 16:14:55,284:INFO:               tbats: 1.1.3
2025-06-02 16:14:55,284:INFO:            pmdarima: 2.0.4
2025-06-02 16:14:55,284:INFO:              psutil: 7.0.0
2025-06-02 16:14:55,285:INFO:          markupsafe: 2.1.2
2025-06-02 16:14:55,285:INFO:             pickle5: Not installed
2025-06-02 16:14:55,285:INFO:         cloudpickle: 3.1.1
2025-06-02 16:14:55,285:INFO:         deprecation: 2.1.0
2025-06-02 16:14:55,285:INFO:              xxhash: 3.5.0
2025-06-02 16:14:55,285:INFO:           wurlitzer: Not installed
2025-06-02 16:14:55,285:INFO:PyCaret optional dependencies:
2025-06-02 16:14:55,286:INFO:                shap: 0.44.1
2025-06-02 16:14:55,286:INFO:           interpret: 0.6.9
2025-06-02 16:14:55,286:INFO:                umap: 0.5.7
2025-06-02 16:14:55,286:INFO:     ydata_profiling: 4.16.1
2025-06-02 16:14:55,286:INFO:  explainerdashboard: 0.4.8
2025-06-02 16:14:55,286:INFO:             autoviz: Not installed
2025-06-02 16:14:55,286:INFO:           fairlearn: 0.7.0
2025-06-02 16:14:55,286:INFO:          deepchecks: Not installed
2025-06-02 16:14:55,286:INFO:             xgboost: 3.0.2
2025-06-02 16:14:55,286:INFO:            catboost: 1.2.8
2025-06-02 16:14:55,286:INFO:              kmodes: 0.12.2
2025-06-02 16:14:55,286:INFO:             mlxtend: 0.23.4
2025-06-02 16:14:55,286:INFO:       statsforecast: 1.5.0
2025-06-02 16:14:55,287:INFO:        tune_sklearn: Not installed
2025-06-02 16:14:55,287:INFO:                 ray: Not installed
2025-06-02 16:14:55,287:INFO:            hyperopt: 0.2.7
2025-06-02 16:14:55,287:INFO:              optuna: 4.3.0
2025-06-02 16:14:55,287:INFO:               skopt: 0.10.2
2025-06-02 16:14:55,287:INFO:              mlflow: 2.22.0
2025-06-02 16:14:55,287:INFO:              gradio: 5.32.0
2025-06-02 16:14:55,287:INFO:             fastapi: 0.115.12
2025-06-02 16:14:55,287:INFO:             uvicorn: 0.34.3
2025-06-02 16:14:55,287:INFO:              m2cgen: 0.10.0
2025-06-02 16:14:55,287:INFO:           evidently: 0.4.40
2025-06-02 16:14:55,287:INFO:               fugue: 0.8.5
2025-06-02 16:14:55,287:INFO:           streamlit: Not installed
2025-06-02 16:14:55,287:INFO:             prophet: Not installed
2025-06-02 16:14:55,287:INFO:None
2025-06-02 16:14:55,289:INFO:Set up data.
2025-06-02 16:14:55,479:INFO:Set up folding strategy.
2025-06-02 16:14:55,481:INFO:Set up train/test split.
2025-06-02 16:14:55,602:INFO:Set up index.
2025-06-02 16:14:55,610:INFO:Assigning column types.
2025-06-02 16:14:55,675:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 16:14:55,679:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 16:14:55,687:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 16:14:55,699:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 16:14:55,869:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:14:55,951:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:14:55,956:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:14:55,964:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:14:55,966:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 16:14:55,973:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 16:14:55,981:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 16:14:56,130:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:14:56,222:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:14:56,223:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:14:56,229:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:14:56,231:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 16:14:56,242:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 16:14:56,251:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 16:14:56,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:14:56,517:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:14:56,518:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:14:56,523:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:14:56,532:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 16:14:56,540:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 16:14:56,693:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:14:56,776:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:14:56,776:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:14:56,781:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:14:56,783:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 16:14:56,799:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 16:14:56,951:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:14:57,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:14:57,032:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:14:57,037:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:14:57,052:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 16:14:57,198:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:14:57,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:14:57,283:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:14:57,287:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:14:57,288:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 16:14:57,446:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:14:57,524:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:14:57,525:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:14:57,529:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:14:57,702:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:14:57,781:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:14:57,782:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:14:57,786:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:14:57,787:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 16:14:57,960:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:14:58,048:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:14:58,053:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:14:58,225:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:14:58,314:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:14:58,318:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:14:58,319:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 16:14:58,575:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:14:58,580:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:14:58,848:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:14:58,852:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:14:58,868:INFO:Preparing preprocessing pipeline...
2025-06-02 16:14:58,868:INFO:Set up simple imputation.
2025-06-02 16:14:58,870:INFO:Set up removing multicollinearity.
2025-06-02 16:14:58,880:INFO:Set up column name cleaning.
2025-06-02 16:14:59,449:INFO:Finished creating preprocessing pipeline.
2025-06-02 16:14:59,464:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 16:14:59,464:INFO:Creating final display dataframe.
2025-06-02 16:15:00,516:INFO:Setup _display_container:                     Description             Value
0                    Session id               124
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              14e3
2025-06-02 16:15:00,900:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:15:00,905:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:15:01,252:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:15:01,259:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:15:01,264:INFO:setup() successfully completed in 6.08s...............
2025-06-02 16:15:01,347:INFO:Initializing compare_models()
2025-06-02 16:15:01,348:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 16:15:01,348:INFO:Checking exceptions
2025-06-02 16:15:01,386:INFO:Preparing display monitor
2025-06-02 16:15:01,536:INFO:Initializing Linear Regression
2025-06-02 16:15:01,545:INFO:Total runtime is 0.00014999707539876302 minutes
2025-06-02 16:15:01,580:INFO:SubProcess create_model() called ==================================
2025-06-02 16:15:01,595:INFO:Initializing create_model()
2025-06-02 16:15:01,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:15:01,596:INFO:Checking exceptions
2025-06-02 16:15:01,597:INFO:Importing libraries
2025-06-02 16:15:01,597:INFO:Copying training dataset
2025-06-02 16:15:01,881:INFO:Defining folds
2025-06-02 16:15:01,881:INFO:Declaring metric variables
2025-06-02 16:15:01,910:INFO:Importing untrained model
2025-06-02 16:15:01,931:INFO:Linear Regression Imported successfully
2025-06-02 16:15:01,978:INFO:Starting cross validation
2025-06-02 16:15:01,986:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:15:19,267:INFO:Calculating mean and std
2025-06-02 16:15:19,280:INFO:Creating metrics dataframe
2025-06-02 16:15:19,313:INFO:Uploading results into container
2025-06-02 16:15:19,326:INFO:Uploading model into container now
2025-06-02 16:15:19,331:INFO:_master_model_container: 1
2025-06-02 16:15:19,331:INFO:_display_container: 2
2025-06-02 16:15:19,332:INFO:LinearRegression(n_jobs=-1)
2025-06-02 16:15:19,332:INFO:create_model() successfully completed......................................
2025-06-02 16:15:32,392:INFO:SubProcess create_model() end ==================================
2025-06-02 16:15:32,393:INFO:Creating metrics dataframe
2025-06-02 16:15:32,427:INFO:Initializing Lasso Regression
2025-06-02 16:15:32,428:INFO:Total runtime is 0.5148754318555196 minutes
2025-06-02 16:15:32,443:INFO:SubProcess create_model() called ==================================
2025-06-02 16:15:32,444:INFO:Initializing create_model()
2025-06-02 16:15:32,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:15:32,445:INFO:Checking exceptions
2025-06-02 16:15:32,446:INFO:Importing libraries
2025-06-02 16:15:32,447:INFO:Copying training dataset
2025-06-02 16:15:32,618:INFO:Defining folds
2025-06-02 16:15:32,619:INFO:Declaring metric variables
2025-06-02 16:15:32,638:INFO:Importing untrained model
2025-06-02 16:15:32,651:INFO:Lasso Regression Imported successfully
2025-06-02 16:15:32,684:INFO:Starting cross validation
2025-06-02 16:15:32,689:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:15:44,147:INFO:Calculating mean and std
2025-06-02 16:15:44,153:INFO:Creating metrics dataframe
2025-06-02 16:15:44,165:INFO:Uploading results into container
2025-06-02 16:15:44,167:INFO:Uploading model into container now
2025-06-02 16:15:44,169:INFO:_master_model_container: 2
2025-06-02 16:15:44,170:INFO:_display_container: 2
2025-06-02 16:15:44,171:INFO:Lasso(random_state=124)
2025-06-02 16:15:44,172:INFO:create_model() successfully completed......................................
2025-06-02 16:15:46,157:INFO:SubProcess create_model() end ==================================
2025-06-02 16:15:46,157:INFO:Creating metrics dataframe
2025-06-02 16:15:46,176:INFO:Initializing Ridge Regression
2025-06-02 16:15:46,177:INFO:Total runtime is 0.7440251350402832 minutes
2025-06-02 16:15:46,193:INFO:SubProcess create_model() called ==================================
2025-06-02 16:15:46,193:INFO:Initializing create_model()
2025-06-02 16:15:46,194:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:15:46,194:INFO:Checking exceptions
2025-06-02 16:15:46,195:INFO:Importing libraries
2025-06-02 16:15:46,196:INFO:Copying training dataset
2025-06-02 16:15:46,259:INFO:Defining folds
2025-06-02 16:15:46,259:INFO:Declaring metric variables
2025-06-02 16:15:46,272:INFO:Importing untrained model
2025-06-02 16:15:46,284:INFO:Ridge Regression Imported successfully
2025-06-02 16:15:46,308:INFO:Starting cross validation
2025-06-02 16:15:46,313:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:15:47,045:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.26677e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 16:15:47,249:INFO:Calculating mean and std
2025-06-02 16:15:47,252:INFO:Creating metrics dataframe
2025-06-02 16:15:47,256:INFO:Uploading results into container
2025-06-02 16:15:47,257:INFO:Uploading model into container now
2025-06-02 16:15:47,259:INFO:_master_model_container: 3
2025-06-02 16:15:47,259:INFO:_display_container: 2
2025-06-02 16:15:47,260:INFO:Ridge(random_state=124)
2025-06-02 16:15:47,260:INFO:create_model() successfully completed......................................
2025-06-02 16:15:48,772:INFO:SubProcess create_model() end ==================================
2025-06-02 16:15:48,772:INFO:Creating metrics dataframe
2025-06-02 16:15:48,792:INFO:Initializing Elastic Net
2025-06-02 16:15:48,792:INFO:Total runtime is 0.7876020431518554 minutes
2025-06-02 16:15:48,806:INFO:SubProcess create_model() called ==================================
2025-06-02 16:15:48,807:INFO:Initializing create_model()
2025-06-02 16:15:48,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:15:48,807:INFO:Checking exceptions
2025-06-02 16:15:48,808:INFO:Importing libraries
2025-06-02 16:15:48,808:INFO:Copying training dataset
2025-06-02 16:15:48,867:INFO:Defining folds
2025-06-02 16:15:48,868:INFO:Declaring metric variables
2025-06-02 16:15:48,882:INFO:Importing untrained model
2025-06-02 16:15:48,895:INFO:Elastic Net Imported successfully
2025-06-02 16:15:48,920:INFO:Starting cross validation
2025-06-02 16:15:48,924:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:15:49,801:INFO:Calculating mean and std
2025-06-02 16:15:49,804:INFO:Creating metrics dataframe
2025-06-02 16:15:49,808:INFO:Uploading results into container
2025-06-02 16:15:49,809:INFO:Uploading model into container now
2025-06-02 16:15:49,811:INFO:_master_model_container: 4
2025-06-02 16:15:49,811:INFO:_display_container: 2
2025-06-02 16:15:49,812:INFO:ElasticNet(random_state=124)
2025-06-02 16:15:49,813:INFO:create_model() successfully completed......................................
2025-06-02 16:15:51,145:INFO:SubProcess create_model() end ==================================
2025-06-02 16:15:51,145:INFO:Creating metrics dataframe
2025-06-02 16:15:51,161:INFO:Initializing Least Angle Regression
2025-06-02 16:15:51,162:INFO:Total runtime is 0.8270851254463195 minutes
2025-06-02 16:15:51,173:INFO:SubProcess create_model() called ==================================
2025-06-02 16:15:51,173:INFO:Initializing create_model()
2025-06-02 16:15:51,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:15:51,174:INFO:Checking exceptions
2025-06-02 16:15:51,174:INFO:Importing libraries
2025-06-02 16:15:51,175:INFO:Copying training dataset
2025-06-02 16:15:51,233:INFO:Defining folds
2025-06-02 16:15:51,234:INFO:Declaring metric variables
2025-06-02 16:15:51,250:INFO:Importing untrained model
2025-06-02 16:15:51,263:INFO:Least Angle Regression Imported successfully
2025-06-02 16:15:51,286:INFO:Starting cross validation
2025-06-02 16:15:51,291:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:15:52,586:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=1.459e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 16:15:52,733:INFO:Calculating mean and std
2025-06-02 16:15:52,736:INFO:Creating metrics dataframe
2025-06-02 16:15:52,742:INFO:Uploading results into container
2025-06-02 16:15:52,743:INFO:Uploading model into container now
2025-06-02 16:15:52,745:INFO:_master_model_container: 5
2025-06-02 16:15:52,745:INFO:_display_container: 2
2025-06-02 16:15:52,748:INFO:Lars(random_state=124)
2025-06-02 16:15:52,748:INFO:create_model() successfully completed......................................
2025-06-02 16:15:54,086:INFO:SubProcess create_model() end ==================================
2025-06-02 16:15:54,087:INFO:Creating metrics dataframe
2025-06-02 16:15:54,108:INFO:Initializing Lasso Least Angle Regression
2025-06-02 16:15:54,108:INFO:Total runtime is 0.8762006839116414 minutes
2025-06-02 16:15:54,120:INFO:SubProcess create_model() called ==================================
2025-06-02 16:15:54,121:INFO:Initializing create_model()
2025-06-02 16:15:54,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:15:54,123:INFO:Checking exceptions
2025-06-02 16:15:54,123:INFO:Importing libraries
2025-06-02 16:15:54,124:INFO:Copying training dataset
2025-06-02 16:15:54,192:INFO:Defining folds
2025-06-02 16:15:54,192:INFO:Declaring metric variables
2025-06-02 16:15:54,206:INFO:Importing untrained model
2025-06-02 16:15:54,221:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 16:15:54,245:INFO:Starting cross validation
2025-06-02 16:15:54,250:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:15:55,001:INFO:Calculating mean and std
2025-06-02 16:15:55,004:INFO:Creating metrics dataframe
2025-06-02 16:15:55,008:INFO:Uploading results into container
2025-06-02 16:15:55,009:INFO:Uploading model into container now
2025-06-02 16:15:55,011:INFO:_master_model_container: 6
2025-06-02 16:15:55,012:INFO:_display_container: 2
2025-06-02 16:15:55,013:INFO:LassoLars(random_state=124)
2025-06-02 16:15:55,014:INFO:create_model() successfully completed......................................
2025-06-02 16:15:56,624:INFO:SubProcess create_model() end ==================================
2025-06-02 16:15:56,625:INFO:Creating metrics dataframe
2025-06-02 16:15:56,648:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 16:15:56,648:INFO:Total runtime is 0.9185452421506246 minutes
2025-06-02 16:15:56,659:INFO:SubProcess create_model() called ==================================
2025-06-02 16:15:56,661:INFO:Initializing create_model()
2025-06-02 16:15:56,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:15:56,662:INFO:Checking exceptions
2025-06-02 16:15:56,662:INFO:Importing libraries
2025-06-02 16:15:56,663:INFO:Copying training dataset
2025-06-02 16:15:56,733:INFO:Defining folds
2025-06-02 16:15:56,733:INFO:Declaring metric variables
2025-06-02 16:15:56,747:INFO:Importing untrained model
2025-06-02 16:15:56,760:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 16:15:56,785:INFO:Starting cross validation
2025-06-02 16:15:56,790:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:15:57,564:INFO:Calculating mean and std
2025-06-02 16:15:57,566:INFO:Creating metrics dataframe
2025-06-02 16:15:57,569:INFO:Uploading results into container
2025-06-02 16:15:57,570:INFO:Uploading model into container now
2025-06-02 16:15:57,571:INFO:_master_model_container: 7
2025-06-02 16:15:57,572:INFO:_display_container: 2
2025-06-02 16:15:57,573:INFO:OrthogonalMatchingPursuit()
2025-06-02 16:15:57,573:INFO:create_model() successfully completed......................................
2025-06-02 16:15:58,911:INFO:SubProcess create_model() end ==================================
2025-06-02 16:15:58,911:INFO:Creating metrics dataframe
2025-06-02 16:15:58,926:INFO:Initializing Bayesian Ridge
2025-06-02 16:15:58,927:INFO:Total runtime is 0.9565208395322164 minutes
2025-06-02 16:15:58,940:INFO:SubProcess create_model() called ==================================
2025-06-02 16:15:58,941:INFO:Initializing create_model()
2025-06-02 16:15:58,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:15:58,941:INFO:Checking exceptions
2025-06-02 16:15:58,942:INFO:Importing libraries
2025-06-02 16:15:58,942:INFO:Copying training dataset
2025-06-02 16:15:59,014:INFO:Defining folds
2025-06-02 16:15:59,014:INFO:Declaring metric variables
2025-06-02 16:15:59,025:INFO:Importing untrained model
2025-06-02 16:15:59,039:INFO:Bayesian Ridge Imported successfully
2025-06-02 16:15:59,060:INFO:Starting cross validation
2025-06-02 16:15:59,066:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:15:59,800:INFO:Calculating mean and std
2025-06-02 16:15:59,802:INFO:Creating metrics dataframe
2025-06-02 16:15:59,805:INFO:Uploading results into container
2025-06-02 16:15:59,806:INFO:Uploading model into container now
2025-06-02 16:15:59,807:INFO:_master_model_container: 8
2025-06-02 16:15:59,807:INFO:_display_container: 2
2025-06-02 16:15:59,807:INFO:BayesianRidge()
2025-06-02 16:15:59,808:INFO:create_model() successfully completed......................................
2025-06-02 16:16:01,622:INFO:SubProcess create_model() end ==================================
2025-06-02 16:16:01,623:INFO:Creating metrics dataframe
2025-06-02 16:16:01,639:INFO:Initializing Passive Aggressive Regressor
2025-06-02 16:16:01,639:INFO:Total runtime is 1.0017277280489605 minutes
2025-06-02 16:16:01,654:INFO:SubProcess create_model() called ==================================
2025-06-02 16:16:01,655:INFO:Initializing create_model()
2025-06-02 16:16:01,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:16:01,656:INFO:Checking exceptions
2025-06-02 16:16:01,656:INFO:Importing libraries
2025-06-02 16:16:01,657:INFO:Copying training dataset
2025-06-02 16:16:01,737:INFO:Defining folds
2025-06-02 16:16:01,737:INFO:Declaring metric variables
2025-06-02 16:16:01,754:INFO:Importing untrained model
2025-06-02 16:16:01,771:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 16:16:01,805:INFO:Starting cross validation
2025-06-02 16:16:01,810:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:16:02,549:INFO:Calculating mean and std
2025-06-02 16:16:02,552:INFO:Creating metrics dataframe
2025-06-02 16:16:02,556:INFO:Uploading results into container
2025-06-02 16:16:02,557:INFO:Uploading model into container now
2025-06-02 16:16:02,558:INFO:_master_model_container: 9
2025-06-02 16:16:02,558:INFO:_display_container: 2
2025-06-02 16:16:02,559:INFO:PassiveAggressiveRegressor(random_state=124)
2025-06-02 16:16:02,560:INFO:create_model() successfully completed......................................
2025-06-02 16:16:03,833:INFO:SubProcess create_model() end ==================================
2025-06-02 16:16:03,834:INFO:Creating metrics dataframe
2025-06-02 16:16:03,853:INFO:Initializing Huber Regressor
2025-06-02 16:16:03,854:INFO:Total runtime is 1.038644333680471 minutes
2025-06-02 16:16:03,863:INFO:SubProcess create_model() called ==================================
2025-06-02 16:16:03,864:INFO:Initializing create_model()
2025-06-02 16:16:03,864:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:16:03,865:INFO:Checking exceptions
2025-06-02 16:16:03,865:INFO:Importing libraries
2025-06-02 16:16:03,866:INFO:Copying training dataset
2025-06-02 16:16:03,922:INFO:Defining folds
2025-06-02 16:16:03,923:INFO:Declaring metric variables
2025-06-02 16:16:03,936:INFO:Importing untrained model
2025-06-02 16:16:03,948:INFO:Huber Regressor Imported successfully
2025-06-02 16:16:03,970:INFO:Starting cross validation
2025-06-02 16:16:03,974:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:16:05,501:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 16:16:05,513:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 16:16:05,561:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 16:16:05,615:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 16:16:05,616:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 16:16:05,685:INFO:Calculating mean and std
2025-06-02 16:16:05,688:INFO:Creating metrics dataframe
2025-06-02 16:16:05,692:INFO:Uploading results into container
2025-06-02 16:16:05,694:INFO:Uploading model into container now
2025-06-02 16:16:05,695:INFO:_master_model_container: 10
2025-06-02 16:16:05,695:INFO:_display_container: 2
2025-06-02 16:16:05,696:INFO:HuberRegressor()
2025-06-02 16:16:05,697:INFO:create_model() successfully completed......................................
2025-06-02 16:16:07,102:INFO:SubProcess create_model() end ==================================
2025-06-02 16:16:07,103:INFO:Creating metrics dataframe
2025-06-02 16:16:07,121:INFO:Initializing K Neighbors Regressor
2025-06-02 16:16:07,121:INFO:Total runtime is 1.0930946509043378 minutes
2025-06-02 16:16:07,132:INFO:SubProcess create_model() called ==================================
2025-06-02 16:16:07,133:INFO:Initializing create_model()
2025-06-02 16:16:07,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:16:07,134:INFO:Checking exceptions
2025-06-02 16:16:07,134:INFO:Importing libraries
2025-06-02 16:16:07,135:INFO:Copying training dataset
2025-06-02 16:16:07,199:INFO:Defining folds
2025-06-02 16:16:07,199:INFO:Declaring metric variables
2025-06-02 16:16:07,214:INFO:Importing untrained model
2025-06-02 16:16:07,226:INFO:K Neighbors Regressor Imported successfully
2025-06-02 16:16:07,252:INFO:Starting cross validation
2025-06-02 16:16:07,256:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:16:08,259:INFO:Calculating mean and std
2025-06-02 16:16:08,262:INFO:Creating metrics dataframe
2025-06-02 16:16:08,266:INFO:Uploading results into container
2025-06-02 16:16:08,267:INFO:Uploading model into container now
2025-06-02 16:16:08,267:INFO:_master_model_container: 11
2025-06-02 16:16:08,267:INFO:_display_container: 2
2025-06-02 16:16:08,268:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 16:16:08,268:INFO:create_model() successfully completed......................................
2025-06-02 16:16:09,604:INFO:SubProcess create_model() end ==================================
2025-06-02 16:16:09,604:INFO:Creating metrics dataframe
2025-06-02 16:16:09,624:INFO:Initializing Decision Tree Regressor
2025-06-02 16:16:09,624:INFO:Total runtime is 1.1348114609718325 minutes
2025-06-02 16:16:09,636:INFO:SubProcess create_model() called ==================================
2025-06-02 16:16:09,637:INFO:Initializing create_model()
2025-06-02 16:16:09,637:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:16:09,637:INFO:Checking exceptions
2025-06-02 16:16:09,638:INFO:Importing libraries
2025-06-02 16:16:09,638:INFO:Copying training dataset
2025-06-02 16:16:09,699:INFO:Defining folds
2025-06-02 16:16:09,699:INFO:Declaring metric variables
2025-06-02 16:16:09,709:INFO:Importing untrained model
2025-06-02 16:16:09,722:INFO:Decision Tree Regressor Imported successfully
2025-06-02 16:16:09,744:INFO:Starting cross validation
2025-06-02 16:16:09,748:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:16:10,569:INFO:Calculating mean and std
2025-06-02 16:16:10,572:INFO:Creating metrics dataframe
2025-06-02 16:16:10,575:INFO:Uploading results into container
2025-06-02 16:16:10,576:INFO:Uploading model into container now
2025-06-02 16:16:10,577:INFO:_master_model_container: 12
2025-06-02 16:16:10,578:INFO:_display_container: 2
2025-06-02 16:16:10,578:INFO:DecisionTreeRegressor(random_state=124)
2025-06-02 16:16:10,579:INFO:create_model() successfully completed......................................
2025-06-02 16:16:11,865:INFO:SubProcess create_model() end ==================================
2025-06-02 16:16:11,865:INFO:Creating metrics dataframe
2025-06-02 16:16:11,883:INFO:Initializing Random Forest Regressor
2025-06-02 16:16:11,883:INFO:Total runtime is 1.1724521001180015 minutes
2025-06-02 16:16:11,893:INFO:SubProcess create_model() called ==================================
2025-06-02 16:16:11,893:INFO:Initializing create_model()
2025-06-02 16:16:11,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:16:11,894:INFO:Checking exceptions
2025-06-02 16:16:11,895:INFO:Importing libraries
2025-06-02 16:16:11,895:INFO:Copying training dataset
2025-06-02 16:16:11,952:INFO:Defining folds
2025-06-02 16:16:11,953:INFO:Declaring metric variables
2025-06-02 16:16:11,965:INFO:Importing untrained model
2025-06-02 16:16:11,976:INFO:Random Forest Regressor Imported successfully
2025-06-02 16:16:12,000:INFO:Starting cross validation
2025-06-02 16:16:12,005:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:16:20,495:INFO:Calculating mean and std
2025-06-02 16:16:20,498:INFO:Creating metrics dataframe
2025-06-02 16:16:20,501:INFO:Uploading results into container
2025-06-02 16:16:20,502:INFO:Uploading model into container now
2025-06-02 16:16:20,503:INFO:_master_model_container: 13
2025-06-02 16:16:20,504:INFO:_display_container: 2
2025-06-02 16:16:20,504:INFO:RandomForestRegressor(n_jobs=-1, random_state=124)
2025-06-02 16:16:20,505:INFO:create_model() successfully completed......................................
2025-06-02 16:16:21,777:INFO:SubProcess create_model() end ==================================
2025-06-02 16:16:21,777:INFO:Creating metrics dataframe
2025-06-02 16:16:21,801:INFO:Initializing Extra Trees Regressor
2025-06-02 16:16:21,801:INFO:Total runtime is 1.3377462307612102 minutes
2025-06-02 16:16:21,812:INFO:SubProcess create_model() called ==================================
2025-06-02 16:16:21,812:INFO:Initializing create_model()
2025-06-02 16:16:21,813:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:16:21,813:INFO:Checking exceptions
2025-06-02 16:16:21,814:INFO:Importing libraries
2025-06-02 16:16:21,814:INFO:Copying training dataset
2025-06-02 16:16:21,872:INFO:Defining folds
2025-06-02 16:16:21,873:INFO:Declaring metric variables
2025-06-02 16:16:21,889:INFO:Importing untrained model
2025-06-02 16:16:21,900:INFO:Extra Trees Regressor Imported successfully
2025-06-02 16:16:21,921:INFO:Starting cross validation
2025-06-02 16:16:21,924:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:16:27,319:INFO:Calculating mean and std
2025-06-02 16:16:27,321:INFO:Creating metrics dataframe
2025-06-02 16:16:27,325:INFO:Uploading results into container
2025-06-02 16:16:27,326:INFO:Uploading model into container now
2025-06-02 16:16:27,327:INFO:_master_model_container: 14
2025-06-02 16:16:27,327:INFO:_display_container: 2
2025-06-02 16:16:27,328:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=124)
2025-06-02 16:16:27,329:INFO:create_model() successfully completed......................................
2025-06-02 16:16:28,612:INFO:SubProcess create_model() end ==================================
2025-06-02 16:16:28,612:INFO:Creating metrics dataframe
2025-06-02 16:16:28,633:INFO:Initializing AdaBoost Regressor
2025-06-02 16:16:28,634:INFO:Total runtime is 1.4516409556070964 minutes
2025-06-02 16:16:28,643:INFO:SubProcess create_model() called ==================================
2025-06-02 16:16:28,644:INFO:Initializing create_model()
2025-06-02 16:16:28,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:16:28,644:INFO:Checking exceptions
2025-06-02 16:16:28,644:INFO:Importing libraries
2025-06-02 16:16:28,644:INFO:Copying training dataset
2025-06-02 16:16:28,708:INFO:Defining folds
2025-06-02 16:16:28,708:INFO:Declaring metric variables
2025-06-02 16:16:28,722:INFO:Importing untrained model
2025-06-02 16:16:28,735:INFO:AdaBoost Regressor Imported successfully
2025-06-02 16:16:28,757:INFO:Starting cross validation
2025-06-02 16:16:28,762:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:16:30,783:INFO:Calculating mean and std
2025-06-02 16:16:30,785:INFO:Creating metrics dataframe
2025-06-02 16:16:30,788:INFO:Uploading results into container
2025-06-02 16:16:30,789:INFO:Uploading model into container now
2025-06-02 16:16:30,790:INFO:_master_model_container: 15
2025-06-02 16:16:30,791:INFO:_display_container: 2
2025-06-02 16:16:30,792:INFO:AdaBoostRegressor(random_state=124)
2025-06-02 16:16:30,792:INFO:create_model() successfully completed......................................
2025-06-02 16:16:32,155:INFO:SubProcess create_model() end ==================================
2025-06-02 16:16:32,156:INFO:Creating metrics dataframe
2025-06-02 16:16:32,183:INFO:Initializing Gradient Boosting Regressor
2025-06-02 16:16:32,183:INFO:Total runtime is 1.510794758796692 minutes
2025-06-02 16:16:32,195:INFO:SubProcess create_model() called ==================================
2025-06-02 16:16:32,195:INFO:Initializing create_model()
2025-06-02 16:16:32,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:16:32,196:INFO:Checking exceptions
2025-06-02 16:16:32,197:INFO:Importing libraries
2025-06-02 16:16:32,197:INFO:Copying training dataset
2025-06-02 16:16:32,266:INFO:Defining folds
2025-06-02 16:16:32,267:INFO:Declaring metric variables
2025-06-02 16:16:32,283:INFO:Importing untrained model
2025-06-02 16:16:32,295:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 16:16:32,322:INFO:Starting cross validation
2025-06-02 16:16:32,327:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:16:36,089:INFO:Calculating mean and std
2025-06-02 16:16:36,092:INFO:Creating metrics dataframe
2025-06-02 16:16:36,095:INFO:Uploading results into container
2025-06-02 16:16:36,096:INFO:Uploading model into container now
2025-06-02 16:16:36,097:INFO:_master_model_container: 16
2025-06-02 16:16:36,097:INFO:_display_container: 2
2025-06-02 16:16:36,098:INFO:GradientBoostingRegressor(random_state=124)
2025-06-02 16:16:36,099:INFO:create_model() successfully completed......................................
2025-06-02 16:16:37,413:INFO:SubProcess create_model() end ==================================
2025-06-02 16:16:37,413:INFO:Creating metrics dataframe
2025-06-02 16:16:37,437:INFO:Initializing Extreme Gradient Boosting
2025-06-02 16:16:37,437:INFO:Total runtime is 1.5983459989229838 minutes
2025-06-02 16:16:37,450:INFO:SubProcess create_model() called ==================================
2025-06-02 16:16:37,451:INFO:Initializing create_model()
2025-06-02 16:16:37,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:16:37,452:INFO:Checking exceptions
2025-06-02 16:16:37,452:INFO:Importing libraries
2025-06-02 16:16:37,453:INFO:Copying training dataset
2025-06-02 16:16:37,518:INFO:Defining folds
2025-06-02 16:16:37,519:INFO:Declaring metric variables
2025-06-02 16:16:37,533:INFO:Importing untrained model
2025-06-02 16:16:37,547:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 16:16:37,569:INFO:Starting cross validation
2025-06-02 16:16:37,574:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:16:39,652:INFO:Calculating mean and std
2025-06-02 16:16:39,654:INFO:Creating metrics dataframe
2025-06-02 16:16:39,658:INFO:Uploading results into container
2025-06-02 16:16:39,659:INFO:Uploading model into container now
2025-06-02 16:16:39,661:INFO:_master_model_container: 17
2025-06-02 16:16:39,662:INFO:_display_container: 2
2025-06-02 16:16:39,666:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 16:16:39,668:INFO:create_model() successfully completed......................................
2025-06-02 16:16:41,104:INFO:SubProcess create_model() end ==================================
2025-06-02 16:16:41,105:INFO:Creating metrics dataframe
2025-06-02 16:16:41,130:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 16:16:41,130:INFO:Total runtime is 1.6599035263061523 minutes
2025-06-02 16:16:41,139:INFO:SubProcess create_model() called ==================================
2025-06-02 16:16:41,140:INFO:Initializing create_model()
2025-06-02 16:16:41,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:16:41,140:INFO:Checking exceptions
2025-06-02 16:16:41,140:INFO:Importing libraries
2025-06-02 16:16:41,141:INFO:Copying training dataset
2025-06-02 16:16:41,210:INFO:Defining folds
2025-06-02 16:16:41,211:INFO:Declaring metric variables
2025-06-02 16:16:41,225:INFO:Importing untrained model
2025-06-02 16:16:41,241:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 16:16:41,270:INFO:Starting cross validation
2025-06-02 16:16:41,274:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:16:42,917:INFO:Calculating mean and std
2025-06-02 16:16:42,919:INFO:Creating metrics dataframe
2025-06-02 16:16:42,924:INFO:Uploading results into container
2025-06-02 16:16:42,925:INFO:Uploading model into container now
2025-06-02 16:16:42,926:INFO:_master_model_container: 18
2025-06-02 16:16:42,926:INFO:_display_container: 2
2025-06-02 16:16:42,928:INFO:LGBMRegressor(n_jobs=-1, random_state=124)
2025-06-02 16:16:42,928:INFO:create_model() successfully completed......................................
2025-06-02 16:16:44,314:INFO:SubProcess create_model() end ==================================
2025-06-02 16:16:44,314:INFO:Creating metrics dataframe
2025-06-02 16:16:44,341:INFO:Initializing CatBoost Regressor
2025-06-02 16:16:44,341:INFO:Total runtime is 1.7134147087732952 minutes
2025-06-02 16:16:44,353:INFO:SubProcess create_model() called ==================================
2025-06-02 16:16:44,353:INFO:Initializing create_model()
2025-06-02 16:16:44,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:16:44,354:INFO:Checking exceptions
2025-06-02 16:16:44,355:INFO:Importing libraries
2025-06-02 16:16:44,355:INFO:Copying training dataset
2025-06-02 16:16:44,417:INFO:Defining folds
2025-06-02 16:16:44,418:INFO:Declaring metric variables
2025-06-02 16:16:44,431:INFO:Importing untrained model
2025-06-02 16:16:44,452:INFO:CatBoost Regressor Imported successfully
2025-06-02 16:16:44,476:INFO:Starting cross validation
2025-06-02 16:16:44,479:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:17:16,039:INFO:Calculating mean and std
2025-06-02 16:17:16,043:INFO:Creating metrics dataframe
2025-06-02 16:17:16,054:INFO:Uploading results into container
2025-06-02 16:17:16,055:INFO:Uploading model into container now
2025-06-02 16:17:16,057:INFO:_master_model_container: 19
2025-06-02 16:17:16,057:INFO:_display_container: 2
2025-06-02 16:17:16,057:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6E4F866E0>
2025-06-02 16:17:16,057:INFO:create_model() successfully completed......................................
2025-06-02 16:17:18,291:INFO:SubProcess create_model() end ==================================
2025-06-02 16:17:18,292:INFO:Creating metrics dataframe
2025-06-02 16:17:18,330:INFO:Initializing Dummy Regressor
2025-06-02 16:17:18,330:INFO:Total runtime is 2.2799060662587483 minutes
2025-06-02 16:17:18,343:INFO:SubProcess create_model() called ==================================
2025-06-02 16:17:18,344:INFO:Initializing create_model()
2025-06-02 16:17:18,345:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DD396350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:17:18,346:INFO:Checking exceptions
2025-06-02 16:17:18,347:INFO:Importing libraries
2025-06-02 16:17:18,347:INFO:Copying training dataset
2025-06-02 16:17:18,431:INFO:Defining folds
2025-06-02 16:17:18,432:INFO:Declaring metric variables
2025-06-02 16:17:18,449:INFO:Importing untrained model
2025-06-02 16:17:18,467:INFO:Dummy Regressor Imported successfully
2025-06-02 16:17:18,495:INFO:Starting cross validation
2025-06-02 16:17:18,501:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:17:19,380:INFO:Calculating mean and std
2025-06-02 16:17:19,382:INFO:Creating metrics dataframe
2025-06-02 16:17:19,385:INFO:Uploading results into container
2025-06-02 16:17:19,387:INFO:Uploading model into container now
2025-06-02 16:17:19,388:INFO:_master_model_container: 20
2025-06-02 16:17:19,388:INFO:_display_container: 2
2025-06-02 16:17:19,389:INFO:DummyRegressor()
2025-06-02 16:17:19,389:INFO:create_model() successfully completed......................................
2025-06-02 16:17:21,211:INFO:SubProcess create_model() end ==================================
2025-06-02 16:17:21,211:INFO:Creating metrics dataframe
2025-06-02 16:17:21,279:INFO:Initializing create_model()
2025-06-02 16:17:21,279:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=LGBMRegressor(n_jobs=-1, random_state=124), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:17:21,280:INFO:Checking exceptions
2025-06-02 16:17:21,292:INFO:Importing libraries
2025-06-02 16:17:21,293:INFO:Copying training dataset
2025-06-02 16:17:21,371:INFO:Defining folds
2025-06-02 16:17:21,371:INFO:Declaring metric variables
2025-06-02 16:17:21,372:INFO:Importing untrained model
2025-06-02 16:17:21,372:INFO:Declaring custom model
2025-06-02 16:17:21,374:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 16:17:21,380:INFO:Cross validation set to False
2025-06-02 16:17:21,380:INFO:Fitting Model
2025-06-02 16:17:21,903:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 16:17:21,913:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005972 seconds.
2025-06-02 16:17:21,914:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 16:17:21,914:INFO:[LightGBM] [Info] Total Bins 6263
2025-06-02 16:17:21,921:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 16:17:21,923:INFO:[LightGBM] [Info] Start training from score -0.505554
2025-06-02 16:17:22,213:INFO:LGBMRegressor(n_jobs=-1, random_state=124)
2025-06-02 16:17:22,213:INFO:create_model() successfully completed......................................
2025-06-02 16:17:23,772:INFO:Initializing create_model()
2025-06-02 16:17:23,773:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=<catboost.core.CatBoostRegressor object at 0x000001B6E4F866E0>, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:17:23,773:INFO:Checking exceptions
2025-06-02 16:17:23,780:INFO:Importing libraries
2025-06-02 16:17:23,781:INFO:Copying training dataset
2025-06-02 16:17:23,848:INFO:Defining folds
2025-06-02 16:17:23,848:INFO:Declaring metric variables
2025-06-02 16:17:23,849:INFO:Importing untrained model
2025-06-02 16:17:23,849:INFO:Declaring custom model
2025-06-02 16:17:23,849:INFO:CatBoost Regressor Imported successfully
2025-06-02 16:17:23,852:INFO:Cross validation set to False
2025-06-02 16:17:23,852:INFO:Fitting Model
2025-06-02 16:17:32,020:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6E5073BB0>
2025-06-02 16:17:32,021:INFO:create_model() successfully completed......................................
2025-06-02 16:17:33,684:INFO:Initializing create_model()
2025-06-02 16:17:33,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>, estimator=RandomForestRegressor(n_jobs=-1, random_state=124), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:17:33,686:INFO:Checking exceptions
2025-06-02 16:17:33,699:INFO:Importing libraries
2025-06-02 16:17:33,699:INFO:Copying training dataset
2025-06-02 16:17:33,827:INFO:Defining folds
2025-06-02 16:17:33,827:INFO:Declaring metric variables
2025-06-02 16:17:33,828:INFO:Importing untrained model
2025-06-02 16:17:33,829:INFO:Declaring custom model
2025-06-02 16:17:33,832:INFO:Random Forest Regressor Imported successfully
2025-06-02 16:17:33,837:INFO:Cross validation set to False
2025-06-02 16:17:33,837:INFO:Fitting Model
2025-06-02 16:17:36,623:INFO:RandomForestRegressor(n_jobs=-1, random_state=124)
2025-06-02 16:17:36,623:INFO:create_model() successfully completed......................................
2025-06-02 16:17:38,006:INFO:_master_model_container: 20
2025-06-02 16:17:38,007:INFO:_display_container: 2
2025-06-02 16:17:38,009:INFO:[LGBMRegressor(n_jobs=-1, random_state=124), <catboost.core.CatBoostRegressor object at 0x000001B6E5073BB0>, RandomForestRegressor(n_jobs=-1, random_state=124)]
2025-06-02 16:17:38,009:INFO:compare_models() successfully completed......................................
2025-06-02 16:17:38,108:INFO:Initializing tune_model()
2025-06-02 16:17:38,108:INFO:tune_model(estimator=[LGBMRegressor(n_jobs=-1, random_state=124), <catboost.core.CatBoostRegressor object at 0x000001B6E5073BB0>, RandomForestRegressor(n_jobs=-1, random_state=124)], fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6E4967910>)
2025-06-02 16:17:38,108:INFO:Checking exceptions
2025-06-02 16:23:16,675:INFO:PyCaret RegressionExperiment
2025-06-02 16:23:16,677:INFO:Logging name: reg-default-name
2025-06-02 16:23:16,677:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 16:23:16,678:INFO:version 3.3.2
2025-06-02 16:23:16,678:INFO:Initializing setup()
2025-06-02 16:23:16,678:INFO:self.USI: 3c34
2025-06-02 16:23:16,678:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 16:23:16,679:INFO:Checking environment
2025-06-02 16:23:16,680:INFO:python_version: 3.10.16
2025-06-02 16:23:16,680:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 16:23:16,681:INFO:machine: AMD64
2025-06-02 16:23:16,681:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 16:23:16,700:INFO:Memory: svmem(total=6378008576, available=1216393216, percent=80.9, used=5161615360, free=1216393216)
2025-06-02 16:23:16,701:INFO:Physical Core: 4
2025-06-02 16:23:16,701:INFO:Logical Core: 8
2025-06-02 16:23:16,702:INFO:Checking libraries
2025-06-02 16:23:16,703:INFO:System:
2025-06-02 16:23:16,704:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 16:23:16,704:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 16:23:16,704:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 16:23:16,704:INFO:PyCaret required dependencies:
2025-06-02 16:23:16,710:INFO:                 pip: 25.1
2025-06-02 16:23:16,710:INFO:          setuptools: 78.1.1
2025-06-02 16:23:16,710:INFO:             pycaret: 3.3.2
2025-06-02 16:23:16,710:INFO:             IPython: 8.37.0
2025-06-02 16:23:16,710:INFO:          ipywidgets: 8.1.7
2025-06-02 16:23:16,710:INFO:                tqdm: 4.67.1
2025-06-02 16:23:16,710:INFO:               numpy: 1.26.4
2025-06-02 16:23:16,710:INFO:              pandas: 2.0.1
2025-06-02 16:23:16,711:INFO:              jinja2: 3.1.6
2025-06-02 16:23:16,711:INFO:               scipy: 1.10.1
2025-06-02 16:23:16,711:INFO:              joblib: 1.3.2
2025-06-02 16:23:16,711:INFO:             sklearn: 1.4.2
2025-06-02 16:23:16,711:INFO:                pyod: 2.0.5
2025-06-02 16:23:16,711:INFO:            imblearn: 0.13.0
2025-06-02 16:23:16,711:INFO:   category_encoders: 2.7.0
2025-06-02 16:23:16,711:INFO:            lightgbm: 4.6.0
2025-06-02 16:23:16,711:INFO:               numba: 0.61.0
2025-06-02 16:23:16,711:INFO:            requests: 2.32.3
2025-06-02 16:23:16,711:INFO:          matplotlib: 3.7.1
2025-06-02 16:23:16,711:INFO:          scikitplot: 0.3.7
2025-06-02 16:23:16,711:INFO:         yellowbrick: 1.5
2025-06-02 16:23:16,711:INFO:              plotly: 6.1.2
2025-06-02 16:23:16,712:INFO:    plotly-resampler: Not installed
2025-06-02 16:23:16,712:INFO:             kaleido: 0.2.1
2025-06-02 16:23:16,712:INFO:           schemdraw: 0.15
2025-06-02 16:23:16,712:INFO:         statsmodels: 0.14.4
2025-06-02 16:23:16,712:INFO:              sktime: 0.26.0
2025-06-02 16:23:16,712:INFO:               tbats: 1.1.3
2025-06-02 16:23:16,712:INFO:            pmdarima: 2.0.4
2025-06-02 16:23:16,712:INFO:              psutil: 7.0.0
2025-06-02 16:23:16,712:INFO:          markupsafe: 2.1.2
2025-06-02 16:23:16,712:INFO:             pickle5: Not installed
2025-06-02 16:23:16,712:INFO:         cloudpickle: 3.1.1
2025-06-02 16:23:16,712:INFO:         deprecation: 2.1.0
2025-06-02 16:23:16,712:INFO:              xxhash: 3.5.0
2025-06-02 16:23:16,712:INFO:           wurlitzer: Not installed
2025-06-02 16:23:16,712:INFO:PyCaret optional dependencies:
2025-06-02 16:23:16,713:INFO:                shap: 0.44.1
2025-06-02 16:23:16,713:INFO:           interpret: 0.6.9
2025-06-02 16:23:16,713:INFO:                umap: 0.5.7
2025-06-02 16:23:16,713:INFO:     ydata_profiling: 4.16.1
2025-06-02 16:23:16,713:INFO:  explainerdashboard: 0.4.8
2025-06-02 16:23:16,714:INFO:             autoviz: Not installed
2025-06-02 16:23:16,714:INFO:           fairlearn: 0.7.0
2025-06-02 16:23:16,714:INFO:          deepchecks: Not installed
2025-06-02 16:23:16,714:INFO:             xgboost: 3.0.2
2025-06-02 16:23:16,714:INFO:            catboost: 1.2.8
2025-06-02 16:23:16,714:INFO:              kmodes: 0.12.2
2025-06-02 16:23:16,714:INFO:             mlxtend: 0.23.4
2025-06-02 16:23:16,714:INFO:       statsforecast: 1.5.0
2025-06-02 16:23:16,714:INFO:        tune_sklearn: Not installed
2025-06-02 16:23:16,714:INFO:                 ray: Not installed
2025-06-02 16:23:16,714:INFO:            hyperopt: 0.2.7
2025-06-02 16:23:16,714:INFO:              optuna: 4.3.0
2025-06-02 16:23:16,714:INFO:               skopt: 0.10.2
2025-06-02 16:23:16,714:INFO:              mlflow: 2.22.0
2025-06-02 16:23:16,714:INFO:              gradio: 5.32.0
2025-06-02 16:23:16,715:INFO:             fastapi: 0.115.12
2025-06-02 16:23:16,715:INFO:             uvicorn: 0.34.3
2025-06-02 16:23:16,715:INFO:              m2cgen: 0.10.0
2025-06-02 16:23:16,715:INFO:           evidently: 0.4.40
2025-06-02 16:23:16,715:INFO:               fugue: 0.8.5
2025-06-02 16:23:16,715:INFO:           streamlit: Not installed
2025-06-02 16:23:16,715:INFO:             prophet: Not installed
2025-06-02 16:23:16,715:INFO:None
2025-06-02 16:23:16,717:INFO:Set up data.
2025-06-02 16:23:16,935:INFO:Set up folding strategy.
2025-06-02 16:23:16,938:INFO:Set up train/test split.
2025-06-02 16:23:17,037:INFO:Set up index.
2025-06-02 16:23:17,043:INFO:Assigning column types.
2025-06-02 16:23:17,104:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 16:23:17,109:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 16:23:17,118:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 16:23:17,127:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 16:23:17,291:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:23:17,469:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:23:17,480:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:23:17,504:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:23:17,507:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 16:23:17,521:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 16:23:17,556:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 16:23:17,795:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:23:17,885:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:23:17,886:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:23:17,890:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:23:17,891:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 16:23:17,898:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 16:23:17,905:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 16:23:18,053:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:23:18,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:23:18,128:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:23:18,132:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:23:18,140:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 16:23:18,147:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 16:23:18,283:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:23:18,362:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:23:18,363:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:23:18,367:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:23:18,368:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 16:23:18,383:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 16:23:18,526:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:23:18,620:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:23:18,620:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:23:18,624:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:23:18,640:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 16:23:18,782:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:23:18,866:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:23:18,866:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:23:18,870:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:23:18,871:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 16:23:19,018:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:23:19,091:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:23:19,092:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:23:19,096:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:23:19,249:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:23:19,322:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 16:23:19,323:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:23:19,327:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:23:19,328:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 16:23:19,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:23:19,571:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:23:19,575:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:23:19,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 16:23:19,802:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:23:19,807:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:23:19,808:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 16:23:20,028:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:23:20,032:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:23:20,254:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:23:20,258:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:23:20,275:INFO:Preparing preprocessing pipeline...
2025-06-02 16:23:20,275:INFO:Set up simple imputation.
2025-06-02 16:23:20,276:INFO:Set up removing multicollinearity.
2025-06-02 16:23:20,283:INFO:Set up column name cleaning.
2025-06-02 16:23:20,576:INFO:Finished creating preprocessing pipeline.
2025-06-02 16:23:20,597:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 16:23:20,597:INFO:Creating final display dataframe.
2025-06-02 16:23:21,043:INFO:Setup _display_container:                     Description             Value
0                    Session id               124
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3134, 97)
6    Transformed test set shape        (1344, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              3c34
2025-06-02 16:23:21,332:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:23:21,337:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:23:21,550:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 16:23:21,554:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 16:23:21,566:INFO:setup() successfully completed in 5.04s...............
2025-06-02 16:23:21,569:INFO:Initializing compare_models()
2025-06-02 16:23:21,569:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 16:23:21,569:INFO:Checking exceptions
2025-06-02 16:23:21,592:INFO:Preparing display monitor
2025-06-02 16:23:21,692:INFO:Initializing Linear Regression
2025-06-02 16:23:21,693:INFO:Total runtime is 1.6681353251139323e-05 minutes
2025-06-02 16:23:21,708:INFO:SubProcess create_model() called ==================================
2025-06-02 16:23:21,710:INFO:Initializing create_model()
2025-06-02 16:23:21,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:23:21,711:INFO:Checking exceptions
2025-06-02 16:23:21,712:INFO:Importing libraries
2025-06-02 16:23:21,712:INFO:Copying training dataset
2025-06-02 16:23:21,798:INFO:Defining folds
2025-06-02 16:23:21,799:INFO:Declaring metric variables
2025-06-02 16:23:21,835:INFO:Importing untrained model
2025-06-02 16:23:21,849:INFO:Linear Regression Imported successfully
2025-06-02 16:23:21,872:INFO:Starting cross validation
2025-06-02 16:23:21,881:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:23:35,453:INFO:Calculating mean and std
2025-06-02 16:23:35,467:INFO:Creating metrics dataframe
2025-06-02 16:23:35,504:INFO:Uploading results into container
2025-06-02 16:23:35,516:INFO:Uploading model into container now
2025-06-02 16:23:35,520:INFO:_master_model_container: 1
2025-06-02 16:23:35,521:INFO:_display_container: 2
2025-06-02 16:23:35,522:INFO:LinearRegression(n_jobs=-1)
2025-06-02 16:23:35,522:INFO:create_model() successfully completed......................................
2025-06-02 16:23:48,035:INFO:SubProcess create_model() end ==================================
2025-06-02 16:23:48,036:INFO:Creating metrics dataframe
2025-06-02 16:23:48,067:INFO:Initializing Lasso Regression
2025-06-02 16:23:48,067:INFO:Total runtime is 0.4395820021629333 minutes
2025-06-02 16:23:48,078:INFO:SubProcess create_model() called ==================================
2025-06-02 16:23:48,079:INFO:Initializing create_model()
2025-06-02 16:23:48,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:23:48,080:INFO:Checking exceptions
2025-06-02 16:23:48,080:INFO:Importing libraries
2025-06-02 16:23:48,081:INFO:Copying training dataset
2025-06-02 16:23:48,177:INFO:Defining folds
2025-06-02 16:23:48,178:INFO:Declaring metric variables
2025-06-02 16:23:48,191:INFO:Importing untrained model
2025-06-02 16:23:48,209:INFO:Lasso Regression Imported successfully
2025-06-02 16:23:48,231:INFO:Starting cross validation
2025-06-02 16:23:48,236:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:23:58,431:INFO:Calculating mean and std
2025-06-02 16:23:58,437:INFO:Creating metrics dataframe
2025-06-02 16:23:58,449:INFO:Uploading results into container
2025-06-02 16:23:58,452:INFO:Uploading model into container now
2025-06-02 16:23:58,453:INFO:_master_model_container: 2
2025-06-02 16:23:58,454:INFO:_display_container: 2
2025-06-02 16:23:58,457:INFO:Lasso(random_state=124)
2025-06-02 16:23:58,457:INFO:create_model() successfully completed......................................
2025-06-02 16:23:59,831:INFO:SubProcess create_model() end ==================================
2025-06-02 16:23:59,831:INFO:Creating metrics dataframe
2025-06-02 16:23:59,853:INFO:Initializing Ridge Regression
2025-06-02 16:23:59,853:INFO:Total runtime is 0.6360211491584777 minutes
2025-06-02 16:23:59,865:INFO:SubProcess create_model() called ==================================
2025-06-02 16:23:59,866:INFO:Initializing create_model()
2025-06-02 16:23:59,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:23:59,866:INFO:Checking exceptions
2025-06-02 16:23:59,867:INFO:Importing libraries
2025-06-02 16:23:59,868:INFO:Copying training dataset
2025-06-02 16:23:59,941:INFO:Defining folds
2025-06-02 16:23:59,942:INFO:Declaring metric variables
2025-06-02 16:23:59,955:INFO:Importing untrained model
2025-06-02 16:23:59,968:INFO:Ridge Regression Imported successfully
2025-06-02 16:23:59,997:INFO:Starting cross validation
2025-06-02 16:24:00,001:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:01,465:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.26677e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 16:24:01,748:INFO:Calculating mean and std
2025-06-02 16:24:01,757:INFO:Creating metrics dataframe
2025-06-02 16:24:01,772:INFO:Uploading results into container
2025-06-02 16:24:01,779:INFO:Uploading model into container now
2025-06-02 16:24:01,783:INFO:_master_model_container: 3
2025-06-02 16:24:01,784:INFO:_display_container: 2
2025-06-02 16:24:01,785:INFO:Ridge(random_state=124)
2025-06-02 16:24:01,786:INFO:create_model() successfully completed......................................
2025-06-02 16:24:04,044:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:04,044:INFO:Creating metrics dataframe
2025-06-02 16:24:04,062:INFO:Initializing Elastic Net
2025-06-02 16:24:04,062:INFO:Total runtime is 0.7061666886011759 minutes
2025-06-02 16:24:04,074:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:04,075:INFO:Initializing create_model()
2025-06-02 16:24:04,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:04,075:INFO:Checking exceptions
2025-06-02 16:24:04,076:INFO:Importing libraries
2025-06-02 16:24:04,076:INFO:Copying training dataset
2025-06-02 16:24:04,157:INFO:Defining folds
2025-06-02 16:24:04,158:INFO:Declaring metric variables
2025-06-02 16:24:04,173:INFO:Importing untrained model
2025-06-02 16:24:04,186:INFO:Elastic Net Imported successfully
2025-06-02 16:24:04,212:INFO:Starting cross validation
2025-06-02 16:24:04,218:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:05,146:INFO:Calculating mean and std
2025-06-02 16:24:05,149:INFO:Creating metrics dataframe
2025-06-02 16:24:05,152:INFO:Uploading results into container
2025-06-02 16:24:05,153:INFO:Uploading model into container now
2025-06-02 16:24:05,154:INFO:_master_model_container: 4
2025-06-02 16:24:05,154:INFO:_display_container: 2
2025-06-02 16:24:05,155:INFO:ElasticNet(random_state=124)
2025-06-02 16:24:05,156:INFO:create_model() successfully completed......................................
2025-06-02 16:24:06,461:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:06,461:INFO:Creating metrics dataframe
2025-06-02 16:24:06,476:INFO:Initializing Least Angle Regression
2025-06-02 16:24:06,476:INFO:Total runtime is 0.7463997681935628 minutes
2025-06-02 16:24:06,487:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:06,487:INFO:Initializing create_model()
2025-06-02 16:24:06,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:06,488:INFO:Checking exceptions
2025-06-02 16:24:06,488:INFO:Importing libraries
2025-06-02 16:24:06,489:INFO:Copying training dataset
2025-06-02 16:24:06,557:INFO:Defining folds
2025-06-02 16:24:06,558:INFO:Declaring metric variables
2025-06-02 16:24:06,572:INFO:Importing untrained model
2025-06-02 16:24:06,587:INFO:Least Angle Regression Imported successfully
2025-06-02 16:24:06,613:INFO:Starting cross validation
2025-06-02 16:24:06,618:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:07,483:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=1.459e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 16:24:07,545:INFO:Calculating mean and std
2025-06-02 16:24:07,548:INFO:Creating metrics dataframe
2025-06-02 16:24:07,552:INFO:Uploading results into container
2025-06-02 16:24:07,553:INFO:Uploading model into container now
2025-06-02 16:24:07,555:INFO:_master_model_container: 5
2025-06-02 16:24:07,555:INFO:_display_container: 2
2025-06-02 16:24:07,557:INFO:Lars(random_state=124)
2025-06-02 16:24:07,557:INFO:create_model() successfully completed......................................
2025-06-02 16:24:09,015:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:09,016:INFO:Creating metrics dataframe
2025-06-02 16:24:09,036:INFO:Initializing Lasso Least Angle Regression
2025-06-02 16:24:09,037:INFO:Total runtime is 0.789090343316396 minutes
2025-06-02 16:24:09,050:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:09,052:INFO:Initializing create_model()
2025-06-02 16:24:09,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:09,054:INFO:Checking exceptions
2025-06-02 16:24:09,055:INFO:Importing libraries
2025-06-02 16:24:09,055:INFO:Copying training dataset
2025-06-02 16:24:09,137:INFO:Defining folds
2025-06-02 16:24:09,138:INFO:Declaring metric variables
2025-06-02 16:24:09,153:INFO:Importing untrained model
2025-06-02 16:24:09,167:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 16:24:09,199:INFO:Starting cross validation
2025-06-02 16:24:09,204:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:10,067:INFO:Calculating mean and std
2025-06-02 16:24:10,070:INFO:Creating metrics dataframe
2025-06-02 16:24:10,075:INFO:Uploading results into container
2025-06-02 16:24:10,077:INFO:Uploading model into container now
2025-06-02 16:24:10,079:INFO:_master_model_container: 6
2025-06-02 16:24:10,079:INFO:_display_container: 2
2025-06-02 16:24:10,080:INFO:LassoLars(random_state=124)
2025-06-02 16:24:10,080:INFO:create_model() successfully completed......................................
2025-06-02 16:24:11,411:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:11,411:INFO:Creating metrics dataframe
2025-06-02 16:24:11,430:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 16:24:11,431:INFO:Total runtime is 0.8289850234985351 minutes
2025-06-02 16:24:11,441:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:11,442:INFO:Initializing create_model()
2025-06-02 16:24:11,442:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:11,442:INFO:Checking exceptions
2025-06-02 16:24:11,443:INFO:Importing libraries
2025-06-02 16:24:11,443:INFO:Copying training dataset
2025-06-02 16:24:11,518:INFO:Defining folds
2025-06-02 16:24:11,518:INFO:Declaring metric variables
2025-06-02 16:24:11,530:INFO:Importing untrained model
2025-06-02 16:24:11,542:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 16:24:11,568:INFO:Starting cross validation
2025-06-02 16:24:11,572:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:12,407:INFO:Calculating mean and std
2025-06-02 16:24:12,409:INFO:Creating metrics dataframe
2025-06-02 16:24:12,415:INFO:Uploading results into container
2025-06-02 16:24:12,417:INFO:Uploading model into container now
2025-06-02 16:24:12,418:INFO:_master_model_container: 7
2025-06-02 16:24:12,418:INFO:_display_container: 2
2025-06-02 16:24:12,419:INFO:OrthogonalMatchingPursuit()
2025-06-02 16:24:12,419:INFO:create_model() successfully completed......................................
2025-06-02 16:24:13,728:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:13,729:INFO:Creating metrics dataframe
2025-06-02 16:24:13,748:INFO:Initializing Bayesian Ridge
2025-06-02 16:24:13,748:INFO:Total runtime is 0.8675973693529764 minutes
2025-06-02 16:24:13,757:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:13,758:INFO:Initializing create_model()
2025-06-02 16:24:13,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:13,758:INFO:Checking exceptions
2025-06-02 16:24:13,759:INFO:Importing libraries
2025-06-02 16:24:13,759:INFO:Copying training dataset
2025-06-02 16:24:13,831:INFO:Defining folds
2025-06-02 16:24:13,832:INFO:Declaring metric variables
2025-06-02 16:24:13,844:INFO:Importing untrained model
2025-06-02 16:24:13,857:INFO:Bayesian Ridge Imported successfully
2025-06-02 16:24:13,884:INFO:Starting cross validation
2025-06-02 16:24:13,888:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:14,703:INFO:Calculating mean and std
2025-06-02 16:24:14,705:INFO:Creating metrics dataframe
2025-06-02 16:24:14,709:INFO:Uploading results into container
2025-06-02 16:24:14,710:INFO:Uploading model into container now
2025-06-02 16:24:14,712:INFO:_master_model_container: 8
2025-06-02 16:24:14,712:INFO:_display_container: 2
2025-06-02 16:24:14,713:INFO:BayesianRidge()
2025-06-02 16:24:14,713:INFO:create_model() successfully completed......................................
2025-06-02 16:24:16,025:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:16,025:INFO:Creating metrics dataframe
2025-06-02 16:24:16,043:INFO:Initializing Passive Aggressive Regressor
2025-06-02 16:24:16,043:INFO:Total runtime is 0.9058478554089863 minutes
2025-06-02 16:24:16,055:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:16,056:INFO:Initializing create_model()
2025-06-02 16:24:16,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:16,057:INFO:Checking exceptions
2025-06-02 16:24:16,057:INFO:Importing libraries
2025-06-02 16:24:16,058:INFO:Copying training dataset
2025-06-02 16:24:16,243:INFO:Defining folds
2025-06-02 16:24:16,246:INFO:Declaring metric variables
2025-06-02 16:24:16,263:INFO:Importing untrained model
2025-06-02 16:24:16,281:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 16:24:16,326:INFO:Starting cross validation
2025-06-02 16:24:16,331:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:17,279:INFO:Calculating mean and std
2025-06-02 16:24:17,281:INFO:Creating metrics dataframe
2025-06-02 16:24:17,285:INFO:Uploading results into container
2025-06-02 16:24:17,286:INFO:Uploading model into container now
2025-06-02 16:24:17,287:INFO:_master_model_container: 9
2025-06-02 16:24:17,287:INFO:_display_container: 2
2025-06-02 16:24:17,288:INFO:PassiveAggressiveRegressor(random_state=124)
2025-06-02 16:24:17,289:INFO:create_model() successfully completed......................................
2025-06-02 16:24:18,579:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:18,580:INFO:Creating metrics dataframe
2025-06-02 16:24:18,598:INFO:Initializing Huber Regressor
2025-06-02 16:24:18,599:INFO:Total runtime is 0.9484521865844725 minutes
2025-06-02 16:24:18,608:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:18,608:INFO:Initializing create_model()
2025-06-02 16:24:18,609:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:18,609:INFO:Checking exceptions
2025-06-02 16:24:18,609:INFO:Importing libraries
2025-06-02 16:24:18,610:INFO:Copying training dataset
2025-06-02 16:24:18,680:INFO:Defining folds
2025-06-02 16:24:18,681:INFO:Declaring metric variables
2025-06-02 16:24:18,694:INFO:Importing untrained model
2025-06-02 16:24:18,706:INFO:Huber Regressor Imported successfully
2025-06-02 16:24:18,732:INFO:Starting cross validation
2025-06-02 16:24:18,736:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:20,421:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 16:24:20,436:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 16:24:20,437:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 16:24:20,454:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 16:24:20,464:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 16:24:20,524:INFO:Calculating mean and std
2025-06-02 16:24:20,526:INFO:Creating metrics dataframe
2025-06-02 16:24:20,529:INFO:Uploading results into container
2025-06-02 16:24:20,530:INFO:Uploading model into container now
2025-06-02 16:24:20,531:INFO:_master_model_container: 10
2025-06-02 16:24:20,532:INFO:_display_container: 2
2025-06-02 16:24:20,532:INFO:HuberRegressor()
2025-06-02 16:24:20,532:INFO:create_model() successfully completed......................................
2025-06-02 16:24:21,844:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:21,845:INFO:Creating metrics dataframe
2025-06-02 16:24:21,871:INFO:Initializing K Neighbors Regressor
2025-06-02 16:24:21,871:INFO:Total runtime is 1.0029779314994811 minutes
2025-06-02 16:24:21,880:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:21,881:INFO:Initializing create_model()
2025-06-02 16:24:21,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:21,882:INFO:Checking exceptions
2025-06-02 16:24:21,882:INFO:Importing libraries
2025-06-02 16:24:21,883:INFO:Copying training dataset
2025-06-02 16:24:21,957:INFO:Defining folds
2025-06-02 16:24:21,958:INFO:Declaring metric variables
2025-06-02 16:24:21,972:INFO:Importing untrained model
2025-06-02 16:24:21,986:INFO:K Neighbors Regressor Imported successfully
2025-06-02 16:24:22,014:INFO:Starting cross validation
2025-06-02 16:24:22,017:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:22,885:INFO:Calculating mean and std
2025-06-02 16:24:22,887:INFO:Creating metrics dataframe
2025-06-02 16:24:22,891:INFO:Uploading results into container
2025-06-02 16:24:22,892:INFO:Uploading model into container now
2025-06-02 16:24:22,893:INFO:_master_model_container: 11
2025-06-02 16:24:22,893:INFO:_display_container: 2
2025-06-02 16:24:22,894:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 16:24:22,895:INFO:create_model() successfully completed......................................
2025-06-02 16:24:24,194:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:24,194:INFO:Creating metrics dataframe
2025-06-02 16:24:24,213:INFO:Initializing Decision Tree Regressor
2025-06-02 16:24:24,213:INFO:Total runtime is 1.0420234243075053 minutes
2025-06-02 16:24:24,223:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:24,224:INFO:Initializing create_model()
2025-06-02 16:24:24,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:24,225:INFO:Checking exceptions
2025-06-02 16:24:24,226:INFO:Importing libraries
2025-06-02 16:24:24,226:INFO:Copying training dataset
2025-06-02 16:24:24,333:INFO:Defining folds
2025-06-02 16:24:24,334:INFO:Declaring metric variables
2025-06-02 16:24:24,346:INFO:Importing untrained model
2025-06-02 16:24:24,357:INFO:Decision Tree Regressor Imported successfully
2025-06-02 16:24:24,383:INFO:Starting cross validation
2025-06-02 16:24:24,387:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:25,390:INFO:Calculating mean and std
2025-06-02 16:24:25,392:INFO:Creating metrics dataframe
2025-06-02 16:24:25,395:INFO:Uploading results into container
2025-06-02 16:24:25,396:INFO:Uploading model into container now
2025-06-02 16:24:25,396:INFO:_master_model_container: 12
2025-06-02 16:24:25,397:INFO:_display_container: 2
2025-06-02 16:24:25,397:INFO:DecisionTreeRegressor(random_state=124)
2025-06-02 16:24:25,397:INFO:create_model() successfully completed......................................
2025-06-02 16:24:26,710:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:26,710:INFO:Creating metrics dataframe
2025-06-02 16:24:26,729:INFO:Initializing Random Forest Regressor
2025-06-02 16:24:26,729:INFO:Total runtime is 1.0839507102966308 minutes
2025-06-02 16:24:26,739:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:26,740:INFO:Initializing create_model()
2025-06-02 16:24:26,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:26,741:INFO:Checking exceptions
2025-06-02 16:24:26,741:INFO:Importing libraries
2025-06-02 16:24:26,742:INFO:Copying training dataset
2025-06-02 16:24:26,821:INFO:Defining folds
2025-06-02 16:24:26,822:INFO:Declaring metric variables
2025-06-02 16:24:26,837:INFO:Importing untrained model
2025-06-02 16:24:26,852:INFO:Random Forest Regressor Imported successfully
2025-06-02 16:24:26,876:INFO:Starting cross validation
2025-06-02 16:24:26,882:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:35,622:INFO:Calculating mean and std
2025-06-02 16:24:35,624:INFO:Creating metrics dataframe
2025-06-02 16:24:35,630:INFO:Uploading results into container
2025-06-02 16:24:35,631:INFO:Uploading model into container now
2025-06-02 16:24:35,633:INFO:_master_model_container: 13
2025-06-02 16:24:35,633:INFO:_display_container: 2
2025-06-02 16:24:35,634:INFO:RandomForestRegressor(n_jobs=-1, random_state=124)
2025-06-02 16:24:35,635:INFO:create_model() successfully completed......................................
2025-06-02 16:24:36,985:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:36,986:INFO:Creating metrics dataframe
2025-06-02 16:24:37,013:INFO:Initializing Extra Trees Regressor
2025-06-02 16:24:37,014:INFO:Total runtime is 1.2553739547729492 minutes
2025-06-02 16:24:37,023:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:37,023:INFO:Initializing create_model()
2025-06-02 16:24:37,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:37,024:INFO:Checking exceptions
2025-06-02 16:24:37,024:INFO:Importing libraries
2025-06-02 16:24:37,025:INFO:Copying training dataset
2025-06-02 16:24:37,108:INFO:Defining folds
2025-06-02 16:24:37,111:INFO:Declaring metric variables
2025-06-02 16:24:37,158:INFO:Importing untrained model
2025-06-02 16:24:37,169:INFO:Extra Trees Regressor Imported successfully
2025-06-02 16:24:37,203:INFO:Starting cross validation
2025-06-02 16:24:37,208:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:43,017:INFO:Calculating mean and std
2025-06-02 16:24:43,020:INFO:Creating metrics dataframe
2025-06-02 16:24:43,024:INFO:Uploading results into container
2025-06-02 16:24:43,026:INFO:Uploading model into container now
2025-06-02 16:24:43,027:INFO:_master_model_container: 14
2025-06-02 16:24:43,027:INFO:_display_container: 2
2025-06-02 16:24:43,029:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=124)
2025-06-02 16:24:43,030:INFO:create_model() successfully completed......................................
2025-06-02 16:24:44,525:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:44,525:INFO:Creating metrics dataframe
2025-06-02 16:24:44,552:INFO:Initializing AdaBoost Regressor
2025-06-02 16:24:44,553:INFO:Total runtime is 1.3809972604115803 minutes
2025-06-02 16:24:44,562:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:44,563:INFO:Initializing create_model()
2025-06-02 16:24:44,563:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:44,563:INFO:Checking exceptions
2025-06-02 16:24:44,563:INFO:Importing libraries
2025-06-02 16:24:44,563:INFO:Copying training dataset
2025-06-02 16:24:44,663:INFO:Defining folds
2025-06-02 16:24:44,663:INFO:Declaring metric variables
2025-06-02 16:24:44,682:INFO:Importing untrained model
2025-06-02 16:24:44,700:INFO:AdaBoost Regressor Imported successfully
2025-06-02 16:24:44,730:INFO:Starting cross validation
2025-06-02 16:24:44,735:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:46,719:INFO:Calculating mean and std
2025-06-02 16:24:46,721:INFO:Creating metrics dataframe
2025-06-02 16:24:46,725:INFO:Uploading results into container
2025-06-02 16:24:46,726:INFO:Uploading model into container now
2025-06-02 16:24:46,727:INFO:_master_model_container: 15
2025-06-02 16:24:46,727:INFO:_display_container: 2
2025-06-02 16:24:46,728:INFO:AdaBoostRegressor(random_state=124)
2025-06-02 16:24:46,729:INFO:create_model() successfully completed......................................
2025-06-02 16:24:48,034:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:48,034:INFO:Creating metrics dataframe
2025-06-02 16:24:48,057:INFO:Initializing Gradient Boosting Regressor
2025-06-02 16:24:48,057:INFO:Total runtime is 1.4394214550654092 minutes
2025-06-02 16:24:48,068:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:48,068:INFO:Initializing create_model()
2025-06-02 16:24:48,068:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:48,068:INFO:Checking exceptions
2025-06-02 16:24:48,069:INFO:Importing libraries
2025-06-02 16:24:48,069:INFO:Copying training dataset
2025-06-02 16:24:48,179:INFO:Defining folds
2025-06-02 16:24:48,179:INFO:Declaring metric variables
2025-06-02 16:24:48,195:INFO:Importing untrained model
2025-06-02 16:24:48,207:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 16:24:48,235:INFO:Starting cross validation
2025-06-02 16:24:48,239:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:51,757:INFO:Calculating mean and std
2025-06-02 16:24:51,760:INFO:Creating metrics dataframe
2025-06-02 16:24:51,763:INFO:Uploading results into container
2025-06-02 16:24:51,765:INFO:Uploading model into container now
2025-06-02 16:24:51,766:INFO:_master_model_container: 16
2025-06-02 16:24:51,766:INFO:_display_container: 2
2025-06-02 16:24:51,766:INFO:GradientBoostingRegressor(random_state=124)
2025-06-02 16:24:51,766:INFO:create_model() successfully completed......................................
2025-06-02 16:24:53,080:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:53,081:INFO:Creating metrics dataframe
2025-06-02 16:24:53,102:INFO:Initializing Extreme Gradient Boosting
2025-06-02 16:24:53,102:INFO:Total runtime is 1.5235077261924743 minutes
2025-06-02 16:24:53,113:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:53,113:INFO:Initializing create_model()
2025-06-02 16:24:53,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:53,114:INFO:Checking exceptions
2025-06-02 16:24:53,114:INFO:Importing libraries
2025-06-02 16:24:53,115:INFO:Copying training dataset
2025-06-02 16:24:53,184:INFO:Defining folds
2025-06-02 16:24:53,185:INFO:Declaring metric variables
2025-06-02 16:24:53,198:INFO:Importing untrained model
2025-06-02 16:24:53,209:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 16:24:53,236:INFO:Starting cross validation
2025-06-02 16:24:53,240:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:55,359:INFO:Calculating mean and std
2025-06-02 16:24:55,361:INFO:Creating metrics dataframe
2025-06-02 16:24:55,366:INFO:Uploading results into container
2025-06-02 16:24:55,367:INFO:Uploading model into container now
2025-06-02 16:24:55,368:INFO:_master_model_container: 17
2025-06-02 16:24:55,368:INFO:_display_container: 2
2025-06-02 16:24:55,371:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 16:24:55,372:INFO:create_model() successfully completed......................................
2025-06-02 16:24:56,679:INFO:SubProcess create_model() end ==================================
2025-06-02 16:24:56,679:INFO:Creating metrics dataframe
2025-06-02 16:24:56,705:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 16:24:56,705:INFO:Total runtime is 1.5835523009300232 minutes
2025-06-02 16:24:56,715:INFO:SubProcess create_model() called ==================================
2025-06-02 16:24:56,715:INFO:Initializing create_model()
2025-06-02 16:24:56,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:24:56,716:INFO:Checking exceptions
2025-06-02 16:24:56,716:INFO:Importing libraries
2025-06-02 16:24:56,716:INFO:Copying training dataset
2025-06-02 16:24:56,787:INFO:Defining folds
2025-06-02 16:24:56,788:INFO:Declaring metric variables
2025-06-02 16:24:56,813:INFO:Importing untrained model
2025-06-02 16:24:56,836:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 16:24:56,875:INFO:Starting cross validation
2025-06-02 16:24:56,880:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:24:58,656:INFO:Calculating mean and std
2025-06-02 16:24:58,658:INFO:Creating metrics dataframe
2025-06-02 16:24:58,662:INFO:Uploading results into container
2025-06-02 16:24:58,663:INFO:Uploading model into container now
2025-06-02 16:24:58,665:INFO:_master_model_container: 18
2025-06-02 16:24:58,665:INFO:_display_container: 2
2025-06-02 16:24:58,667:INFO:LGBMRegressor(n_jobs=-1, random_state=124)
2025-06-02 16:24:58,667:INFO:create_model() successfully completed......................................
2025-06-02 16:25:00,046:INFO:SubProcess create_model() end ==================================
2025-06-02 16:25:00,047:INFO:Creating metrics dataframe
2025-06-02 16:25:00,077:INFO:Initializing CatBoost Regressor
2025-06-02 16:25:00,077:INFO:Total runtime is 1.6397500077883402 minutes
2025-06-02 16:25:00,089:INFO:SubProcess create_model() called ==================================
2025-06-02 16:25:00,090:INFO:Initializing create_model()
2025-06-02 16:25:00,090:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:25:00,090:INFO:Checking exceptions
2025-06-02 16:25:00,091:INFO:Importing libraries
2025-06-02 16:25:00,091:INFO:Copying training dataset
2025-06-02 16:25:00,202:INFO:Defining folds
2025-06-02 16:25:00,214:INFO:Declaring metric variables
2025-06-02 16:25:00,225:INFO:Importing untrained model
2025-06-02 16:25:00,265:INFO:CatBoost Regressor Imported successfully
2025-06-02 16:25:00,296:INFO:Starting cross validation
2025-06-02 16:25:00,303:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:25:25,512:INFO:Calculating mean and std
2025-06-02 16:25:25,514:INFO:Creating metrics dataframe
2025-06-02 16:25:25,518:INFO:Uploading results into container
2025-06-02 16:25:25,519:INFO:Uploading model into container now
2025-06-02 16:25:25,520:INFO:_master_model_container: 19
2025-06-02 16:25:25,520:INFO:_display_container: 2
2025-06-02 16:25:25,521:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6E499B490>
2025-06-02 16:25:25,521:INFO:create_model() successfully completed......................................
2025-06-02 16:25:26,974:INFO:SubProcess create_model() end ==================================
2025-06-02 16:25:26,974:INFO:Creating metrics dataframe
2025-06-02 16:25:26,998:INFO:Initializing Dummy Regressor
2025-06-02 16:25:26,998:INFO:Total runtime is 2.088430901368459 minutes
2025-06-02 16:25:27,006:INFO:SubProcess create_model() called ==================================
2025-06-02 16:25:27,007:INFO:Initializing create_model()
2025-06-02 16:25:27,007:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCEA7700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:25:27,007:INFO:Checking exceptions
2025-06-02 16:25:27,008:INFO:Importing libraries
2025-06-02 16:25:27,008:INFO:Copying training dataset
2025-06-02 16:25:27,079:INFO:Defining folds
2025-06-02 16:25:27,080:INFO:Declaring metric variables
2025-06-02 16:25:27,093:INFO:Importing untrained model
2025-06-02 16:25:27,111:INFO:Dummy Regressor Imported successfully
2025-06-02 16:25:27,169:INFO:Starting cross validation
2025-06-02 16:25:27,175:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:25:28,463:INFO:Calculating mean and std
2025-06-02 16:25:28,466:INFO:Creating metrics dataframe
2025-06-02 16:25:28,470:INFO:Uploading results into container
2025-06-02 16:25:28,471:INFO:Uploading model into container now
2025-06-02 16:25:28,472:INFO:_master_model_container: 20
2025-06-02 16:25:28,473:INFO:_display_container: 2
2025-06-02 16:25:28,473:INFO:DummyRegressor()
2025-06-02 16:25:28,474:INFO:create_model() successfully completed......................................
2025-06-02 16:25:29,796:INFO:SubProcess create_model() end ==================================
2025-06-02 16:25:29,796:INFO:Creating metrics dataframe
2025-06-02 16:25:29,849:INFO:Initializing create_model()
2025-06-02 16:25:29,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=124), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:25:29,850:INFO:Checking exceptions
2025-06-02 16:25:29,857:INFO:Importing libraries
2025-06-02 16:25:29,858:INFO:Copying training dataset
2025-06-02 16:25:29,976:INFO:Defining folds
2025-06-02 16:25:29,977:INFO:Declaring metric variables
2025-06-02 16:25:29,977:INFO:Importing untrained model
2025-06-02 16:25:29,977:INFO:Declaring custom model
2025-06-02 16:25:29,980:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 16:25:29,986:INFO:Cross validation set to False
2025-06-02 16:25:29,986:INFO:Fitting Model
2025-06-02 16:25:30,702:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 16:25:30,716:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010250 seconds.
2025-06-02 16:25:30,716:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 16:25:30,717:INFO:[LightGBM] [Info] Total Bins 6263
2025-06-02 16:25:30,724:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 16:25:30,725:INFO:[LightGBM] [Info] Start training from score -0.505554
2025-06-02 16:25:30,968:INFO:LGBMRegressor(n_jobs=-1, random_state=124)
2025-06-02 16:25:30,968:INFO:create_model() successfully completed......................................
2025-06-02 16:25:32,358:INFO:Initializing create_model()
2025-06-02 16:25:32,358:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=<catboost.core.CatBoostRegressor object at 0x000001B6E499B490>, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:25:32,359:INFO:Checking exceptions
2025-06-02 16:25:32,364:INFO:Importing libraries
2025-06-02 16:25:32,365:INFO:Copying training dataset
2025-06-02 16:25:32,434:INFO:Defining folds
2025-06-02 16:25:32,435:INFO:Declaring metric variables
2025-06-02 16:25:32,435:INFO:Importing untrained model
2025-06-02 16:25:32,435:INFO:Declaring custom model
2025-06-02 16:25:32,436:INFO:CatBoost Regressor Imported successfully
2025-06-02 16:25:32,439:INFO:Cross validation set to False
2025-06-02 16:25:32,439:INFO:Fitting Model
2025-06-02 16:25:39,005:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6E48D9FC0>
2025-06-02 16:25:39,005:INFO:create_model() successfully completed......................................
2025-06-02 16:25:40,639:INFO:Initializing create_model()
2025-06-02 16:25:40,640:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=124), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:25:40,640:INFO:Checking exceptions
2025-06-02 16:25:40,644:INFO:Importing libraries
2025-06-02 16:25:40,645:INFO:Copying training dataset
2025-06-02 16:25:40,718:INFO:Defining folds
2025-06-02 16:25:40,718:INFO:Declaring metric variables
2025-06-02 16:25:40,718:INFO:Importing untrained model
2025-06-02 16:25:40,719:INFO:Declaring custom model
2025-06-02 16:25:40,720:INFO:Random Forest Regressor Imported successfully
2025-06-02 16:25:40,724:INFO:Cross validation set to False
2025-06-02 16:25:40,724:INFO:Fitting Model
2025-06-02 16:25:43,232:INFO:RandomForestRegressor(n_jobs=-1, random_state=124)
2025-06-02 16:25:43,232:INFO:create_model() successfully completed......................................
2025-06-02 16:25:44,620:INFO:_master_model_container: 20
2025-06-02 16:25:44,620:INFO:_display_container: 2
2025-06-02 16:25:44,622:INFO:[LGBMRegressor(n_jobs=-1, random_state=124), <catboost.core.CatBoostRegressor object at 0x000001B6E48D9FC0>, RandomForestRegressor(n_jobs=-1, random_state=124)]
2025-06-02 16:25:44,622:INFO:compare_models() successfully completed......................................
2025-06-02 16:25:44,625:INFO:Initializing tune_model()
2025-06-02 16:25:44,626:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=124), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>)
2025-06-02 16:25:44,627:INFO:Checking exceptions
2025-06-02 16:25:44,627:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 16:25:44,693:INFO:Copying training dataset
2025-06-02 16:25:44,751:INFO:Checking base model
2025-06-02 16:25:44,751:INFO:Base model : Light Gradient Boosting Machine
2025-06-02 16:25:44,770:INFO:Declaring metric variables
2025-06-02 16:25:44,785:INFO:Defining Hyperparameters
2025-06-02 16:25:46,268:INFO:Tuning with n_jobs=-1
2025-06-02 16:25:46,285:INFO:Initializing skopt.BayesSearchCV
2025-06-02 16:26:08,538:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.9913095246754634), ('actual_estimator__bagging_freq', 1), ('actual_estimator__feature_fraction', 0.9211599849219095), ('actual_estimator__learning_rate', 0.21136499069406833), ('actual_estimator__min_child_samples', 14), ('actual_estimator__min_split_gain', 0.6262984370406117), ('actual_estimator__n_estimators', 179), ('actual_estimator__num_leaves', 224), ('actual_estimator__reg_alpha', 3.1387651466927824e-05), ('actual_estimator__reg_lambda', 6.88892157310396)])
2025-06-02 16:26:08,540:INFO:Hyperparameter search completed
2025-06-02 16:26:08,540:INFO:SubProcess create_model() called ==================================
2025-06-02 16:26:08,542:INFO:Initializing create_model()
2025-06-02 16:26:08,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=124), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DBD1C0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.9913095246754634, 'bagging_freq': 1, 'feature_fraction': 0.9211599849219095, 'learning_rate': 0.21136499069406833, 'min_child_samples': 14, 'min_split_gain': 0.6262984370406117, 'n_estimators': 179, 'num_leaves': 224, 'reg_alpha': 3.1387651466927824e-05, 'reg_lambda': 6.88892157310396})
2025-06-02 16:26:08,542:INFO:Checking exceptions
2025-06-02 16:26:08,543:INFO:Importing libraries
2025-06-02 16:26:08,543:INFO:Copying training dataset
2025-06-02 16:26:08,608:INFO:Defining folds
2025-06-02 16:26:08,609:INFO:Declaring metric variables
2025-06-02 16:26:08,617:INFO:Importing untrained model
2025-06-02 16:26:08,617:INFO:Declaring custom model
2025-06-02 16:26:08,634:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 16:26:08,655:INFO:Starting cross validation
2025-06-02 16:26:08,659:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:26:10,100:INFO:Calculating mean and std
2025-06-02 16:26:10,104:INFO:Creating metrics dataframe
2025-06-02 16:26:10,127:INFO:Finalizing model
2025-06-02 16:26:10,727:INFO:[LightGBM] [Warning] feature_fraction is set=0.9211599849219095, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9211599849219095
2025-06-02 16:26:10,727:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9913095246754634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9913095246754634
2025-06-02 16:26:10,727:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 16:26:10,761:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 16:26:10,762:INFO:[LightGBM] [Warning] feature_fraction is set=0.9211599849219095, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9211599849219095
2025-06-02 16:26:10,763:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9913095246754634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9913095246754634
2025-06-02 16:26:10,763:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 16:26:10,770:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004473 seconds.
2025-06-02 16:26:10,770:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 16:26:10,771:INFO:[LightGBM] [Info] Total Bins 6263
2025-06-02 16:26:10,797:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 16:26:10,798:INFO:[LightGBM] [Info] Start training from score -0.505554
2025-06-02 16:26:10,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,860:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,864:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,864:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,866:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,867:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,867:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,868:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,869:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,870:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,871:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,872:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,872:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,873:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,874:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,875:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,876:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,876:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,877:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,878:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,880:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,881:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,882:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,883:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,883:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,884:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,885:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,886:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,887:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,888:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,888:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,889:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,890:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,891:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,891:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,892:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,893:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,893:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,894:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,896:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,896:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,899:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,900:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,901:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,902:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,903:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,904:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,905:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,906:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,907:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,908:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,909:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,910:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,911:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,912:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,913:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,914:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,915:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,916:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,916:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,917:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,917:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,918:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,919:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,920:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,920:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,921:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,922:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,922:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,923:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,923:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,924:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,925:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,925:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,926:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,931:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,932:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,951:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,951:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,952:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,953:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,954:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,954:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,956:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,957:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,958:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,961:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,964:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,965:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,966:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,966:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,967:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,968:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,969:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,970:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,971:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,972:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,974:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,975:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,975:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,976:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,979:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,980:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,982:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,982:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,983:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,984:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,984:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,985:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,986:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,989:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,992:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,992:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,994:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,995:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:10,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 16:26:10,996:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-02 16:26:11,046:INFO:Uploading results into container
2025-06-02 16:26:11,049:INFO:Uploading model into container now
2025-06-02 16:26:11,051:INFO:_master_model_container: 21
2025-06-02 16:26:11,051:INFO:_display_container: 3
2025-06-02 16:26:11,055:INFO:LGBMRegressor(bagging_fraction=0.9913095246754634, bagging_freq=1,
              feature_fraction=0.9211599849219095,
              learning_rate=0.21136499069406833, min_child_samples=14,
              min_split_gain=0.6262984370406117, n_estimators=179, n_jobs=-1,
              num_leaves=224, random_state=124,
              reg_alpha=3.1387651466927824e-05, reg_lambda=6.88892157310396)
2025-06-02 16:26:11,055:INFO:create_model() successfully completed......................................
2025-06-02 16:26:12,512:INFO:SubProcess create_model() end ==================================
2025-06-02 16:26:12,513:INFO:choose_better activated
2025-06-02 16:26:12,523:INFO:SubProcess create_model() called ==================================
2025-06-02 16:26:12,525:INFO:Initializing create_model()
2025-06-02 16:26:12,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=124), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:26:12,525:INFO:Checking exceptions
2025-06-02 16:26:12,530:INFO:Importing libraries
2025-06-02 16:26:12,531:INFO:Copying training dataset
2025-06-02 16:26:12,606:INFO:Defining folds
2025-06-02 16:26:12,606:INFO:Declaring metric variables
2025-06-02 16:26:12,606:INFO:Importing untrained model
2025-06-02 16:26:12,606:INFO:Declaring custom model
2025-06-02 16:26:12,608:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 16:26:12,609:INFO:Starting cross validation
2025-06-02 16:26:12,612:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 16:26:14,200:INFO:Calculating mean and std
2025-06-02 16:26:14,201:INFO:Creating metrics dataframe
2025-06-02 16:26:14,204:INFO:Finalizing model
2025-06-02 16:26:14,588:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 16:26:14,592:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002502 seconds.
2025-06-02 16:26:14,592:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 16:26:14,593:INFO:[LightGBM] [Info] Total Bins 6263
2025-06-02 16:26:14,593:INFO:[LightGBM] [Info] Number of data points in the train set: 3134, number of used features: 96
2025-06-02 16:26:14,595:INFO:[LightGBM] [Info] Start training from score -0.505554
2025-06-02 16:26:14,768:INFO:Uploading results into container
2025-06-02 16:26:14,769:INFO:Uploading model into container now
2025-06-02 16:26:14,770:INFO:_master_model_container: 22
2025-06-02 16:26:14,770:INFO:_display_container: 4
2025-06-02 16:26:14,771:INFO:LGBMRegressor(n_jobs=-1, random_state=124)
2025-06-02 16:26:14,771:INFO:create_model() successfully completed......................................
2025-06-02 16:26:16,081:INFO:SubProcess create_model() end ==================================
2025-06-02 16:26:16,082:INFO:LGBMRegressor(n_jobs=-1, random_state=124) result for R2 is 0.8781
2025-06-02 16:26:16,083:INFO:LGBMRegressor(bagging_fraction=0.9913095246754634, bagging_freq=1,
              feature_fraction=0.9211599849219095,
              learning_rate=0.21136499069406833, min_child_samples=14,
              min_split_gain=0.6262984370406117, n_estimators=179, n_jobs=-1,
              num_leaves=224, random_state=124,
              reg_alpha=3.1387651466927824e-05, reg_lambda=6.88892157310396) result for R2 is 0.8609
2025-06-02 16:26:16,084:INFO:LGBMRegressor(n_jobs=-1, random_state=124) is best model
2025-06-02 16:26:16,084:INFO:choose_better completed
2025-06-02 16:26:16,084:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 16:26:16,106:INFO:_master_model_container: 22
2025-06-02 16:26:16,106:INFO:_display_container: 3
2025-06-02 16:26:16,107:INFO:LGBMRegressor(n_jobs=-1, random_state=124)
2025-06-02 16:26:16,107:INFO:tune_model() successfully completed......................................
2025-06-02 16:26:17,523:INFO:Initializing finalize_model()
2025-06-02 16:26:17,524:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=124), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 16:26:17,524:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=124)
2025-06-02 16:26:17,596:INFO:Initializing create_model()
2025-06-02 16:26:17,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED6735E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=124), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 16:26:17,596:INFO:Checking exceptions
2025-06-02 16:26:17,599:INFO:Importing libraries
2025-06-02 16:26:17,599:INFO:Copying training dataset
2025-06-02 16:26:17,605:INFO:Defining folds
2025-06-02 16:26:17,606:INFO:Declaring metric variables
2025-06-02 16:26:17,606:INFO:Importing untrained model
2025-06-02 16:26:17,606:INFO:Declaring custom model
2025-06-02 16:26:17,608:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 16:26:17,611:INFO:Cross validation set to False
2025-06-02 16:26:17,611:INFO:Fitting Model
2025-06-02 16:26:18,018:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 16:26:18,023:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003667 seconds.
2025-06-02 16:26:18,024:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 16:26:18,024:INFO:[LightGBM] [Info] Total Bins 6237
2025-06-02 16:26:18,025:INFO:[LightGBM] [Info] Number of data points in the train set: 4478, number of used features: 95
2025-06-02 16:26:18,026:INFO:[LightGBM] [Info] Start training from score -0.483793
2025-06-02 16:26:18,226:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=124))])
2025-06-02 16:26:18,226:INFO:create_model() successfully completed......................................
2025-06-02 16:26:19,548:INFO:_master_model_container: 22
2025-06-02 16:26:19,548:INFO:_display_container: 3
2025-06-02 16:26:19,563:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=124))])
2025-06-02 16:26:19,563:INFO:finalize_model() successfully completed......................................
2025-06-02 16:26:20,928:INFO:Initializing save_model()
2025-06-02 16:26:20,929:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=124))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 16:26:20,929:INFO:Adding model into prep_pipe
2025-06-02 16:26:20,929:WARNING:Only Model saved as it was a pipeline.
2025-06-02 16:26:20,949:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 16:26:20,974:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=124))])
2025-06-02 16:26:20,974:INFO:save_model() successfully completed......................................
2025-06-02 17:02:07,757:INFO:PyCaret RegressionExperiment
2025-06-02 17:02:07,761:INFO:Logging name: reg-default-name
2025-06-02 17:02:07,762:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 17:02:07,763:INFO:version 3.3.2
2025-06-02 17:02:07,763:INFO:Initializing setup()
2025-06-02 17:02:07,763:INFO:self.USI: f18a
2025-06-02 17:02:07,763:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 17:02:07,764:INFO:Checking environment
2025-06-02 17:02:07,765:INFO:python_version: 3.10.16
2025-06-02 17:02:07,765:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 17:02:07,766:INFO:machine: AMD64
2025-06-02 17:02:07,766:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 17:02:07,783:INFO:Memory: svmem(total=6378008576, available=843575296, percent=86.8, used=5534433280, free=843575296)
2025-06-02 17:02:07,784:INFO:Physical Core: 4
2025-06-02 17:02:07,784:INFO:Logical Core: 8
2025-06-02 17:02:07,785:INFO:Checking libraries
2025-06-02 17:02:07,786:INFO:System:
2025-06-02 17:02:07,788:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 17:02:07,788:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 17:02:07,788:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 17:02:07,788:INFO:PyCaret required dependencies:
2025-06-02 17:02:07,796:INFO:                 pip: 25.1
2025-06-02 17:02:07,796:INFO:          setuptools: 78.1.1
2025-06-02 17:02:07,796:INFO:             pycaret: 3.3.2
2025-06-02 17:02:07,796:INFO:             IPython: 8.37.0
2025-06-02 17:02:07,796:INFO:          ipywidgets: 8.1.7
2025-06-02 17:02:07,796:INFO:                tqdm: 4.67.1
2025-06-02 17:02:07,796:INFO:               numpy: 1.26.4
2025-06-02 17:02:07,797:INFO:              pandas: 2.0.1
2025-06-02 17:02:07,797:INFO:              jinja2: 3.1.6
2025-06-02 17:02:07,797:INFO:               scipy: 1.10.1
2025-06-02 17:02:07,797:INFO:              joblib: 1.3.2
2025-06-02 17:02:07,797:INFO:             sklearn: 1.4.2
2025-06-02 17:02:07,797:INFO:                pyod: 2.0.5
2025-06-02 17:02:07,797:INFO:            imblearn: 0.13.0
2025-06-02 17:02:07,797:INFO:   category_encoders: 2.7.0
2025-06-02 17:02:07,797:INFO:            lightgbm: 4.6.0
2025-06-02 17:02:07,797:INFO:               numba: 0.61.0
2025-06-02 17:02:07,797:INFO:            requests: 2.32.3
2025-06-02 17:02:07,797:INFO:          matplotlib: 3.7.1
2025-06-02 17:02:07,797:INFO:          scikitplot: 0.3.7
2025-06-02 17:02:07,797:INFO:         yellowbrick: 1.5
2025-06-02 17:02:07,797:INFO:              plotly: 6.1.2
2025-06-02 17:02:07,797:INFO:    plotly-resampler: Not installed
2025-06-02 17:02:07,797:INFO:             kaleido: 0.2.1
2025-06-02 17:02:07,797:INFO:           schemdraw: 0.15
2025-06-02 17:02:07,799:INFO:         statsmodels: 0.14.4
2025-06-02 17:02:07,799:INFO:              sktime: 0.26.0
2025-06-02 17:02:07,799:INFO:               tbats: 1.1.3
2025-06-02 17:02:07,799:INFO:            pmdarima: 2.0.4
2025-06-02 17:02:07,799:INFO:              psutil: 7.0.0
2025-06-02 17:02:07,799:INFO:          markupsafe: 2.1.2
2025-06-02 17:02:07,799:INFO:             pickle5: Not installed
2025-06-02 17:02:07,799:INFO:         cloudpickle: 3.1.1
2025-06-02 17:02:07,799:INFO:         deprecation: 2.1.0
2025-06-02 17:02:07,799:INFO:              xxhash: 3.5.0
2025-06-02 17:02:07,800:INFO:           wurlitzer: Not installed
2025-06-02 17:02:07,800:INFO:PyCaret optional dependencies:
2025-06-02 17:02:07,802:INFO:                shap: 0.44.1
2025-06-02 17:02:07,802:INFO:           interpret: 0.6.9
2025-06-02 17:02:07,802:INFO:                umap: 0.5.7
2025-06-02 17:02:07,802:INFO:     ydata_profiling: 4.16.1
2025-06-02 17:02:07,802:INFO:  explainerdashboard: 0.4.8
2025-06-02 17:02:07,802:INFO:             autoviz: Not installed
2025-06-02 17:02:07,802:INFO:           fairlearn: 0.7.0
2025-06-02 17:02:07,803:INFO:          deepchecks: Not installed
2025-06-02 17:02:07,803:INFO:             xgboost: 3.0.2
2025-06-02 17:02:07,803:INFO:            catboost: 1.2.8
2025-06-02 17:02:07,803:INFO:              kmodes: 0.12.2
2025-06-02 17:02:07,803:INFO:             mlxtend: 0.23.4
2025-06-02 17:02:07,803:INFO:       statsforecast: 1.5.0
2025-06-02 17:02:07,803:INFO:        tune_sklearn: Not installed
2025-06-02 17:02:07,803:INFO:                 ray: Not installed
2025-06-02 17:02:07,804:INFO:            hyperopt: 0.2.7
2025-06-02 17:02:07,804:INFO:              optuna: 4.3.0
2025-06-02 17:02:07,804:INFO:               skopt: 0.10.2
2025-06-02 17:02:07,804:INFO:              mlflow: 2.22.0
2025-06-02 17:02:07,804:INFO:              gradio: 5.32.0
2025-06-02 17:02:07,804:INFO:             fastapi: 0.115.12
2025-06-02 17:02:07,804:INFO:             uvicorn: 0.34.3
2025-06-02 17:02:07,805:INFO:              m2cgen: 0.10.0
2025-06-02 17:02:07,805:INFO:           evidently: 0.4.40
2025-06-02 17:02:07,805:INFO:               fugue: 0.8.5
2025-06-02 17:02:07,805:INFO:           streamlit: Not installed
2025-06-02 17:02:07,805:INFO:             prophet: Not installed
2025-06-02 17:02:07,805:INFO:None
2025-06-02 17:02:07,807:INFO:Set up data.
2025-06-02 17:02:08,129:INFO:Set up folding strategy.
2025-06-02 17:02:08,132:INFO:Set up train/test split.
2025-06-02 17:02:08,235:INFO:Set up index.
2025-06-02 17:02:08,242:INFO:Assigning column types.
2025-06-02 17:02:08,305:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 17:02:08,313:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 17:02:08,322:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:02:08,331:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:02:08,496:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:02:08,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:02:08,591:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:02:08,606:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:02:08,610:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 17:02:08,621:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:02:08,631:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:02:08,780:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:02:08,862:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:02:08,863:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:02:08,867:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:02:08,868:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 17:02:08,875:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:02:08,883:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:02:09,050:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:02:09,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:02:09,129:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:02:09,133:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:02:09,141:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:02:09,151:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:02:09,292:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:02:09,379:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:02:09,380:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:02:09,385:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:02:09,386:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 17:02:09,402:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:02:09,549:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:02:09,628:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:02:09,629:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:02:09,633:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:02:09,648:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:02:09,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:02:09,886:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:02:09,887:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:02:09,891:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:02:09,894:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 17:02:10,049:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:02:10,124:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:02:10,125:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:02:10,131:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:02:10,302:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:02:10,382:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:02:10,383:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:02:10,389:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:02:10,390:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 17:02:10,558:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:02:10,647:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:02:10,651:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:02:10,817:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:02:10,898:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:02:10,902:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:02:10,903:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 17:02:11,150:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:02:11,154:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:02:11,415:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:02:11,419:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:02:11,449:INFO:Preparing preprocessing pipeline...
2025-06-02 17:02:11,449:INFO:Set up simple imputation.
2025-06-02 17:02:11,452:INFO:Set up polynomial features.
2025-06-02 17:02:11,453:INFO:Set up removing multicollinearity.
2025-06-02 17:02:11,464:INFO:Set up column name cleaning.
2025-06-02 17:16:38,861:WARNING:Persisting input arguments took 1.34s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.

2025-06-02 17:16:40,845:WARNING:Persisting input arguments took 0.92s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.

2025-06-02 17:16:40,919:INFO:Finished creating preprocessing pipeline.
2025-06-02 17:16:40,934:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 17:16:40,935:INFO:Creating final display dataframe.
2025-06-02 17:16:44,025:WARNING:Persisting input arguments took 0.87s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.

2025-06-02 17:16:46,965:WARNING:Persisting input arguments took 0.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.

2025-06-02 17:16:48,838:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape      (4478, 3096)
5   Transformed train set shape      (3582, 3096)
6    Transformed test set shape       (896, 3096)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14     Remove multicollinearity              True
15  Multicollinearity threshold              0.95
16               Fold Generator             KFold
17                  Fold Number                 5
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              f18a
2025-06-02 17:16:49,118:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:16:49,123:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:16:49,353:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:16:49,357:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:16:49,359:INFO:setup() successfully completed in 881.8s...............
2025-06-02 17:16:49,361:INFO:Initializing compare_models()
2025-06-02 17:16:49,361:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED671000>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED671000>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 17:16:49,361:INFO:Checking exceptions
2025-06-02 17:16:49,386:INFO:Preparing display monitor
2025-06-02 17:16:49,455:INFO:Initializing Linear Regression
2025-06-02 17:16:49,455:INFO:Total runtime is 0.0 minutes
2025-06-02 17:16:49,468:INFO:SubProcess create_model() called ==================================
2025-06-02 17:16:49,469:INFO:Initializing create_model()
2025-06-02 17:16:49,470:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6ED671000>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E499AA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:16:49,470:INFO:Checking exceptions
2025-06-02 17:16:49,470:INFO:Importing libraries
2025-06-02 17:16:49,471:INFO:Copying training dataset
2025-06-02 17:16:49,550:INFO:Defining folds
2025-06-02 17:16:49,551:INFO:Declaring metric variables
2025-06-02 17:16:49,561:INFO:Importing untrained model
2025-06-02 17:16:49,573:INFO:Linear Regression Imported successfully
2025-06-02 17:16:49,598:INFO:Starting cross validation
2025-06-02 17:16:49,717:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:27:28,929:INFO:PyCaret RegressionExperiment
2025-06-02 17:27:28,929:INFO:Logging name: reg-default-name
2025-06-02 17:27:28,930:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 17:27:28,930:INFO:version 3.3.2
2025-06-02 17:27:28,930:INFO:Initializing setup()
2025-06-02 17:27:28,930:INFO:self.USI: e144
2025-06-02 17:27:28,930:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 17:27:28,930:INFO:Checking environment
2025-06-02 17:27:28,930:INFO:python_version: 3.10.16
2025-06-02 17:27:28,930:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 17:27:28,930:INFO:machine: AMD64
2025-06-02 17:27:28,931:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 17:27:28,937:INFO:Memory: svmem(total=6378008576, available=968134656, percent=84.8, used=5409873920, free=968134656)
2025-06-02 17:27:28,937:INFO:Physical Core: 4
2025-06-02 17:27:28,937:INFO:Logical Core: 8
2025-06-02 17:27:28,937:INFO:Checking libraries
2025-06-02 17:27:28,937:INFO:System:
2025-06-02 17:27:28,938:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 17:27:28,938:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 17:27:28,938:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 17:27:28,938:INFO:PyCaret required dependencies:
2025-06-02 17:27:28,940:INFO:                 pip: 25.1
2025-06-02 17:27:28,940:INFO:          setuptools: 78.1.1
2025-06-02 17:27:28,940:INFO:             pycaret: 3.3.2
2025-06-02 17:27:28,940:INFO:             IPython: 8.37.0
2025-06-02 17:27:28,940:INFO:          ipywidgets: 8.1.7
2025-06-02 17:27:28,940:INFO:                tqdm: 4.67.1
2025-06-02 17:27:28,940:INFO:               numpy: 1.26.4
2025-06-02 17:27:28,940:INFO:              pandas: 2.0.1
2025-06-02 17:27:28,940:INFO:              jinja2: 3.1.6
2025-06-02 17:27:28,940:INFO:               scipy: 1.10.1
2025-06-02 17:27:28,940:INFO:              joblib: 1.3.2
2025-06-02 17:27:28,940:INFO:             sklearn: 1.4.2
2025-06-02 17:27:28,940:INFO:                pyod: 2.0.5
2025-06-02 17:27:28,941:INFO:            imblearn: 0.13.0
2025-06-02 17:27:28,941:INFO:   category_encoders: 2.7.0
2025-06-02 17:27:28,941:INFO:            lightgbm: 4.6.0
2025-06-02 17:27:28,941:INFO:               numba: 0.61.0
2025-06-02 17:27:28,941:INFO:            requests: 2.32.3
2025-06-02 17:27:28,941:INFO:          matplotlib: 3.7.1
2025-06-02 17:27:28,941:INFO:          scikitplot: 0.3.7
2025-06-02 17:27:28,941:INFO:         yellowbrick: 1.5
2025-06-02 17:27:28,941:INFO:              plotly: 6.1.2
2025-06-02 17:27:28,941:INFO:    plotly-resampler: Not installed
2025-06-02 17:27:28,942:INFO:             kaleido: 0.2.1
2025-06-02 17:27:28,942:INFO:           schemdraw: 0.15
2025-06-02 17:27:28,942:INFO:         statsmodels: 0.14.4
2025-06-02 17:27:28,942:INFO:              sktime: 0.26.0
2025-06-02 17:27:28,942:INFO:               tbats: 1.1.3
2025-06-02 17:27:28,942:INFO:            pmdarima: 2.0.4
2025-06-02 17:27:28,942:INFO:              psutil: 7.0.0
2025-06-02 17:27:28,942:INFO:          markupsafe: 2.1.2
2025-06-02 17:27:28,942:INFO:             pickle5: Not installed
2025-06-02 17:27:28,942:INFO:         cloudpickle: 3.1.1
2025-06-02 17:27:28,942:INFO:         deprecation: 2.1.0
2025-06-02 17:27:28,943:INFO:              xxhash: 3.5.0
2025-06-02 17:27:28,943:INFO:           wurlitzer: Not installed
2025-06-02 17:27:28,943:INFO:PyCaret optional dependencies:
2025-06-02 17:27:28,944:INFO:                shap: 0.44.1
2025-06-02 17:27:28,944:INFO:           interpret: 0.6.9
2025-06-02 17:27:28,944:INFO:                umap: 0.5.7
2025-06-02 17:27:28,944:INFO:     ydata_profiling: 4.16.1
2025-06-02 17:27:28,944:INFO:  explainerdashboard: 0.4.8
2025-06-02 17:27:28,944:INFO:             autoviz: Not installed
2025-06-02 17:27:28,944:INFO:           fairlearn: 0.7.0
2025-06-02 17:27:28,944:INFO:          deepchecks: Not installed
2025-06-02 17:27:28,944:INFO:             xgboost: 3.0.2
2025-06-02 17:27:28,944:INFO:            catboost: 1.2.8
2025-06-02 17:27:28,944:INFO:              kmodes: 0.12.2
2025-06-02 17:27:28,944:INFO:             mlxtend: 0.23.4
2025-06-02 17:27:28,944:INFO:       statsforecast: 1.5.0
2025-06-02 17:27:28,945:INFO:        tune_sklearn: Not installed
2025-06-02 17:27:28,945:INFO:                 ray: Not installed
2025-06-02 17:27:28,945:INFO:            hyperopt: 0.2.7
2025-06-02 17:27:28,945:INFO:              optuna: 4.3.0
2025-06-02 17:27:28,945:INFO:               skopt: 0.10.2
2025-06-02 17:27:28,945:INFO:              mlflow: 2.22.0
2025-06-02 17:27:28,945:INFO:              gradio: 5.32.0
2025-06-02 17:27:28,945:INFO:             fastapi: 0.115.12
2025-06-02 17:27:28,945:INFO:             uvicorn: 0.34.3
2025-06-02 17:27:28,945:INFO:              m2cgen: 0.10.0
2025-06-02 17:27:28,945:INFO:           evidently: 0.4.40
2025-06-02 17:27:28,945:INFO:               fugue: 0.8.5
2025-06-02 17:27:28,945:INFO:           streamlit: Not installed
2025-06-02 17:27:28,945:INFO:             prophet: Not installed
2025-06-02 17:27:28,946:INFO:None
2025-06-02 17:27:28,946:INFO:Set up data.
2025-06-02 17:27:29,091:INFO:Set up folding strategy.
2025-06-02 17:27:29,092:INFO:Set up train/test split.
2025-06-02 17:27:29,176:INFO:Set up index.
2025-06-02 17:27:29,185:INFO:Assigning column types.
2025-06-02 17:27:29,239:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 17:27:29,240:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,249:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,256:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,402:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,474:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,476:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:29,482:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:29,483:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,490:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,497:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,624:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,700:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,701:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:29,707:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:29,708:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 17:27:29,715:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,722:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,850:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,932:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,934:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:29,938:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:29,947:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:27:29,953:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:27:30,094:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:27:30,173:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:27:30,173:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:30,177:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:30,178:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 17:27:30,193:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:27:30,327:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:27:30,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:27:30,412:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:30,416:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:30,431:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:27:30,564:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:27:30,646:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:27:30,647:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:30,651:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:30,652:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 17:27:30,791:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:27:30,862:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:27:30,863:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:30,867:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:31,004:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:27:31,070:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:27:31,071:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:31,075:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:31,076:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 17:27:31,215:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:27:31,283:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:31,287:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:31,429:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:27:31,506:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:31,510:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:31,511:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 17:27:31,733:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:31,739:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:31,955:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:31,960:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:31,971:INFO:Preparing preprocessing pipeline...
2025-06-02 17:27:31,971:INFO:Set up simple imputation.
2025-06-02 17:27:31,973:INFO:Set up removing multicollinearity.
2025-06-02 17:27:31,981:INFO:Set up column name cleaning.
2025-06-02 17:27:32,595:INFO:Finished creating preprocessing pipeline.
2025-06-02 17:27:32,607:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 17:27:32,608:INFO:Creating final display dataframe.
2025-06-02 17:27:33,705:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape       (4478, 116)
5   Transformed train set shape       (3582, 116)
6    Transformed test set shape        (896, 116)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold              0.95
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              e144
2025-06-02 17:27:33,964:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:33,968:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:34,178:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:34,182:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:34,184:INFO:setup() successfully completed in 5.31s...............
2025-06-02 17:27:34,184:INFO:Initializing compare_models()
2025-06-02 17:27:34,184:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70223D600>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B70223D600>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 17:27:34,184:INFO:Checking exceptions
2025-06-02 17:27:34,204:INFO:Preparing display monitor
2025-06-02 17:27:34,278:INFO:Initializing Linear Regression
2025-06-02 17:27:34,279:INFO:Total runtime is 1.666545867919922e-05 minutes
2025-06-02 17:27:34,294:INFO:SubProcess create_model() called ==================================
2025-06-02 17:27:34,295:INFO:Initializing create_model()
2025-06-02 17:27:34,295:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70223D600>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B7022EF400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:27:34,296:INFO:Checking exceptions
2025-06-02 17:27:34,296:INFO:Importing libraries
2025-06-02 17:27:34,297:INFO:Copying training dataset
2025-06-02 17:27:34,435:INFO:Defining folds
2025-06-02 17:27:34,435:INFO:Declaring metric variables
2025-06-02 17:27:34,445:INFO:Importing untrained model
2025-06-02 17:27:34,466:INFO:Linear Regression Imported successfully
2025-06-02 17:27:34,496:INFO:Starting cross validation
2025-06-02 17:27:34,501:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:27:59,012:INFO:PyCaret RegressionExperiment
2025-06-02 17:27:59,013:INFO:Logging name: reg-default-name
2025-06-02 17:27:59,013:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 17:27:59,013:INFO:version 3.3.2
2025-06-02 17:27:59,013:INFO:Initializing setup()
2025-06-02 17:27:59,013:INFO:self.USI: 0567
2025-06-02 17:27:59,013:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 17:27:59,013:INFO:Checking environment
2025-06-02 17:27:59,013:INFO:python_version: 3.10.16
2025-06-02 17:27:59,013:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 17:27:59,013:INFO:machine: AMD64
2025-06-02 17:27:59,013:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 17:27:59,019:INFO:Memory: svmem(total=6378008576, available=1110884352, percent=82.6, used=5267124224, free=1110884352)
2025-06-02 17:27:59,019:INFO:Physical Core: 4
2025-06-02 17:27:59,019:INFO:Logical Core: 8
2025-06-02 17:27:59,019:INFO:Checking libraries
2025-06-02 17:27:59,020:INFO:System:
2025-06-02 17:27:59,020:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 17:27:59,020:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 17:27:59,020:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 17:27:59,020:INFO:PyCaret required dependencies:
2025-06-02 17:27:59,020:INFO:                 pip: 25.1
2025-06-02 17:27:59,020:INFO:          setuptools: 78.1.1
2025-06-02 17:27:59,020:INFO:             pycaret: 3.3.2
2025-06-02 17:27:59,020:INFO:             IPython: 8.37.0
2025-06-02 17:27:59,020:INFO:          ipywidgets: 8.1.7
2025-06-02 17:27:59,021:INFO:                tqdm: 4.67.1
2025-06-02 17:27:59,021:INFO:               numpy: 1.26.4
2025-06-02 17:27:59,021:INFO:              pandas: 2.0.1
2025-06-02 17:27:59,021:INFO:              jinja2: 3.1.6
2025-06-02 17:27:59,021:INFO:               scipy: 1.10.1
2025-06-02 17:27:59,021:INFO:              joblib: 1.3.2
2025-06-02 17:27:59,021:INFO:             sklearn: 1.4.2
2025-06-02 17:27:59,021:INFO:                pyod: 2.0.5
2025-06-02 17:27:59,022:INFO:            imblearn: 0.13.0
2025-06-02 17:27:59,022:INFO:   category_encoders: 2.7.0
2025-06-02 17:27:59,022:INFO:            lightgbm: 4.6.0
2025-06-02 17:27:59,022:INFO:               numba: 0.61.0
2025-06-02 17:27:59,022:INFO:            requests: 2.32.3
2025-06-02 17:27:59,022:INFO:          matplotlib: 3.7.1
2025-06-02 17:27:59,022:INFO:          scikitplot: 0.3.7
2025-06-02 17:27:59,022:INFO:         yellowbrick: 1.5
2025-06-02 17:27:59,023:INFO:              plotly: 6.1.2
2025-06-02 17:27:59,023:INFO:    plotly-resampler: Not installed
2025-06-02 17:27:59,023:INFO:             kaleido: 0.2.1
2025-06-02 17:27:59,023:INFO:           schemdraw: 0.15
2025-06-02 17:27:59,023:INFO:         statsmodels: 0.14.4
2025-06-02 17:27:59,023:INFO:              sktime: 0.26.0
2025-06-02 17:27:59,023:INFO:               tbats: 1.1.3
2025-06-02 17:27:59,023:INFO:            pmdarima: 2.0.4
2025-06-02 17:27:59,024:INFO:              psutil: 7.0.0
2025-06-02 17:27:59,024:INFO:          markupsafe: 2.1.2
2025-06-02 17:27:59,024:INFO:             pickle5: Not installed
2025-06-02 17:27:59,024:INFO:         cloudpickle: 3.1.1
2025-06-02 17:27:59,024:INFO:         deprecation: 2.1.0
2025-06-02 17:27:59,024:INFO:              xxhash: 3.5.0
2025-06-02 17:27:59,025:INFO:           wurlitzer: Not installed
2025-06-02 17:27:59,025:INFO:PyCaret optional dependencies:
2025-06-02 17:27:59,025:INFO:                shap: 0.44.1
2025-06-02 17:27:59,025:INFO:           interpret: 0.6.9
2025-06-02 17:27:59,025:INFO:                umap: 0.5.7
2025-06-02 17:27:59,025:INFO:     ydata_profiling: 4.16.1
2025-06-02 17:27:59,025:INFO:  explainerdashboard: 0.4.8
2025-06-02 17:27:59,025:INFO:             autoviz: Not installed
2025-06-02 17:27:59,025:INFO:           fairlearn: 0.7.0
2025-06-02 17:27:59,025:INFO:          deepchecks: Not installed
2025-06-02 17:27:59,026:INFO:             xgboost: 3.0.2
2025-06-02 17:27:59,026:INFO:            catboost: 1.2.8
2025-06-02 17:27:59,026:INFO:              kmodes: 0.12.2
2025-06-02 17:27:59,026:INFO:             mlxtend: 0.23.4
2025-06-02 17:27:59,026:INFO:       statsforecast: 1.5.0
2025-06-02 17:27:59,026:INFO:        tune_sklearn: Not installed
2025-06-02 17:27:59,026:INFO:                 ray: Not installed
2025-06-02 17:27:59,026:INFO:            hyperopt: 0.2.7
2025-06-02 17:27:59,027:INFO:              optuna: 4.3.0
2025-06-02 17:27:59,027:INFO:               skopt: 0.10.2
2025-06-02 17:27:59,027:INFO:              mlflow: 2.22.0
2025-06-02 17:27:59,027:INFO:              gradio: 5.32.0
2025-06-02 17:27:59,027:INFO:             fastapi: 0.115.12
2025-06-02 17:27:59,027:INFO:             uvicorn: 0.34.3
2025-06-02 17:27:59,027:INFO:              m2cgen: 0.10.0
2025-06-02 17:27:59,027:INFO:           evidently: 0.4.40
2025-06-02 17:27:59,028:INFO:               fugue: 0.8.5
2025-06-02 17:27:59,028:INFO:           streamlit: Not installed
2025-06-02 17:27:59,028:INFO:             prophet: Not installed
2025-06-02 17:27:59,028:INFO:None
2025-06-02 17:27:59,028:INFO:Set up data.
2025-06-02 17:27:59,121:INFO:Set up folding strategy.
2025-06-02 17:27:59,121:INFO:Set up train/test split.
2025-06-02 17:27:59,184:INFO:Set up index.
2025-06-02 17:27:59,185:INFO:Assigning column types.
2025-06-02 17:27:59,242:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 17:27:59,242:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,251:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,259:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,396:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,473:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,474:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:59,479:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:59,480:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,488:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,630:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,709:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,709:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:59,714:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:59,715:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 17:27:59,722:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,730:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,867:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,936:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,937:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:27:59,941:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:27:59,950:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:27:59,957:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:28:00,102:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:28:00,186:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:28:00,187:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:28:00,192:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:28:00,194:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 17:28:00,212:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:28:00,387:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:28:00,470:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:28:00,471:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:28:00,476:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:28:00,492:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:28:00,636:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:28:00,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:28:00,719:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:28:00,724:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:28:00,726:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 17:28:00,886:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:28:00,970:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:28:00,971:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:28:00,975:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:28:01,144:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:28:01,222:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:28:01,222:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:28:01,229:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:28:01,231:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 17:28:01,382:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:28:01,481:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:28:01,487:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:28:01,638:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:28:01,717:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:28:01,721:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:28:01,722:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 17:28:01,967:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:28:01,972:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:28:02,200:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:28:02,205:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:28:02,207:INFO:Preparing preprocessing pipeline...
2025-06-02 17:28:02,207:INFO:Set up simple imputation.
2025-06-02 17:28:02,207:INFO:Set up removing multicollinearity.
2025-06-02 17:28:02,215:INFO:Set up column name cleaning.
2025-06-02 17:28:02,851:INFO:Finished creating preprocessing pipeline.
2025-06-02 17:28:02,865:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 17:28:02,865:INFO:Creating final display dataframe.
2025-06-02 17:28:03,968:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3582, 97)
6    Transformed test set shape         (896, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              0567
2025-06-02 17:28:04,260:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:28:04,265:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:28:04,500:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:28:04,504:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:28:04,506:INFO:setup() successfully completed in 5.51s...............
2025-06-02 17:28:04,506:INFO:Initializing compare_models()
2025-06-02 17:28:04,506:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 17:28:04,506:INFO:Checking exceptions
2025-06-02 17:28:04,528:INFO:Preparing display monitor
2025-06-02 17:28:04,594:INFO:Initializing Linear Regression
2025-06-02 17:28:04,594:INFO:Total runtime is 0.0 minutes
2025-06-02 17:28:04,611:INFO:SubProcess create_model() called ==================================
2025-06-02 17:28:04,612:INFO:Initializing create_model()
2025-06-02 17:28:04,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:28:04,613:INFO:Checking exceptions
2025-06-02 17:28:04,613:INFO:Importing libraries
2025-06-02 17:28:04,613:INFO:Copying training dataset
2025-06-02 17:28:04,780:INFO:Defining folds
2025-06-02 17:28:04,781:INFO:Declaring metric variables
2025-06-02 17:28:04,797:INFO:Importing untrained model
2025-06-02 17:28:04,825:INFO:Linear Regression Imported successfully
2025-06-02 17:28:04,871:INFO:Starting cross validation
2025-06-02 17:28:04,877:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:28:18,686:INFO:Calculating mean and std
2025-06-02 17:28:18,702:INFO:Creating metrics dataframe
2025-06-02 17:28:18,722:INFO:Uploading results into container
2025-06-02 17:28:18,725:INFO:Uploading model into container now
2025-06-02 17:28:18,727:INFO:_master_model_container: 1
2025-06-02 17:28:18,728:INFO:_display_container: 2
2025-06-02 17:28:18,730:INFO:LinearRegression(n_jobs=-1)
2025-06-02 17:28:18,731:INFO:create_model() successfully completed......................................
2025-06-02 17:28:31,264:INFO:SubProcess create_model() end ==================================
2025-06-02 17:28:31,264:INFO:Creating metrics dataframe
2025-06-02 17:28:31,292:INFO:Initializing Lasso Regression
2025-06-02 17:28:31,292:INFO:Total runtime is 0.444962747891744 minutes
2025-06-02 17:28:31,305:INFO:SubProcess create_model() called ==================================
2025-06-02 17:28:31,306:INFO:Initializing create_model()
2025-06-02 17:28:31,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:28:31,306:INFO:Checking exceptions
2025-06-02 17:28:31,307:INFO:Importing libraries
2025-06-02 17:28:31,309:INFO:Copying training dataset
2025-06-02 17:28:31,488:INFO:Defining folds
2025-06-02 17:28:31,489:INFO:Declaring metric variables
2025-06-02 17:28:31,501:INFO:Importing untrained model
2025-06-02 17:28:31,516:INFO:Lasso Regression Imported successfully
2025-06-02 17:28:31,540:INFO:Starting cross validation
2025-06-02 17:28:31,545:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:28:42,876:INFO:Calculating mean and std
2025-06-02 17:28:42,882:INFO:Creating metrics dataframe
2025-06-02 17:28:42,893:INFO:Uploading results into container
2025-06-02 17:28:42,895:INFO:Uploading model into container now
2025-06-02 17:28:42,897:INFO:_master_model_container: 2
2025-06-02 17:28:42,898:INFO:_display_container: 2
2025-06-02 17:28:42,899:INFO:Lasso(random_state=123)
2025-06-02 17:28:42,899:INFO:create_model() successfully completed......................................
2025-06-02 17:28:45,215:INFO:SubProcess create_model() end ==================================
2025-06-02 17:28:45,215:INFO:Creating metrics dataframe
2025-06-02 17:28:45,242:INFO:Initializing Ridge Regression
2025-06-02 17:28:45,242:INFO:Total runtime is 0.6774595022201538 minutes
2025-06-02 17:28:45,257:INFO:SubProcess create_model() called ==================================
2025-06-02 17:28:45,258:INFO:Initializing create_model()
2025-06-02 17:28:45,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:28:45,260:INFO:Checking exceptions
2025-06-02 17:28:45,260:INFO:Importing libraries
2025-06-02 17:28:45,261:INFO:Copying training dataset
2025-06-02 17:28:45,773:INFO:Defining folds
2025-06-02 17:28:45,774:INFO:Declaring metric variables
2025-06-02 17:28:45,786:INFO:Importing untrained model
2025-06-02 17:28:45,798:INFO:Ridge Regression Imported successfully
2025-06-02 17:28:45,865:INFO:Starting cross validation
2025-06-02 17:28:45,872:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:28:48,314:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.46278e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 17:28:48,372:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.7164e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 17:28:48,506:INFO:Calculating mean and std
2025-06-02 17:28:48,511:INFO:Creating metrics dataframe
2025-06-02 17:28:48,515:INFO:Uploading results into container
2025-06-02 17:28:48,517:INFO:Uploading model into container now
2025-06-02 17:28:48,518:INFO:_master_model_container: 3
2025-06-02 17:28:48,518:INFO:_display_container: 2
2025-06-02 17:28:48,519:INFO:Ridge(random_state=123)
2025-06-02 17:28:48,519:INFO:create_model() successfully completed......................................
2025-06-02 17:28:51,356:INFO:SubProcess create_model() end ==================================
2025-06-02 17:28:51,358:INFO:Creating metrics dataframe
2025-06-02 17:28:51,402:INFO:Initializing Elastic Net
2025-06-02 17:28:51,403:INFO:Total runtime is 0.7801500161488851 minutes
2025-06-02 17:28:51,423:INFO:SubProcess create_model() called ==================================
2025-06-02 17:28:51,425:INFO:Initializing create_model()
2025-06-02 17:28:51,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:28:51,426:INFO:Checking exceptions
2025-06-02 17:28:51,426:INFO:Importing libraries
2025-06-02 17:28:51,426:INFO:Copying training dataset
2025-06-02 17:28:51,601:INFO:Defining folds
2025-06-02 17:28:51,603:INFO:Declaring metric variables
2025-06-02 17:28:51,619:INFO:Importing untrained model
2025-06-02 17:28:51,636:INFO:Elastic Net Imported successfully
2025-06-02 17:28:51,670:INFO:Starting cross validation
2025-06-02 17:28:51,676:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:28:53,020:INFO:Calculating mean and std
2025-06-02 17:28:53,024:INFO:Creating metrics dataframe
2025-06-02 17:28:53,033:INFO:Uploading results into container
2025-06-02 17:28:53,035:INFO:Uploading model into container now
2025-06-02 17:28:53,037:INFO:_master_model_container: 4
2025-06-02 17:28:53,038:INFO:_display_container: 2
2025-06-02 17:28:53,039:INFO:ElasticNet(random_state=123)
2025-06-02 17:28:53,039:INFO:create_model() successfully completed......................................
2025-06-02 17:28:54,596:INFO:SubProcess create_model() end ==================================
2025-06-02 17:28:54,596:INFO:Creating metrics dataframe
2025-06-02 17:28:54,613:INFO:Initializing Least Angle Regression
2025-06-02 17:28:54,613:INFO:Total runtime is 0.8336506088574728 minutes
2025-06-02 17:28:54,623:INFO:SubProcess create_model() called ==================================
2025-06-02 17:28:54,625:INFO:Initializing create_model()
2025-06-02 17:28:54,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:28:54,627:INFO:Checking exceptions
2025-06-02 17:28:54,627:INFO:Importing libraries
2025-06-02 17:28:54,627:INFO:Copying training dataset
2025-06-02 17:28:54,691:INFO:Defining folds
2025-06-02 17:28:54,691:INFO:Declaring metric variables
2025-06-02 17:28:54,701:INFO:Importing untrained model
2025-06-02 17:28:54,714:INFO:Least Angle Regression Imported successfully
2025-06-02 17:28:54,738:INFO:Starting cross validation
2025-06-02 17:28:54,743:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:28:55,401:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.173e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 17:28:55,403:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.339e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 17:28:55,404:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.722e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 17:28:55,404:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.721e-01, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 17:28:55,406:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.411e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 17:28:55,409:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.434e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 17:28:55,442:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=4.180e-01, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 17:28:55,522:INFO:Calculating mean and std
2025-06-02 17:28:55,525:INFO:Creating metrics dataframe
2025-06-02 17:28:55,528:INFO:Uploading results into container
2025-06-02 17:28:55,529:INFO:Uploading model into container now
2025-06-02 17:28:55,530:INFO:_master_model_container: 5
2025-06-02 17:28:55,530:INFO:_display_container: 2
2025-06-02 17:28:55,532:INFO:Lars(random_state=123)
2025-06-02 17:28:55,532:INFO:create_model() successfully completed......................................
2025-06-02 17:28:56,832:INFO:SubProcess create_model() end ==================================
2025-06-02 17:28:56,833:INFO:Creating metrics dataframe
2025-06-02 17:28:56,853:INFO:Initializing Lasso Least Angle Regression
2025-06-02 17:28:56,854:INFO:Total runtime is 0.8709907372792562 minutes
2025-06-02 17:28:56,865:INFO:SubProcess create_model() called ==================================
2025-06-02 17:28:56,866:INFO:Initializing create_model()
2025-06-02 17:28:56,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:28:56,867:INFO:Checking exceptions
2025-06-02 17:28:56,867:INFO:Importing libraries
2025-06-02 17:28:56,868:INFO:Copying training dataset
2025-06-02 17:28:56,927:INFO:Defining folds
2025-06-02 17:28:56,928:INFO:Declaring metric variables
2025-06-02 17:28:56,944:INFO:Importing untrained model
2025-06-02 17:28:56,956:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 17:28:56,981:INFO:Starting cross validation
2025-06-02 17:28:56,986:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:28:57,753:INFO:Calculating mean and std
2025-06-02 17:28:57,755:INFO:Creating metrics dataframe
2025-06-02 17:28:57,760:INFO:Uploading results into container
2025-06-02 17:28:57,762:INFO:Uploading model into container now
2025-06-02 17:28:57,762:INFO:_master_model_container: 6
2025-06-02 17:28:57,763:INFO:_display_container: 2
2025-06-02 17:28:57,764:INFO:LassoLars(random_state=123)
2025-06-02 17:28:57,764:INFO:create_model() successfully completed......................................
2025-06-02 17:28:59,088:INFO:SubProcess create_model() end ==================================
2025-06-02 17:28:59,088:INFO:Creating metrics dataframe
2025-06-02 17:28:59,106:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 17:28:59,106:INFO:Total runtime is 0.9085354407628378 minutes
2025-06-02 17:28:59,118:INFO:SubProcess create_model() called ==================================
2025-06-02 17:28:59,118:INFO:Initializing create_model()
2025-06-02 17:28:59,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:28:59,119:INFO:Checking exceptions
2025-06-02 17:28:59,119:INFO:Importing libraries
2025-06-02 17:28:59,120:INFO:Copying training dataset
2025-06-02 17:28:59,191:INFO:Defining folds
2025-06-02 17:28:59,192:INFO:Declaring metric variables
2025-06-02 17:28:59,208:INFO:Importing untrained model
2025-06-02 17:28:59,223:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 17:28:59,247:INFO:Starting cross validation
2025-06-02 17:28:59,252:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:29:00,052:INFO:Calculating mean and std
2025-06-02 17:29:00,054:INFO:Creating metrics dataframe
2025-06-02 17:29:00,059:INFO:Uploading results into container
2025-06-02 17:29:00,060:INFO:Uploading model into container now
2025-06-02 17:29:00,061:INFO:_master_model_container: 7
2025-06-02 17:29:00,061:INFO:_display_container: 2
2025-06-02 17:29:00,061:INFO:OrthogonalMatchingPursuit()
2025-06-02 17:29:00,062:INFO:create_model() successfully completed......................................
2025-06-02 17:29:01,825:INFO:SubProcess create_model() end ==================================
2025-06-02 17:29:01,825:INFO:Creating metrics dataframe
2025-06-02 17:29:01,852:INFO:Initializing Bayesian Ridge
2025-06-02 17:29:01,852:INFO:Total runtime is 0.9542973875999451 minutes
2025-06-02 17:29:01,866:INFO:SubProcess create_model() called ==================================
2025-06-02 17:29:01,867:INFO:Initializing create_model()
2025-06-02 17:29:01,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:29:01,869:INFO:Checking exceptions
2025-06-02 17:29:01,869:INFO:Importing libraries
2025-06-02 17:29:01,870:INFO:Copying training dataset
2025-06-02 17:29:01,972:INFO:Defining folds
2025-06-02 17:29:01,973:INFO:Declaring metric variables
2025-06-02 17:29:01,984:INFO:Importing untrained model
2025-06-02 17:29:01,993:INFO:Bayesian Ridge Imported successfully
2025-06-02 17:29:02,013:INFO:Starting cross validation
2025-06-02 17:29:02,017:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:29:02,946:INFO:Calculating mean and std
2025-06-02 17:29:02,948:INFO:Creating metrics dataframe
2025-06-02 17:29:02,954:INFO:Uploading results into container
2025-06-02 17:29:02,955:INFO:Uploading model into container now
2025-06-02 17:29:02,957:INFO:_master_model_container: 8
2025-06-02 17:29:02,957:INFO:_display_container: 2
2025-06-02 17:29:02,959:INFO:BayesianRidge()
2025-06-02 17:29:02,959:INFO:create_model() successfully completed......................................
2025-06-02 17:29:04,333:INFO:SubProcess create_model() end ==================================
2025-06-02 17:29:04,333:INFO:Creating metrics dataframe
2025-06-02 17:29:04,352:INFO:Initializing Passive Aggressive Regressor
2025-06-02 17:29:04,353:INFO:Total runtime is 0.9959713697433472 minutes
2025-06-02 17:29:04,362:INFO:SubProcess create_model() called ==================================
2025-06-02 17:29:04,363:INFO:Initializing create_model()
2025-06-02 17:29:04,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:29:04,363:INFO:Checking exceptions
2025-06-02 17:29:04,364:INFO:Importing libraries
2025-06-02 17:29:04,364:INFO:Copying training dataset
2025-06-02 17:29:04,421:INFO:Defining folds
2025-06-02 17:29:04,422:INFO:Declaring metric variables
2025-06-02 17:29:04,436:INFO:Importing untrained model
2025-06-02 17:29:04,448:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 17:29:04,469:INFO:Starting cross validation
2025-06-02 17:29:04,472:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:29:05,776:INFO:Calculating mean and std
2025-06-02 17:29:05,779:INFO:Creating metrics dataframe
2025-06-02 17:29:05,784:INFO:Uploading results into container
2025-06-02 17:29:05,786:INFO:Uploading model into container now
2025-06-02 17:29:05,787:INFO:_master_model_container: 9
2025-06-02 17:29:05,787:INFO:_display_container: 2
2025-06-02 17:29:05,788:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 17:29:05,788:INFO:create_model() successfully completed......................................
2025-06-02 17:29:07,145:INFO:SubProcess create_model() end ==================================
2025-06-02 17:29:07,145:INFO:Creating metrics dataframe
2025-06-02 17:29:07,166:INFO:Initializing Huber Regressor
2025-06-02 17:29:07,167:INFO:Total runtime is 1.0428836941719055 minutes
2025-06-02 17:29:07,177:INFO:SubProcess create_model() called ==================================
2025-06-02 17:29:07,178:INFO:Initializing create_model()
2025-06-02 17:29:07,179:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:29:07,179:INFO:Checking exceptions
2025-06-02 17:29:07,180:INFO:Importing libraries
2025-06-02 17:29:07,180:INFO:Copying training dataset
2025-06-02 17:29:07,237:INFO:Defining folds
2025-06-02 17:29:07,237:INFO:Declaring metric variables
2025-06-02 17:29:07,252:INFO:Importing untrained model
2025-06-02 17:29:07,263:INFO:Huber Regressor Imported successfully
2025-06-02 17:29:07,286:INFO:Starting cross validation
2025-06-02 17:29:07,289:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:29:08,949:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:29:08,972:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:29:09,046:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:29:09,060:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:29:09,072:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:29:09,122:INFO:Calculating mean and std
2025-06-02 17:29:09,126:INFO:Creating metrics dataframe
2025-06-02 17:29:09,130:INFO:Uploading results into container
2025-06-02 17:29:09,131:INFO:Uploading model into container now
2025-06-02 17:29:09,132:INFO:_master_model_container: 10
2025-06-02 17:29:09,132:INFO:_display_container: 2
2025-06-02 17:29:09,132:INFO:HuberRegressor()
2025-06-02 17:29:09,133:INFO:create_model() successfully completed......................................
2025-06-02 17:29:10,431:INFO:SubProcess create_model() end ==================================
2025-06-02 17:29:10,432:INFO:Creating metrics dataframe
2025-06-02 17:29:10,453:INFO:Initializing K Neighbors Regressor
2025-06-02 17:29:10,453:INFO:Total runtime is 1.0976465702056886 minutes
2025-06-02 17:29:10,465:INFO:SubProcess create_model() called ==================================
2025-06-02 17:29:10,466:INFO:Initializing create_model()
2025-06-02 17:29:10,466:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:29:10,467:INFO:Checking exceptions
2025-06-02 17:29:10,467:INFO:Importing libraries
2025-06-02 17:29:10,468:INFO:Copying training dataset
2025-06-02 17:29:10,527:INFO:Defining folds
2025-06-02 17:29:10,527:INFO:Declaring metric variables
2025-06-02 17:29:10,542:INFO:Importing untrained model
2025-06-02 17:29:10,553:INFO:K Neighbors Regressor Imported successfully
2025-06-02 17:29:10,577:INFO:Starting cross validation
2025-06-02 17:29:10,581:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:29:11,370:INFO:Calculating mean and std
2025-06-02 17:29:11,372:INFO:Creating metrics dataframe
2025-06-02 17:29:11,376:INFO:Uploading results into container
2025-06-02 17:29:11,377:INFO:Uploading model into container now
2025-06-02 17:29:11,379:INFO:_master_model_container: 11
2025-06-02 17:29:11,379:INFO:_display_container: 2
2025-06-02 17:29:11,380:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 17:29:11,380:INFO:create_model() successfully completed......................................
2025-06-02 17:29:12,911:INFO:SubProcess create_model() end ==================================
2025-06-02 17:29:12,912:INFO:Creating metrics dataframe
2025-06-02 17:29:12,947:INFO:Initializing Decision Tree Regressor
2025-06-02 17:29:12,948:INFO:Total runtime is 1.1392229715983073 minutes
2025-06-02 17:29:12,968:INFO:SubProcess create_model() called ==================================
2025-06-02 17:29:12,969:INFO:Initializing create_model()
2025-06-02 17:29:12,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:29:12,970:INFO:Checking exceptions
2025-06-02 17:29:12,970:INFO:Importing libraries
2025-06-02 17:29:12,971:INFO:Copying training dataset
2025-06-02 17:29:13,073:INFO:Defining folds
2025-06-02 17:29:13,074:INFO:Declaring metric variables
2025-06-02 17:29:13,090:INFO:Importing untrained model
2025-06-02 17:29:13,111:INFO:Decision Tree Regressor Imported successfully
2025-06-02 17:29:13,144:INFO:Starting cross validation
2025-06-02 17:29:13,148:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:29:14,192:INFO:Calculating mean and std
2025-06-02 17:29:14,194:INFO:Creating metrics dataframe
2025-06-02 17:29:14,199:INFO:Uploading results into container
2025-06-02 17:29:14,201:INFO:Uploading model into container now
2025-06-02 17:29:14,202:INFO:_master_model_container: 12
2025-06-02 17:29:14,202:INFO:_display_container: 2
2025-06-02 17:29:14,203:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 17:29:14,204:INFO:create_model() successfully completed......................................
2025-06-02 17:29:15,647:INFO:SubProcess create_model() end ==================================
2025-06-02 17:29:15,648:INFO:Creating metrics dataframe
2025-06-02 17:29:15,668:INFO:Initializing Random Forest Regressor
2025-06-02 17:29:15,668:INFO:Total runtime is 1.1845661520957946 minutes
2025-06-02 17:29:15,679:INFO:SubProcess create_model() called ==================================
2025-06-02 17:29:15,680:INFO:Initializing create_model()
2025-06-02 17:29:15,680:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:29:15,681:INFO:Checking exceptions
2025-06-02 17:29:15,681:INFO:Importing libraries
2025-06-02 17:29:15,681:INFO:Copying training dataset
2025-06-02 17:29:15,743:INFO:Defining folds
2025-06-02 17:29:15,743:INFO:Declaring metric variables
2025-06-02 17:29:15,759:INFO:Importing untrained model
2025-06-02 17:29:15,770:INFO:Random Forest Regressor Imported successfully
2025-06-02 17:29:15,797:INFO:Starting cross validation
2025-06-02 17:29:15,801:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:29:27,826:INFO:Calculating mean and std
2025-06-02 17:29:27,829:INFO:Creating metrics dataframe
2025-06-02 17:29:27,833:INFO:Uploading results into container
2025-06-02 17:29:27,834:INFO:Uploading model into container now
2025-06-02 17:29:27,836:INFO:_master_model_container: 13
2025-06-02 17:29:27,836:INFO:_display_container: 2
2025-06-02 17:29:27,838:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:29:27,839:INFO:create_model() successfully completed......................................
2025-06-02 17:29:29,689:INFO:SubProcess create_model() end ==================================
2025-06-02 17:29:29,689:INFO:Creating metrics dataframe
2025-06-02 17:29:29,727:INFO:Initializing Extra Trees Regressor
2025-06-02 17:29:29,728:INFO:Total runtime is 1.4189032038052876 minutes
2025-06-02 17:29:29,747:INFO:SubProcess create_model() called ==================================
2025-06-02 17:29:29,749:INFO:Initializing create_model()
2025-06-02 17:29:29,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:29:29,750:INFO:Checking exceptions
2025-06-02 17:29:29,751:INFO:Importing libraries
2025-06-02 17:29:29,751:INFO:Copying training dataset
2025-06-02 17:29:29,855:INFO:Defining folds
2025-06-02 17:29:29,855:INFO:Declaring metric variables
2025-06-02 17:29:29,872:INFO:Importing untrained model
2025-06-02 17:29:29,889:INFO:Extra Trees Regressor Imported successfully
2025-06-02 17:29:29,936:INFO:Starting cross validation
2025-06-02 17:29:29,944:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:29:38,552:INFO:Calculating mean and std
2025-06-02 17:29:38,556:INFO:Creating metrics dataframe
2025-06-02 17:29:38,563:INFO:Uploading results into container
2025-06-02 17:29:38,564:INFO:Uploading model into container now
2025-06-02 17:29:38,565:INFO:_master_model_container: 14
2025-06-02 17:29:38,566:INFO:_display_container: 2
2025-06-02 17:29:38,568:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:29:38,568:INFO:create_model() successfully completed......................................
2025-06-02 17:29:40,353:INFO:SubProcess create_model() end ==================================
2025-06-02 17:29:40,354:INFO:Creating metrics dataframe
2025-06-02 17:29:40,383:INFO:Initializing AdaBoost Regressor
2025-06-02 17:29:40,384:INFO:Total runtime is 1.5964885314305621 minutes
2025-06-02 17:29:40,397:INFO:SubProcess create_model() called ==================================
2025-06-02 17:29:40,398:INFO:Initializing create_model()
2025-06-02 17:29:40,399:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:29:40,399:INFO:Checking exceptions
2025-06-02 17:29:40,400:INFO:Importing libraries
2025-06-02 17:29:40,400:INFO:Copying training dataset
2025-06-02 17:29:40,481:INFO:Defining folds
2025-06-02 17:29:40,483:INFO:Declaring metric variables
2025-06-02 17:29:40,503:INFO:Importing untrained model
2025-06-02 17:29:40,522:INFO:AdaBoost Regressor Imported successfully
2025-06-02 17:29:40,552:INFO:Starting cross validation
2025-06-02 17:29:40,559:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:29:43,636:INFO:Calculating mean and std
2025-06-02 17:29:43,638:INFO:Creating metrics dataframe
2025-06-02 17:29:43,644:INFO:Uploading results into container
2025-06-02 17:29:43,645:INFO:Uploading model into container now
2025-06-02 17:29:43,646:INFO:_master_model_container: 15
2025-06-02 17:29:43,647:INFO:_display_container: 2
2025-06-02 17:29:43,647:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 17:29:43,648:INFO:create_model() successfully completed......................................
2025-06-02 17:29:45,111:INFO:SubProcess create_model() end ==================================
2025-06-02 17:29:45,112:INFO:Creating metrics dataframe
2025-06-02 17:29:45,136:INFO:Initializing Gradient Boosting Regressor
2025-06-02 17:29:45,136:INFO:Total runtime is 1.6756978313128152 minutes
2025-06-02 17:29:45,147:INFO:SubProcess create_model() called ==================================
2025-06-02 17:29:45,147:INFO:Initializing create_model()
2025-06-02 17:29:45,147:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:29:45,148:INFO:Checking exceptions
2025-06-02 17:29:45,148:INFO:Importing libraries
2025-06-02 17:29:45,148:INFO:Copying training dataset
2025-06-02 17:29:45,217:INFO:Defining folds
2025-06-02 17:29:45,218:INFO:Declaring metric variables
2025-06-02 17:29:45,231:INFO:Importing untrained model
2025-06-02 17:29:45,245:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 17:29:45,269:INFO:Starting cross validation
2025-06-02 17:29:45,273:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:29:49,427:INFO:Calculating mean and std
2025-06-02 17:29:49,429:INFO:Creating metrics dataframe
2025-06-02 17:29:49,432:INFO:Uploading results into container
2025-06-02 17:29:49,433:INFO:Uploading model into container now
2025-06-02 17:29:49,433:INFO:_master_model_container: 16
2025-06-02 17:29:49,434:INFO:_display_container: 2
2025-06-02 17:29:49,435:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 17:29:49,436:INFO:create_model() successfully completed......................................
2025-06-02 17:29:50,807:INFO:SubProcess create_model() end ==================================
2025-06-02 17:29:50,808:INFO:Creating metrics dataframe
2025-06-02 17:29:50,834:INFO:Initializing Extreme Gradient Boosting
2025-06-02 17:29:50,834:INFO:Total runtime is 1.7706705331802368 minutes
2025-06-02 17:29:50,846:INFO:SubProcess create_model() called ==================================
2025-06-02 17:29:50,847:INFO:Initializing create_model()
2025-06-02 17:29:50,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:29:50,847:INFO:Checking exceptions
2025-06-02 17:29:50,848:INFO:Importing libraries
2025-06-02 17:29:50,848:INFO:Copying training dataset
2025-06-02 17:29:50,910:INFO:Defining folds
2025-06-02 17:29:50,911:INFO:Declaring metric variables
2025-06-02 17:29:50,925:INFO:Importing untrained model
2025-06-02 17:29:50,939:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 17:29:50,963:INFO:Starting cross validation
2025-06-02 17:29:50,967:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:29:53,230:INFO:Calculating mean and std
2025-06-02 17:29:53,232:INFO:Creating metrics dataframe
2025-06-02 17:29:53,236:INFO:Uploading results into container
2025-06-02 17:29:53,237:INFO:Uploading model into container now
2025-06-02 17:29:53,237:INFO:_master_model_container: 17
2025-06-02 17:29:53,238:INFO:_display_container: 2
2025-06-02 17:29:53,242:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 17:29:53,243:INFO:create_model() successfully completed......................................
2025-06-02 17:29:54,609:INFO:SubProcess create_model() end ==================================
2025-06-02 17:29:54,609:INFO:Creating metrics dataframe
2025-06-02 17:29:54,631:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 17:29:54,631:INFO:Total runtime is 1.8339449922243753 minutes
2025-06-02 17:29:54,641:INFO:SubProcess create_model() called ==================================
2025-06-02 17:29:54,642:INFO:Initializing create_model()
2025-06-02 17:29:54,642:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:29:54,643:INFO:Checking exceptions
2025-06-02 17:29:54,643:INFO:Importing libraries
2025-06-02 17:29:54,643:INFO:Copying training dataset
2025-06-02 17:29:54,707:INFO:Defining folds
2025-06-02 17:29:54,707:INFO:Declaring metric variables
2025-06-02 17:29:54,722:INFO:Importing untrained model
2025-06-02 17:29:54,736:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 17:29:54,760:INFO:Starting cross validation
2025-06-02 17:29:54,764:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:29:56,514:INFO:Calculating mean and std
2025-06-02 17:29:56,516:INFO:Creating metrics dataframe
2025-06-02 17:29:56,520:INFO:Uploading results into container
2025-06-02 17:29:56,521:INFO:Uploading model into container now
2025-06-02 17:29:56,522:INFO:_master_model_container: 18
2025-06-02 17:29:56,522:INFO:_display_container: 2
2025-06-02 17:29:56,524:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:29:56,524:INFO:create_model() successfully completed......................................
2025-06-02 17:29:57,958:INFO:SubProcess create_model() end ==================================
2025-06-02 17:29:57,958:INFO:Creating metrics dataframe
2025-06-02 17:29:57,983:INFO:Initializing CatBoost Regressor
2025-06-02 17:29:57,984:INFO:Total runtime is 1.8898220419883727 minutes
2025-06-02 17:29:57,996:INFO:SubProcess create_model() called ==================================
2025-06-02 17:29:57,996:INFO:Initializing create_model()
2025-06-02 17:29:57,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:29:57,997:INFO:Checking exceptions
2025-06-02 17:29:57,997:INFO:Importing libraries
2025-06-02 17:29:57,997:INFO:Copying training dataset
2025-06-02 17:29:58,068:INFO:Defining folds
2025-06-02 17:29:58,068:INFO:Declaring metric variables
2025-06-02 17:29:58,082:INFO:Importing untrained model
2025-06-02 17:29:58,102:INFO:CatBoost Regressor Imported successfully
2025-06-02 17:29:58,128:INFO:Starting cross validation
2025-06-02 17:29:58,132:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:30:25,426:INFO:Calculating mean and std
2025-06-02 17:30:25,428:INFO:Creating metrics dataframe
2025-06-02 17:30:25,432:INFO:Uploading results into container
2025-06-02 17:30:25,433:INFO:Uploading model into container now
2025-06-02 17:30:25,434:INFO:_master_model_container: 19
2025-06-02 17:30:25,435:INFO:_display_container: 2
2025-06-02 17:30:25,435:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6FB095840>
2025-06-02 17:30:25,435:INFO:create_model() successfully completed......................................
2025-06-02 17:30:26,963:INFO:SubProcess create_model() end ==================================
2025-06-02 17:30:26,964:INFO:Creating metrics dataframe
2025-06-02 17:30:26,990:INFO:Initializing Dummy Regressor
2025-06-02 17:30:26,990:INFO:Total runtime is 2.373264122009277 minutes
2025-06-02 17:30:27,002:INFO:SubProcess create_model() called ==================================
2025-06-02 17:30:27,003:INFO:Initializing create_model()
2025-06-02 17:30:27,003:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70215C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:30:27,004:INFO:Checking exceptions
2025-06-02 17:30:27,004:INFO:Importing libraries
2025-06-02 17:30:27,004:INFO:Copying training dataset
2025-06-02 17:30:27,087:INFO:Defining folds
2025-06-02 17:30:27,087:INFO:Declaring metric variables
2025-06-02 17:30:27,103:INFO:Importing untrained model
2025-06-02 17:30:27,116:INFO:Dummy Regressor Imported successfully
2025-06-02 17:30:27,144:INFO:Starting cross validation
2025-06-02 17:30:27,147:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:30:27,952:INFO:Calculating mean and std
2025-06-02 17:30:27,954:INFO:Creating metrics dataframe
2025-06-02 17:30:27,958:INFO:Uploading results into container
2025-06-02 17:30:27,959:INFO:Uploading model into container now
2025-06-02 17:30:27,960:INFO:_master_model_container: 20
2025-06-02 17:30:27,960:INFO:_display_container: 2
2025-06-02 17:30:27,960:INFO:DummyRegressor()
2025-06-02 17:30:27,961:INFO:create_model() successfully completed......................................
2025-06-02 17:30:29,439:INFO:SubProcess create_model() end ==================================
2025-06-02 17:30:29,440:INFO:Creating metrics dataframe
2025-06-02 17:30:29,497:INFO:Initializing create_model()
2025-06-02 17:30:29,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:30:29,498:INFO:Checking exceptions
2025-06-02 17:30:29,509:INFO:Importing libraries
2025-06-02 17:30:29,510:INFO:Copying training dataset
2025-06-02 17:30:29,573:INFO:Defining folds
2025-06-02 17:30:29,574:INFO:Declaring metric variables
2025-06-02 17:30:29,574:INFO:Importing untrained model
2025-06-02 17:30:29,574:INFO:Declaring custom model
2025-06-02 17:30:29,576:INFO:Extra Trees Regressor Imported successfully
2025-06-02 17:30:29,579:INFO:Cross validation set to False
2025-06-02 17:30:29,580:INFO:Fitting Model
2025-06-02 17:30:31,655:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:30:31,655:INFO:create_model() successfully completed......................................
2025-06-02 17:30:33,052:INFO:Initializing create_model()
2025-06-02 17:30:33,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=<catboost.core.CatBoostRegressor object at 0x000001B6FB095840>, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:30:33,053:INFO:Checking exceptions
2025-06-02 17:30:33,061:INFO:Importing libraries
2025-06-02 17:30:33,061:INFO:Copying training dataset
2025-06-02 17:30:33,132:INFO:Defining folds
2025-06-02 17:30:33,132:INFO:Declaring metric variables
2025-06-02 17:30:33,133:INFO:Importing untrained model
2025-06-02 17:30:33,133:INFO:Declaring custom model
2025-06-02 17:30:33,134:INFO:CatBoost Regressor Imported successfully
2025-06-02 17:30:33,137:INFO:Cross validation set to False
2025-06-02 17:30:33,137:INFO:Fitting Model
2025-06-02 17:30:40,150:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6FB07D540>
2025-06-02 17:30:40,150:INFO:create_model() successfully completed......................................
2025-06-02 17:30:41,881:INFO:Initializing create_model()
2025-06-02 17:30:41,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:30:41,881:INFO:Checking exceptions
2025-06-02 17:30:41,884:INFO:Importing libraries
2025-06-02 17:30:41,885:INFO:Copying training dataset
2025-06-02 17:30:41,961:INFO:Defining folds
2025-06-02 17:30:41,961:INFO:Declaring metric variables
2025-06-02 17:30:41,962:INFO:Importing untrained model
2025-06-02 17:30:41,962:INFO:Declaring custom model
2025-06-02 17:30:41,964:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 17:30:41,967:INFO:Cross validation set to False
2025-06-02 17:30:41,967:INFO:Fitting Model
2025-06-02 17:30:43,243:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 17:30:43,243:INFO:create_model() successfully completed......................................
2025-06-02 17:30:44,754:INFO:_master_model_container: 20
2025-06-02 17:30:44,754:INFO:_display_container: 2
2025-06-02 17:30:44,757:INFO:[ExtraTreesRegressor(n_jobs=-1, random_state=123), <catboost.core.CatBoostRegressor object at 0x000001B6FB07D540>, XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)]
2025-06-02 17:30:44,758:INFO:compare_models() successfully completed......................................
2025-06-02 17:30:44,764:INFO:Initializing tune_model()
2025-06-02 17:30:44,764:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>)
2025-06-02 17:30:44,764:INFO:Checking exceptions
2025-06-02 17:30:44,765:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 17:30:44,825:INFO:Copying training dataset
2025-06-02 17:30:44,873:INFO:Checking base model
2025-06-02 17:30:44,875:INFO:Base model : Extra Trees Regressor
2025-06-02 17:30:44,888:INFO:Declaring metric variables
2025-06-02 17:30:44,902:INFO:Defining Hyperparameters
2025-06-02 17:30:47,170:INFO:Tuning with n_jobs=-1
2025-06-02 17:30:47,186:INFO:Initializing skopt.BayesSearchCV
2025-06-02 17:35:25,048:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', False), ('actual_estimator__criterion', 'absolute_error'), ('actual_estimator__max_depth', 11), ('actual_estimator__max_features', 0.4556655086335653), ('actual_estimator__min_impurity_decrease', 0.00012891733508622256), ('actual_estimator__min_samples_leaf', 1), ('actual_estimator__min_samples_split', 9), ('actual_estimator__n_estimators', 11)])
2025-06-02 17:35:25,049:INFO:Hyperparameter search completed
2025-06-02 17:35:25,050:INFO:SubProcess create_model() called ==================================
2025-06-02 17:35:25,051:INFO:Initializing create_model()
2025-06-02 17:35:25,052:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E498AA40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bootstrap': False, 'criterion': 'absolute_error', 'max_depth': 11, 'max_features': 0.4556655086335653, 'min_impurity_decrease': 0.00012891733508622256, 'min_samples_leaf': 1, 'min_samples_split': 9, 'n_estimators': 11})
2025-06-02 17:35:25,052:INFO:Checking exceptions
2025-06-02 17:35:25,052:INFO:Importing libraries
2025-06-02 17:35:25,053:INFO:Copying training dataset
2025-06-02 17:35:25,158:INFO:Defining folds
2025-06-02 17:35:25,159:INFO:Declaring metric variables
2025-06-02 17:35:25,172:INFO:Importing untrained model
2025-06-02 17:35:25,172:INFO:Declaring custom model
2025-06-02 17:35:25,191:INFO:Extra Trees Regressor Imported successfully
2025-06-02 17:35:25,213:INFO:Starting cross validation
2025-06-02 17:35:25,216:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:35:35,947:INFO:Calculating mean and std
2025-06-02 17:35:35,949:INFO:Creating metrics dataframe
2025-06-02 17:35:35,965:INFO:Finalizing model
2025-06-02 17:35:40,135:INFO:Uploading results into container
2025-06-02 17:35:40,137:INFO:Uploading model into container now
2025-06-02 17:35:40,139:INFO:_master_model_container: 21
2025-06-02 17:35:40,139:INFO:_display_container: 3
2025-06-02 17:35:40,142:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=11,
                    max_features=0.4556655086335653,
                    min_impurity_decrease=0.00012891733508622256,
                    min_samples_split=9, n_estimators=11, n_jobs=-1,
                    random_state=123)
2025-06-02 17:35:40,143:INFO:create_model() successfully completed......................................
2025-06-02 17:35:41,829:INFO:SubProcess create_model() end ==================================
2025-06-02 17:35:41,829:INFO:choose_better activated
2025-06-02 17:35:41,839:INFO:SubProcess create_model() called ==================================
2025-06-02 17:35:41,840:INFO:Initializing create_model()
2025-06-02 17:35:41,840:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:35:41,840:INFO:Checking exceptions
2025-06-02 17:35:41,843:INFO:Importing libraries
2025-06-02 17:35:41,844:INFO:Copying training dataset
2025-06-02 17:35:41,908:INFO:Defining folds
2025-06-02 17:35:41,908:INFO:Declaring metric variables
2025-06-02 17:35:41,909:INFO:Importing untrained model
2025-06-02 17:35:41,909:INFO:Declaring custom model
2025-06-02 17:35:41,910:INFO:Extra Trees Regressor Imported successfully
2025-06-02 17:35:41,910:INFO:Starting cross validation
2025-06-02 17:35:41,913:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:35:50,934:INFO:Calculating mean and std
2025-06-02 17:35:50,935:INFO:Creating metrics dataframe
2025-06-02 17:35:50,939:INFO:Finalizing model
2025-06-02 17:35:52,944:INFO:Uploading results into container
2025-06-02 17:35:52,945:INFO:Uploading model into container now
2025-06-02 17:35:52,946:INFO:_master_model_container: 22
2025-06-02 17:35:52,946:INFO:_display_container: 4
2025-06-02 17:35:52,947:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:35:52,947:INFO:create_model() successfully completed......................................
2025-06-02 17:35:54,268:INFO:SubProcess create_model() end ==================================
2025-06-02 17:35:54,269:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 0.1682
2025-06-02 17:35:54,271:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=11,
                    max_features=0.4556655086335653,
                    min_impurity_decrease=0.00012891733508622256,
                    min_samples_split=9, n_estimators=11, n_jobs=-1,
                    random_state=123) result for MAE is 0.1935
2025-06-02 17:35:54,272:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 17:35:54,272:INFO:choose_better completed
2025-06-02 17:35:54,272:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 17:35:54,293:INFO:_master_model_container: 22
2025-06-02 17:35:54,293:INFO:_display_container: 3
2025-06-02 17:35:54,294:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:35:54,295:INFO:tune_model() successfully completed......................................
2025-06-02 17:35:56,198:INFO:Initializing finalize_model()
2025-06-02 17:35:56,198:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 17:35:56,199:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:35:56,275:INFO:Initializing create_model()
2025-06-02 17:35:56,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:35:56,275:INFO:Checking exceptions
2025-06-02 17:35:56,277:INFO:Importing libraries
2025-06-02 17:35:56,278:INFO:Copying training dataset
2025-06-02 17:35:56,283:INFO:Defining folds
2025-06-02 17:35:56,283:INFO:Declaring metric variables
2025-06-02 17:35:56,283:INFO:Importing untrained model
2025-06-02 17:35:56,283:INFO:Declaring custom model
2025-06-02 17:35:56,284:INFO:Extra Trees Regressor Imported successfully
2025-06-02 17:35:56,287:INFO:Cross validation set to False
2025-06-02 17:35:56,287:INFO:Fitting Model
2025-06-02 17:35:58,835:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 17:35:58,835:INFO:create_model() successfully completed......................................
2025-06-02 17:36:00,466:INFO:_master_model_container: 22
2025-06-02 17:36:00,467:INFO:_display_container: 3
2025-06-02 17:36:00,493:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 17:36:00,493:INFO:finalize_model() successfully completed......................................
2025-06-02 17:36:02,047:INFO:Initializing save_model()
2025-06-02 17:36:02,047:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model_mae, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 17:36:02,047:INFO:Adding model into prep_pipe
2025-06-02 17:36:02,047:WARNING:Only Model saved as it was a pipeline.
2025-06-02 17:36:02,207:INFO:formation_energy_final_model_mae.pkl saved in current working directory
2025-06-02 17:36:02,222:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 17:36:02,222:INFO:save_model() successfully completed......................................
2025-06-02 17:38:34,737:INFO:Initializing load_model()
2025-06-02 17:38:34,739:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 17:38:35,162:INFO:Initializing get_config()
2025-06-02 17:38:35,162:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, variable=X_test)
2025-06-02 17:38:35,164:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 17:38:35,165:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 17:38:35,277:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2870                       12.0                       29.0   
3683                       12.0                       14.0   
1311                        7.0                       75.0   
2107                       83.0                       90.0   
3090                       16.0                       33.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2870                     17.0               24.750000   
3683                      2.0               13.285714   
1311                     68.0               29.666666   
2107                      7.0               85.800003   
3090                     17.0               24.000000   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2870                   6.375000                    29.0   
3683                   0.918367                    14.0   
1311                  30.222221                     7.0   
2107                   3.360000                    83.0   
3090                   8.470589                    16.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2870                                64.0                                68.0   
3683                                68.0                                78.0   
1311                                54.0                                82.0   
2107                                16.0                                86.0   
3090                                84.0                                88.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2870                               4.0                        65.000000  ...   
3683                              10.0                        74.428574  ...   
1311                              28.0                        72.666664  ...   
2107                              70.0                        58.000000  ...   
3090                               4.0                        86.117645  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2870                 4.0                   1            32.0   
3683                 7.0                   0             2.0   
1311                 6.0                   1             8.0   
2107                 4.0                   1            16.0   
3090                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2870                 False                     False   
3683                 False                     False   
1311                 False                     False   
2107                 False                     False   
3090                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2870                      False                        False   
3683                      False                        False   
1311                       True                        False   
2107                      False                        False   
3090                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2870                       True                     False   
3683                      False                      True   
1311                      False                     False   
2107                       True                     False   
3090                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2870                    False  
3683                    False  
1311                    False  
2107                    False  
3090                    False  

[896 rows x 146 columns]
2025-06-02 17:38:35,278:INFO:get_config() successfully completed......................................
2025-06-02 17:38:35,298:INFO:Initializing get_config()
2025-06-02 17:38:35,298:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, variable=y_test)
2025-06-02 17:38:35,299:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 17:38:35,299:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 17:38:35,318:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2870   -0.023269
3683    0.188325
1311    0.073840
2107    2.768059
3090   -0.156522
Name: target, Length: 896, dtype: float32
2025-06-02 17:38:35,318:INFO:get_config() successfully completed......................................
2025-06-02 17:38:35,347:INFO:Initializing predict_model()
2025-06-02 17:38:35,348:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=124))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B70229CDC0>)
2025-06-02 17:38:35,348:INFO:Checking exceptions
2025-06-02 17:38:35,348:INFO:Preloading libraries
2025-06-02 17:38:35,367:INFO:Set up data.
2025-06-02 17:38:35,468:INFO:Set up index.
2025-06-02 17:38:46,449:INFO:Initializing load_model()
2025-06-02 17:38:46,450:INFO:load_model(model_name=formation_energy_final_model_mae, platform=None, authentication=None, verbose=True)
2025-06-02 17:38:47,011:INFO:Initializing get_config()
2025-06-02 17:38:47,011:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, variable=X_test)
2025-06-02 17:38:47,011:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 17:38:47,011:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 17:38:47,058:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2870                       12.0                       29.0   
3683                       12.0                       14.0   
1311                        7.0                       75.0   
2107                       83.0                       90.0   
3090                       16.0                       33.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2870                     17.0               24.750000   
3683                      2.0               13.285714   
1311                     68.0               29.666666   
2107                      7.0               85.800003   
3090                     17.0               24.000000   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2870                   6.375000                    29.0   
3683                   0.918367                    14.0   
1311                  30.222221                     7.0   
2107                   3.360000                    83.0   
3090                   8.470589                    16.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2870                                64.0                                68.0   
3683                                68.0                                78.0   
1311                                54.0                                82.0   
2107                                16.0                                86.0   
3090                                84.0                                88.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2870                               4.0                        65.000000  ...   
3683                              10.0                        74.428574  ...   
1311                              28.0                        72.666664  ...   
2107                              70.0                        58.000000  ...   
3090                               4.0                        86.117645  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2870                 4.0                   1            32.0   
3683                 7.0                   0             2.0   
1311                 6.0                   1             8.0   
2107                 4.0                   1            16.0   
3090                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2870                 False                     False   
3683                 False                     False   
1311                 False                     False   
2107                 False                     False   
3090                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2870                      False                        False   
3683                      False                        False   
1311                       True                        False   
2107                      False                        False   
3090                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2870                       True                     False   
3683                      False                      True   
1311                      False                     False   
2107                       True                     False   
3090                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2870                    False  
3683                    False  
1311                    False  
2107                    False  
3090                    False  

[896 rows x 146 columns]
2025-06-02 17:38:47,058:INFO:get_config() successfully completed......................................
2025-06-02 17:38:47,067:INFO:Initializing get_config()
2025-06-02 17:38:47,067:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, variable=y_test)
2025-06-02 17:38:47,067:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 17:38:47,067:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 17:38:47,084:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2870   -0.023269
3683    0.188325
1311    0.073840
2107    2.768059
3090   -0.156522
Name: target, Length: 896, dtype: float32
2025-06-02 17:38:47,084:INFO:get_config() successfully completed......................................
2025-06-02 17:38:47,101:INFO:Initializing predict_model()
2025-06-02 17:38:47,101:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6ED730160>)
2025-06-02 17:38:47,101:INFO:Checking exceptions
2025-06-02 17:38:47,101:INFO:Preloading libraries
2025-06-02 17:38:47,105:INFO:Set up data.
2025-06-02 17:38:47,187:INFO:Set up index.
2025-06-02 17:40:14,369:INFO:Initializing load_model()
2025-06-02 17:40:14,370:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 17:40:46,881:INFO:Initializing load_model()
2025-06-02 17:40:46,881:INFO:load_model(model_name=formation_energy_final_model_mae, platform=None, authentication=None, verbose=True)
2025-06-02 17:40:47,455:INFO:Initializing get_config()
2025-06-02 17:40:47,455:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, variable=X_test)
2025-06-02 17:40:47,457:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 17:40:47,458:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 17:40:47,537:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2870                       12.0                       29.0   
3683                       12.0                       14.0   
1311                        7.0                       75.0   
2107                       83.0                       90.0   
3090                       16.0                       33.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2870                     17.0               24.750000   
3683                      2.0               13.285714   
1311                     68.0               29.666666   
2107                      7.0               85.800003   
3090                     17.0               24.000000   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2870                   6.375000                    29.0   
3683                   0.918367                    14.0   
1311                  30.222221                     7.0   
2107                   3.360000                    83.0   
3090                   8.470589                    16.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2870                                64.0                                68.0   
3683                                68.0                                78.0   
1311                                54.0                                82.0   
2107                                16.0                                86.0   
3090                                84.0                                88.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2870                               4.0                        65.000000  ...   
3683                              10.0                        74.428574  ...   
1311                              28.0                        72.666664  ...   
2107                              70.0                        58.000000  ...   
3090                               4.0                        86.117645  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2870                 4.0                   1            32.0   
3683                 7.0                   0             2.0   
1311                 6.0                   1             8.0   
2107                 4.0                   1            16.0   
3090                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2870                 False                     False   
3683                 False                     False   
1311                 False                     False   
2107                 False                     False   
3090                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2870                      False                        False   
3683                      False                        False   
1311                       True                        False   
2107                      False                        False   
3090                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2870                       True                     False   
3683                      False                      True   
1311                      False                     False   
2107                       True                     False   
3090                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2870                    False  
3683                    False  
1311                    False  
2107                    False  
3090                    False  

[896 rows x 146 columns]
2025-06-02 17:40:47,537:INFO:get_config() successfully completed......................................
2025-06-02 17:40:47,540:INFO:Initializing get_config()
2025-06-02 17:40:47,540:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, variable=y_test)
2025-06-02 17:40:47,540:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 17:40:47,541:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 17:40:47,558:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2870   -0.023269
3683    0.188325
1311    0.073840
2107    2.768059
3090   -0.156522
Name: target, Length: 896, dtype: float32
2025-06-02 17:40:47,558:INFO:get_config() successfully completed......................................
2025-06-02 17:40:47,582:INFO:Initializing predict_model()
2025-06-02 17:40:47,583:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B702C16140>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6FAFAEE60>)
2025-06-02 17:40:47,583:INFO:Checking exceptions
2025-06-02 17:40:47,583:INFO:Preloading libraries
2025-06-02 17:40:47,595:INFO:Set up data.
2025-06-02 17:40:47,683:INFO:Set up index.
2025-06-02 17:42:32,931:INFO:PyCaret RegressionExperiment
2025-06-02 17:42:32,932:INFO:Logging name: reg-default-name
2025-06-02 17:42:32,932:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 17:42:32,932:INFO:version 3.3.2
2025-06-02 17:42:32,932:INFO:Initializing setup()
2025-06-02 17:42:32,933:INFO:self.USI: f3ad
2025-06-02 17:42:32,933:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 17:42:32,933:INFO:Checking environment
2025-06-02 17:42:32,933:INFO:python_version: 3.10.16
2025-06-02 17:42:32,934:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 17:42:32,934:INFO:machine: AMD64
2025-06-02 17:42:32,934:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 17:42:32,939:INFO:Memory: svmem(total=6378008576, available=892125184, percent=86.0, used=5485883392, free=892125184)
2025-06-02 17:42:32,939:INFO:Physical Core: 4
2025-06-02 17:42:32,939:INFO:Logical Core: 8
2025-06-02 17:42:32,939:INFO:Checking libraries
2025-06-02 17:42:32,939:INFO:System:
2025-06-02 17:42:32,940:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 17:42:32,940:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 17:42:32,940:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 17:42:32,940:INFO:PyCaret required dependencies:
2025-06-02 17:42:32,940:INFO:                 pip: 25.1
2025-06-02 17:42:32,940:INFO:          setuptools: 78.1.1
2025-06-02 17:42:32,940:INFO:             pycaret: 3.3.2
2025-06-02 17:42:32,940:INFO:             IPython: 8.37.0
2025-06-02 17:42:32,940:INFO:          ipywidgets: 8.1.7
2025-06-02 17:42:32,940:INFO:                tqdm: 4.67.1
2025-06-02 17:42:32,940:INFO:               numpy: 1.26.4
2025-06-02 17:42:32,940:INFO:              pandas: 2.0.1
2025-06-02 17:42:32,940:INFO:              jinja2: 3.1.6
2025-06-02 17:42:32,941:INFO:               scipy: 1.10.1
2025-06-02 17:42:32,941:INFO:              joblib: 1.3.2
2025-06-02 17:42:32,941:INFO:             sklearn: 1.4.2
2025-06-02 17:42:32,941:INFO:                pyod: 2.0.5
2025-06-02 17:42:32,941:INFO:            imblearn: 0.13.0
2025-06-02 17:42:32,941:INFO:   category_encoders: 2.7.0
2025-06-02 17:42:32,941:INFO:            lightgbm: 4.6.0
2025-06-02 17:42:32,941:INFO:               numba: 0.61.0
2025-06-02 17:42:32,941:INFO:            requests: 2.32.3
2025-06-02 17:42:32,941:INFO:          matplotlib: 3.7.1
2025-06-02 17:42:32,941:INFO:          scikitplot: 0.3.7
2025-06-02 17:42:32,942:INFO:         yellowbrick: 1.5
2025-06-02 17:42:32,942:INFO:              plotly: 6.1.2
2025-06-02 17:42:32,942:INFO:    plotly-resampler: Not installed
2025-06-02 17:42:32,942:INFO:             kaleido: 0.2.1
2025-06-02 17:42:32,942:INFO:           schemdraw: 0.15
2025-06-02 17:42:32,942:INFO:         statsmodels: 0.14.4
2025-06-02 17:42:32,942:INFO:              sktime: 0.26.0
2025-06-02 17:42:32,942:INFO:               tbats: 1.1.3
2025-06-02 17:42:32,942:INFO:            pmdarima: 2.0.4
2025-06-02 17:42:32,942:INFO:              psutil: 7.0.0
2025-06-02 17:42:32,942:INFO:          markupsafe: 2.1.2
2025-06-02 17:42:32,942:INFO:             pickle5: Not installed
2025-06-02 17:42:32,942:INFO:         cloudpickle: 3.1.1
2025-06-02 17:42:32,942:INFO:         deprecation: 2.1.0
2025-06-02 17:42:32,942:INFO:              xxhash: 3.5.0
2025-06-02 17:42:32,943:INFO:           wurlitzer: Not installed
2025-06-02 17:42:32,943:INFO:PyCaret optional dependencies:
2025-06-02 17:42:32,943:INFO:                shap: 0.44.1
2025-06-02 17:42:32,943:INFO:           interpret: 0.6.9
2025-06-02 17:42:32,943:INFO:                umap: 0.5.7
2025-06-02 17:42:32,943:INFO:     ydata_profiling: 4.16.1
2025-06-02 17:42:32,943:INFO:  explainerdashboard: 0.4.8
2025-06-02 17:42:32,943:INFO:             autoviz: Not installed
2025-06-02 17:42:32,943:INFO:           fairlearn: 0.7.0
2025-06-02 17:42:32,943:INFO:          deepchecks: Not installed
2025-06-02 17:42:32,943:INFO:             xgboost: 3.0.2
2025-06-02 17:42:32,943:INFO:            catboost: 1.2.8
2025-06-02 17:42:32,943:INFO:              kmodes: 0.12.2
2025-06-02 17:42:32,944:INFO:             mlxtend: 0.23.4
2025-06-02 17:42:32,944:INFO:       statsforecast: 1.5.0
2025-06-02 17:42:32,944:INFO:        tune_sklearn: Not installed
2025-06-02 17:42:32,944:INFO:                 ray: Not installed
2025-06-02 17:42:32,944:INFO:            hyperopt: 0.2.7
2025-06-02 17:42:32,944:INFO:              optuna: 4.3.0
2025-06-02 17:42:32,944:INFO:               skopt: 0.10.2
2025-06-02 17:42:32,944:INFO:              mlflow: 2.22.0
2025-06-02 17:42:32,944:INFO:              gradio: 5.32.0
2025-06-02 17:42:32,944:INFO:             fastapi: 0.115.12
2025-06-02 17:42:32,944:INFO:             uvicorn: 0.34.3
2025-06-02 17:42:32,944:INFO:              m2cgen: 0.10.0
2025-06-02 17:42:32,944:INFO:           evidently: 0.4.40
2025-06-02 17:42:32,944:INFO:               fugue: 0.8.5
2025-06-02 17:42:32,944:INFO:           streamlit: Not installed
2025-06-02 17:42:32,945:INFO:             prophet: Not installed
2025-06-02 17:42:32,945:INFO:None
2025-06-02 17:42:32,945:INFO:Set up data.
2025-06-02 17:42:33,050:INFO:Set up folding strategy.
2025-06-02 17:42:33,051:INFO:Set up train/test split.
2025-06-02 17:42:33,228:INFO:Set up index.
2025-06-02 17:42:33,233:INFO:Assigning column types.
2025-06-02 17:42:33,422:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 17:42:33,425:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 17:42:33,444:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:42:33,454:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:42:33,671:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:42:33,754:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:42:33,756:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:42:33,762:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:42:33,764:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 17:42:33,772:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:42:33,780:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:42:33,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:42:34,008:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:42:34,010:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:42:34,014:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:42:34,015:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 17:42:34,023:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:42:34,033:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:42:34,186:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:42:34,266:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:42:34,267:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:42:34,271:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:42:34,280:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:42:34,288:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:42:34,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:42:34,511:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:42:34,512:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:42:34,516:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:42:34,517:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 17:42:34,537:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:42:34,682:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:42:34,759:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:42:34,760:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:42:34,766:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:42:34,782:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:42:34,919:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:42:35,002:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:42:35,003:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:42:35,008:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:42:35,009:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 17:42:35,157:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:42:35,235:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:42:35,236:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:42:35,240:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:42:35,398:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:42:35,471:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:42:35,471:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:42:35,475:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:42:35,477:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 17:42:35,622:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:42:35,694:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:42:35,699:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:42:35,866:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:42:35,948:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:42:35,953:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:42:35,954:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 17:42:36,172:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:42:36,177:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:42:36,414:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:42:36,419:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:42:36,423:INFO:Preparing preprocessing pipeline...
2025-06-02 17:42:36,423:INFO:Set up simple imputation.
2025-06-02 17:42:36,423:INFO:Set up removing multicollinearity.
2025-06-02 17:42:36,432:INFO:Set up column name cleaning.
2025-06-02 17:42:36,747:INFO:Finished creating preprocessing pipeline.
2025-06-02 17:42:36,761:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 17:42:36,761:INFO:Creating final display dataframe.
2025-06-02 17:42:37,175:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 97)
5   Transformed train set shape        (3582, 97)
6    Transformed test set shape         (896, 97)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              f3ad
2025-06-02 17:42:37,438:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:42:37,443:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:42:37,674:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:42:37,678:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:42:37,679:INFO:setup() successfully completed in 4.77s...............
2025-06-02 17:42:37,730:INFO:Initializing compare_models()
2025-06-02 17:42:37,730:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 17:42:37,730:INFO:Checking exceptions
2025-06-02 17:42:37,753:INFO:Preparing display monitor
2025-06-02 17:42:37,821:INFO:Initializing Linear Regression
2025-06-02 17:42:37,821:INFO:Total runtime is 0.0 minutes
2025-06-02 17:42:37,833:INFO:SubProcess create_model() called ==================================
2025-06-02 17:42:37,835:INFO:Initializing create_model()
2025-06-02 17:42:37,835:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:42:37,835:INFO:Checking exceptions
2025-06-02 17:42:37,836:INFO:Importing libraries
2025-06-02 17:42:37,836:INFO:Copying training dataset
2025-06-02 17:42:37,934:INFO:Defining folds
2025-06-02 17:42:37,934:INFO:Declaring metric variables
2025-06-02 17:42:37,949:INFO:Importing untrained model
2025-06-02 17:42:37,965:INFO:Linear Regression Imported successfully
2025-06-02 17:42:37,996:INFO:Starting cross validation
2025-06-02 17:42:38,002:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:42:53,275:INFO:Calculating mean and std
2025-06-02 17:42:53,281:INFO:Creating metrics dataframe
2025-06-02 17:42:53,318:INFO:Uploading results into container
2025-06-02 17:42:53,329:INFO:Uploading model into container now
2025-06-02 17:42:53,335:INFO:_master_model_container: 1
2025-06-02 17:42:53,335:INFO:_display_container: 2
2025-06-02 17:42:53,337:INFO:LinearRegression(n_jobs=-1)
2025-06-02 17:42:53,337:INFO:create_model() successfully completed......................................
2025-06-02 17:43:02,475:INFO:SubProcess create_model() end ==================================
2025-06-02 17:43:02,476:INFO:Creating metrics dataframe
2025-06-02 17:43:02,521:INFO:Initializing Lasso Regression
2025-06-02 17:43:02,521:INFO:Total runtime is 0.4116587320963542 minutes
2025-06-02 17:43:02,536:INFO:SubProcess create_model() called ==================================
2025-06-02 17:43:02,538:INFO:Initializing create_model()
2025-06-02 17:43:02,538:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:43:02,539:INFO:Checking exceptions
2025-06-02 17:43:02,539:INFO:Importing libraries
2025-06-02 17:43:02,541:INFO:Copying training dataset
2025-06-02 17:43:02,775:INFO:Defining folds
2025-06-02 17:43:02,776:INFO:Declaring metric variables
2025-06-02 17:43:02,790:INFO:Importing untrained model
2025-06-02 17:43:02,804:INFO:Lasso Regression Imported successfully
2025-06-02 17:43:02,831:INFO:Starting cross validation
2025-06-02 17:43:02,836:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:43:14,013:INFO:Calculating mean and std
2025-06-02 17:43:14,019:INFO:Creating metrics dataframe
2025-06-02 17:43:14,030:INFO:Uploading results into container
2025-06-02 17:43:14,031:INFO:Uploading model into container now
2025-06-02 17:43:14,033:INFO:_master_model_container: 2
2025-06-02 17:43:14,033:INFO:_display_container: 2
2025-06-02 17:43:14,036:INFO:Lasso(random_state=123)
2025-06-02 17:43:14,036:INFO:create_model() successfully completed......................................
2025-06-02 17:43:16,109:INFO:SubProcess create_model() end ==================================
2025-06-02 17:43:16,110:INFO:Creating metrics dataframe
2025-06-02 17:43:16,137:INFO:Initializing Ridge Regression
2025-06-02 17:43:16,137:INFO:Total runtime is 0.6385963241259257 minutes
2025-06-02 17:43:16,152:INFO:SubProcess create_model() called ==================================
2025-06-02 17:43:16,153:INFO:Initializing create_model()
2025-06-02 17:43:16,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:43:16,154:INFO:Checking exceptions
2025-06-02 17:43:16,154:INFO:Importing libraries
2025-06-02 17:43:16,155:INFO:Copying training dataset
2025-06-02 17:43:16,223:INFO:Defining folds
2025-06-02 17:43:16,224:INFO:Declaring metric variables
2025-06-02 17:43:16,236:INFO:Importing untrained model
2025-06-02 17:43:16,248:INFO:Ridge Regression Imported successfully
2025-06-02 17:43:16,272:INFO:Starting cross validation
2025-06-02 17:43:16,279:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:43:17,259:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.46278e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 17:43:17,344:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.7164e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 17:43:17,431:INFO:Calculating mean and std
2025-06-02 17:43:17,433:INFO:Creating metrics dataframe
2025-06-02 17:43:17,437:INFO:Uploading results into container
2025-06-02 17:43:17,438:INFO:Uploading model into container now
2025-06-02 17:43:17,439:INFO:_master_model_container: 3
2025-06-02 17:43:17,439:INFO:_display_container: 2
2025-06-02 17:43:17,440:INFO:Ridge(random_state=123)
2025-06-02 17:43:17,440:INFO:create_model() successfully completed......................................
2025-06-02 17:43:18,932:INFO:SubProcess create_model() end ==================================
2025-06-02 17:43:18,932:INFO:Creating metrics dataframe
2025-06-02 17:43:18,954:INFO:Initializing Elastic Net
2025-06-02 17:43:18,955:INFO:Total runtime is 0.6855636397997539 minutes
2025-06-02 17:43:18,969:INFO:SubProcess create_model() called ==================================
2025-06-02 17:43:18,969:INFO:Initializing create_model()
2025-06-02 17:43:18,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:43:18,970:INFO:Checking exceptions
2025-06-02 17:43:18,970:INFO:Importing libraries
2025-06-02 17:43:18,971:INFO:Copying training dataset
2025-06-02 17:43:19,036:INFO:Defining folds
2025-06-02 17:43:19,037:INFO:Declaring metric variables
2025-06-02 17:43:19,049:INFO:Importing untrained model
2025-06-02 17:43:19,062:INFO:Elastic Net Imported successfully
2025-06-02 17:43:19,086:INFO:Starting cross validation
2025-06-02 17:43:19,091:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:43:19,991:INFO:Calculating mean and std
2025-06-02 17:43:19,994:INFO:Creating metrics dataframe
2025-06-02 17:43:19,998:INFO:Uploading results into container
2025-06-02 17:43:19,998:INFO:Uploading model into container now
2025-06-02 17:43:19,999:INFO:_master_model_container: 4
2025-06-02 17:43:19,999:INFO:_display_container: 2
2025-06-02 17:43:20,000:INFO:ElasticNet(random_state=123)
2025-06-02 17:43:20,000:INFO:create_model() successfully completed......................................
2025-06-02 17:43:21,472:INFO:SubProcess create_model() end ==================================
2025-06-02 17:43:21,472:INFO:Creating metrics dataframe
2025-06-02 17:43:21,488:INFO:Initializing Least Angle Regression
2025-06-02 17:43:21,488:INFO:Total runtime is 0.7277753353118896 minutes
2025-06-02 17:43:21,498:INFO:SubProcess create_model() called ==================================
2025-06-02 17:43:21,499:INFO:Initializing create_model()
2025-06-02 17:43:21,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:43:21,500:INFO:Checking exceptions
2025-06-02 17:43:21,500:INFO:Importing libraries
2025-06-02 17:43:21,500:INFO:Copying training dataset
2025-06-02 17:43:21,560:INFO:Defining folds
2025-06-02 17:43:21,561:INFO:Declaring metric variables
2025-06-02 17:43:21,570:INFO:Importing untrained model
2025-06-02 17:43:21,585:INFO:Least Angle Regression Imported successfully
2025-06-02 17:43:21,606:INFO:Starting cross validation
2025-06-02 17:43:21,610:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:43:22,276:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.173e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 17:43:22,277:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.339e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 17:43:22,278:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.722e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 17:43:22,279:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.721e-01, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 17:43:22,280:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.411e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 17:43:22,282:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.434e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 17:43:22,287:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=4.180e-01, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 17:43:22,410:INFO:Calculating mean and std
2025-06-02 17:43:22,412:INFO:Creating metrics dataframe
2025-06-02 17:43:22,416:INFO:Uploading results into container
2025-06-02 17:43:22,417:INFO:Uploading model into container now
2025-06-02 17:43:22,419:INFO:_master_model_container: 5
2025-06-02 17:43:22,419:INFO:_display_container: 2
2025-06-02 17:43:22,421:INFO:Lars(random_state=123)
2025-06-02 17:43:22,421:INFO:create_model() successfully completed......................................
2025-06-02 17:43:23,930:INFO:SubProcess create_model() end ==================================
2025-06-02 17:43:23,930:INFO:Creating metrics dataframe
2025-06-02 17:43:23,952:INFO:Initializing Lasso Least Angle Regression
2025-06-02 17:43:23,953:INFO:Total runtime is 0.768868621190389 minutes
2025-06-02 17:43:23,967:INFO:SubProcess create_model() called ==================================
2025-06-02 17:43:23,969:INFO:Initializing create_model()
2025-06-02 17:43:23,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:43:23,970:INFO:Checking exceptions
2025-06-02 17:43:23,971:INFO:Importing libraries
2025-06-02 17:43:23,971:INFO:Copying training dataset
2025-06-02 17:43:24,048:INFO:Defining folds
2025-06-02 17:43:24,048:INFO:Declaring metric variables
2025-06-02 17:43:24,061:INFO:Importing untrained model
2025-06-02 17:43:24,074:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 17:43:24,098:INFO:Starting cross validation
2025-06-02 17:43:24,103:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:43:24,910:INFO:Calculating mean and std
2025-06-02 17:43:24,913:INFO:Creating metrics dataframe
2025-06-02 17:43:24,917:INFO:Uploading results into container
2025-06-02 17:43:24,918:INFO:Uploading model into container now
2025-06-02 17:43:24,919:INFO:_master_model_container: 6
2025-06-02 17:43:24,919:INFO:_display_container: 2
2025-06-02 17:43:24,920:INFO:LassoLars(random_state=123)
2025-06-02 17:43:24,921:INFO:create_model() successfully completed......................................
2025-06-02 17:43:26,614:INFO:SubProcess create_model() end ==================================
2025-06-02 17:43:26,614:INFO:Creating metrics dataframe
2025-06-02 17:43:26,636:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 17:43:26,637:INFO:Total runtime is 0.8136017441749573 minutes
2025-06-02 17:43:26,654:INFO:SubProcess create_model() called ==================================
2025-06-02 17:43:26,655:INFO:Initializing create_model()
2025-06-02 17:43:26,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:43:26,656:INFO:Checking exceptions
2025-06-02 17:43:26,656:INFO:Importing libraries
2025-06-02 17:43:26,658:INFO:Copying training dataset
2025-06-02 17:43:26,731:INFO:Defining folds
2025-06-02 17:43:26,731:INFO:Declaring metric variables
2025-06-02 17:43:26,749:INFO:Importing untrained model
2025-06-02 17:43:26,764:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 17:43:26,792:INFO:Starting cross validation
2025-06-02 17:43:26,797:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:43:27,638:INFO:Calculating mean and std
2025-06-02 17:43:27,642:INFO:Creating metrics dataframe
2025-06-02 17:43:27,646:INFO:Uploading results into container
2025-06-02 17:43:27,647:INFO:Uploading model into container now
2025-06-02 17:43:27,648:INFO:_master_model_container: 7
2025-06-02 17:43:27,648:INFO:_display_container: 2
2025-06-02 17:43:27,649:INFO:OrthogonalMatchingPursuit()
2025-06-02 17:43:27,650:INFO:create_model() successfully completed......................................
2025-06-02 17:43:29,002:INFO:SubProcess create_model() end ==================================
2025-06-02 17:43:29,002:INFO:Creating metrics dataframe
2025-06-02 17:43:29,017:INFO:Initializing Bayesian Ridge
2025-06-02 17:43:29,017:INFO:Total runtime is 0.8532722353935243 minutes
2025-06-02 17:43:29,029:INFO:SubProcess create_model() called ==================================
2025-06-02 17:43:29,029:INFO:Initializing create_model()
2025-06-02 17:43:29,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:43:29,030:INFO:Checking exceptions
2025-06-02 17:43:29,031:INFO:Importing libraries
2025-06-02 17:43:29,031:INFO:Copying training dataset
2025-06-02 17:43:29,090:INFO:Defining folds
2025-06-02 17:43:29,091:INFO:Declaring metric variables
2025-06-02 17:43:29,103:INFO:Importing untrained model
2025-06-02 17:43:29,119:INFO:Bayesian Ridge Imported successfully
2025-06-02 17:43:29,143:INFO:Starting cross validation
2025-06-02 17:43:29,147:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:43:30,032:INFO:Calculating mean and std
2025-06-02 17:43:30,034:INFO:Creating metrics dataframe
2025-06-02 17:43:30,038:INFO:Uploading results into container
2025-06-02 17:43:30,039:INFO:Uploading model into container now
2025-06-02 17:43:30,039:INFO:_master_model_container: 8
2025-06-02 17:43:30,040:INFO:_display_container: 2
2025-06-02 17:43:30,043:INFO:BayesianRidge()
2025-06-02 17:43:30,043:INFO:create_model() successfully completed......................................
2025-06-02 17:43:31,377:INFO:SubProcess create_model() end ==================================
2025-06-02 17:43:31,378:INFO:Creating metrics dataframe
2025-06-02 17:43:31,395:INFO:Initializing Passive Aggressive Regressor
2025-06-02 17:43:31,396:INFO:Total runtime is 0.8929121573766073 minutes
2025-06-02 17:43:31,405:INFO:SubProcess create_model() called ==================================
2025-06-02 17:43:31,405:INFO:Initializing create_model()
2025-06-02 17:43:31,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:43:31,406:INFO:Checking exceptions
2025-06-02 17:43:31,408:INFO:Importing libraries
2025-06-02 17:43:31,409:INFO:Copying training dataset
2025-06-02 17:43:31,469:INFO:Defining folds
2025-06-02 17:43:31,470:INFO:Declaring metric variables
2025-06-02 17:43:31,484:INFO:Importing untrained model
2025-06-02 17:43:31,497:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 17:43:31,519:INFO:Starting cross validation
2025-06-02 17:43:31,524:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:43:32,346:INFO:Calculating mean and std
2025-06-02 17:43:32,348:INFO:Creating metrics dataframe
2025-06-02 17:43:32,353:INFO:Uploading results into container
2025-06-02 17:43:32,354:INFO:Uploading model into container now
2025-06-02 17:43:32,355:INFO:_master_model_container: 9
2025-06-02 17:43:32,355:INFO:_display_container: 2
2025-06-02 17:43:32,357:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 17:43:32,358:INFO:create_model() successfully completed......................................
2025-06-02 17:43:33,725:INFO:SubProcess create_model() end ==================================
2025-06-02 17:43:33,726:INFO:Creating metrics dataframe
2025-06-02 17:43:33,745:INFO:Initializing Huber Regressor
2025-06-02 17:43:33,746:INFO:Total runtime is 0.9320897897084555 minutes
2025-06-02 17:43:33,760:INFO:SubProcess create_model() called ==================================
2025-06-02 17:43:33,761:INFO:Initializing create_model()
2025-06-02 17:43:33,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:43:33,762:INFO:Checking exceptions
2025-06-02 17:43:33,762:INFO:Importing libraries
2025-06-02 17:43:33,762:INFO:Copying training dataset
2025-06-02 17:43:33,834:INFO:Defining folds
2025-06-02 17:43:33,835:INFO:Declaring metric variables
2025-06-02 17:43:33,851:INFO:Importing untrained model
2025-06-02 17:43:33,864:INFO:Huber Regressor Imported successfully
2025-06-02 17:43:33,891:INFO:Starting cross validation
2025-06-02 17:43:33,898:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:43:35,950:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:43:35,956:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:43:35,982:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:43:36,021:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:43:36,239:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:43:36,319:INFO:Calculating mean and std
2025-06-02 17:43:36,321:INFO:Creating metrics dataframe
2025-06-02 17:43:36,325:INFO:Uploading results into container
2025-06-02 17:43:36,326:INFO:Uploading model into container now
2025-06-02 17:43:36,327:INFO:_master_model_container: 10
2025-06-02 17:43:36,328:INFO:_display_container: 2
2025-06-02 17:43:36,328:INFO:HuberRegressor()
2025-06-02 17:43:36,329:INFO:create_model() successfully completed......................................
2025-06-02 17:43:37,784:INFO:SubProcess create_model() end ==================================
2025-06-02 17:43:37,784:INFO:Creating metrics dataframe
2025-06-02 17:43:37,809:INFO:Initializing K Neighbors Regressor
2025-06-02 17:43:37,809:INFO:Total runtime is 0.9997927943865459 minutes
2025-06-02 17:43:37,821:INFO:SubProcess create_model() called ==================================
2025-06-02 17:43:37,822:INFO:Initializing create_model()
2025-06-02 17:43:37,822:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:43:37,823:INFO:Checking exceptions
2025-06-02 17:43:37,824:INFO:Importing libraries
2025-06-02 17:43:37,825:INFO:Copying training dataset
2025-06-02 17:43:37,897:INFO:Defining folds
2025-06-02 17:43:37,897:INFO:Declaring metric variables
2025-06-02 17:43:37,913:INFO:Importing untrained model
2025-06-02 17:43:37,927:INFO:K Neighbors Regressor Imported successfully
2025-06-02 17:43:37,954:INFO:Starting cross validation
2025-06-02 17:43:37,958:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:43:38,842:INFO:Calculating mean and std
2025-06-02 17:43:38,844:INFO:Creating metrics dataframe
2025-06-02 17:43:38,848:INFO:Uploading results into container
2025-06-02 17:43:38,849:INFO:Uploading model into container now
2025-06-02 17:43:38,851:INFO:_master_model_container: 11
2025-06-02 17:43:38,851:INFO:_display_container: 2
2025-06-02 17:43:38,852:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 17:43:38,853:INFO:create_model() successfully completed......................................
2025-06-02 17:43:40,272:INFO:SubProcess create_model() end ==================================
2025-06-02 17:43:40,272:INFO:Creating metrics dataframe
2025-06-02 17:43:40,297:INFO:Initializing Decision Tree Regressor
2025-06-02 17:43:40,297:INFO:Total runtime is 1.0412737886110943 minutes
2025-06-02 17:43:40,311:INFO:SubProcess create_model() called ==================================
2025-06-02 17:43:40,312:INFO:Initializing create_model()
2025-06-02 17:43:40,312:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:43:40,312:INFO:Checking exceptions
2025-06-02 17:43:40,314:INFO:Importing libraries
2025-06-02 17:43:40,314:INFO:Copying training dataset
2025-06-02 17:43:40,386:INFO:Defining folds
2025-06-02 17:43:40,386:INFO:Declaring metric variables
2025-06-02 17:43:40,403:INFO:Importing untrained model
2025-06-02 17:43:40,418:INFO:Decision Tree Regressor Imported successfully
2025-06-02 17:43:40,445:INFO:Starting cross validation
2025-06-02 17:43:40,450:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:43:41,470:INFO:Calculating mean and std
2025-06-02 17:43:41,475:INFO:Creating metrics dataframe
2025-06-02 17:43:41,480:INFO:Uploading results into container
2025-06-02 17:43:41,482:INFO:Uploading model into container now
2025-06-02 17:43:41,483:INFO:_master_model_container: 12
2025-06-02 17:43:41,483:INFO:_display_container: 2
2025-06-02 17:43:41,484:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 17:43:41,484:INFO:create_model() successfully completed......................................
2025-06-02 17:43:43,105:INFO:SubProcess create_model() end ==================================
2025-06-02 17:43:43,105:INFO:Creating metrics dataframe
2025-06-02 17:43:43,132:INFO:Initializing Random Forest Regressor
2025-06-02 17:43:43,133:INFO:Total runtime is 1.088536051909129 minutes
2025-06-02 17:43:43,161:INFO:SubProcess create_model() called ==================================
2025-06-02 17:43:43,163:INFO:Initializing create_model()
2025-06-02 17:43:43,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:43:43,163:INFO:Checking exceptions
2025-06-02 17:43:43,164:INFO:Importing libraries
2025-06-02 17:43:43,164:INFO:Copying training dataset
2025-06-02 17:43:43,348:INFO:Defining folds
2025-06-02 17:43:43,355:INFO:Declaring metric variables
2025-06-02 17:43:43,397:INFO:Importing untrained model
2025-06-02 17:43:43,427:INFO:Random Forest Regressor Imported successfully
2025-06-02 17:43:43,464:INFO:Starting cross validation
2025-06-02 17:43:43,490:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:43:54,357:INFO:Calculating mean and std
2025-06-02 17:43:54,360:INFO:Creating metrics dataframe
2025-06-02 17:43:54,367:INFO:Uploading results into container
2025-06-02 17:43:54,369:INFO:Uploading model into container now
2025-06-02 17:43:54,370:INFO:_master_model_container: 13
2025-06-02 17:43:54,371:INFO:_display_container: 2
2025-06-02 17:43:54,375:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:43:54,376:INFO:create_model() successfully completed......................................
2025-06-02 17:43:55,985:INFO:SubProcess create_model() end ==================================
2025-06-02 17:43:55,985:INFO:Creating metrics dataframe
2025-06-02 17:43:56,011:INFO:Initializing Extra Trees Regressor
2025-06-02 17:43:56,012:INFO:Total runtime is 1.3031844933827719 minutes
2025-06-02 17:43:56,027:INFO:SubProcess create_model() called ==================================
2025-06-02 17:43:56,027:INFO:Initializing create_model()
2025-06-02 17:43:56,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:43:56,028:INFO:Checking exceptions
2025-06-02 17:43:56,029:INFO:Importing libraries
2025-06-02 17:43:56,029:INFO:Copying training dataset
2025-06-02 17:43:56,089:INFO:Defining folds
2025-06-02 17:43:56,089:INFO:Declaring metric variables
2025-06-02 17:43:56,101:INFO:Importing untrained model
2025-06-02 17:43:56,114:INFO:Extra Trees Regressor Imported successfully
2025-06-02 17:43:56,138:INFO:Starting cross validation
2025-06-02 17:43:56,143:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:44:04,384:INFO:Calculating mean and std
2025-06-02 17:44:04,388:INFO:Creating metrics dataframe
2025-06-02 17:44:04,394:INFO:Uploading results into container
2025-06-02 17:44:04,395:INFO:Uploading model into container now
2025-06-02 17:44:04,397:INFO:_master_model_container: 14
2025-06-02 17:44:04,397:INFO:_display_container: 2
2025-06-02 17:44:04,398:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:44:04,398:INFO:create_model() successfully completed......................................
2025-06-02 17:44:06,059:INFO:SubProcess create_model() end ==================================
2025-06-02 17:44:06,059:INFO:Creating metrics dataframe
2025-06-02 17:44:06,089:INFO:Initializing AdaBoost Regressor
2025-06-02 17:44:06,090:INFO:Total runtime is 1.4711459596951804 minutes
2025-06-02 17:44:06,102:INFO:SubProcess create_model() called ==================================
2025-06-02 17:44:06,102:INFO:Initializing create_model()
2025-06-02 17:44:06,103:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:44:06,103:INFO:Checking exceptions
2025-06-02 17:44:06,104:INFO:Importing libraries
2025-06-02 17:44:06,104:INFO:Copying training dataset
2025-06-02 17:44:06,192:INFO:Defining folds
2025-06-02 17:44:06,192:INFO:Declaring metric variables
2025-06-02 17:44:06,212:INFO:Importing untrained model
2025-06-02 17:44:06,223:INFO:AdaBoost Regressor Imported successfully
2025-06-02 17:44:06,247:INFO:Starting cross validation
2025-06-02 17:44:06,252:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:44:08,704:INFO:Calculating mean and std
2025-06-02 17:44:08,707:INFO:Creating metrics dataframe
2025-06-02 17:44:08,711:INFO:Uploading results into container
2025-06-02 17:44:08,712:INFO:Uploading model into container now
2025-06-02 17:44:08,712:INFO:_master_model_container: 15
2025-06-02 17:44:08,713:INFO:_display_container: 2
2025-06-02 17:44:08,713:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 17:44:08,714:INFO:create_model() successfully completed......................................
2025-06-02 17:44:10,130:INFO:SubProcess create_model() end ==================================
2025-06-02 17:44:10,131:INFO:Creating metrics dataframe
2025-06-02 17:44:10,157:INFO:Initializing Gradient Boosting Regressor
2025-06-02 17:44:10,157:INFO:Total runtime is 1.538940425713857 minutes
2025-06-02 17:44:10,167:INFO:SubProcess create_model() called ==================================
2025-06-02 17:44:10,168:INFO:Initializing create_model()
2025-06-02 17:44:10,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:44:10,168:INFO:Checking exceptions
2025-06-02 17:44:10,169:INFO:Importing libraries
2025-06-02 17:44:10,169:INFO:Copying training dataset
2025-06-02 17:44:10,246:INFO:Defining folds
2025-06-02 17:44:10,246:INFO:Declaring metric variables
2025-06-02 17:44:10,261:INFO:Importing untrained model
2025-06-02 17:44:10,276:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 17:44:10,364:INFO:Starting cross validation
2025-06-02 17:44:10,369:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:44:14,728:INFO:Calculating mean and std
2025-06-02 17:44:14,730:INFO:Creating metrics dataframe
2025-06-02 17:44:14,733:INFO:Uploading results into container
2025-06-02 17:44:14,734:INFO:Uploading model into container now
2025-06-02 17:44:14,735:INFO:_master_model_container: 16
2025-06-02 17:44:14,735:INFO:_display_container: 2
2025-06-02 17:44:14,737:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 17:44:14,737:INFO:create_model() successfully completed......................................
2025-06-02 17:44:16,101:INFO:SubProcess create_model() end ==================================
2025-06-02 17:44:16,101:INFO:Creating metrics dataframe
2025-06-02 17:44:16,133:INFO:Initializing Extreme Gradient Boosting
2025-06-02 17:44:16,134:INFO:Total runtime is 1.6385549863179525 minutes
2025-06-02 17:44:16,146:INFO:SubProcess create_model() called ==================================
2025-06-02 17:44:16,146:INFO:Initializing create_model()
2025-06-02 17:44:16,147:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:44:16,147:INFO:Checking exceptions
2025-06-02 17:44:16,148:INFO:Importing libraries
2025-06-02 17:44:16,148:INFO:Copying training dataset
2025-06-02 17:44:16,233:INFO:Defining folds
2025-06-02 17:44:16,233:INFO:Declaring metric variables
2025-06-02 17:44:16,246:INFO:Importing untrained model
2025-06-02 17:44:16,258:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 17:44:16,276:INFO:Starting cross validation
2025-06-02 17:44:16,281:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:44:19,002:INFO:Calculating mean and std
2025-06-02 17:44:19,004:INFO:Creating metrics dataframe
2025-06-02 17:44:19,009:INFO:Uploading results into container
2025-06-02 17:44:19,010:INFO:Uploading model into container now
2025-06-02 17:44:19,011:INFO:_master_model_container: 17
2025-06-02 17:44:19,011:INFO:_display_container: 2
2025-06-02 17:44:19,015:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 17:44:19,016:INFO:create_model() successfully completed......................................
2025-06-02 17:44:20,384:INFO:SubProcess create_model() end ==================================
2025-06-02 17:44:20,384:INFO:Creating metrics dataframe
2025-06-02 17:44:20,413:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 17:44:20,413:INFO:Total runtime is 1.7098736087481181 minutes
2025-06-02 17:44:20,422:INFO:SubProcess create_model() called ==================================
2025-06-02 17:44:20,423:INFO:Initializing create_model()
2025-06-02 17:44:20,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:44:20,424:INFO:Checking exceptions
2025-06-02 17:44:20,424:INFO:Importing libraries
2025-06-02 17:44:20,425:INFO:Copying training dataset
2025-06-02 17:44:20,508:INFO:Defining folds
2025-06-02 17:44:20,509:INFO:Declaring metric variables
2025-06-02 17:44:20,533:INFO:Importing untrained model
2025-06-02 17:44:20,563:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 17:44:20,599:INFO:Starting cross validation
2025-06-02 17:44:20,606:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:44:22,900:INFO:Calculating mean and std
2025-06-02 17:44:22,902:INFO:Creating metrics dataframe
2025-06-02 17:44:22,906:INFO:Uploading results into container
2025-06-02 17:44:22,908:INFO:Uploading model into container now
2025-06-02 17:44:22,909:INFO:_master_model_container: 18
2025-06-02 17:44:22,909:INFO:_display_container: 2
2025-06-02 17:44:22,910:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:44:22,910:INFO:create_model() successfully completed......................................
2025-06-02 17:44:24,351:INFO:SubProcess create_model() end ==================================
2025-06-02 17:44:24,351:INFO:Creating metrics dataframe
2025-06-02 17:44:24,379:INFO:Initializing CatBoost Regressor
2025-06-02 17:44:24,380:INFO:Total runtime is 1.7759806950887045 minutes
2025-06-02 17:44:24,392:INFO:SubProcess create_model() called ==================================
2025-06-02 17:44:24,393:INFO:Initializing create_model()
2025-06-02 17:44:24,393:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:44:24,394:INFO:Checking exceptions
2025-06-02 17:44:24,394:INFO:Importing libraries
2025-06-02 17:44:24,394:INFO:Copying training dataset
2025-06-02 17:44:24,488:INFO:Defining folds
2025-06-02 17:44:24,495:INFO:Declaring metric variables
2025-06-02 17:44:24,515:INFO:Importing untrained model
2025-06-02 17:44:24,561:INFO:CatBoost Regressor Imported successfully
2025-06-02 17:44:24,592:INFO:Starting cross validation
2025-06-02 17:44:24,595:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:44:54,311:INFO:Calculating mean and std
2025-06-02 17:44:54,318:INFO:Creating metrics dataframe
2025-06-02 17:44:54,332:INFO:Uploading results into container
2025-06-02 17:44:54,335:INFO:Uploading model into container now
2025-06-02 17:44:54,337:INFO:_master_model_container: 19
2025-06-02 17:44:54,337:INFO:_display_container: 2
2025-06-02 17:44:54,337:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6E4FD1D50>
2025-06-02 17:44:54,337:INFO:create_model() successfully completed......................................
2025-06-02 17:44:56,373:INFO:SubProcess create_model() end ==================================
2025-06-02 17:44:56,373:INFO:Creating metrics dataframe
2025-06-02 17:44:56,399:INFO:Initializing Dummy Regressor
2025-06-02 17:44:56,400:INFO:Total runtime is 2.3096434831619264 minutes
2025-06-02 17:44:56,411:INFO:SubProcess create_model() called ==================================
2025-06-02 17:44:56,412:INFO:Initializing create_model()
2025-06-02 17:44:56,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E4897C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:44:56,412:INFO:Checking exceptions
2025-06-02 17:44:56,413:INFO:Importing libraries
2025-06-02 17:44:56,413:INFO:Copying training dataset
2025-06-02 17:44:56,543:INFO:Defining folds
2025-06-02 17:44:56,544:INFO:Declaring metric variables
2025-06-02 17:44:56,562:INFO:Importing untrained model
2025-06-02 17:44:56,601:INFO:Dummy Regressor Imported successfully
2025-06-02 17:44:56,636:INFO:Starting cross validation
2025-06-02 17:44:56,645:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:44:58,126:INFO:Calculating mean and std
2025-06-02 17:44:58,131:INFO:Creating metrics dataframe
2025-06-02 17:44:58,137:INFO:Uploading results into container
2025-06-02 17:44:58,138:INFO:Uploading model into container now
2025-06-02 17:44:58,143:INFO:_master_model_container: 20
2025-06-02 17:44:58,143:INFO:_display_container: 2
2025-06-02 17:44:58,144:INFO:DummyRegressor()
2025-06-02 17:44:58,144:INFO:create_model() successfully completed......................................
2025-06-02 17:44:59,924:INFO:SubProcess create_model() end ==================================
2025-06-02 17:44:59,924:INFO:Creating metrics dataframe
2025-06-02 17:44:59,991:INFO:Initializing create_model()
2025-06-02 17:44:59,992:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:44:59,992:INFO:Checking exceptions
2025-06-02 17:45:00,005:INFO:Importing libraries
2025-06-02 17:45:00,005:INFO:Copying training dataset
2025-06-02 17:45:00,132:INFO:Defining folds
2025-06-02 17:45:00,132:INFO:Declaring metric variables
2025-06-02 17:45:00,133:INFO:Importing untrained model
2025-06-02 17:45:00,134:INFO:Declaring custom model
2025-06-02 17:45:00,136:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 17:45:00,142:INFO:Cross validation set to False
2025-06-02 17:45:00,142:INFO:Fitting Model
2025-06-02 17:45:01,297:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 17:45:01,332:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006158 seconds.
2025-06-02 17:45:01,333:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-06-02 17:45:01,333:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-06-02 17:45:01,334:INFO:[LightGBM] [Info] Total Bins 6332
2025-06-02 17:45:01,355:INFO:[LightGBM] [Info] Number of data points in the train set: 3582, number of used features: 96
2025-06-02 17:45:01,361:INFO:[LightGBM] [Info] Start training from score -0.480202
2025-06-02 17:45:02,009:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:45:02,009:INFO:create_model() successfully completed......................................
2025-06-02 17:45:03,348:INFO:Initializing create_model()
2025-06-02 17:45:03,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=<catboost.core.CatBoostRegressor object at 0x000001B6E4FD1D50>, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:45:03,349:INFO:Checking exceptions
2025-06-02 17:45:03,355:INFO:Importing libraries
2025-06-02 17:45:03,355:INFO:Copying training dataset
2025-06-02 17:45:03,436:INFO:Defining folds
2025-06-02 17:45:03,436:INFO:Declaring metric variables
2025-06-02 17:45:03,437:INFO:Importing untrained model
2025-06-02 17:45:03,437:INFO:Declaring custom model
2025-06-02 17:45:03,438:INFO:CatBoost Regressor Imported successfully
2025-06-02 17:45:03,442:INFO:Cross validation set to False
2025-06-02 17:45:03,443:INFO:Fitting Model
2025-06-02 17:45:10,558:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6ED6947F0>
2025-06-02 17:45:10,558:INFO:create_model() successfully completed......................................
2025-06-02 17:45:12,064:INFO:Initializing create_model()
2025-06-02 17:45:12,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:45:12,065:INFO:Checking exceptions
2025-06-02 17:45:12,070:INFO:Importing libraries
2025-06-02 17:45:12,070:INFO:Copying training dataset
2025-06-02 17:45:12,165:INFO:Defining folds
2025-06-02 17:45:12,166:INFO:Declaring metric variables
2025-06-02 17:45:12,166:INFO:Importing untrained model
2025-06-02 17:45:12,166:INFO:Declaring custom model
2025-06-02 17:45:12,170:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 17:45:12,174:INFO:Cross validation set to False
2025-06-02 17:45:12,174:INFO:Fitting Model
2025-06-02 17:45:13,346:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 17:45:13,346:INFO:create_model() successfully completed......................................
2025-06-02 17:45:14,769:INFO:_master_model_container: 20
2025-06-02 17:45:14,770:INFO:_display_container: 2
2025-06-02 17:45:14,774:INFO:[LGBMRegressor(n_jobs=-1, random_state=123), <catboost.core.CatBoostRegressor object at 0x000001B6ED6947F0>, XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)]
2025-06-02 17:45:14,775:INFO:compare_models() successfully completed......................................
2025-06-02 17:45:14,883:INFO:Initializing tune_model()
2025-06-02 17:45:14,883:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>)
2025-06-02 17:45:14,883:INFO:Checking exceptions
2025-06-02 17:45:14,884:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 17:45:15,021:INFO:Copying training dataset
2025-06-02 17:45:15,106:INFO:Checking base model
2025-06-02 17:45:15,106:INFO:Base model : Light Gradient Boosting Machine
2025-06-02 17:45:15,122:INFO:Declaring metric variables
2025-06-02 17:45:15,140:INFO:Defining Hyperparameters
2025-06-02 17:45:16,803:INFO:Tuning with n_jobs=-1
2025-06-02 17:45:16,825:INFO:Initializing skopt.BayesSearchCV
2025-06-02 17:45:38,319:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.8608120752388259), ('actual_estimator__bagging_freq', 1), ('actual_estimator__feature_fraction', 0.4284489606984907), ('actual_estimator__learning_rate', 0.016133245419918712), ('actual_estimator__min_child_samples', 95), ('actual_estimator__min_split_gain', 0.8209314243567916), ('actual_estimator__n_estimators', 239), ('actual_estimator__num_leaves', 183), ('actual_estimator__reg_alpha', 8.662569304197528e-07), ('actual_estimator__reg_lambda', 5.001062744294253e-06)])
2025-06-02 17:45:38,321:INFO:Hyperparameter search completed
2025-06-02 17:45:38,321:INFO:SubProcess create_model() called ==================================
2025-06-02 17:45:38,323:INFO:Initializing create_model()
2025-06-02 17:45:38,323:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFA0E080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.8608120752388259, 'bagging_freq': 1, 'feature_fraction': 0.4284489606984907, 'learning_rate': 0.016133245419918712, 'min_child_samples': 95, 'min_split_gain': 0.8209314243567916, 'n_estimators': 239, 'num_leaves': 183, 'reg_alpha': 8.662569304197528e-07, 'reg_lambda': 5.001062744294253e-06})
2025-06-02 17:45:38,323:INFO:Checking exceptions
2025-06-02 17:45:38,323:INFO:Importing libraries
2025-06-02 17:45:38,324:INFO:Copying training dataset
2025-06-02 17:45:38,415:INFO:Defining folds
2025-06-02 17:45:38,416:INFO:Declaring metric variables
2025-06-02 17:45:38,427:INFO:Importing untrained model
2025-06-02 17:45:38,427:INFO:Declaring custom model
2025-06-02 17:45:38,443:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 17:45:38,470:INFO:Starting cross validation
2025-06-02 17:45:38,476:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:45:40,876:INFO:Calculating mean and std
2025-06-02 17:45:40,877:INFO:Creating metrics dataframe
2025-06-02 17:45:40,894:INFO:Finalizing model
2025-06-02 17:45:41,581:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 17:45:41,581:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 17:45:41,581:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 17:45:41,610:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 17:45:41,612:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 17:45:41,612:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 17:45:41,612:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 17:45:41,619:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004330 seconds.
2025-06-02 17:45:41,619:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 17:45:41,620:INFO:[LightGBM] [Info] Total Bins 6321
2025-06-02 17:45:41,685:INFO:[LightGBM] [Info] Number of data points in the train set: 3582, number of used features: 94
2025-06-02 17:45:41,687:INFO:[LightGBM] [Info] Start training from score -0.480202
2025-06-02 17:45:41,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:41,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 17:45:42,004:INFO:Uploading results into container
2025-06-02 17:45:42,007:INFO:Uploading model into container now
2025-06-02 17:45:42,009:INFO:_master_model_container: 21
2025-06-02 17:45:42,009:INFO:_display_container: 3
2025-06-02 17:45:42,012:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06)
2025-06-02 17:45:42,013:INFO:create_model() successfully completed......................................
2025-06-02 17:45:43,521:INFO:SubProcess create_model() end ==================================
2025-06-02 17:45:43,523:INFO:choose_better activated
2025-06-02 17:45:43,532:INFO:SubProcess create_model() called ==================================
2025-06-02 17:45:43,534:INFO:Initializing create_model()
2025-06-02 17:45:43,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:45:43,535:INFO:Checking exceptions
2025-06-02 17:45:43,538:INFO:Importing libraries
2025-06-02 17:45:43,539:INFO:Copying training dataset
2025-06-02 17:45:43,609:INFO:Defining folds
2025-06-02 17:45:43,609:INFO:Declaring metric variables
2025-06-02 17:45:43,610:INFO:Importing untrained model
2025-06-02 17:45:43,610:INFO:Declaring custom model
2025-06-02 17:45:43,612:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 17:45:43,612:INFO:Starting cross validation
2025-06-02 17:45:43,615:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:45:45,570:INFO:Calculating mean and std
2025-06-02 17:45:45,571:INFO:Creating metrics dataframe
2025-06-02 17:45:45,575:INFO:Finalizing model
2025-06-02 17:45:46,043:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 17:45:46,049:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003334 seconds.
2025-06-02 17:45:46,049:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 17:45:46,050:INFO:[LightGBM] [Info] Total Bins 6332
2025-06-02 17:45:46,050:INFO:[LightGBM] [Info] Number of data points in the train set: 3582, number of used features: 96
2025-06-02 17:45:46,051:INFO:[LightGBM] [Info] Start training from score -0.480202
2025-06-02 17:45:46,268:INFO:Uploading results into container
2025-06-02 17:45:46,270:INFO:Uploading model into container now
2025-06-02 17:45:46,270:INFO:_master_model_container: 22
2025-06-02 17:45:46,271:INFO:_display_container: 4
2025-06-02 17:45:46,272:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:45:46,272:INFO:create_model() successfully completed......................................
2025-06-02 17:45:47,648:INFO:SubProcess create_model() end ==================================
2025-06-02 17:45:47,649:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8815
2025-06-02 17:45:47,650:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06) result for R2 is 0.8284
2025-06-02 17:45:47,651:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 17:45:47,651:INFO:choose_better completed
2025-06-02 17:45:47,651:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 17:45:47,671:INFO:_master_model_container: 22
2025-06-02 17:45:47,672:INFO:_display_container: 3
2025-06-02 17:45:47,674:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:45:47,674:INFO:tune_model() successfully completed......................................
2025-06-02 17:45:49,361:INFO:Initializing finalize_model()
2025-06-02 17:45:49,361:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 17:45:49,361:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:45:49,416:INFO:Initializing create_model()
2025-06-02 17:45:49,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:45:49,416:INFO:Checking exceptions
2025-06-02 17:45:49,419:INFO:Importing libraries
2025-06-02 17:45:49,419:INFO:Copying training dataset
2025-06-02 17:45:49,426:INFO:Defining folds
2025-06-02 17:45:49,427:INFO:Declaring metric variables
2025-06-02 17:45:49,427:INFO:Importing untrained model
2025-06-02 17:45:49,427:INFO:Declaring custom model
2025-06-02 17:45:49,430:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 17:45:49,432:INFO:Cross validation set to False
2025-06-02 17:45:49,432:INFO:Fitting Model
2025-06-02 17:45:49,860:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 17:45:49,864:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003089 seconds.
2025-06-02 17:45:49,865:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 17:45:49,865:INFO:[LightGBM] [Info] Total Bins 6237
2025-06-02 17:45:49,867:INFO:[LightGBM] [Info] Number of data points in the train set: 4478, number of used features: 95
2025-06-02 17:45:49,868:INFO:[LightGBM] [Info] Start training from score -0.483793
2025-06-02 17:45:50,080:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 17:45:50,080:INFO:create_model() successfully completed......................................
2025-06-02 17:45:51,417:INFO:_master_model_container: 22
2025-06-02 17:45:51,417:INFO:_display_container: 3
2025-06-02 17:45:51,435:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 17:45:51,435:INFO:finalize_model() successfully completed......................................
2025-06-02 17:45:52,823:INFO:Initializing save_model()
2025-06-02 17:45:52,823:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 17:45:52,823:INFO:Adding model into prep_pipe
2025-06-02 17:45:52,823:WARNING:Only Model saved as it was a pipeline.
2025-06-02 17:45:52,847:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 17:45:52,871:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 17:45:52,871:INFO:save_model() successfully completed......................................
2025-06-02 17:53:42,455:INFO:Initializing load_model()
2025-06-02 17:53:42,456:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 17:58:13,012:INFO:Initializing load_model()
2025-06-02 17:58:13,013:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 17:58:13,041:INFO:Initializing get_config()
2025-06-02 17:58:13,041:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, variable=X_test)
2025-06-02 17:58:13,044:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 17:58:13,047:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 17:58:13,223:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
2870                       12.0                       29.0   
3683                       12.0                       14.0   
1311                        7.0                       75.0   
2107                       83.0                       90.0   
3090                       16.0                       33.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
2870                     17.0               24.750000   
3683                      2.0               13.285714   
1311                     68.0               29.666666   
2107                      7.0               85.800003   
3090                     17.0               24.000000   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
2870                   6.375000                    29.0   
3683                   0.918367                    14.0   
1311                  30.222221                     7.0   
2107                   3.360000                    83.0   
3090                   8.470589                    16.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
2870                                64.0                                68.0   
3683                                68.0                                78.0   
1311                                54.0                                82.0   
2107                                16.0                                86.0   
3090                                84.0                                88.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
2870                               4.0                        65.000000  ...   
3683                              10.0                        74.428574  ...   
1311                              28.0                        72.666664  ...   
2107                              70.0                        58.000000  ...   
3090                               4.0                        86.117645  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
2870                 4.0                   1            32.0   
3683                 7.0                   0             2.0   
1311                 6.0                   1             8.0   
2107                 4.0                   1            16.0   
3090                 6.0                   1             8.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
2870                 False                     False   
3683                 False                     False   
1311                 False                     False   
2107                 False                     False   
3090                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
2870                      False                        False   
3683                      False                        False   
1311                       True                        False   
2107                      False                        False   
3090                       True                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
2870                       True                     False   
3683                      False                      True   
1311                      False                     False   
2107                       True                     False   
3090                      False                     False   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
2870                    False  
3683                    False  
1311                    False  
2107                    False  
3090                    False  

[896 rows x 146 columns]
2025-06-02 17:58:13,223:INFO:get_config() successfully completed......................................
2025-06-02 17:58:13,237:INFO:Initializing get_config()
2025-06-02 17:58:13,237:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, variable=y_test)
2025-06-02 17:58:13,237:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 17:58:13,237:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 17:58:13,256:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
2870   -0.023269
3683    0.188325
1311    0.073840
2107    2.768059
3090   -0.156522
Name: target, Length: 896, dtype: float32
2025-06-02 17:58:13,257:INFO:get_config() successfully completed......................................
2025-06-02 17:58:13,288:INFO:Initializing predict_model()
2025-06-02 17:58:13,289:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6FAE80DC0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B6EF9600D0>)
2025-06-02 17:58:13,289:INFO:Checking exceptions
2025-06-02 17:58:13,289:INFO:Preloading libraries
2025-06-02 17:58:13,316:INFO:Set up data.
2025-06-02 17:58:13,413:INFO:Set up index.
2025-06-02 17:58:38,731:INFO:PyCaret RegressionExperiment
2025-06-02 17:58:38,731:INFO:Logging name: reg-default-name
2025-06-02 17:58:38,731:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 17:58:38,732:INFO:version 3.3.2
2025-06-02 17:58:38,732:INFO:Initializing setup()
2025-06-02 17:58:38,732:INFO:self.USI: 8d3a
2025-06-02 17:58:38,732:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 17:58:38,732:INFO:Checking environment
2025-06-02 17:58:38,732:INFO:python_version: 3.10.16
2025-06-02 17:58:38,732:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 17:58:38,732:INFO:machine: AMD64
2025-06-02 17:58:38,733:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 17:58:38,740:INFO:Memory: svmem(total=6378008576, available=413794304, percent=93.5, used=5964214272, free=413794304)
2025-06-02 17:58:38,741:INFO:Physical Core: 4
2025-06-02 17:58:38,741:INFO:Logical Core: 8
2025-06-02 17:58:38,741:INFO:Checking libraries
2025-06-02 17:58:38,741:INFO:System:
2025-06-02 17:58:38,741:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 17:58:38,741:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 17:58:38,741:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 17:58:38,741:INFO:PyCaret required dependencies:
2025-06-02 17:58:38,741:INFO:                 pip: 25.1
2025-06-02 17:58:38,741:INFO:          setuptools: 78.1.1
2025-06-02 17:58:38,742:INFO:             pycaret: 3.3.2
2025-06-02 17:58:38,742:INFO:             IPython: 8.37.0
2025-06-02 17:58:38,742:INFO:          ipywidgets: 8.1.7
2025-06-02 17:58:38,742:INFO:                tqdm: 4.67.1
2025-06-02 17:58:38,742:INFO:               numpy: 1.26.4
2025-06-02 17:58:38,742:INFO:              pandas: 2.0.1
2025-06-02 17:58:38,742:INFO:              jinja2: 3.1.6
2025-06-02 17:58:38,742:INFO:               scipy: 1.10.1
2025-06-02 17:58:38,742:INFO:              joblib: 1.3.2
2025-06-02 17:58:38,742:INFO:             sklearn: 1.4.2
2025-06-02 17:58:38,742:INFO:                pyod: 2.0.5
2025-06-02 17:58:38,742:INFO:            imblearn: 0.13.0
2025-06-02 17:58:38,742:INFO:   category_encoders: 2.7.0
2025-06-02 17:58:38,742:INFO:            lightgbm: 4.6.0
2025-06-02 17:58:38,743:INFO:               numba: 0.61.0
2025-06-02 17:58:38,743:INFO:            requests: 2.32.3
2025-06-02 17:58:38,743:INFO:          matplotlib: 3.7.1
2025-06-02 17:58:38,743:INFO:          scikitplot: 0.3.7
2025-06-02 17:58:38,743:INFO:         yellowbrick: 1.5
2025-06-02 17:58:38,743:INFO:              plotly: 6.1.2
2025-06-02 17:58:38,743:INFO:    plotly-resampler: Not installed
2025-06-02 17:58:38,743:INFO:             kaleido: 0.2.1
2025-06-02 17:58:38,743:INFO:           schemdraw: 0.15
2025-06-02 17:58:38,743:INFO:         statsmodels: 0.14.4
2025-06-02 17:58:38,743:INFO:              sktime: 0.26.0
2025-06-02 17:58:38,743:INFO:               tbats: 1.1.3
2025-06-02 17:58:38,743:INFO:            pmdarima: 2.0.4
2025-06-02 17:58:38,743:INFO:              psutil: 7.0.0
2025-06-02 17:58:38,743:INFO:          markupsafe: 2.1.2
2025-06-02 17:58:38,744:INFO:             pickle5: Not installed
2025-06-02 17:58:38,744:INFO:         cloudpickle: 3.1.1
2025-06-02 17:58:38,744:INFO:         deprecation: 2.1.0
2025-06-02 17:58:38,744:INFO:              xxhash: 3.5.0
2025-06-02 17:58:38,744:INFO:           wurlitzer: Not installed
2025-06-02 17:58:38,744:INFO:PyCaret optional dependencies:
2025-06-02 17:58:38,744:INFO:                shap: 0.44.1
2025-06-02 17:58:38,744:INFO:           interpret: 0.6.9
2025-06-02 17:58:38,744:INFO:                umap: 0.5.7
2025-06-02 17:58:38,744:INFO:     ydata_profiling: 4.16.1
2025-06-02 17:58:38,744:INFO:  explainerdashboard: 0.4.8
2025-06-02 17:58:38,744:INFO:             autoviz: Not installed
2025-06-02 17:58:38,744:INFO:           fairlearn: 0.7.0
2025-06-02 17:58:38,744:INFO:          deepchecks: Not installed
2025-06-02 17:58:38,745:INFO:             xgboost: 3.0.2
2025-06-02 17:58:38,745:INFO:            catboost: 1.2.8
2025-06-02 17:58:38,745:INFO:              kmodes: 0.12.2
2025-06-02 17:58:38,745:INFO:             mlxtend: 0.23.4
2025-06-02 17:58:38,745:INFO:       statsforecast: 1.5.0
2025-06-02 17:58:38,745:INFO:        tune_sklearn: Not installed
2025-06-02 17:58:38,745:INFO:                 ray: Not installed
2025-06-02 17:58:38,745:INFO:            hyperopt: 0.2.7
2025-06-02 17:58:38,745:INFO:              optuna: 4.3.0
2025-06-02 17:58:38,745:INFO:               skopt: 0.10.2
2025-06-02 17:58:38,745:INFO:              mlflow: 2.22.0
2025-06-02 17:58:38,745:INFO:              gradio: 5.32.0
2025-06-02 17:58:38,745:INFO:             fastapi: 0.115.12
2025-06-02 17:58:38,745:INFO:             uvicorn: 0.34.3
2025-06-02 17:58:38,746:INFO:              m2cgen: 0.10.0
2025-06-02 17:58:38,746:INFO:           evidently: 0.4.40
2025-06-02 17:58:38,746:INFO:               fugue: 0.8.5
2025-06-02 17:58:38,746:INFO:           streamlit: Not installed
2025-06-02 17:58:38,746:INFO:             prophet: Not installed
2025-06-02 17:58:38,746:INFO:None
2025-06-02 17:58:38,746:INFO:Set up data.
2025-06-02 17:58:38,860:INFO:Set up folding strategy.
2025-06-02 17:58:38,861:INFO:Set up train/test split.
2025-06-02 17:58:38,976:INFO:Set up index.
2025-06-02 17:58:38,979:INFO:Assigning column types.
2025-06-02 17:58:39,036:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 17:58:39,037:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,049:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,057:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,290:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,293:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:58:39,300:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:58:39,301:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,309:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,316:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,462:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,561:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,562:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:58:39,567:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:58:39,568:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 17:58:39,576:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,584:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,789:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,789:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:58:39,793:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:58:39,801:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,808:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:58:39,936:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:58:40,014:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:58:40,014:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:58:40,018:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:58:40,019:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 17:58:40,033:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:58:40,162:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:58:40,241:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:58:40,242:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:58:40,246:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:58:40,260:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 17:58:40,388:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:58:40,465:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:58:40,466:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:58:40,470:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:58:40,471:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 17:58:40,613:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:58:40,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:58:40,686:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:58:40,691:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:58:40,829:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:58:40,902:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 17:58:40,903:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:58:40,907:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:58:40,908:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 17:58:41,046:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:58:41,116:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:58:41,120:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:58:41,271:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 17:58:41,341:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:58:41,348:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:58:41,349:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 17:58:41,573:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:58:41,578:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:58:41,798:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:58:41,801:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:58:41,804:INFO:Preparing preprocessing pipeline...
2025-06-02 17:58:41,805:INFO:Set up simple imputation.
2025-06-02 17:58:41,805:INFO:Set up removing multicollinearity.
2025-06-02 17:58:41,812:INFO:Set up column name cleaning.
2025-06-02 17:58:42,361:INFO:Finished creating preprocessing pipeline.
2025-06-02 17:58:42,376:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 17:58:42,377:INFO:Creating final display dataframe.
2025-06-02 17:58:43,443:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 98)
5   Transformed train set shape        (3358, 98)
6    Transformed test set shape        (1120, 98)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              8d3a
2025-06-02 17:58:43,698:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:58:43,702:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:58:43,919:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 17:58:43,923:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 17:58:43,925:INFO:setup() successfully completed in 5.25s...............
2025-06-02 17:58:43,971:INFO:Initializing compare_models()
2025-06-02 17:58:43,971:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 17:58:43,971:INFO:Checking exceptions
2025-06-02 17:58:43,992:INFO:Preparing display monitor
2025-06-02 17:58:44,058:INFO:Initializing Linear Regression
2025-06-02 17:58:44,058:INFO:Total runtime is 0.0 minutes
2025-06-02 17:58:44,071:INFO:SubProcess create_model() called ==================================
2025-06-02 17:58:44,073:INFO:Initializing create_model()
2025-06-02 17:58:44,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:58:44,074:INFO:Checking exceptions
2025-06-02 17:58:44,075:INFO:Importing libraries
2025-06-02 17:58:44,075:INFO:Copying training dataset
2025-06-02 17:58:44,163:INFO:Defining folds
2025-06-02 17:58:44,163:INFO:Declaring metric variables
2025-06-02 17:58:44,174:INFO:Importing untrained model
2025-06-02 17:58:44,184:INFO:Linear Regression Imported successfully
2025-06-02 17:58:44,212:INFO:Starting cross validation
2025-06-02 17:58:44,216:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:59:00,344:INFO:Calculating mean and std
2025-06-02 17:59:00,373:INFO:Creating metrics dataframe
2025-06-02 17:59:00,432:INFO:Uploading results into container
2025-06-02 17:59:00,439:INFO:Uploading model into container now
2025-06-02 17:59:00,443:INFO:_master_model_container: 1
2025-06-02 17:59:00,444:INFO:_display_container: 2
2025-06-02 17:59:00,485:INFO:LinearRegression(n_jobs=-1)
2025-06-02 17:59:00,486:INFO:create_model() successfully completed......................................
2025-06-02 17:59:09,950:INFO:SubProcess create_model() end ==================================
2025-06-02 17:59:09,951:INFO:Creating metrics dataframe
2025-06-02 17:59:10,000:INFO:Initializing Lasso Regression
2025-06-02 17:59:10,000:INFO:Total runtime is 0.4323591629664103 minutes
2025-06-02 17:59:10,020:INFO:SubProcess create_model() called ==================================
2025-06-02 17:59:10,022:INFO:Initializing create_model()
2025-06-02 17:59:10,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:59:10,026:INFO:Checking exceptions
2025-06-02 17:59:10,026:INFO:Importing libraries
2025-06-02 17:59:10,027:INFO:Copying training dataset
2025-06-02 17:59:10,159:INFO:Defining folds
2025-06-02 17:59:10,160:INFO:Declaring metric variables
2025-06-02 17:59:10,171:INFO:Importing untrained model
2025-06-02 17:59:10,185:INFO:Lasso Regression Imported successfully
2025-06-02 17:59:10,213:INFO:Starting cross validation
2025-06-02 17:59:10,219:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:59:19,693:INFO:Calculating mean and std
2025-06-02 17:59:19,697:INFO:Creating metrics dataframe
2025-06-02 17:59:19,711:INFO:Uploading results into container
2025-06-02 17:59:19,713:INFO:Uploading model into container now
2025-06-02 17:59:19,715:INFO:_master_model_container: 2
2025-06-02 17:59:19,715:INFO:_display_container: 2
2025-06-02 17:59:19,717:INFO:Lasso(random_state=123)
2025-06-02 17:59:19,718:INFO:create_model() successfully completed......................................
2025-06-02 17:59:21,057:INFO:SubProcess create_model() end ==================================
2025-06-02 17:59:21,058:INFO:Creating metrics dataframe
2025-06-02 17:59:21,079:INFO:Initializing Ridge Regression
2025-06-02 17:59:21,079:INFO:Total runtime is 0.6170104940732319 minutes
2025-06-02 17:59:21,088:INFO:SubProcess create_model() called ==================================
2025-06-02 17:59:21,089:INFO:Initializing create_model()
2025-06-02 17:59:21,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:59:21,090:INFO:Checking exceptions
2025-06-02 17:59:21,091:INFO:Importing libraries
2025-06-02 17:59:21,091:INFO:Copying training dataset
2025-06-02 17:59:21,147:INFO:Defining folds
2025-06-02 17:59:21,148:INFO:Declaring metric variables
2025-06-02 17:59:21,162:INFO:Importing untrained model
2025-06-02 17:59:21,174:INFO:Ridge Regression Imported successfully
2025-06-02 17:59:21,195:INFO:Starting cross validation
2025-06-02 17:59:21,199:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:59:21,833:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.98589e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 17:59:21,858:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14793e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 17:59:21,886:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.19864e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 17:59:21,911:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.48483e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 17:59:21,963:INFO:Calculating mean and std
2025-06-02 17:59:21,965:INFO:Creating metrics dataframe
2025-06-02 17:59:21,969:INFO:Uploading results into container
2025-06-02 17:59:21,970:INFO:Uploading model into container now
2025-06-02 17:59:21,971:INFO:_master_model_container: 3
2025-06-02 17:59:21,971:INFO:_display_container: 2
2025-06-02 17:59:21,972:INFO:Ridge(random_state=123)
2025-06-02 17:59:21,973:INFO:create_model() successfully completed......................................
2025-06-02 17:59:23,312:INFO:SubProcess create_model() end ==================================
2025-06-02 17:59:23,312:INFO:Creating metrics dataframe
2025-06-02 17:59:23,327:INFO:Initializing Elastic Net
2025-06-02 17:59:23,327:INFO:Total runtime is 0.6544893542925516 minutes
2025-06-02 17:59:23,335:INFO:SubProcess create_model() called ==================================
2025-06-02 17:59:23,336:INFO:Initializing create_model()
2025-06-02 17:59:23,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:59:23,336:INFO:Checking exceptions
2025-06-02 17:59:23,337:INFO:Importing libraries
2025-06-02 17:59:23,337:INFO:Copying training dataset
2025-06-02 17:59:23,395:INFO:Defining folds
2025-06-02 17:59:23,395:INFO:Declaring metric variables
2025-06-02 17:59:23,404:INFO:Importing untrained model
2025-06-02 17:59:23,417:INFO:Elastic Net Imported successfully
2025-06-02 17:59:23,437:INFO:Starting cross validation
2025-06-02 17:59:23,441:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:59:24,191:INFO:Calculating mean and std
2025-06-02 17:59:24,194:INFO:Creating metrics dataframe
2025-06-02 17:59:24,199:INFO:Uploading results into container
2025-06-02 17:59:24,201:INFO:Uploading model into container now
2025-06-02 17:59:24,202:INFO:_master_model_container: 4
2025-06-02 17:59:24,203:INFO:_display_container: 2
2025-06-02 17:59:24,203:INFO:ElasticNet(random_state=123)
2025-06-02 17:59:24,204:INFO:create_model() successfully completed......................................
2025-06-02 17:59:25,541:INFO:SubProcess create_model() end ==================================
2025-06-02 17:59:25,541:INFO:Creating metrics dataframe
2025-06-02 17:59:25,553:INFO:Initializing Least Angle Regression
2025-06-02 17:59:25,553:INFO:Total runtime is 0.691576345761617 minutes
2025-06-02 17:59:25,564:INFO:SubProcess create_model() called ==================================
2025-06-02 17:59:25,565:INFO:Initializing create_model()
2025-06-02 17:59:25,565:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:59:25,566:INFO:Checking exceptions
2025-06-02 17:59:25,566:INFO:Importing libraries
2025-06-02 17:59:25,567:INFO:Copying training dataset
2025-06-02 17:59:25,623:INFO:Defining folds
2025-06-02 17:59:25,624:INFO:Declaring metric variables
2025-06-02 17:59:25,632:INFO:Importing untrained model
2025-06-02 17:59:25,647:INFO:Least Angle Regression Imported successfully
2025-06-02 17:59:25,667:INFO:Starting cross validation
2025-06-02 17:59:25,671:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:59:26,410:INFO:Calculating mean and std
2025-06-02 17:59:26,412:INFO:Creating metrics dataframe
2025-06-02 17:59:26,416:INFO:Uploading results into container
2025-06-02 17:59:26,417:INFO:Uploading model into container now
2025-06-02 17:59:26,418:INFO:_master_model_container: 5
2025-06-02 17:59:26,418:INFO:_display_container: 2
2025-06-02 17:59:26,420:INFO:Lars(random_state=123)
2025-06-02 17:59:26,420:INFO:create_model() successfully completed......................................
2025-06-02 17:59:27,722:INFO:SubProcess create_model() end ==================================
2025-06-02 17:59:27,723:INFO:Creating metrics dataframe
2025-06-02 17:59:27,738:INFO:Initializing Lasso Least Angle Regression
2025-06-02 17:59:27,739:INFO:Total runtime is 0.7280152638753254 minutes
2025-06-02 17:59:27,748:INFO:SubProcess create_model() called ==================================
2025-06-02 17:59:27,749:INFO:Initializing create_model()
2025-06-02 17:59:27,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:59:27,750:INFO:Checking exceptions
2025-06-02 17:59:27,750:INFO:Importing libraries
2025-06-02 17:59:27,751:INFO:Copying training dataset
2025-06-02 17:59:27,811:INFO:Defining folds
2025-06-02 17:59:27,811:INFO:Declaring metric variables
2025-06-02 17:59:27,825:INFO:Importing untrained model
2025-06-02 17:59:27,835:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 17:59:27,853:INFO:Starting cross validation
2025-06-02 17:59:27,856:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:59:28,930:INFO:Calculating mean and std
2025-06-02 17:59:28,932:INFO:Creating metrics dataframe
2025-06-02 17:59:28,936:INFO:Uploading results into container
2025-06-02 17:59:28,937:INFO:Uploading model into container now
2025-06-02 17:59:28,939:INFO:_master_model_container: 6
2025-06-02 17:59:28,940:INFO:_display_container: 2
2025-06-02 17:59:28,942:INFO:LassoLars(random_state=123)
2025-06-02 17:59:28,942:INFO:create_model() successfully completed......................................
2025-06-02 17:59:30,647:INFO:SubProcess create_model() end ==================================
2025-06-02 17:59:30,647:INFO:Creating metrics dataframe
2025-06-02 17:59:30,666:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 17:59:30,667:INFO:Total runtime is 0.7768218239148457 minutes
2025-06-02 17:59:30,679:INFO:SubProcess create_model() called ==================================
2025-06-02 17:59:30,680:INFO:Initializing create_model()
2025-06-02 17:59:30,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:59:30,681:INFO:Checking exceptions
2025-06-02 17:59:30,681:INFO:Importing libraries
2025-06-02 17:59:30,682:INFO:Copying training dataset
2025-06-02 17:59:30,749:INFO:Defining folds
2025-06-02 17:59:30,749:INFO:Declaring metric variables
2025-06-02 17:59:30,762:INFO:Importing untrained model
2025-06-02 17:59:30,777:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 17:59:30,797:INFO:Starting cross validation
2025-06-02 17:59:30,801:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:59:31,793:INFO:Calculating mean and std
2025-06-02 17:59:31,795:INFO:Creating metrics dataframe
2025-06-02 17:59:31,798:INFO:Uploading results into container
2025-06-02 17:59:31,799:INFO:Uploading model into container now
2025-06-02 17:59:31,800:INFO:_master_model_container: 7
2025-06-02 17:59:31,800:INFO:_display_container: 2
2025-06-02 17:59:31,801:INFO:OrthogonalMatchingPursuit()
2025-06-02 17:59:31,801:INFO:create_model() successfully completed......................................
2025-06-02 17:59:33,115:INFO:SubProcess create_model() end ==================================
2025-06-02 17:59:33,115:INFO:Creating metrics dataframe
2025-06-02 17:59:33,137:INFO:Initializing Bayesian Ridge
2025-06-02 17:59:33,137:INFO:Total runtime is 0.8179877122243244 minutes
2025-06-02 17:59:33,148:INFO:SubProcess create_model() called ==================================
2025-06-02 17:59:33,148:INFO:Initializing create_model()
2025-06-02 17:59:33,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:59:33,149:INFO:Checking exceptions
2025-06-02 17:59:33,149:INFO:Importing libraries
2025-06-02 17:59:33,150:INFO:Copying training dataset
2025-06-02 17:59:33,210:INFO:Defining folds
2025-06-02 17:59:33,210:INFO:Declaring metric variables
2025-06-02 17:59:33,221:INFO:Importing untrained model
2025-06-02 17:59:33,232:INFO:Bayesian Ridge Imported successfully
2025-06-02 17:59:33,251:INFO:Starting cross validation
2025-06-02 17:59:33,254:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:59:34,042:INFO:Calculating mean and std
2025-06-02 17:59:34,044:INFO:Creating metrics dataframe
2025-06-02 17:59:34,047:INFO:Uploading results into container
2025-06-02 17:59:34,048:INFO:Uploading model into container now
2025-06-02 17:59:34,049:INFO:_master_model_container: 8
2025-06-02 17:59:34,050:INFO:_display_container: 2
2025-06-02 17:59:34,051:INFO:BayesianRidge()
2025-06-02 17:59:34,051:INFO:create_model() successfully completed......................................
2025-06-02 17:59:35,335:INFO:SubProcess create_model() end ==================================
2025-06-02 17:59:35,336:INFO:Creating metrics dataframe
2025-06-02 17:59:35,354:INFO:Initializing Passive Aggressive Regressor
2025-06-02 17:59:35,354:INFO:Total runtime is 0.8549281954765319 minutes
2025-06-02 17:59:35,364:INFO:SubProcess create_model() called ==================================
2025-06-02 17:59:35,366:INFO:Initializing create_model()
2025-06-02 17:59:35,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:59:35,366:INFO:Checking exceptions
2025-06-02 17:59:35,367:INFO:Importing libraries
2025-06-02 17:59:35,367:INFO:Copying training dataset
2025-06-02 17:59:35,421:INFO:Defining folds
2025-06-02 17:59:35,421:INFO:Declaring metric variables
2025-06-02 17:59:35,432:INFO:Importing untrained model
2025-06-02 17:59:35,442:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 17:59:35,461:INFO:Starting cross validation
2025-06-02 17:59:35,465:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:59:36,190:INFO:Calculating mean and std
2025-06-02 17:59:36,192:INFO:Creating metrics dataframe
2025-06-02 17:59:36,196:INFO:Uploading results into container
2025-06-02 17:59:36,197:INFO:Uploading model into container now
2025-06-02 17:59:36,198:INFO:_master_model_container: 9
2025-06-02 17:59:36,199:INFO:_display_container: 2
2025-06-02 17:59:36,200:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 17:59:36,200:INFO:create_model() successfully completed......................................
2025-06-02 17:59:37,507:INFO:SubProcess create_model() end ==================================
2025-06-02 17:59:37,507:INFO:Creating metrics dataframe
2025-06-02 17:59:37,522:INFO:Initializing Huber Regressor
2025-06-02 17:59:37,522:INFO:Total runtime is 0.8910730520884195 minutes
2025-06-02 17:59:37,532:INFO:SubProcess create_model() called ==================================
2025-06-02 17:59:37,532:INFO:Initializing create_model()
2025-06-02 17:59:37,533:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:59:37,533:INFO:Checking exceptions
2025-06-02 17:59:37,533:INFO:Importing libraries
2025-06-02 17:59:37,534:INFO:Copying training dataset
2025-06-02 17:59:37,592:INFO:Defining folds
2025-06-02 17:59:37,592:INFO:Declaring metric variables
2025-06-02 17:59:37,602:INFO:Importing untrained model
2025-06-02 17:59:37,613:INFO:Huber Regressor Imported successfully
2025-06-02 17:59:37,632:INFO:Starting cross validation
2025-06-02 17:59:37,637:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:59:39,176:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:59:39,195:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:59:39,238:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:59:39,304:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:59:39,332:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 17:59:39,389:INFO:Calculating mean and std
2025-06-02 17:59:39,391:INFO:Creating metrics dataframe
2025-06-02 17:59:39,395:INFO:Uploading results into container
2025-06-02 17:59:39,395:INFO:Uploading model into container now
2025-06-02 17:59:39,396:INFO:_master_model_container: 10
2025-06-02 17:59:39,397:INFO:_display_container: 2
2025-06-02 17:59:39,397:INFO:HuberRegressor()
2025-06-02 17:59:39,398:INFO:create_model() successfully completed......................................
2025-06-02 17:59:40,700:INFO:SubProcess create_model() end ==================================
2025-06-02 17:59:40,700:INFO:Creating metrics dataframe
2025-06-02 17:59:40,718:INFO:Initializing K Neighbors Regressor
2025-06-02 17:59:40,718:INFO:Total runtime is 0.9443265875180561 minutes
2025-06-02 17:59:40,728:INFO:SubProcess create_model() called ==================================
2025-06-02 17:59:40,728:INFO:Initializing create_model()
2025-06-02 17:59:40,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:59:40,729:INFO:Checking exceptions
2025-06-02 17:59:40,730:INFO:Importing libraries
2025-06-02 17:59:40,730:INFO:Copying training dataset
2025-06-02 17:59:40,790:INFO:Defining folds
2025-06-02 17:59:40,790:INFO:Declaring metric variables
2025-06-02 17:59:40,802:INFO:Importing untrained model
2025-06-02 17:59:40,813:INFO:K Neighbors Regressor Imported successfully
2025-06-02 17:59:40,833:INFO:Starting cross validation
2025-06-02 17:59:40,837:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:59:41,596:INFO:Calculating mean and std
2025-06-02 17:59:41,598:INFO:Creating metrics dataframe
2025-06-02 17:59:41,603:INFO:Uploading results into container
2025-06-02 17:59:41,604:INFO:Uploading model into container now
2025-06-02 17:59:41,605:INFO:_master_model_container: 11
2025-06-02 17:59:41,606:INFO:_display_container: 2
2025-06-02 17:59:41,607:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 17:59:41,607:INFO:create_model() successfully completed......................................
2025-06-02 17:59:42,923:INFO:SubProcess create_model() end ==================================
2025-06-02 17:59:42,923:INFO:Creating metrics dataframe
2025-06-02 17:59:42,942:INFO:Initializing Decision Tree Regressor
2025-06-02 17:59:42,942:INFO:Total runtime is 0.9814070502916971 minutes
2025-06-02 17:59:42,951:INFO:SubProcess create_model() called ==================================
2025-06-02 17:59:42,952:INFO:Initializing create_model()
2025-06-02 17:59:42,952:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:59:42,952:INFO:Checking exceptions
2025-06-02 17:59:42,953:INFO:Importing libraries
2025-06-02 17:59:42,953:INFO:Copying training dataset
2025-06-02 17:59:43,008:INFO:Defining folds
2025-06-02 17:59:43,008:INFO:Declaring metric variables
2025-06-02 17:59:43,020:INFO:Importing untrained model
2025-06-02 17:59:43,032:INFO:Decision Tree Regressor Imported successfully
2025-06-02 17:59:43,052:INFO:Starting cross validation
2025-06-02 17:59:43,055:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:59:43,972:INFO:Calculating mean and std
2025-06-02 17:59:43,974:INFO:Creating metrics dataframe
2025-06-02 17:59:43,978:INFO:Uploading results into container
2025-06-02 17:59:43,979:INFO:Uploading model into container now
2025-06-02 17:59:43,980:INFO:_master_model_container: 12
2025-06-02 17:59:43,981:INFO:_display_container: 2
2025-06-02 17:59:43,982:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 17:59:43,982:INFO:create_model() successfully completed......................................
2025-06-02 17:59:45,268:INFO:SubProcess create_model() end ==================================
2025-06-02 17:59:45,268:INFO:Creating metrics dataframe
2025-06-02 17:59:45,286:INFO:Initializing Random Forest Regressor
2025-06-02 17:59:45,286:INFO:Total runtime is 1.0204740047454832 minutes
2025-06-02 17:59:45,298:INFO:SubProcess create_model() called ==================================
2025-06-02 17:59:45,298:INFO:Initializing create_model()
2025-06-02 17:59:45,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:59:45,299:INFO:Checking exceptions
2025-06-02 17:59:45,299:INFO:Importing libraries
2025-06-02 17:59:45,300:INFO:Copying training dataset
2025-06-02 17:59:45,365:INFO:Defining folds
2025-06-02 17:59:45,366:INFO:Declaring metric variables
2025-06-02 17:59:45,380:INFO:Importing untrained model
2025-06-02 17:59:45,391:INFO:Random Forest Regressor Imported successfully
2025-06-02 17:59:45,412:INFO:Starting cross validation
2025-06-02 17:59:45,415:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 17:59:54,858:INFO:Calculating mean and std
2025-06-02 17:59:54,860:INFO:Creating metrics dataframe
2025-06-02 17:59:54,863:INFO:Uploading results into container
2025-06-02 17:59:54,864:INFO:Uploading model into container now
2025-06-02 17:59:54,865:INFO:_master_model_container: 13
2025-06-02 17:59:54,866:INFO:_display_container: 2
2025-06-02 17:59:54,867:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 17:59:54,867:INFO:create_model() successfully completed......................................
2025-06-02 17:59:56,482:INFO:SubProcess create_model() end ==================================
2025-06-02 17:59:56,482:INFO:Creating metrics dataframe
2025-06-02 17:59:56,501:INFO:Initializing Extra Trees Regressor
2025-06-02 17:59:56,501:INFO:Total runtime is 1.2073914011319475 minutes
2025-06-02 17:59:56,511:INFO:SubProcess create_model() called ==================================
2025-06-02 17:59:56,511:INFO:Initializing create_model()
2025-06-02 17:59:56,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 17:59:56,512:INFO:Checking exceptions
2025-06-02 17:59:56,512:INFO:Importing libraries
2025-06-02 17:59:56,513:INFO:Copying training dataset
2025-06-02 17:59:56,566:INFO:Defining folds
2025-06-02 17:59:56,566:INFO:Declaring metric variables
2025-06-02 17:59:56,578:INFO:Importing untrained model
2025-06-02 17:59:56,589:INFO:Extra Trees Regressor Imported successfully
2025-06-02 17:59:56,611:INFO:Starting cross validation
2025-06-02 17:59:56,614:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:00:03,971:INFO:Calculating mean and std
2025-06-02 18:00:03,974:INFO:Creating metrics dataframe
2025-06-02 18:00:03,980:INFO:Uploading results into container
2025-06-02 18:00:03,981:INFO:Uploading model into container now
2025-06-02 18:00:03,982:INFO:_master_model_container: 14
2025-06-02 18:00:03,982:INFO:_display_container: 2
2025-06-02 18:00:03,983:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:00:03,984:INFO:create_model() successfully completed......................................
2025-06-02 18:00:05,709:INFO:SubProcess create_model() end ==================================
2025-06-02 18:00:05,709:INFO:Creating metrics dataframe
2025-06-02 18:00:05,730:INFO:Initializing AdaBoost Regressor
2025-06-02 18:00:05,730:INFO:Total runtime is 1.3612018903096514 minutes
2025-06-02 18:00:05,738:INFO:SubProcess create_model() called ==================================
2025-06-02 18:00:05,739:INFO:Initializing create_model()
2025-06-02 18:00:05,739:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:00:05,740:INFO:Checking exceptions
2025-06-02 18:00:05,740:INFO:Importing libraries
2025-06-02 18:00:05,740:INFO:Copying training dataset
2025-06-02 18:00:05,797:INFO:Defining folds
2025-06-02 18:00:05,798:INFO:Declaring metric variables
2025-06-02 18:00:05,809:INFO:Importing untrained model
2025-06-02 18:00:05,820:INFO:AdaBoost Regressor Imported successfully
2025-06-02 18:00:05,841:INFO:Starting cross validation
2025-06-02 18:00:05,844:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:00:07,789:INFO:Calculating mean and std
2025-06-02 18:00:07,791:INFO:Creating metrics dataframe
2025-06-02 18:00:07,796:INFO:Uploading results into container
2025-06-02 18:00:07,797:INFO:Uploading model into container now
2025-06-02 18:00:07,798:INFO:_master_model_container: 15
2025-06-02 18:00:07,800:INFO:_display_container: 2
2025-06-02 18:00:07,801:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 18:00:07,801:INFO:create_model() successfully completed......................................
2025-06-02 18:00:09,169:INFO:SubProcess create_model() end ==================================
2025-06-02 18:00:09,169:INFO:Creating metrics dataframe
2025-06-02 18:00:09,200:INFO:Initializing Gradient Boosting Regressor
2025-06-02 18:00:09,200:INFO:Total runtime is 1.4190302371978758 minutes
2025-06-02 18:00:09,212:INFO:SubProcess create_model() called ==================================
2025-06-02 18:00:09,212:INFO:Initializing create_model()
2025-06-02 18:00:09,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:00:09,213:INFO:Checking exceptions
2025-06-02 18:00:09,213:INFO:Importing libraries
2025-06-02 18:00:09,213:INFO:Copying training dataset
2025-06-02 18:00:09,274:INFO:Defining folds
2025-06-02 18:00:09,275:INFO:Declaring metric variables
2025-06-02 18:00:09,287:INFO:Importing untrained model
2025-06-02 18:00:09,300:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 18:00:09,323:INFO:Starting cross validation
2025-06-02 18:00:09,328:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:00:13,142:INFO:Calculating mean and std
2025-06-02 18:00:13,145:INFO:Creating metrics dataframe
2025-06-02 18:00:13,149:INFO:Uploading results into container
2025-06-02 18:00:13,149:INFO:Uploading model into container now
2025-06-02 18:00:13,150:INFO:_master_model_container: 16
2025-06-02 18:00:13,150:INFO:_display_container: 2
2025-06-02 18:00:13,151:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 18:00:13,152:INFO:create_model() successfully completed......................................
2025-06-02 18:00:14,844:INFO:SubProcess create_model() end ==================================
2025-06-02 18:00:14,845:INFO:Creating metrics dataframe
2025-06-02 18:00:14,873:INFO:Initializing Extreme Gradient Boosting
2025-06-02 18:00:14,873:INFO:Total runtime is 1.5135870655377703 minutes
2025-06-02 18:00:14,883:INFO:SubProcess create_model() called ==================================
2025-06-02 18:00:14,884:INFO:Initializing create_model()
2025-06-02 18:00:14,884:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:00:14,884:INFO:Checking exceptions
2025-06-02 18:00:14,885:INFO:Importing libraries
2025-06-02 18:00:14,885:INFO:Copying training dataset
2025-06-02 18:00:14,948:INFO:Defining folds
2025-06-02 18:00:14,949:INFO:Declaring metric variables
2025-06-02 18:00:14,959:INFO:Importing untrained model
2025-06-02 18:00:14,969:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 18:00:14,986:INFO:Starting cross validation
2025-06-02 18:00:14,990:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:00:17,363:INFO:Calculating mean and std
2025-06-02 18:00:17,365:INFO:Creating metrics dataframe
2025-06-02 18:00:17,369:INFO:Uploading results into container
2025-06-02 18:00:17,370:INFO:Uploading model into container now
2025-06-02 18:00:17,371:INFO:_master_model_container: 17
2025-06-02 18:00:17,371:INFO:_display_container: 2
2025-06-02 18:00:17,376:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 18:00:17,377:INFO:create_model() successfully completed......................................
2025-06-02 18:00:19,145:INFO:SubProcess create_model() end ==================================
2025-06-02 18:00:19,146:INFO:Creating metrics dataframe
2025-06-02 18:00:19,165:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 18:00:19,165:INFO:Total runtime is 1.5851231455802914 minutes
2025-06-02 18:00:19,175:INFO:SubProcess create_model() called ==================================
2025-06-02 18:00:19,176:INFO:Initializing create_model()
2025-06-02 18:00:19,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:00:19,177:INFO:Checking exceptions
2025-06-02 18:00:19,178:INFO:Importing libraries
2025-06-02 18:00:19,178:INFO:Copying training dataset
2025-06-02 18:00:19,232:INFO:Defining folds
2025-06-02 18:00:19,232:INFO:Declaring metric variables
2025-06-02 18:00:19,244:INFO:Importing untrained model
2025-06-02 18:00:19,254:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 18:00:19,297:INFO:Starting cross validation
2025-06-02 18:00:19,304:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:00:21,282:INFO:Calculating mean and std
2025-06-02 18:00:21,284:INFO:Creating metrics dataframe
2025-06-02 18:00:21,289:INFO:Uploading results into container
2025-06-02 18:00:21,291:INFO:Uploading model into container now
2025-06-02 18:00:21,292:INFO:_master_model_container: 18
2025-06-02 18:00:21,292:INFO:_display_container: 2
2025-06-02 18:00:21,293:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:00:21,293:INFO:create_model() successfully completed......................................
2025-06-02 18:00:22,916:INFO:SubProcess create_model() end ==================================
2025-06-02 18:00:22,916:INFO:Creating metrics dataframe
2025-06-02 18:00:22,941:INFO:Initializing CatBoost Regressor
2025-06-02 18:00:22,942:INFO:Total runtime is 1.6480607628822324 minutes
2025-06-02 18:00:22,953:INFO:SubProcess create_model() called ==================================
2025-06-02 18:00:22,954:INFO:Initializing create_model()
2025-06-02 18:00:22,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:00:22,955:INFO:Checking exceptions
2025-06-02 18:00:22,956:INFO:Importing libraries
2025-06-02 18:00:22,956:INFO:Copying training dataset
2025-06-02 18:00:23,065:INFO:Defining folds
2025-06-02 18:00:23,065:INFO:Declaring metric variables
2025-06-02 18:00:23,081:INFO:Importing untrained model
2025-06-02 18:00:23,105:INFO:CatBoost Regressor Imported successfully
2025-06-02 18:00:23,136:INFO:Starting cross validation
2025-06-02 18:00:23,140:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:00:50,625:INFO:Calculating mean and std
2025-06-02 18:00:50,627:INFO:Creating metrics dataframe
2025-06-02 18:00:50,632:INFO:Uploading results into container
2025-06-02 18:00:50,633:INFO:Uploading model into container now
2025-06-02 18:00:50,634:INFO:_master_model_container: 19
2025-06-02 18:00:50,634:INFO:_display_container: 2
2025-06-02 18:00:50,634:INFO:<catboost.core.CatBoostRegressor object at 0x000001B702C15B40>
2025-06-02 18:00:50,634:INFO:create_model() successfully completed......................................
2025-06-02 18:00:52,065:INFO:SubProcess create_model() end ==================================
2025-06-02 18:00:52,066:INFO:Creating metrics dataframe
2025-06-02 18:00:52,090:INFO:Initializing Dummy Regressor
2025-06-02 18:00:52,090:INFO:Total runtime is 2.133864867687225 minutes
2025-06-02 18:00:52,098:INFO:SubProcess create_model() called ==================================
2025-06-02 18:00:52,099:INFO:Initializing create_model()
2025-06-02 18:00:52,099:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DB334820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:00:52,099:INFO:Checking exceptions
2025-06-02 18:00:52,099:INFO:Importing libraries
2025-06-02 18:00:52,100:INFO:Copying training dataset
2025-06-02 18:00:52,231:INFO:Defining folds
2025-06-02 18:00:52,253:INFO:Declaring metric variables
2025-06-02 18:00:52,269:INFO:Importing untrained model
2025-06-02 18:00:52,293:INFO:Dummy Regressor Imported successfully
2025-06-02 18:00:52,339:INFO:Starting cross validation
2025-06-02 18:00:52,345:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:00:53,423:INFO:Calculating mean and std
2025-06-02 18:00:53,426:INFO:Creating metrics dataframe
2025-06-02 18:00:53,429:INFO:Uploading results into container
2025-06-02 18:00:53,430:INFO:Uploading model into container now
2025-06-02 18:00:53,431:INFO:_master_model_container: 20
2025-06-02 18:00:53,431:INFO:_display_container: 2
2025-06-02 18:00:53,433:INFO:DummyRegressor()
2025-06-02 18:00:53,434:INFO:create_model() successfully completed......................................
2025-06-02 18:00:54,763:INFO:SubProcess create_model() end ==================================
2025-06-02 18:00:54,763:INFO:Creating metrics dataframe
2025-06-02 18:00:54,813:INFO:Initializing create_model()
2025-06-02 18:00:54,813:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:00:54,814:INFO:Checking exceptions
2025-06-02 18:00:54,827:INFO:Importing libraries
2025-06-02 18:00:54,827:INFO:Copying training dataset
2025-06-02 18:00:54,900:INFO:Defining folds
2025-06-02 18:00:54,900:INFO:Declaring metric variables
2025-06-02 18:00:54,901:INFO:Importing untrained model
2025-06-02 18:00:54,901:INFO:Declaring custom model
2025-06-02 18:00:54,903:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 18:00:54,908:INFO:Cross validation set to False
2025-06-02 18:00:54,908:INFO:Fitting Model
2025-06-02 18:00:55,338:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 18:00:55,361:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014816 seconds.
2025-06-02 18:00:55,361:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 18:00:55,362:INFO:[LightGBM] [Info] Total Bins 6291
2025-06-02 18:00:55,371:INFO:[LightGBM] [Info] Number of data points in the train set: 3358, number of used features: 97
2025-06-02 18:00:55,374:INFO:[LightGBM] [Info] Start training from score -0.484244
2025-06-02 18:00:55,566:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:00:55,566:INFO:create_model() successfully completed......................................
2025-06-02 18:00:56,885:INFO:Initializing create_model()
2025-06-02 18:00:56,886:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=<catboost.core.CatBoostRegressor object at 0x000001B702C15B40>, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:00:56,886:INFO:Checking exceptions
2025-06-02 18:00:56,893:INFO:Importing libraries
2025-06-02 18:00:56,893:INFO:Copying training dataset
2025-06-02 18:00:56,952:INFO:Defining folds
2025-06-02 18:00:56,952:INFO:Declaring metric variables
2025-06-02 18:00:56,952:INFO:Importing untrained model
2025-06-02 18:00:56,952:INFO:Declaring custom model
2025-06-02 18:00:56,953:INFO:CatBoost Regressor Imported successfully
2025-06-02 18:00:56,958:INFO:Cross validation set to False
2025-06-02 18:00:56,958:INFO:Fitting Model
2025-06-02 18:01:04,197:INFO:<catboost.core.CatBoostRegressor object at 0x000001B702C14490>
2025-06-02 18:01:04,199:INFO:create_model() successfully completed......................................
2025-06-02 18:01:05,538:INFO:Initializing create_model()
2025-06-02 18:01:05,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:01:05,539:INFO:Checking exceptions
2025-06-02 18:01:05,546:INFO:Importing libraries
2025-06-02 18:01:05,546:INFO:Copying training dataset
2025-06-02 18:01:05,622:INFO:Defining folds
2025-06-02 18:01:05,623:INFO:Declaring metric variables
2025-06-02 18:01:05,623:INFO:Importing untrained model
2025-06-02 18:01:05,623:INFO:Declaring custom model
2025-06-02 18:01:05,626:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 18:01:05,629:INFO:Cross validation set to False
2025-06-02 18:01:05,629:INFO:Fitting Model
2025-06-02 18:01:06,683:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 18:01:06,683:INFO:create_model() successfully completed......................................
2025-06-02 18:01:08,069:INFO:_master_model_container: 20
2025-06-02 18:01:08,069:INFO:_display_container: 2
2025-06-02 18:01:08,072:INFO:[LGBMRegressor(n_jobs=-1, random_state=123), <catboost.core.CatBoostRegressor object at 0x000001B702C14490>, XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)]
2025-06-02 18:01:08,073:INFO:compare_models() successfully completed......................................
2025-06-02 18:01:08,101:INFO:Initializing tune_model()
2025-06-02 18:01:08,101:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>)
2025-06-02 18:01:08,101:INFO:Checking exceptions
2025-06-02 18:01:08,101:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 18:01:08,154:INFO:Copying training dataset
2025-06-02 18:01:08,209:INFO:Checking base model
2025-06-02 18:01:08,210:INFO:Base model : Light Gradient Boosting Machine
2025-06-02 18:01:08,227:INFO:Declaring metric variables
2025-06-02 18:01:08,240:INFO:Defining Hyperparameters
2025-06-02 18:01:09,876:INFO:Tuning with n_jobs=-1
2025-06-02 18:01:09,891:INFO:Initializing skopt.BayesSearchCV
2025-06-02 18:01:29,337:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.8608120752388259), ('actual_estimator__bagging_freq', 1), ('actual_estimator__feature_fraction', 0.4284489606984907), ('actual_estimator__learning_rate', 0.016133245419918712), ('actual_estimator__min_child_samples', 95), ('actual_estimator__min_split_gain', 0.8209314243567916), ('actual_estimator__n_estimators', 239), ('actual_estimator__num_leaves', 183), ('actual_estimator__reg_alpha', 8.662569304197528e-07), ('actual_estimator__reg_lambda', 5.001062744294253e-06)])
2025-06-02 18:01:29,339:INFO:Hyperparameter search completed
2025-06-02 18:01:29,339:INFO:SubProcess create_model() called ==================================
2025-06-02 18:01:29,340:INFO:Initializing create_model()
2025-06-02 18:01:29,341:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DCE9E4A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.8608120752388259, 'bagging_freq': 1, 'feature_fraction': 0.4284489606984907, 'learning_rate': 0.016133245419918712, 'min_child_samples': 95, 'min_split_gain': 0.8209314243567916, 'n_estimators': 239, 'num_leaves': 183, 'reg_alpha': 8.662569304197528e-07, 'reg_lambda': 5.001062744294253e-06})
2025-06-02 18:01:29,341:INFO:Checking exceptions
2025-06-02 18:01:29,341:INFO:Importing libraries
2025-06-02 18:01:29,342:INFO:Copying training dataset
2025-06-02 18:01:29,421:INFO:Defining folds
2025-06-02 18:01:29,421:INFO:Declaring metric variables
2025-06-02 18:01:29,429:INFO:Importing untrained model
2025-06-02 18:01:29,430:INFO:Declaring custom model
2025-06-02 18:01:29,444:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 18:01:29,468:INFO:Starting cross validation
2025-06-02 18:01:29,472:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:01:31,444:INFO:Calculating mean and std
2025-06-02 18:01:31,445:INFO:Creating metrics dataframe
2025-06-02 18:01:31,458:INFO:Finalizing model
2025-06-02 18:01:31,865:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 18:01:31,865:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 18:01:31,865:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 18:01:31,885:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 18:01:31,887:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 18:01:31,887:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 18:01:31,887:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 18:01:31,897:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006964 seconds.
2025-06-02 18:01:31,897:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 18:01:31,898:INFO:[LightGBM] [Info] Total Bins 6280
2025-06-02 18:01:31,923:INFO:[LightGBM] [Info] Number of data points in the train set: 3358, number of used features: 95
2025-06-02 18:01:31,924:INFO:[LightGBM] [Info] Start training from score -0.484244
2025-06-02 18:01:31,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:31,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:01:32,214:INFO:Uploading results into container
2025-06-02 18:01:32,216:INFO:Uploading model into container now
2025-06-02 18:01:32,218:INFO:_master_model_container: 21
2025-06-02 18:01:32,218:INFO:_display_container: 3
2025-06-02 18:01:32,221:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06)
2025-06-02 18:01:32,222:INFO:create_model() successfully completed......................................
2025-06-02 18:01:33,629:INFO:SubProcess create_model() end ==================================
2025-06-02 18:01:33,630:INFO:choose_better activated
2025-06-02 18:01:33,639:INFO:SubProcess create_model() called ==================================
2025-06-02 18:01:33,641:INFO:Initializing create_model()
2025-06-02 18:01:33,642:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:01:33,642:INFO:Checking exceptions
2025-06-02 18:01:33,645:INFO:Importing libraries
2025-06-02 18:01:33,645:INFO:Copying training dataset
2025-06-02 18:01:33,712:INFO:Defining folds
2025-06-02 18:01:33,712:INFO:Declaring metric variables
2025-06-02 18:01:33,712:INFO:Importing untrained model
2025-06-02 18:01:33,713:INFO:Declaring custom model
2025-06-02 18:01:33,715:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 18:01:33,715:INFO:Starting cross validation
2025-06-02 18:01:33,718:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:01:35,517:INFO:Calculating mean and std
2025-06-02 18:01:35,518:INFO:Creating metrics dataframe
2025-06-02 18:01:35,521:INFO:Finalizing model
2025-06-02 18:01:35,889:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 18:01:35,895:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003878 seconds.
2025-06-02 18:01:35,895:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 18:01:35,896:INFO:[LightGBM] [Info] Total Bins 6291
2025-06-02 18:01:35,896:INFO:[LightGBM] [Info] Number of data points in the train set: 3358, number of used features: 97
2025-06-02 18:01:35,897:INFO:[LightGBM] [Info] Start training from score -0.484244
2025-06-02 18:01:36,078:INFO:Uploading results into container
2025-06-02 18:01:36,080:INFO:Uploading model into container now
2025-06-02 18:01:36,080:INFO:_master_model_container: 22
2025-06-02 18:01:36,081:INFO:_display_container: 4
2025-06-02 18:01:36,082:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:01:36,082:INFO:create_model() successfully completed......................................
2025-06-02 18:01:37,403:INFO:SubProcess create_model() end ==================================
2025-06-02 18:01:37,404:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8801
2025-06-02 18:01:37,405:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06) result for R2 is 0.8221
2025-06-02 18:01:37,406:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 18:01:37,406:INFO:choose_better completed
2025-06-02 18:01:37,406:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 18:01:37,420:INFO:_master_model_container: 22
2025-06-02 18:01:37,421:INFO:_display_container: 3
2025-06-02 18:01:37,422:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:01:37,423:INFO:tune_model() successfully completed......................................
2025-06-02 18:01:38,776:INFO:Initializing finalize_model()
2025-06-02 18:01:38,776:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 18:01:38,777:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:01:38,823:INFO:Initializing create_model()
2025-06-02 18:01:38,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:01:38,824:INFO:Checking exceptions
2025-06-02 18:01:38,827:INFO:Importing libraries
2025-06-02 18:01:38,827:INFO:Copying training dataset
2025-06-02 18:01:38,832:INFO:Defining folds
2025-06-02 18:01:38,833:INFO:Declaring metric variables
2025-06-02 18:01:38,833:INFO:Importing untrained model
2025-06-02 18:01:38,833:INFO:Declaring custom model
2025-06-02 18:01:38,835:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 18:01:38,837:INFO:Cross validation set to False
2025-06-02 18:01:38,837:INFO:Fitting Model
2025-06-02 18:01:39,234:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 18:01:39,240:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001167 seconds.
2025-06-02 18:01:39,240:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-06-02 18:01:39,240:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-06-02 18:01:39,241:INFO:[LightGBM] [Info] Total Bins 6237
2025-06-02 18:01:39,242:INFO:[LightGBM] [Info] Number of data points in the train set: 4478, number of used features: 95
2025-06-02 18:01:39,243:INFO:[LightGBM] [Info] Start training from score -0.483793
2025-06-02 18:01:39,461:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 18:01:39,461:INFO:create_model() successfully completed......................................
2025-06-02 18:01:40,781:INFO:_master_model_container: 22
2025-06-02 18:01:40,781:INFO:_display_container: 3
2025-06-02 18:01:40,795:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 18:01:40,795:INFO:finalize_model() successfully completed......................................
2025-06-02 18:01:42,130:INFO:Initializing save_model()
2025-06-02 18:01:42,130:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 18:01:42,130:INFO:Adding model into prep_pipe
2025-06-02 18:01:42,130:WARNING:Only Model saved as it was a pipeline.
2025-06-02 18:01:42,148:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 18:01:42,174:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 18:01:42,174:INFO:save_model() successfully completed......................................
2025-06-02 18:02:35,037:INFO:Initializing load_model()
2025-06-02 18:02:35,038:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 18:02:35,155:INFO:Initializing get_config()
2025-06-02 18:02:35,155:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, variable=X_test)
2025-06-02 18:02:35,155:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 18:02:35,155:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 18:02:35,205:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
717                         1.0                        1.0   
1329                       27.0                       72.0   
2669                       28.0                       31.0   
253                        83.0                       83.0   
3622                        8.0                       23.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
717                       0.0                1.000000   
1329                     45.0               37.000000   
2669                      3.0               28.750000   
253                       0.0               83.000000   
3622                     15.0               12.285714   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
717                    0.000000                     1.0   
1329                  15.555555                    27.0   
2669                   1.125000                    28.0   
253                    0.000000                    83.0   
3622                   6.122449                     8.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
717                                 92.0                                92.0   
1329                                45.0                                58.0   
2669                                61.0                                74.0   
253                                 86.0                                86.0   
3622                                46.0                                87.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
717                                0.0                        92.000000  ...   
1329                              13.0                        55.111111  ...   
2669                              13.0                        64.250000  ...   
253                                0.0                        86.000000  ...   
3622                              41.0                        75.285713  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
717                  7.0                   1             2.0   
1329                 6.0                   1             4.0   
2669                 4.0                   1            16.0   
253                  3.0                   1            24.0   
3622                 7.0                   0             1.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
717                  False                     False   
1329                 False                     False   
2669                 False                     False   
253                  False                     False   
3622                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
717                       False                        False   
1329                       True                        False   
2669                      False                        False   
253                       False                        False   
3622                      False                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
717                       False                      True   
1329                      False                     False   
2669                       True                     False   
253                       False                     False   
3622                      False                      True   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
717                     False  
1329                    False  
2669                    False  
253                      True  
3622                    False  

[1120 rows x 146 columns]
2025-06-02 18:02:35,206:INFO:get_config() successfully completed......................................
2025-06-02 18:02:35,209:INFO:Initializing get_config()
2025-06-02 18:02:35,209:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, variable=y_test)
2025-06-02 18:02:35,210:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 18:02:35,210:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 18:02:35,228:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
717     1.188433
1329   -0.222675
2669   -0.245426
253     0.000000
3622   -1.777082
Name: target, Length: 1120, dtype: float32
2025-06-02 18:02:35,228:INFO:get_config() successfully completed......................................
2025-06-02 18:02:35,249:INFO:Initializing predict_model()
2025-06-02 18:02:35,249:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B702972560>)
2025-06-02 18:02:35,249:INFO:Checking exceptions
2025-06-02 18:02:35,249:INFO:Preloading libraries
2025-06-02 18:02:35,253:INFO:Set up data.
2025-06-02 18:02:35,333:INFO:Set up index.
2025-06-02 18:02:40,778:INFO:Initializing load_model()
2025-06-02 18:02:40,778:INFO:load_model(model_name=formation_energy_final_model_mae, platform=None, authentication=None, verbose=True)
2025-06-02 18:02:41,425:INFO:Initializing get_config()
2025-06-02 18:02:41,426:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, variable=X_test)
2025-06-02 18:02:41,426:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 18:02:41,426:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 18:02:41,489:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
717                         1.0                        1.0   
1329                       27.0                       72.0   
2669                       28.0                       31.0   
253                        83.0                       83.0   
3622                        8.0                       23.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
717                       0.0                1.000000   
1329                     45.0               37.000000   
2669                      3.0               28.750000   
253                       0.0               83.000000   
3622                     15.0               12.285714   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
717                    0.000000                     1.0   
1329                  15.555555                    27.0   
2669                   1.125000                    28.0   
253                    0.000000                    83.0   
3622                   6.122449                     8.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
717                                 92.0                                92.0   
1329                                45.0                                58.0   
2669                                61.0                                74.0   
253                                 86.0                                86.0   
3622                                46.0                                87.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
717                                0.0                        92.000000  ...   
1329                              13.0                        55.111111  ...   
2669                              13.0                        64.250000  ...   
253                                0.0                        86.000000  ...   
3622                              41.0                        75.285713  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
717                  7.0                   1             2.0   
1329                 6.0                   1             4.0   
2669                 4.0                   1            16.0   
253                  3.0                   1            24.0   
3622                 7.0                   0             1.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
717                  False                     False   
1329                 False                     False   
2669                 False                     False   
253                  False                     False   
3622                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
717                       False                        False   
1329                       True                        False   
2669                      False                        False   
253                       False                        False   
3622                      False                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
717                       False                      True   
1329                      False                     False   
2669                       True                     False   
253                       False                     False   
3622                      False                      True   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
717                     False  
1329                    False  
2669                    False  
253                      True  
3622                    False  

[1120 rows x 146 columns]
2025-06-02 18:02:41,489:INFO:get_config() successfully completed......................................
2025-06-02 18:02:41,497:INFO:Initializing get_config()
2025-06-02 18:02:41,498:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, variable=y_test)
2025-06-02 18:02:41,498:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 18:02:41,498:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 18:02:41,519:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
717     1.188433
1329   -0.222675
2669   -0.245426
253     0.000000
3622   -1.777082
Name: target, Length: 1120, dtype: float32
2025-06-02 18:02:41,519:INFO:get_config() successfully completed......................................
2025-06-02 18:02:41,544:INFO:Initializing predict_model()
2025-06-02 18:02:41,545:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DB9C3A30>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B702924790>)
2025-06-02 18:02:41,545:INFO:Checking exceptions
2025-06-02 18:02:41,545:INFO:Preloading libraries
2025-06-02 18:02:41,551:INFO:Set up data.
2025-06-02 18:02:41,660:INFO:Set up index.
2025-06-02 18:04:30,615:INFO:PyCaret RegressionExperiment
2025-06-02 18:04:30,616:INFO:Logging name: reg-default-name
2025-06-02 18:04:30,617:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 18:04:30,617:INFO:version 3.3.2
2025-06-02 18:04:30,617:INFO:Initializing setup()
2025-06-02 18:04:30,617:INFO:self.USI: 8d8f
2025-06-02 18:04:30,617:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 18:04:30,618:INFO:Checking environment
2025-06-02 18:04:30,618:INFO:python_version: 3.10.16
2025-06-02 18:04:30,618:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 18:04:30,618:INFO:machine: AMD64
2025-06-02 18:04:30,618:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 18:04:30,626:INFO:Memory: svmem(total=6378008576, available=524275712, percent=91.8, used=5853732864, free=524275712)
2025-06-02 18:04:30,627:INFO:Physical Core: 4
2025-06-02 18:04:30,627:INFO:Logical Core: 8
2025-06-02 18:04:30,628:INFO:Checking libraries
2025-06-02 18:04:30,629:INFO:System:
2025-06-02 18:04:30,630:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 18:04:30,630:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 18:04:30,630:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 18:04:30,630:INFO:PyCaret required dependencies:
2025-06-02 18:04:30,633:INFO:                 pip: 25.1
2025-06-02 18:04:30,634:INFO:          setuptools: 78.1.1
2025-06-02 18:04:30,634:INFO:             pycaret: 3.3.2
2025-06-02 18:04:30,634:INFO:             IPython: 8.37.0
2025-06-02 18:04:30,634:INFO:          ipywidgets: 8.1.7
2025-06-02 18:04:30,634:INFO:                tqdm: 4.67.1
2025-06-02 18:04:30,635:INFO:               numpy: 1.26.4
2025-06-02 18:04:30,635:INFO:              pandas: 2.0.1
2025-06-02 18:04:30,635:INFO:              jinja2: 3.1.6
2025-06-02 18:04:30,635:INFO:               scipy: 1.10.1
2025-06-02 18:04:30,635:INFO:              joblib: 1.3.2
2025-06-02 18:04:30,635:INFO:             sklearn: 1.4.2
2025-06-02 18:04:30,635:INFO:                pyod: 2.0.5
2025-06-02 18:04:30,635:INFO:            imblearn: 0.13.0
2025-06-02 18:04:30,635:INFO:   category_encoders: 2.7.0
2025-06-02 18:04:30,635:INFO:            lightgbm: 4.6.0
2025-06-02 18:04:30,636:INFO:               numba: 0.61.0
2025-06-02 18:04:30,636:INFO:            requests: 2.32.3
2025-06-02 18:04:30,636:INFO:          matplotlib: 3.7.1
2025-06-02 18:04:30,636:INFO:          scikitplot: 0.3.7
2025-06-02 18:04:30,636:INFO:         yellowbrick: 1.5
2025-06-02 18:04:30,636:INFO:              plotly: 6.1.2
2025-06-02 18:04:30,636:INFO:    plotly-resampler: Not installed
2025-06-02 18:04:30,636:INFO:             kaleido: 0.2.1
2025-06-02 18:04:30,636:INFO:           schemdraw: 0.15
2025-06-02 18:04:30,636:INFO:         statsmodels: 0.14.4
2025-06-02 18:04:30,636:INFO:              sktime: 0.26.0
2025-06-02 18:04:30,637:INFO:               tbats: 1.1.3
2025-06-02 18:04:30,637:INFO:            pmdarima: 2.0.4
2025-06-02 18:04:30,637:INFO:              psutil: 7.0.0
2025-06-02 18:04:30,637:INFO:          markupsafe: 2.1.2
2025-06-02 18:04:30,637:INFO:             pickle5: Not installed
2025-06-02 18:04:30,637:INFO:         cloudpickle: 3.1.1
2025-06-02 18:04:30,637:INFO:         deprecation: 2.1.0
2025-06-02 18:04:30,637:INFO:              xxhash: 3.5.0
2025-06-02 18:04:30,637:INFO:           wurlitzer: Not installed
2025-06-02 18:04:30,637:INFO:PyCaret optional dependencies:
2025-06-02 18:04:30,638:INFO:                shap: 0.44.1
2025-06-02 18:04:30,638:INFO:           interpret: 0.6.9
2025-06-02 18:04:30,638:INFO:                umap: 0.5.7
2025-06-02 18:04:30,638:INFO:     ydata_profiling: 4.16.1
2025-06-02 18:04:30,638:INFO:  explainerdashboard: 0.4.8
2025-06-02 18:04:30,638:INFO:             autoviz: Not installed
2025-06-02 18:04:30,638:INFO:           fairlearn: 0.7.0
2025-06-02 18:04:30,638:INFO:          deepchecks: Not installed
2025-06-02 18:04:30,638:INFO:             xgboost: 3.0.2
2025-06-02 18:04:30,638:INFO:            catboost: 1.2.8
2025-06-02 18:04:30,638:INFO:              kmodes: 0.12.2
2025-06-02 18:04:30,639:INFO:             mlxtend: 0.23.4
2025-06-02 18:04:30,639:INFO:       statsforecast: 1.5.0
2025-06-02 18:04:30,639:INFO:        tune_sklearn: Not installed
2025-06-02 18:04:30,639:INFO:                 ray: Not installed
2025-06-02 18:04:30,639:INFO:            hyperopt: 0.2.7
2025-06-02 18:04:30,639:INFO:              optuna: 4.3.0
2025-06-02 18:04:30,639:INFO:               skopt: 0.10.2
2025-06-02 18:04:30,639:INFO:              mlflow: 2.22.0
2025-06-02 18:04:30,639:INFO:              gradio: 5.32.0
2025-06-02 18:04:30,639:INFO:             fastapi: 0.115.12
2025-06-02 18:04:30,639:INFO:             uvicorn: 0.34.3
2025-06-02 18:04:30,639:INFO:              m2cgen: 0.10.0
2025-06-02 18:04:30,639:INFO:           evidently: 0.4.40
2025-06-02 18:04:30,640:INFO:               fugue: 0.8.5
2025-06-02 18:04:30,640:INFO:           streamlit: Not installed
2025-06-02 18:04:30,640:INFO:             prophet: Not installed
2025-06-02 18:04:30,640:INFO:None
2025-06-02 18:04:30,640:INFO:Set up data.
2025-06-02 18:04:30,753:INFO:Set up folding strategy.
2025-06-02 18:04:30,754:INFO:Set up train/test split.
2025-06-02 18:04:30,829:INFO:Set up index.
2025-06-02 18:04:30,830:INFO:Assigning column types.
2025-06-02 18:04:30,885:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 18:04:30,888:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 18:04:30,900:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 18:04:30,908:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,053:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,127:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:04:31,133:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:04:31,134:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,142:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,149:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,355:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:04:31,359:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:04:31,361:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 18:04:31,368:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,376:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,505:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,577:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,578:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:04:31,582:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:04:31,590:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,598:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,804:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:04:31,808:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:04:31,809:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 18:04:31,828:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:04:31,963:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:04:32,038:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:04:32,039:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:04:32,043:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:04:32,059:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:04:32,188:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:04:32,259:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:04:32,260:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:04:32,264:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:04:32,265:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 18:04:32,417:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:04:32,488:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:04:32,489:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:04:32,493:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:04:32,637:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:04:32,709:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:04:32,710:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:04:32,714:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:04:32,715:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 18:04:32,861:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:04:32,941:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:04:32,948:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:04:33,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:04:33,167:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:04:33,171:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:04:33,172:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 18:04:33,402:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:04:33,407:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:04:33,645:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:04:33,649:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:04:33,653:INFO:Preparing preprocessing pipeline...
2025-06-02 18:04:33,654:INFO:Set up simple imputation.
2025-06-02 18:04:33,654:INFO:Set up removing multicollinearity.
2025-06-02 18:04:33,661:INFO:Set up column name cleaning.
2025-06-02 18:04:33,982:INFO:Finished creating preprocessing pipeline.
2025-06-02 18:04:33,999:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 18:04:33,999:INFO:Creating final display dataframe.
2025-06-02 18:04:34,409:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 98)
5   Transformed train set shape        (3358, 98)
6    Transformed test set shape        (1120, 98)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              8d8f
2025-06-02 18:04:34,655:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:04:34,659:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:04:34,912:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:04:34,916:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:04:34,919:INFO:setup() successfully completed in 4.39s...............
2025-06-02 18:04:34,939:INFO:Initializing compare_models()
2025-06-02 18:04:34,939:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 18:04:34,939:INFO:Checking exceptions
2025-06-02 18:04:34,967:INFO:Preparing display monitor
2025-06-02 18:04:35,058:INFO:Initializing Linear Regression
2025-06-02 18:04:35,058:INFO:Total runtime is 0.0 minutes
2025-06-02 18:04:35,077:INFO:SubProcess create_model() called ==================================
2025-06-02 18:04:35,079:INFO:Initializing create_model()
2025-06-02 18:04:35,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:04:35,080:INFO:Checking exceptions
2025-06-02 18:04:35,081:INFO:Importing libraries
2025-06-02 18:04:35,081:INFO:Copying training dataset
2025-06-02 18:04:35,195:INFO:Defining folds
2025-06-02 18:04:35,195:INFO:Declaring metric variables
2025-06-02 18:04:35,210:INFO:Importing untrained model
2025-06-02 18:04:35,224:INFO:Linear Regression Imported successfully
2025-06-02 18:04:35,251:INFO:Starting cross validation
2025-06-02 18:04:35,257:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:04:37,025:INFO:Calculating mean and std
2025-06-02 18:04:37,029:INFO:Creating metrics dataframe
2025-06-02 18:04:37,034:INFO:Uploading results into container
2025-06-02 18:04:37,035:INFO:Uploading model into container now
2025-06-02 18:04:37,037:INFO:_master_model_container: 1
2025-06-02 18:04:37,038:INFO:_display_container: 2
2025-06-02 18:04:37,038:INFO:LinearRegression(n_jobs=-1)
2025-06-02 18:04:37,038:INFO:create_model() successfully completed......................................
2025-06-02 18:04:42,406:INFO:SubProcess create_model() end ==================================
2025-06-02 18:04:42,407:INFO:Creating metrics dataframe
2025-06-02 18:04:42,447:INFO:Initializing Lasso Regression
2025-06-02 18:04:42,447:INFO:Total runtime is 0.12313608725865682 minutes
2025-06-02 18:04:42,465:INFO:SubProcess create_model() called ==================================
2025-06-02 18:04:42,466:INFO:Initializing create_model()
2025-06-02 18:04:42,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:04:42,467:INFO:Checking exceptions
2025-06-02 18:04:42,468:INFO:Importing libraries
2025-06-02 18:04:42,468:INFO:Copying training dataset
2025-06-02 18:04:42,553:INFO:Defining folds
2025-06-02 18:04:42,553:INFO:Declaring metric variables
2025-06-02 18:04:42,565:INFO:Importing untrained model
2025-06-02 18:04:42,575:INFO:Lasso Regression Imported successfully
2025-06-02 18:04:42,594:INFO:Starting cross validation
2025-06-02 18:04:42,598:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:04:43,701:INFO:Calculating mean and std
2025-06-02 18:04:43,704:INFO:Creating metrics dataframe
2025-06-02 18:04:43,711:INFO:Uploading results into container
2025-06-02 18:04:43,712:INFO:Uploading model into container now
2025-06-02 18:04:43,714:INFO:_master_model_container: 2
2025-06-02 18:04:43,714:INFO:_display_container: 2
2025-06-02 18:04:43,715:INFO:Lasso(random_state=123)
2025-06-02 18:04:43,716:INFO:create_model() successfully completed......................................
2025-06-02 18:04:45,223:INFO:SubProcess create_model() end ==================================
2025-06-02 18:04:45,224:INFO:Creating metrics dataframe
2025-06-02 18:04:45,242:INFO:Initializing Ridge Regression
2025-06-02 18:04:45,242:INFO:Total runtime is 0.16973400115966797 minutes
2025-06-02 18:04:45,255:INFO:SubProcess create_model() called ==================================
2025-06-02 18:04:45,256:INFO:Initializing create_model()
2025-06-02 18:04:45,257:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:04:45,257:INFO:Checking exceptions
2025-06-02 18:04:45,257:INFO:Importing libraries
2025-06-02 18:04:45,258:INFO:Copying training dataset
2025-06-02 18:04:45,342:INFO:Defining folds
2025-06-02 18:04:45,343:INFO:Declaring metric variables
2025-06-02 18:04:45,355:INFO:Importing untrained model
2025-06-02 18:04:45,369:INFO:Ridge Regression Imported successfully
2025-06-02 18:04:45,395:INFO:Starting cross validation
2025-06-02 18:04:45,400:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:04:46,127:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.98589e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 18:04:46,194:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.48483e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 18:04:46,185:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14793e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 18:04:46,817:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.19864e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 18:04:46,876:INFO:Calculating mean and std
2025-06-02 18:04:46,880:INFO:Creating metrics dataframe
2025-06-02 18:04:46,885:INFO:Uploading results into container
2025-06-02 18:04:46,887:INFO:Uploading model into container now
2025-06-02 18:04:46,888:INFO:_master_model_container: 3
2025-06-02 18:04:46,888:INFO:_display_container: 2
2025-06-02 18:04:46,889:INFO:Ridge(random_state=123)
2025-06-02 18:04:46,890:INFO:create_model() successfully completed......................................
2025-06-02 18:04:48,570:INFO:SubProcess create_model() end ==================================
2025-06-02 18:04:48,570:INFO:Creating metrics dataframe
2025-06-02 18:04:48,588:INFO:Initializing Elastic Net
2025-06-02 18:04:48,588:INFO:Total runtime is 0.22549023230870566 minutes
2025-06-02 18:04:48,599:INFO:SubProcess create_model() called ==================================
2025-06-02 18:04:48,600:INFO:Initializing create_model()
2025-06-02 18:04:48,601:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:04:48,601:INFO:Checking exceptions
2025-06-02 18:04:48,601:INFO:Importing libraries
2025-06-02 18:04:48,602:INFO:Copying training dataset
2025-06-02 18:04:48,681:INFO:Defining folds
2025-06-02 18:04:48,681:INFO:Declaring metric variables
2025-06-02 18:04:48,695:INFO:Importing untrained model
2025-06-02 18:04:48,706:INFO:Elastic Net Imported successfully
2025-06-02 18:04:48,732:INFO:Starting cross validation
2025-06-02 18:04:48,736:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:04:50,454:INFO:Calculating mean and std
2025-06-02 18:04:50,457:INFO:Creating metrics dataframe
2025-06-02 18:04:50,461:INFO:Uploading results into container
2025-06-02 18:04:50,462:INFO:Uploading model into container now
2025-06-02 18:04:50,463:INFO:_master_model_container: 4
2025-06-02 18:04:50,463:INFO:_display_container: 2
2025-06-02 18:04:50,464:INFO:ElasticNet(random_state=123)
2025-06-02 18:04:50,465:INFO:create_model() successfully completed......................................
2025-06-02 18:04:51,951:INFO:SubProcess create_model() end ==================================
2025-06-02 18:04:51,952:INFO:Creating metrics dataframe
2025-06-02 18:04:51,967:INFO:Initializing Least Angle Regression
2025-06-02 18:04:51,967:INFO:Total runtime is 0.2818079034487406 minutes
2025-06-02 18:04:51,978:INFO:SubProcess create_model() called ==================================
2025-06-02 18:04:51,979:INFO:Initializing create_model()
2025-06-02 18:04:51,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:04:51,979:INFO:Checking exceptions
2025-06-02 18:04:51,979:INFO:Importing libraries
2025-06-02 18:04:51,980:INFO:Copying training dataset
2025-06-02 18:04:52,159:INFO:Defining folds
2025-06-02 18:04:52,159:INFO:Declaring metric variables
2025-06-02 18:04:52,179:INFO:Importing untrained model
2025-06-02 18:04:52,214:INFO:Least Angle Regression Imported successfully
2025-06-02 18:04:52,243:INFO:Starting cross validation
2025-06-02 18:04:52,247:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:04:55,613:INFO:Calculating mean and std
2025-06-02 18:04:55,615:INFO:Creating metrics dataframe
2025-06-02 18:04:55,621:INFO:Uploading results into container
2025-06-02 18:04:55,622:INFO:Uploading model into container now
2025-06-02 18:04:55,626:INFO:_master_model_container: 5
2025-06-02 18:04:55,626:INFO:_display_container: 2
2025-06-02 18:04:55,629:INFO:Lars(random_state=123)
2025-06-02 18:04:55,629:INFO:create_model() successfully completed......................................
2025-06-02 18:04:57,551:INFO:SubProcess create_model() end ==================================
2025-06-02 18:04:57,552:INFO:Creating metrics dataframe
2025-06-02 18:04:57,581:INFO:Initializing Lasso Least Angle Regression
2025-06-02 18:04:57,582:INFO:Total runtime is 0.3753933986028035 minutes
2025-06-02 18:04:57,602:INFO:SubProcess create_model() called ==================================
2025-06-02 18:04:57,605:INFO:Initializing create_model()
2025-06-02 18:04:57,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:04:57,605:INFO:Checking exceptions
2025-06-02 18:04:57,605:INFO:Importing libraries
2025-06-02 18:04:57,606:INFO:Copying training dataset
2025-06-02 18:04:57,745:INFO:Defining folds
2025-06-02 18:04:57,746:INFO:Declaring metric variables
2025-06-02 18:04:57,763:INFO:Importing untrained model
2025-06-02 18:04:57,783:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 18:04:57,831:INFO:Starting cross validation
2025-06-02 18:04:57,845:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:04:59,153:INFO:Calculating mean and std
2025-06-02 18:04:59,158:INFO:Creating metrics dataframe
2025-06-02 18:04:59,162:INFO:Uploading results into container
2025-06-02 18:04:59,163:INFO:Uploading model into container now
2025-06-02 18:04:59,164:INFO:_master_model_container: 6
2025-06-02 18:04:59,165:INFO:_display_container: 2
2025-06-02 18:04:59,165:INFO:LassoLars(random_state=123)
2025-06-02 18:04:59,166:INFO:create_model() successfully completed......................................
2025-06-02 18:05:01,856:INFO:SubProcess create_model() end ==================================
2025-06-02 18:05:01,857:INFO:Creating metrics dataframe
2025-06-02 18:05:01,884:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 18:05:01,884:INFO:Total runtime is 0.44709035158157345 minutes
2025-06-02 18:05:01,900:INFO:SubProcess create_model() called ==================================
2025-06-02 18:05:01,901:INFO:Initializing create_model()
2025-06-02 18:05:01,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:05:01,902:INFO:Checking exceptions
2025-06-02 18:05:01,902:INFO:Importing libraries
2025-06-02 18:05:01,902:INFO:Copying training dataset
2025-06-02 18:05:01,980:INFO:Defining folds
2025-06-02 18:05:01,980:INFO:Declaring metric variables
2025-06-02 18:05:01,991:INFO:Importing untrained model
2025-06-02 18:05:02,004:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 18:05:02,026:INFO:Starting cross validation
2025-06-02 18:05:02,029:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:05:02,981:INFO:Calculating mean and std
2025-06-02 18:05:02,984:INFO:Creating metrics dataframe
2025-06-02 18:05:02,987:INFO:Uploading results into container
2025-06-02 18:05:02,988:INFO:Uploading model into container now
2025-06-02 18:05:02,989:INFO:_master_model_container: 7
2025-06-02 18:05:02,990:INFO:_display_container: 2
2025-06-02 18:05:02,990:INFO:OrthogonalMatchingPursuit()
2025-06-02 18:05:02,991:INFO:create_model() successfully completed......................................
2025-06-02 18:05:04,381:INFO:SubProcess create_model() end ==================================
2025-06-02 18:05:04,381:INFO:Creating metrics dataframe
2025-06-02 18:05:04,399:INFO:Initializing Bayesian Ridge
2025-06-02 18:05:04,399:INFO:Total runtime is 0.4890144308408101 minutes
2025-06-02 18:05:04,411:INFO:SubProcess create_model() called ==================================
2025-06-02 18:05:04,411:INFO:Initializing create_model()
2025-06-02 18:05:04,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:05:04,412:INFO:Checking exceptions
2025-06-02 18:05:04,412:INFO:Importing libraries
2025-06-02 18:05:04,413:INFO:Copying training dataset
2025-06-02 18:05:04,499:INFO:Defining folds
2025-06-02 18:05:04,499:INFO:Declaring metric variables
2025-06-02 18:05:04,512:INFO:Importing untrained model
2025-06-02 18:05:04,526:INFO:Bayesian Ridge Imported successfully
2025-06-02 18:05:04,556:INFO:Starting cross validation
2025-06-02 18:05:04,561:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:05:05,464:INFO:Calculating mean and std
2025-06-02 18:05:05,467:INFO:Creating metrics dataframe
2025-06-02 18:05:05,471:INFO:Uploading results into container
2025-06-02 18:05:05,472:INFO:Uploading model into container now
2025-06-02 18:05:05,473:INFO:_master_model_container: 8
2025-06-02 18:05:05,473:INFO:_display_container: 2
2025-06-02 18:05:05,474:INFO:BayesianRidge()
2025-06-02 18:05:05,474:INFO:create_model() successfully completed......................................
2025-06-02 18:05:07,108:INFO:SubProcess create_model() end ==================================
2025-06-02 18:05:07,108:INFO:Creating metrics dataframe
2025-06-02 18:05:07,127:INFO:Initializing Passive Aggressive Regressor
2025-06-02 18:05:07,128:INFO:Total runtime is 0.534491741657257 minutes
2025-06-02 18:05:07,141:INFO:SubProcess create_model() called ==================================
2025-06-02 18:05:07,142:INFO:Initializing create_model()
2025-06-02 18:05:07,143:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:05:07,143:INFO:Checking exceptions
2025-06-02 18:05:07,144:INFO:Importing libraries
2025-06-02 18:05:07,144:INFO:Copying training dataset
2025-06-02 18:05:07,205:INFO:Defining folds
2025-06-02 18:05:07,206:INFO:Declaring metric variables
2025-06-02 18:05:07,218:INFO:Importing untrained model
2025-06-02 18:05:07,229:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 18:05:07,254:INFO:Starting cross validation
2025-06-02 18:05:07,258:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:05:08,309:INFO:Calculating mean and std
2025-06-02 18:05:08,314:INFO:Creating metrics dataframe
2025-06-02 18:05:08,318:INFO:Uploading results into container
2025-06-02 18:05:08,320:INFO:Uploading model into container now
2025-06-02 18:05:08,321:INFO:_master_model_container: 9
2025-06-02 18:05:08,321:INFO:_display_container: 2
2025-06-02 18:05:08,322:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 18:05:08,322:INFO:create_model() successfully completed......................................
2025-06-02 18:05:10,010:INFO:SubProcess create_model() end ==================================
2025-06-02 18:05:10,010:INFO:Creating metrics dataframe
2025-06-02 18:05:10,024:INFO:Initializing Huber Regressor
2025-06-02 18:05:10,024:INFO:Total runtime is 0.5827533404032389 minutes
2025-06-02 18:05:10,033:INFO:SubProcess create_model() called ==================================
2025-06-02 18:05:10,034:INFO:Initializing create_model()
2025-06-02 18:05:10,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:05:10,035:INFO:Checking exceptions
2025-06-02 18:05:10,035:INFO:Importing libraries
2025-06-02 18:05:10,036:INFO:Copying training dataset
2025-06-02 18:05:10,099:INFO:Defining folds
2025-06-02 18:05:10,099:INFO:Declaring metric variables
2025-06-02 18:05:10,115:INFO:Importing untrained model
2025-06-02 18:05:10,126:INFO:Huber Regressor Imported successfully
2025-06-02 18:05:10,150:INFO:Starting cross validation
2025-06-02 18:05:10,154:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:05:12,066:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:05:12,110:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:05:12,122:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:05:12,194:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:05:12,235:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:05:12,297:INFO:Calculating mean and std
2025-06-02 18:05:12,300:INFO:Creating metrics dataframe
2025-06-02 18:05:12,303:INFO:Uploading results into container
2025-06-02 18:05:12,304:INFO:Uploading model into container now
2025-06-02 18:05:12,306:INFO:_master_model_container: 10
2025-06-02 18:05:12,306:INFO:_display_container: 2
2025-06-02 18:05:12,307:INFO:HuberRegressor()
2025-06-02 18:05:12,308:INFO:create_model() successfully completed......................................
2025-06-02 18:05:13,665:INFO:SubProcess create_model() end ==================================
2025-06-02 18:05:13,665:INFO:Creating metrics dataframe
2025-06-02 18:05:13,681:INFO:Initializing K Neighbors Regressor
2025-06-02 18:05:13,681:INFO:Total runtime is 0.6437171578407287 minutes
2025-06-02 18:05:13,691:INFO:SubProcess create_model() called ==================================
2025-06-02 18:05:13,692:INFO:Initializing create_model()
2025-06-02 18:05:13,692:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:05:13,692:INFO:Checking exceptions
2025-06-02 18:05:13,692:INFO:Importing libraries
2025-06-02 18:05:13,693:INFO:Copying training dataset
2025-06-02 18:05:13,764:INFO:Defining folds
2025-06-02 18:05:13,764:INFO:Declaring metric variables
2025-06-02 18:05:13,779:INFO:Importing untrained model
2025-06-02 18:05:13,791:INFO:K Neighbors Regressor Imported successfully
2025-06-02 18:05:13,818:INFO:Starting cross validation
2025-06-02 18:05:13,821:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:05:14,825:INFO:Calculating mean and std
2025-06-02 18:05:14,828:INFO:Creating metrics dataframe
2025-06-02 18:05:14,832:INFO:Uploading results into container
2025-06-02 18:05:14,833:INFO:Uploading model into container now
2025-06-02 18:05:14,835:INFO:_master_model_container: 11
2025-06-02 18:05:14,835:INFO:_display_container: 2
2025-06-02 18:05:14,836:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 18:05:14,836:INFO:create_model() successfully completed......................................
2025-06-02 18:05:16,183:INFO:SubProcess create_model() end ==================================
2025-06-02 18:05:16,183:INFO:Creating metrics dataframe
2025-06-02 18:05:16,207:INFO:Initializing Decision Tree Regressor
2025-06-02 18:05:16,207:INFO:Total runtime is 0.6858017007509867 minutes
2025-06-02 18:05:16,217:INFO:SubProcess create_model() called ==================================
2025-06-02 18:05:16,218:INFO:Initializing create_model()
2025-06-02 18:05:16,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:05:16,219:INFO:Checking exceptions
2025-06-02 18:05:16,219:INFO:Importing libraries
2025-06-02 18:05:16,220:INFO:Copying training dataset
2025-06-02 18:05:16,286:INFO:Defining folds
2025-06-02 18:05:16,287:INFO:Declaring metric variables
2025-06-02 18:05:16,301:INFO:Importing untrained model
2025-06-02 18:05:16,312:INFO:Decision Tree Regressor Imported successfully
2025-06-02 18:05:16,335:INFO:Starting cross validation
2025-06-02 18:05:16,340:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:05:17,374:INFO:Calculating mean and std
2025-06-02 18:05:17,377:INFO:Creating metrics dataframe
2025-06-02 18:05:17,381:INFO:Uploading results into container
2025-06-02 18:05:17,382:INFO:Uploading model into container now
2025-06-02 18:05:17,382:INFO:_master_model_container: 12
2025-06-02 18:05:17,382:INFO:_display_container: 2
2025-06-02 18:05:17,383:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 18:05:17,384:INFO:create_model() successfully completed......................................
2025-06-02 18:05:18,944:INFO:SubProcess create_model() end ==================================
2025-06-02 18:05:18,945:INFO:Creating metrics dataframe
2025-06-02 18:05:18,971:INFO:Initializing Random Forest Regressor
2025-06-02 18:05:18,973:INFO:Total runtime is 0.7319096485773722 minutes
2025-06-02 18:05:18,988:INFO:SubProcess create_model() called ==================================
2025-06-02 18:05:18,990:INFO:Initializing create_model()
2025-06-02 18:05:18,990:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:05:18,991:INFO:Checking exceptions
2025-06-02 18:05:18,992:INFO:Importing libraries
2025-06-02 18:05:18,992:INFO:Copying training dataset
2025-06-02 18:05:19,077:INFO:Defining folds
2025-06-02 18:05:19,077:INFO:Declaring metric variables
2025-06-02 18:05:19,092:INFO:Importing untrained model
2025-06-02 18:05:19,104:INFO:Random Forest Regressor Imported successfully
2025-06-02 18:05:19,136:INFO:Starting cross validation
2025-06-02 18:05:19,142:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:05:32,757:INFO:Calculating mean and std
2025-06-02 18:05:32,759:INFO:Creating metrics dataframe
2025-06-02 18:05:32,764:INFO:Uploading results into container
2025-06-02 18:05:32,765:INFO:Uploading model into container now
2025-06-02 18:05:32,766:INFO:_master_model_container: 13
2025-06-02 18:05:32,766:INFO:_display_container: 2
2025-06-02 18:05:32,766:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:05:32,767:INFO:create_model() successfully completed......................................
2025-06-02 18:05:34,392:INFO:SubProcess create_model() end ==================================
2025-06-02 18:05:34,393:INFO:Creating metrics dataframe
2025-06-02 18:05:34,426:INFO:Initializing Extra Trees Regressor
2025-06-02 18:05:34,428:INFO:Total runtime is 0.9894982258478799 minutes
2025-06-02 18:05:34,443:INFO:SubProcess create_model() called ==================================
2025-06-02 18:05:34,444:INFO:Initializing create_model()
2025-06-02 18:05:34,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:05:34,445:INFO:Checking exceptions
2025-06-02 18:05:34,446:INFO:Importing libraries
2025-06-02 18:05:34,446:INFO:Copying training dataset
2025-06-02 18:05:34,679:INFO:Defining folds
2025-06-02 18:05:34,680:INFO:Declaring metric variables
2025-06-02 18:05:34,701:INFO:Importing untrained model
2025-06-02 18:05:34,754:INFO:Extra Trees Regressor Imported successfully
2025-06-02 18:05:34,818:INFO:Starting cross validation
2025-06-02 18:05:34,828:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:05:42,920:INFO:Calculating mean and std
2025-06-02 18:05:42,922:INFO:Creating metrics dataframe
2025-06-02 18:05:42,927:INFO:Uploading results into container
2025-06-02 18:05:42,928:INFO:Uploading model into container now
2025-06-02 18:05:42,929:INFO:_master_model_container: 14
2025-06-02 18:05:42,929:INFO:_display_container: 2
2025-06-02 18:05:42,930:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:05:42,931:INFO:create_model() successfully completed......................................
2025-06-02 18:05:44,425:INFO:SubProcess create_model() end ==================================
2025-06-02 18:05:44,426:INFO:Creating metrics dataframe
2025-06-02 18:05:44,471:INFO:Initializing AdaBoost Regressor
2025-06-02 18:05:44,472:INFO:Total runtime is 1.1568896253903707 minutes
2025-06-02 18:05:44,490:INFO:SubProcess create_model() called ==================================
2025-06-02 18:05:44,491:INFO:Initializing create_model()
2025-06-02 18:05:44,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:05:44,493:INFO:Checking exceptions
2025-06-02 18:05:44,494:INFO:Importing libraries
2025-06-02 18:05:44,495:INFO:Copying training dataset
2025-06-02 18:05:44,611:INFO:Defining folds
2025-06-02 18:05:44,611:INFO:Declaring metric variables
2025-06-02 18:05:44,627:INFO:Importing untrained model
2025-06-02 18:05:44,643:INFO:AdaBoost Regressor Imported successfully
2025-06-02 18:05:44,671:INFO:Starting cross validation
2025-06-02 18:05:44,675:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:05:49,396:INFO:Calculating mean and std
2025-06-02 18:05:49,398:INFO:Creating metrics dataframe
2025-06-02 18:05:49,404:INFO:Uploading results into container
2025-06-02 18:05:49,406:INFO:Uploading model into container now
2025-06-02 18:05:49,408:INFO:_master_model_container: 15
2025-06-02 18:05:49,409:INFO:_display_container: 2
2025-06-02 18:05:49,410:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 18:05:49,410:INFO:create_model() successfully completed......................................
2025-06-02 18:05:50,995:INFO:SubProcess create_model() end ==================================
2025-06-02 18:05:50,995:INFO:Creating metrics dataframe
2025-06-02 18:05:51,026:INFO:Initializing Gradient Boosting Regressor
2025-06-02 18:05:51,027:INFO:Total runtime is 1.2661379416783651 minutes
2025-06-02 18:05:51,039:INFO:SubProcess create_model() called ==================================
2025-06-02 18:05:51,040:INFO:Initializing create_model()
2025-06-02 18:05:51,040:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:05:51,041:INFO:Checking exceptions
2025-06-02 18:05:51,041:INFO:Importing libraries
2025-06-02 18:05:51,041:INFO:Copying training dataset
2025-06-02 18:05:51,102:INFO:Defining folds
2025-06-02 18:05:51,102:INFO:Declaring metric variables
2025-06-02 18:05:51,117:INFO:Importing untrained model
2025-06-02 18:05:51,130:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 18:05:51,154:INFO:Starting cross validation
2025-06-02 18:05:51,159:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:05:56,369:INFO:Calculating mean and std
2025-06-02 18:05:56,371:INFO:Creating metrics dataframe
2025-06-02 18:05:56,374:INFO:Uploading results into container
2025-06-02 18:05:56,375:INFO:Uploading model into container now
2025-06-02 18:05:56,376:INFO:_master_model_container: 16
2025-06-02 18:05:56,376:INFO:_display_container: 2
2025-06-02 18:05:56,377:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 18:05:56,378:INFO:create_model() successfully completed......................................
2025-06-02 18:05:57,802:INFO:SubProcess create_model() end ==================================
2025-06-02 18:05:57,802:INFO:Creating metrics dataframe
2025-06-02 18:05:57,834:INFO:Initializing Extreme Gradient Boosting
2025-06-02 18:05:57,835:INFO:Total runtime is 1.3796118060747784 minutes
2025-06-02 18:05:57,851:INFO:SubProcess create_model() called ==================================
2025-06-02 18:05:57,852:INFO:Initializing create_model()
2025-06-02 18:05:57,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:05:57,853:INFO:Checking exceptions
2025-06-02 18:05:57,853:INFO:Importing libraries
2025-06-02 18:05:57,853:INFO:Copying training dataset
2025-06-02 18:05:57,923:INFO:Defining folds
2025-06-02 18:05:57,924:INFO:Declaring metric variables
2025-06-02 18:05:57,939:INFO:Importing untrained model
2025-06-02 18:05:57,955:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 18:05:57,981:INFO:Starting cross validation
2025-06-02 18:05:57,986:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:06:02,744:INFO:Calculating mean and std
2025-06-02 18:06:02,747:INFO:Creating metrics dataframe
2025-06-02 18:06:02,750:INFO:Uploading results into container
2025-06-02 18:06:02,751:INFO:Uploading model into container now
2025-06-02 18:06:02,753:INFO:_master_model_container: 17
2025-06-02 18:06:02,753:INFO:_display_container: 2
2025-06-02 18:06:02,758:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 18:06:02,760:INFO:create_model() successfully completed......................................
2025-06-02 18:06:04,174:INFO:SubProcess create_model() end ==================================
2025-06-02 18:06:04,174:INFO:Creating metrics dataframe
2025-06-02 18:06:04,209:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 18:06:04,210:INFO:Total runtime is 1.4858619372049968 minutes
2025-06-02 18:06:04,225:INFO:SubProcess create_model() called ==================================
2025-06-02 18:06:04,225:INFO:Initializing create_model()
2025-06-02 18:06:04,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:06:04,227:INFO:Checking exceptions
2025-06-02 18:06:04,228:INFO:Importing libraries
2025-06-02 18:06:04,228:INFO:Copying training dataset
2025-06-02 18:06:04,303:INFO:Defining folds
2025-06-02 18:06:04,303:INFO:Declaring metric variables
2025-06-02 18:06:04,320:INFO:Importing untrained model
2025-06-02 18:06:04,335:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 18:06:04,365:INFO:Starting cross validation
2025-06-02 18:06:04,371:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:06:07,222:INFO:Calculating mean and std
2025-06-02 18:06:07,225:INFO:Creating metrics dataframe
2025-06-02 18:06:07,230:INFO:Uploading results into container
2025-06-02 18:06:07,232:INFO:Uploading model into container now
2025-06-02 18:06:07,233:INFO:_master_model_container: 18
2025-06-02 18:06:07,233:INFO:_display_container: 2
2025-06-02 18:06:07,235:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:06:07,235:INFO:create_model() successfully completed......................................
2025-06-02 18:06:08,893:INFO:SubProcess create_model() end ==================================
2025-06-02 18:06:08,894:INFO:Creating metrics dataframe
2025-06-02 18:06:08,926:INFO:Initializing CatBoost Regressor
2025-06-02 18:06:08,926:INFO:Total runtime is 1.5644632498423259 minutes
2025-06-02 18:06:08,940:INFO:SubProcess create_model() called ==================================
2025-06-02 18:06:08,942:INFO:Initializing create_model()
2025-06-02 18:06:08,942:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:06:08,943:INFO:Checking exceptions
2025-06-02 18:06:08,943:INFO:Importing libraries
2025-06-02 18:06:08,944:INFO:Copying training dataset
2025-06-02 18:06:09,008:INFO:Defining folds
2025-06-02 18:06:09,008:INFO:Declaring metric variables
2025-06-02 18:06:09,027:INFO:Importing untrained model
2025-06-02 18:06:09,050:INFO:CatBoost Regressor Imported successfully
2025-06-02 18:06:09,076:INFO:Starting cross validation
2025-06-02 18:06:09,081:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:06:40,956:INFO:Calculating mean and std
2025-06-02 18:06:40,959:INFO:Creating metrics dataframe
2025-06-02 18:06:40,965:INFO:Uploading results into container
2025-06-02 18:06:40,967:INFO:Uploading model into container now
2025-06-02 18:06:40,968:INFO:_master_model_container: 19
2025-06-02 18:06:40,968:INFO:_display_container: 2
2025-06-02 18:06:40,968:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6FAEF8280>
2025-06-02 18:06:40,969:INFO:create_model() successfully completed......................................
2025-06-02 18:06:42,614:INFO:SubProcess create_model() end ==================================
2025-06-02 18:06:42,615:INFO:Creating metrics dataframe
2025-06-02 18:06:42,642:INFO:Initializing Dummy Regressor
2025-06-02 18:06:42,642:INFO:Total runtime is 2.1263855576515196 minutes
2025-06-02 18:06:42,659:INFO:SubProcess create_model() called ==================================
2025-06-02 18:06:42,660:INFO:Initializing create_model()
2025-06-02 18:06:42,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702245840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:06:42,660:INFO:Checking exceptions
2025-06-02 18:06:42,661:INFO:Importing libraries
2025-06-02 18:06:42,661:INFO:Copying training dataset
2025-06-02 18:06:42,764:INFO:Defining folds
2025-06-02 18:06:42,765:INFO:Declaring metric variables
2025-06-02 18:06:42,784:INFO:Importing untrained model
2025-06-02 18:06:42,803:INFO:Dummy Regressor Imported successfully
2025-06-02 18:06:42,832:INFO:Starting cross validation
2025-06-02 18:06:42,837:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:06:44,089:INFO:Calculating mean and std
2025-06-02 18:06:44,092:INFO:Creating metrics dataframe
2025-06-02 18:06:44,096:INFO:Uploading results into container
2025-06-02 18:06:44,098:INFO:Uploading model into container now
2025-06-02 18:06:44,099:INFO:_master_model_container: 20
2025-06-02 18:06:44,100:INFO:_display_container: 2
2025-06-02 18:06:44,100:INFO:DummyRegressor()
2025-06-02 18:06:44,101:INFO:create_model() successfully completed......................................
2025-06-02 18:06:45,731:INFO:SubProcess create_model() end ==================================
2025-06-02 18:06:45,732:INFO:Creating metrics dataframe
2025-06-02 18:06:45,796:INFO:Initializing create_model()
2025-06-02 18:06:45,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:06:45,797:INFO:Checking exceptions
2025-06-02 18:06:45,808:INFO:Importing libraries
2025-06-02 18:06:45,808:INFO:Copying training dataset
2025-06-02 18:06:45,904:INFO:Defining folds
2025-06-02 18:06:45,904:INFO:Declaring metric variables
2025-06-02 18:06:45,905:INFO:Importing untrained model
2025-06-02 18:06:45,905:INFO:Declaring custom model
2025-06-02 18:06:45,909:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 18:06:45,914:INFO:Cross validation set to False
2025-06-02 18:06:45,914:INFO:Fitting Model
2025-06-02 18:06:46,605:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 18:06:46,632:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003780 seconds.
2025-06-02 18:06:46,632:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-06-02 18:06:46,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-06-02 18:06:46,633:INFO:[LightGBM] [Info] Total Bins 6291
2025-06-02 18:06:46,658:INFO:[LightGBM] [Info] Number of data points in the train set: 3358, number of used features: 97
2025-06-02 18:06:46,660:INFO:[LightGBM] [Info] Start training from score -0.484244
2025-06-02 18:06:47,049:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:06:47,049:INFO:create_model() successfully completed......................................
2025-06-02 18:06:48,676:INFO:Initializing create_model()
2025-06-02 18:06:48,677:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=<catboost.core.CatBoostRegressor object at 0x000001B6FAEF8280>, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:06:48,677:INFO:Checking exceptions
2025-06-02 18:06:48,684:INFO:Importing libraries
2025-06-02 18:06:48,684:INFO:Copying training dataset
2025-06-02 18:06:48,777:INFO:Defining folds
2025-06-02 18:06:48,777:INFO:Declaring metric variables
2025-06-02 18:06:48,778:INFO:Importing untrained model
2025-06-02 18:06:48,778:INFO:Declaring custom model
2025-06-02 18:06:48,780:INFO:CatBoost Regressor Imported successfully
2025-06-02 18:06:48,784:INFO:Cross validation set to False
2025-06-02 18:06:48,785:INFO:Fitting Model
2025-06-02 18:06:56,279:INFO:<catboost.core.CatBoostRegressor object at 0x000001B6EF7A1F90>
2025-06-02 18:06:56,279:INFO:create_model() successfully completed......................................
2025-06-02 18:06:57,681:INFO:Initializing create_model()
2025-06-02 18:06:57,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:06:57,681:INFO:Checking exceptions
2025-06-02 18:06:57,685:INFO:Importing libraries
2025-06-02 18:06:57,686:INFO:Copying training dataset
2025-06-02 18:06:57,798:INFO:Defining folds
2025-06-02 18:06:57,798:INFO:Declaring metric variables
2025-06-02 18:06:57,799:INFO:Importing untrained model
2025-06-02 18:06:57,799:INFO:Declaring custom model
2025-06-02 18:06:57,803:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 18:06:57,808:INFO:Cross validation set to False
2025-06-02 18:06:57,808:INFO:Fitting Model
2025-06-02 18:06:58,790:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 18:06:58,790:INFO:create_model() successfully completed......................................
2025-06-02 18:07:00,219:INFO:_master_model_container: 20
2025-06-02 18:07:00,219:INFO:_display_container: 2
2025-06-02 18:07:00,226:INFO:[LGBMRegressor(n_jobs=-1, random_state=123), <catboost.core.CatBoostRegressor object at 0x000001B6EF7A1F90>, XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)]
2025-06-02 18:07:00,226:INFO:compare_models() successfully completed......................................
2025-06-02 18:07:00,246:INFO:Initializing tune_model()
2025-06-02 18:07:00,247:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>)
2025-06-02 18:07:00,247:INFO:Checking exceptions
2025-06-02 18:07:00,247:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 18:07:00,327:INFO:Copying training dataset
2025-06-02 18:07:00,399:INFO:Checking base model
2025-06-02 18:07:00,400:INFO:Base model : Light Gradient Boosting Machine
2025-06-02 18:07:00,420:INFO:Declaring metric variables
2025-06-02 18:07:00,439:INFO:Defining Hyperparameters
2025-06-02 18:07:02,714:INFO:Tuning with n_jobs=-1
2025-06-02 18:07:02,729:INFO:Initializing skopt.BayesSearchCV
2025-06-02 18:07:20,800:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.8608120752388259), ('actual_estimator__bagging_freq', 1), ('actual_estimator__feature_fraction', 0.4284489606984907), ('actual_estimator__learning_rate', 0.016133245419918712), ('actual_estimator__min_child_samples', 95), ('actual_estimator__min_split_gain', 0.8209314243567916), ('actual_estimator__n_estimators', 239), ('actual_estimator__num_leaves', 183), ('actual_estimator__reg_alpha', 8.662569304197528e-07), ('actual_estimator__reg_lambda', 5.001062744294253e-06)])
2025-06-02 18:07:20,801:INFO:Hyperparameter search completed
2025-06-02 18:07:20,801:INFO:SubProcess create_model() called ==================================
2025-06-02 18:07:20,803:INFO:Initializing create_model()
2025-06-02 18:07:20,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B702254EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.8608120752388259, 'bagging_freq': 1, 'feature_fraction': 0.4284489606984907, 'learning_rate': 0.016133245419918712, 'min_child_samples': 95, 'min_split_gain': 0.8209314243567916, 'n_estimators': 239, 'num_leaves': 183, 'reg_alpha': 8.662569304197528e-07, 'reg_lambda': 5.001062744294253e-06})
2025-06-02 18:07:20,804:INFO:Checking exceptions
2025-06-02 18:07:20,804:INFO:Importing libraries
2025-06-02 18:07:20,805:INFO:Copying training dataset
2025-06-02 18:07:20,876:INFO:Defining folds
2025-06-02 18:07:20,876:INFO:Declaring metric variables
2025-06-02 18:07:20,884:INFO:Importing untrained model
2025-06-02 18:07:20,884:INFO:Declaring custom model
2025-06-02 18:07:20,902:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 18:07:20,930:INFO:Starting cross validation
2025-06-02 18:07:20,934:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:07:22,766:INFO:Calculating mean and std
2025-06-02 18:07:22,767:INFO:Creating metrics dataframe
2025-06-02 18:07:22,781:INFO:Finalizing model
2025-06-02 18:07:23,181:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 18:07:23,181:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 18:07:23,181:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 18:07:23,210:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 18:07:23,212:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 18:07:23,212:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 18:07:23,212:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 18:07:23,219:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003261 seconds.
2025-06-02 18:07:23,219:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 18:07:23,220:INFO:[LightGBM] [Info] Total Bins 6280
2025-06-02 18:07:23,245:INFO:[LightGBM] [Info] Number of data points in the train set: 3358, number of used features: 95
2025-06-02 18:07:23,246:INFO:[LightGBM] [Info] Start training from score -0.484244
2025-06-02 18:07:23,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 18:07:23,519:INFO:Uploading results into container
2025-06-02 18:07:23,521:INFO:Uploading model into container now
2025-06-02 18:07:23,524:INFO:_master_model_container: 21
2025-06-02 18:07:23,525:INFO:_display_container: 3
2025-06-02 18:07:23,528:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06)
2025-06-02 18:07:23,529:INFO:create_model() successfully completed......................................
2025-06-02 18:07:24,950:INFO:SubProcess create_model() end ==================================
2025-06-02 18:07:24,950:INFO:choose_better activated
2025-06-02 18:07:24,959:INFO:SubProcess create_model() called ==================================
2025-06-02 18:07:24,961:INFO:Initializing create_model()
2025-06-02 18:07:24,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:07:24,961:INFO:Checking exceptions
2025-06-02 18:07:24,964:INFO:Importing libraries
2025-06-02 18:07:24,965:INFO:Copying training dataset
2025-06-02 18:07:25,035:INFO:Defining folds
2025-06-02 18:07:25,035:INFO:Declaring metric variables
2025-06-02 18:07:25,036:INFO:Importing untrained model
2025-06-02 18:07:25,036:INFO:Declaring custom model
2025-06-02 18:07:25,039:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 18:07:25,040:INFO:Starting cross validation
2025-06-02 18:07:25,044:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:07:26,747:INFO:Calculating mean and std
2025-06-02 18:07:26,748:INFO:Creating metrics dataframe
2025-06-02 18:07:26,751:INFO:Finalizing model
2025-06-02 18:07:27,137:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 18:07:27,142:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003543 seconds.
2025-06-02 18:07:27,142:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 18:07:27,143:INFO:[LightGBM] [Info] Total Bins 6291
2025-06-02 18:07:27,143:INFO:[LightGBM] [Info] Number of data points in the train set: 3358, number of used features: 97
2025-06-02 18:07:27,145:INFO:[LightGBM] [Info] Start training from score -0.484244
2025-06-02 18:07:27,316:INFO:Uploading results into container
2025-06-02 18:07:27,317:INFO:Uploading model into container now
2025-06-02 18:07:27,318:INFO:_master_model_container: 22
2025-06-02 18:07:27,318:INFO:_display_container: 4
2025-06-02 18:07:27,319:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:07:27,319:INFO:create_model() successfully completed......................................
2025-06-02 18:07:28,670:INFO:SubProcess create_model() end ==================================
2025-06-02 18:07:28,672:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8801
2025-06-02 18:07:28,675:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06) result for R2 is 0.8221
2025-06-02 18:07:28,676:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 18:07:28,676:INFO:choose_better completed
2025-06-02 18:07:28,676:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 18:07:28,693:INFO:_master_model_container: 22
2025-06-02 18:07:28,693:INFO:_display_container: 3
2025-06-02 18:07:28,694:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:07:28,696:INFO:tune_model() successfully completed......................................
2025-06-02 18:07:30,068:INFO:Initializing finalize_model()
2025-06-02 18:07:30,068:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 18:07:30,069:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:07:30,114:INFO:Initializing create_model()
2025-06-02 18:07:30,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:07:30,114:INFO:Checking exceptions
2025-06-02 18:07:30,117:INFO:Importing libraries
2025-06-02 18:07:30,117:INFO:Copying training dataset
2025-06-02 18:07:30,123:INFO:Defining folds
2025-06-02 18:07:30,124:INFO:Declaring metric variables
2025-06-02 18:07:30,124:INFO:Importing untrained model
2025-06-02 18:07:30,124:INFO:Declaring custom model
2025-06-02 18:07:30,126:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 18:07:30,128:INFO:Cross validation set to False
2025-06-02 18:07:30,128:INFO:Fitting Model
2025-06-02 18:07:30,546:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 18:07:30,553:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005196 seconds.
2025-06-02 18:07:30,553:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 18:07:30,554:INFO:[LightGBM] [Info] Total Bins 6237
2025-06-02 18:07:30,554:INFO:[LightGBM] [Info] Number of data points in the train set: 4478, number of used features: 95
2025-06-02 18:07:30,556:INFO:[LightGBM] [Info] Start training from score -0.483793
2025-06-02 18:07:30,758:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 18:07:30,758:INFO:create_model() successfully completed......................................
2025-06-02 18:07:32,110:INFO:_master_model_container: 22
2025-06-02 18:07:32,110:INFO:_display_container: 3
2025-06-02 18:07:32,127:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 18:07:32,128:INFO:finalize_model() successfully completed......................................
2025-06-02 18:07:33,507:INFO:Initializing save_model()
2025-06-02 18:07:33,507:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 18:07:33,507:INFO:Adding model into prep_pipe
2025-06-02 18:07:33,508:WARNING:Only Model saved as it was a pipeline.
2025-06-02 18:07:33,527:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 18:07:33,551:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 18:07:33,551:INFO:save_model() successfully completed......................................
2025-06-02 18:07:34,936:INFO:Initializing load_model()
2025-06-02 18:07:34,936:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 18:07:35,014:INFO:Initializing get_config()
2025-06-02 18:07:35,014:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, variable=X_test)
2025-06-02 18:07:35,015:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 18:07:35,015:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 18:07:35,064:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
717                         1.0                        1.0   
1329                       27.0                       72.0   
2669                       28.0                       31.0   
253                        83.0                       83.0   
3622                        8.0                       23.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
717                       0.0                1.000000   
1329                     45.0               37.000000   
2669                      3.0               28.750000   
253                       0.0               83.000000   
3622                     15.0               12.285714   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
717                    0.000000                     1.0   
1329                  15.555555                    27.0   
2669                   1.125000                    28.0   
253                    0.000000                    83.0   
3622                   6.122449                     8.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
717                                 92.0                                92.0   
1329                                45.0                                58.0   
2669                                61.0                                74.0   
253                                 86.0                                86.0   
3622                                46.0                                87.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
717                                0.0                        92.000000  ...   
1329                              13.0                        55.111111  ...   
2669                              13.0                        64.250000  ...   
253                                0.0                        86.000000  ...   
3622                              41.0                        75.285713  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
717                  7.0                   1             2.0   
1329                 6.0                   1             4.0   
2669                 4.0                   1            16.0   
253                  3.0                   1            24.0   
3622                 7.0                   0             1.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
717                  False                     False   
1329                 False                     False   
2669                 False                     False   
253                  False                     False   
3622                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
717                       False                        False   
1329                       True                        False   
2669                      False                        False   
253                       False                        False   
3622                      False                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
717                       False                      True   
1329                      False                     False   
2669                       True                     False   
253                       False                     False   
3622                      False                      True   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
717                     False  
1329                    False  
2669                    False  
253                      True  
3622                    False  

[1120 rows x 146 columns]
2025-06-02 18:07:35,064:INFO:get_config() successfully completed......................................
2025-06-02 18:07:35,069:INFO:Initializing get_config()
2025-06-02 18:07:35,069:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, variable=y_test)
2025-06-02 18:07:35,070:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 18:07:35,070:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 18:07:35,089:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
717     1.188433
1329   -0.222675
2669   -0.245426
253     0.000000
3622   -1.777082
Name: target, Length: 1120, dtype: float32
2025-06-02 18:07:35,090:INFO:get_config() successfully completed......................................
2025-06-02 18:07:35,111:INFO:Initializing predict_model()
2025-06-02 18:07:35,111:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B6DC888CA0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B702CA2680>)
2025-06-02 18:07:35,111:INFO:Checking exceptions
2025-06-02 18:07:35,111:INFO:Preloading libraries
2025-06-02 18:07:35,115:INFO:Set up data.
2025-06-02 18:07:35,191:INFO:Set up index.
2025-06-02 18:09:48,145:INFO:PyCaret RegressionExperiment
2025-06-02 18:09:48,145:INFO:Logging name: reg-default-name
2025-06-02 18:09:48,145:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 18:09:48,145:INFO:version 3.3.2
2025-06-02 18:09:48,145:INFO:Initializing setup()
2025-06-02 18:09:48,145:INFO:self.USI: 158d
2025-06-02 18:09:48,145:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 18:09:48,146:INFO:Checking environment
2025-06-02 18:09:48,146:INFO:python_version: 3.10.16
2025-06-02 18:09:48,146:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 18:09:48,146:INFO:machine: AMD64
2025-06-02 18:09:48,146:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 18:09:48,153:INFO:Memory: svmem(total=6378008576, available=675164160, percent=89.4, used=5702844416, free=675164160)
2025-06-02 18:09:48,153:INFO:Physical Core: 4
2025-06-02 18:09:48,153:INFO:Logical Core: 8
2025-06-02 18:09:48,153:INFO:Checking libraries
2025-06-02 18:09:48,154:INFO:System:
2025-06-02 18:09:48,154:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 18:09:48,154:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 18:09:48,154:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 18:09:48,154:INFO:PyCaret required dependencies:
2025-06-02 18:09:48,156:INFO:                 pip: 25.1
2025-06-02 18:09:48,156:INFO:          setuptools: 78.1.1
2025-06-02 18:09:48,157:INFO:             pycaret: 3.3.2
2025-06-02 18:09:48,157:INFO:             IPython: 8.37.0
2025-06-02 18:09:48,157:INFO:          ipywidgets: 8.1.7
2025-06-02 18:09:48,157:INFO:                tqdm: 4.67.1
2025-06-02 18:09:48,157:INFO:               numpy: 1.26.4
2025-06-02 18:09:48,157:INFO:              pandas: 2.0.1
2025-06-02 18:09:48,157:INFO:              jinja2: 3.1.6
2025-06-02 18:09:48,157:INFO:               scipy: 1.10.1
2025-06-02 18:09:48,157:INFO:              joblib: 1.3.2
2025-06-02 18:09:48,157:INFO:             sklearn: 1.4.2
2025-06-02 18:09:48,157:INFO:                pyod: 2.0.5
2025-06-02 18:09:48,157:INFO:            imblearn: 0.13.0
2025-06-02 18:09:48,157:INFO:   category_encoders: 2.7.0
2025-06-02 18:09:48,157:INFO:            lightgbm: 4.6.0
2025-06-02 18:09:48,158:INFO:               numba: 0.61.0
2025-06-02 18:09:48,158:INFO:            requests: 2.32.3
2025-06-02 18:09:48,158:INFO:          matplotlib: 3.7.1
2025-06-02 18:09:48,158:INFO:          scikitplot: 0.3.7
2025-06-02 18:09:48,158:INFO:         yellowbrick: 1.5
2025-06-02 18:09:48,158:INFO:              plotly: 6.1.2
2025-06-02 18:09:48,158:INFO:    plotly-resampler: Not installed
2025-06-02 18:09:48,158:INFO:             kaleido: 0.2.1
2025-06-02 18:09:48,158:INFO:           schemdraw: 0.15
2025-06-02 18:09:48,158:INFO:         statsmodels: 0.14.4
2025-06-02 18:09:48,158:INFO:              sktime: 0.26.0
2025-06-02 18:09:48,158:INFO:               tbats: 1.1.3
2025-06-02 18:09:48,158:INFO:            pmdarima: 2.0.4
2025-06-02 18:09:48,158:INFO:              psutil: 7.0.0
2025-06-02 18:09:48,158:INFO:          markupsafe: 2.1.2
2025-06-02 18:09:48,159:INFO:             pickle5: Not installed
2025-06-02 18:09:48,159:INFO:         cloudpickle: 3.1.1
2025-06-02 18:09:48,159:INFO:         deprecation: 2.1.0
2025-06-02 18:09:48,159:INFO:              xxhash: 3.5.0
2025-06-02 18:09:48,159:INFO:           wurlitzer: Not installed
2025-06-02 18:09:48,159:INFO:PyCaret optional dependencies:
2025-06-02 18:09:48,159:INFO:                shap: 0.44.1
2025-06-02 18:09:48,159:INFO:           interpret: 0.6.9
2025-06-02 18:09:48,159:INFO:                umap: 0.5.7
2025-06-02 18:09:48,160:INFO:     ydata_profiling: 4.16.1
2025-06-02 18:09:48,160:INFO:  explainerdashboard: 0.4.8
2025-06-02 18:09:48,160:INFO:             autoviz: Not installed
2025-06-02 18:09:48,160:INFO:           fairlearn: 0.7.0
2025-06-02 18:09:48,160:INFO:          deepchecks: Not installed
2025-06-02 18:09:48,160:INFO:             xgboost: 3.0.2
2025-06-02 18:09:48,160:INFO:            catboost: 1.2.8
2025-06-02 18:09:48,160:INFO:              kmodes: 0.12.2
2025-06-02 18:09:48,160:INFO:             mlxtend: 0.23.4
2025-06-02 18:09:48,160:INFO:       statsforecast: 1.5.0
2025-06-02 18:09:48,160:INFO:        tune_sklearn: Not installed
2025-06-02 18:09:48,160:INFO:                 ray: Not installed
2025-06-02 18:09:48,160:INFO:            hyperopt: 0.2.7
2025-06-02 18:09:48,160:INFO:              optuna: 4.3.0
2025-06-02 18:09:48,160:INFO:               skopt: 0.10.2
2025-06-02 18:09:48,161:INFO:              mlflow: 2.22.0
2025-06-02 18:09:48,161:INFO:              gradio: 5.32.0
2025-06-02 18:09:48,161:INFO:             fastapi: 0.115.12
2025-06-02 18:09:48,161:INFO:             uvicorn: 0.34.3
2025-06-02 18:09:48,161:INFO:              m2cgen: 0.10.0
2025-06-02 18:09:48,161:INFO:           evidently: 0.4.40
2025-06-02 18:09:48,161:INFO:               fugue: 0.8.5
2025-06-02 18:09:48,161:INFO:           streamlit: Not installed
2025-06-02 18:09:48,161:INFO:             prophet: Not installed
2025-06-02 18:09:48,161:INFO:None
2025-06-02 18:09:48,161:INFO:Set up data.
2025-06-02 18:09:48,297:INFO:Set up folding strategy.
2025-06-02 18:09:48,297:INFO:Set up train/test split.
2025-06-02 18:09:48,351:INFO:Set up index.
2025-06-02 18:09:48,352:INFO:Assigning column types.
2025-06-02 18:09:48,411:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 18:09:48,414:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 18:09:48,424:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 18:09:48,431:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:09:48,572:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:09:48,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:09:48,645:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:09:48,653:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:09:48,654:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 18:09:48,661:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 18:09:48,668:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:09:48,795:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:09:48,863:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:09:48,864:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:09:48,868:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:09:48,869:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 18:09:48,876:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 18:09:48,883:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:09:49,007:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:09:49,080:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:09:49,080:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:09:49,084:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:09:49,093:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 18:09:49,103:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:09:49,230:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:09:49,308:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:09:49,309:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:09:49,314:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:09:49,315:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 18:09:49,332:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:09:49,467:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:09:49,541:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:09:49,542:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:09:49,546:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:09:49,561:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:09:49,696:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:09:49,770:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:09:49,771:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:09:49,775:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:09:49,776:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 18:09:49,929:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:09:50,003:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:09:50,004:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:09:50,008:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:09:50,153:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:09:50,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:09:50,227:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:09:50,230:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:09:50,231:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 18:09:50,375:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:09:50,452:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:09:50,456:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:09:50,595:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:09:50,665:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:09:50,669:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:09:50,670:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 18:09:50,889:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:09:50,893:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:09:51,104:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:09:51,109:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:09:51,114:INFO:Preparing preprocessing pipeline...
2025-06-02 18:09:51,114:INFO:Set up simple imputation.
2025-06-02 18:09:51,115:INFO:Set up removing multicollinearity.
2025-06-02 18:09:51,122:INFO:Set up column name cleaning.
2025-06-02 18:09:51,342:INFO:Finished creating preprocessing pipeline.
2025-06-02 18:09:51,358:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 18:09:51,359:INFO:Creating final display dataframe.
2025-06-02 18:09:51,751:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 98)
5   Transformed train set shape        (3358, 98)
6    Transformed test set shape        (1120, 98)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              158d
2025-06-02 18:09:51,966:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:09:51,970:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:09:52,185:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:09:52,189:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:09:52,192:INFO:setup() successfully completed in 4.11s...............
2025-06-02 18:09:52,237:INFO:Initializing compare_models()
2025-06-02 18:09:52,237:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 18:09:52,237:INFO:Checking exceptions
2025-06-02 18:09:52,262:INFO:Preparing display monitor
2025-06-02 18:09:52,331:INFO:Initializing Linear Regression
2025-06-02 18:09:52,332:INFO:Total runtime is 0.0 minutes
2025-06-02 18:09:52,347:INFO:SubProcess create_model() called ==================================
2025-06-02 18:09:52,348:INFO:Initializing create_model()
2025-06-02 18:09:52,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:09:52,348:INFO:Checking exceptions
2025-06-02 18:09:52,349:INFO:Importing libraries
2025-06-02 18:09:52,350:INFO:Copying training dataset
2025-06-02 18:09:52,557:INFO:Defining folds
2025-06-02 18:09:52,557:INFO:Declaring metric variables
2025-06-02 18:09:52,575:INFO:Importing untrained model
2025-06-02 18:09:52,604:INFO:Linear Regression Imported successfully
2025-06-02 18:09:52,633:INFO:Starting cross validation
2025-06-02 18:09:52,638:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:09:53,697:INFO:Calculating mean and std
2025-06-02 18:09:53,700:INFO:Creating metrics dataframe
2025-06-02 18:09:53,706:INFO:Uploading results into container
2025-06-02 18:09:53,708:INFO:Uploading model into container now
2025-06-02 18:09:53,712:INFO:_master_model_container: 1
2025-06-02 18:09:53,712:INFO:_display_container: 2
2025-06-02 18:09:53,713:INFO:LinearRegression(n_jobs=-1)
2025-06-02 18:09:53,713:INFO:create_model() successfully completed......................................
2025-06-02 18:09:59,053:INFO:SubProcess create_model() end ==================================
2025-06-02 18:09:59,053:INFO:Creating metrics dataframe
2025-06-02 18:09:59,069:INFO:Initializing Lasso Regression
2025-06-02 18:09:59,069:INFO:Total runtime is 0.11229478120803833 minutes
2025-06-02 18:09:59,079:INFO:SubProcess create_model() called ==================================
2025-06-02 18:09:59,080:INFO:Initializing create_model()
2025-06-02 18:09:59,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:09:59,080:INFO:Checking exceptions
2025-06-02 18:09:59,081:INFO:Importing libraries
2025-06-02 18:09:59,082:INFO:Copying training dataset
2025-06-02 18:09:59,168:INFO:Defining folds
2025-06-02 18:09:59,168:INFO:Declaring metric variables
2025-06-02 18:09:59,180:INFO:Importing untrained model
2025-06-02 18:09:59,194:INFO:Lasso Regression Imported successfully
2025-06-02 18:09:59,227:INFO:Starting cross validation
2025-06-02 18:09:59,231:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:00,140:INFO:Calculating mean and std
2025-06-02 18:10:00,143:INFO:Creating metrics dataframe
2025-06-02 18:10:00,147:INFO:Uploading results into container
2025-06-02 18:10:00,148:INFO:Uploading model into container now
2025-06-02 18:10:00,149:INFO:_master_model_container: 2
2025-06-02 18:10:00,149:INFO:_display_container: 2
2025-06-02 18:10:00,151:INFO:Lasso(random_state=123)
2025-06-02 18:10:00,151:INFO:create_model() successfully completed......................................
2025-06-02 18:10:01,898:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:01,898:INFO:Creating metrics dataframe
2025-06-02 18:10:01,918:INFO:Initializing Ridge Regression
2025-06-02 18:10:01,918:INFO:Total runtime is 0.15978046655654907 minutes
2025-06-02 18:10:01,930:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:01,931:INFO:Initializing create_model()
2025-06-02 18:10:01,931:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:01,932:INFO:Checking exceptions
2025-06-02 18:10:01,932:INFO:Importing libraries
2025-06-02 18:10:01,933:INFO:Copying training dataset
2025-06-02 18:10:02,011:INFO:Defining folds
2025-06-02 18:10:02,011:INFO:Declaring metric variables
2025-06-02 18:10:02,027:INFO:Importing untrained model
2025-06-02 18:10:02,038:INFO:Ridge Regression Imported successfully
2025-06-02 18:10:02,063:INFO:Starting cross validation
2025-06-02 18:10:02,068:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:02,914:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14793e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 18:10:02,921:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.98589e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 18:10:02,994:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.48483e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 18:10:03,005:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.19864e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 18:10:03,077:INFO:Calculating mean and std
2025-06-02 18:10:03,079:INFO:Creating metrics dataframe
2025-06-02 18:10:03,083:INFO:Uploading results into container
2025-06-02 18:10:03,084:INFO:Uploading model into container now
2025-06-02 18:10:03,085:INFO:_master_model_container: 3
2025-06-02 18:10:03,086:INFO:_display_container: 2
2025-06-02 18:10:03,087:INFO:Ridge(random_state=123)
2025-06-02 18:10:03,087:INFO:create_model() successfully completed......................................
2025-06-02 18:10:04,691:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:04,692:INFO:Creating metrics dataframe
2025-06-02 18:10:04,710:INFO:Initializing Elastic Net
2025-06-02 18:10:04,710:INFO:Total runtime is 0.20631515582402546 minutes
2025-06-02 18:10:04,721:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:04,722:INFO:Initializing create_model()
2025-06-02 18:10:04,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:04,723:INFO:Checking exceptions
2025-06-02 18:10:04,724:INFO:Importing libraries
2025-06-02 18:10:04,725:INFO:Copying training dataset
2025-06-02 18:10:04,801:INFO:Defining folds
2025-06-02 18:10:04,801:INFO:Declaring metric variables
2025-06-02 18:10:04,819:INFO:Importing untrained model
2025-06-02 18:10:04,832:INFO:Elastic Net Imported successfully
2025-06-02 18:10:04,855:INFO:Starting cross validation
2025-06-02 18:10:04,861:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:05,726:INFO:Calculating mean and std
2025-06-02 18:10:05,728:INFO:Creating metrics dataframe
2025-06-02 18:10:05,733:INFO:Uploading results into container
2025-06-02 18:10:05,735:INFO:Uploading model into container now
2025-06-02 18:10:05,736:INFO:_master_model_container: 4
2025-06-02 18:10:05,737:INFO:_display_container: 2
2025-06-02 18:10:05,737:INFO:ElasticNet(random_state=123)
2025-06-02 18:10:05,738:INFO:create_model() successfully completed......................................
2025-06-02 18:10:07,068:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:07,068:INFO:Creating metrics dataframe
2025-06-02 18:10:07,082:INFO:Initializing Least Angle Regression
2025-06-02 18:10:07,083:INFO:Total runtime is 0.24586594104766846 minutes
2025-06-02 18:10:07,092:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:07,093:INFO:Initializing create_model()
2025-06-02 18:10:07,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:07,094:INFO:Checking exceptions
2025-06-02 18:10:07,094:INFO:Importing libraries
2025-06-02 18:10:07,095:INFO:Copying training dataset
2025-06-02 18:10:07,159:INFO:Defining folds
2025-06-02 18:10:07,160:INFO:Declaring metric variables
2025-06-02 18:10:07,173:INFO:Importing untrained model
2025-06-02 18:10:07,183:INFO:Least Angle Regression Imported successfully
2025-06-02 18:10:07,208:INFO:Starting cross validation
2025-06-02 18:10:07,212:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:08,058:INFO:Calculating mean and std
2025-06-02 18:10:08,060:INFO:Creating metrics dataframe
2025-06-02 18:10:08,064:INFO:Uploading results into container
2025-06-02 18:10:08,066:INFO:Uploading model into container now
2025-06-02 18:10:08,067:INFO:_master_model_container: 5
2025-06-02 18:10:08,067:INFO:_display_container: 2
2025-06-02 18:10:08,070:INFO:Lars(random_state=123)
2025-06-02 18:10:08,070:INFO:create_model() successfully completed......................................
2025-06-02 18:10:09,393:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:09,394:INFO:Creating metrics dataframe
2025-06-02 18:10:09,407:INFO:Initializing Lasso Least Angle Regression
2025-06-02 18:10:09,407:INFO:Total runtime is 0.28459545771280925 minutes
2025-06-02 18:10:09,418:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:09,418:INFO:Initializing create_model()
2025-06-02 18:10:09,419:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:09,419:INFO:Checking exceptions
2025-06-02 18:10:09,420:INFO:Importing libraries
2025-06-02 18:10:09,421:INFO:Copying training dataset
2025-06-02 18:10:09,479:INFO:Defining folds
2025-06-02 18:10:09,479:INFO:Declaring metric variables
2025-06-02 18:10:09,492:INFO:Importing untrained model
2025-06-02 18:10:09,501:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 18:10:09,526:INFO:Starting cross validation
2025-06-02 18:10:09,530:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:10,453:INFO:Calculating mean and std
2025-06-02 18:10:10,455:INFO:Creating metrics dataframe
2025-06-02 18:10:10,458:INFO:Uploading results into container
2025-06-02 18:10:10,459:INFO:Uploading model into container now
2025-06-02 18:10:10,460:INFO:_master_model_container: 6
2025-06-02 18:10:10,461:INFO:_display_container: 2
2025-06-02 18:10:10,462:INFO:LassoLars(random_state=123)
2025-06-02 18:10:10,462:INFO:create_model() successfully completed......................................
2025-06-02 18:10:11,869:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:11,869:INFO:Creating metrics dataframe
2025-06-02 18:10:11,886:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 18:10:11,887:INFO:Total runtime is 0.325939412911733 minutes
2025-06-02 18:10:11,897:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:11,898:INFO:Initializing create_model()
2025-06-02 18:10:11,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:11,898:INFO:Checking exceptions
2025-06-02 18:10:11,899:INFO:Importing libraries
2025-06-02 18:10:11,899:INFO:Copying training dataset
2025-06-02 18:10:11,977:INFO:Defining folds
2025-06-02 18:10:11,977:INFO:Declaring metric variables
2025-06-02 18:10:11,988:INFO:Importing untrained model
2025-06-02 18:10:12,001:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 18:10:12,031:INFO:Starting cross validation
2025-06-02 18:10:12,036:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:13,382:INFO:Calculating mean and std
2025-06-02 18:10:13,384:INFO:Creating metrics dataframe
2025-06-02 18:10:13,388:INFO:Uploading results into container
2025-06-02 18:10:13,389:INFO:Uploading model into container now
2025-06-02 18:10:13,390:INFO:_master_model_container: 7
2025-06-02 18:10:13,391:INFO:_display_container: 2
2025-06-02 18:10:13,391:INFO:OrthogonalMatchingPursuit()
2025-06-02 18:10:13,392:INFO:create_model() successfully completed......................................
2025-06-02 18:10:14,733:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:14,733:INFO:Creating metrics dataframe
2025-06-02 18:10:14,750:INFO:Initializing Bayesian Ridge
2025-06-02 18:10:14,750:INFO:Total runtime is 0.373655116558075 minutes
2025-06-02 18:10:14,759:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:14,759:INFO:Initializing create_model()
2025-06-02 18:10:14,760:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:14,760:INFO:Checking exceptions
2025-06-02 18:10:14,761:INFO:Importing libraries
2025-06-02 18:10:14,761:INFO:Copying training dataset
2025-06-02 18:10:14,833:INFO:Defining folds
2025-06-02 18:10:14,834:INFO:Declaring metric variables
2025-06-02 18:10:14,847:INFO:Importing untrained model
2025-06-02 18:10:14,859:INFO:Bayesian Ridge Imported successfully
2025-06-02 18:10:14,882:INFO:Starting cross validation
2025-06-02 18:10:14,887:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:15,910:INFO:Calculating mean and std
2025-06-02 18:10:15,912:INFO:Creating metrics dataframe
2025-06-02 18:10:15,916:INFO:Uploading results into container
2025-06-02 18:10:15,917:INFO:Uploading model into container now
2025-06-02 18:10:15,918:INFO:_master_model_container: 8
2025-06-02 18:10:15,918:INFO:_display_container: 2
2025-06-02 18:10:15,919:INFO:BayesianRidge()
2025-06-02 18:10:15,919:INFO:create_model() successfully completed......................................
2025-06-02 18:10:17,300:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:17,301:INFO:Creating metrics dataframe
2025-06-02 18:10:17,316:INFO:Initializing Passive Aggressive Regressor
2025-06-02 18:10:17,317:INFO:Total runtime is 0.41643903652826947 minutes
2025-06-02 18:10:17,326:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:17,326:INFO:Initializing create_model()
2025-06-02 18:10:17,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:17,327:INFO:Checking exceptions
2025-06-02 18:10:17,327:INFO:Importing libraries
2025-06-02 18:10:17,328:INFO:Copying training dataset
2025-06-02 18:10:17,395:INFO:Defining folds
2025-06-02 18:10:17,396:INFO:Declaring metric variables
2025-06-02 18:10:17,408:INFO:Importing untrained model
2025-06-02 18:10:17,417:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 18:10:17,443:INFO:Starting cross validation
2025-06-02 18:10:17,448:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:18,285:INFO:Calculating mean and std
2025-06-02 18:10:18,287:INFO:Creating metrics dataframe
2025-06-02 18:10:18,290:INFO:Uploading results into container
2025-06-02 18:10:18,291:INFO:Uploading model into container now
2025-06-02 18:10:18,291:INFO:_master_model_container: 9
2025-06-02 18:10:18,292:INFO:_display_container: 2
2025-06-02 18:10:18,293:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 18:10:18,293:INFO:create_model() successfully completed......................................
2025-06-02 18:10:19,627:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:19,627:INFO:Creating metrics dataframe
2025-06-02 18:10:19,645:INFO:Initializing Huber Regressor
2025-06-02 18:10:19,645:INFO:Total runtime is 0.45524354378382365 minutes
2025-06-02 18:10:19,655:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:19,656:INFO:Initializing create_model()
2025-06-02 18:10:19,657:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:19,657:INFO:Checking exceptions
2025-06-02 18:10:19,658:INFO:Importing libraries
2025-06-02 18:10:19,658:INFO:Copying training dataset
2025-06-02 18:10:19,726:INFO:Defining folds
2025-06-02 18:10:19,727:INFO:Declaring metric variables
2025-06-02 18:10:19,737:INFO:Importing untrained model
2025-06-02 18:10:19,749:INFO:Huber Regressor Imported successfully
2025-06-02 18:10:19,776:INFO:Starting cross validation
2025-06-02 18:10:19,780:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:21,939:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:10:21,959:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:10:21,999:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:10:22,045:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:10:22,070:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:10:22,125:INFO:Calculating mean and std
2025-06-02 18:10:22,128:INFO:Creating metrics dataframe
2025-06-02 18:10:22,131:INFO:Uploading results into container
2025-06-02 18:10:22,132:INFO:Uploading model into container now
2025-06-02 18:10:22,133:INFO:_master_model_container: 10
2025-06-02 18:10:22,134:INFO:_display_container: 2
2025-06-02 18:10:22,135:INFO:HuberRegressor()
2025-06-02 18:10:22,135:INFO:create_model() successfully completed......................................
2025-06-02 18:10:23,443:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:23,443:INFO:Creating metrics dataframe
2025-06-02 18:10:23,466:INFO:Initializing K Neighbors Regressor
2025-06-02 18:10:23,466:INFO:Total runtime is 0.5189108888308207 minutes
2025-06-02 18:10:23,475:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:23,476:INFO:Initializing create_model()
2025-06-02 18:10:23,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:23,477:INFO:Checking exceptions
2025-06-02 18:10:23,478:INFO:Importing libraries
2025-06-02 18:10:23,478:INFO:Copying training dataset
2025-06-02 18:10:23,547:INFO:Defining folds
2025-06-02 18:10:23,547:INFO:Declaring metric variables
2025-06-02 18:10:23,563:INFO:Importing untrained model
2025-06-02 18:10:23,574:INFO:K Neighbors Regressor Imported successfully
2025-06-02 18:10:23,599:INFO:Starting cross validation
2025-06-02 18:10:23,604:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:24,513:INFO:Calculating mean and std
2025-06-02 18:10:24,517:INFO:Creating metrics dataframe
2025-06-02 18:10:24,520:INFO:Uploading results into container
2025-06-02 18:10:24,521:INFO:Uploading model into container now
2025-06-02 18:10:24,522:INFO:_master_model_container: 11
2025-06-02 18:10:24,523:INFO:_display_container: 2
2025-06-02 18:10:24,524:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 18:10:24,524:INFO:create_model() successfully completed......................................
2025-06-02 18:10:25,866:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:25,867:INFO:Creating metrics dataframe
2025-06-02 18:10:25,886:INFO:Initializing Decision Tree Regressor
2025-06-02 18:10:25,886:INFO:Total runtime is 0.5592441399892171 minutes
2025-06-02 18:10:25,897:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:25,898:INFO:Initializing create_model()
2025-06-02 18:10:25,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:25,898:INFO:Checking exceptions
2025-06-02 18:10:25,899:INFO:Importing libraries
2025-06-02 18:10:25,899:INFO:Copying training dataset
2025-06-02 18:10:25,973:INFO:Defining folds
2025-06-02 18:10:25,974:INFO:Declaring metric variables
2025-06-02 18:10:25,986:INFO:Importing untrained model
2025-06-02 18:10:25,999:INFO:Decision Tree Regressor Imported successfully
2025-06-02 18:10:26,023:INFO:Starting cross validation
2025-06-02 18:10:26,028:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:27,817:INFO:Calculating mean and std
2025-06-02 18:10:27,819:INFO:Creating metrics dataframe
2025-06-02 18:10:27,823:INFO:Uploading results into container
2025-06-02 18:10:27,825:INFO:Uploading model into container now
2025-06-02 18:10:27,826:INFO:_master_model_container: 12
2025-06-02 18:10:27,826:INFO:_display_container: 2
2025-06-02 18:10:27,827:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 18:10:27,827:INFO:create_model() successfully completed......................................
2025-06-02 18:10:29,183:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:29,184:INFO:Creating metrics dataframe
2025-06-02 18:10:29,203:INFO:Initializing Random Forest Regressor
2025-06-02 18:10:29,203:INFO:Total runtime is 0.614532470703125 minutes
2025-06-02 18:10:29,214:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:29,215:INFO:Initializing create_model()
2025-06-02 18:10:29,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:29,216:INFO:Checking exceptions
2025-06-02 18:10:29,216:INFO:Importing libraries
2025-06-02 18:10:29,217:INFO:Copying training dataset
2025-06-02 18:10:29,283:INFO:Defining folds
2025-06-02 18:10:29,283:INFO:Declaring metric variables
2025-06-02 18:10:29,298:INFO:Importing untrained model
2025-06-02 18:10:29,310:INFO:Random Forest Regressor Imported successfully
2025-06-02 18:10:29,335:INFO:Starting cross validation
2025-06-02 18:10:29,340:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:40,037:INFO:Calculating mean and std
2025-06-02 18:10:40,039:INFO:Creating metrics dataframe
2025-06-02 18:10:40,044:INFO:Uploading results into container
2025-06-02 18:10:40,045:INFO:Uploading model into container now
2025-06-02 18:10:40,046:INFO:_master_model_container: 13
2025-06-02 18:10:40,046:INFO:_display_container: 2
2025-06-02 18:10:40,047:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:10:40,047:INFO:create_model() successfully completed......................................
2025-06-02 18:10:41,433:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:41,434:INFO:Creating metrics dataframe
2025-06-02 18:10:41,451:INFO:Initializing Extra Trees Regressor
2025-06-02 18:10:41,451:INFO:Total runtime is 0.8186619520187378 minutes
2025-06-02 18:10:41,459:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:41,459:INFO:Initializing create_model()
2025-06-02 18:10:41,460:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:41,460:INFO:Checking exceptions
2025-06-02 18:10:41,460:INFO:Importing libraries
2025-06-02 18:10:41,461:INFO:Copying training dataset
2025-06-02 18:10:41,538:INFO:Defining folds
2025-06-02 18:10:41,539:INFO:Declaring metric variables
2025-06-02 18:10:41,553:INFO:Importing untrained model
2025-06-02 18:10:41,569:INFO:Extra Trees Regressor Imported successfully
2025-06-02 18:10:41,596:INFO:Starting cross validation
2025-06-02 18:10:41,601:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:48,578:INFO:Calculating mean and std
2025-06-02 18:10:48,581:INFO:Creating metrics dataframe
2025-06-02 18:10:48,585:INFO:Uploading results into container
2025-06-02 18:10:48,586:INFO:Uploading model into container now
2025-06-02 18:10:48,587:INFO:_master_model_container: 14
2025-06-02 18:10:48,587:INFO:_display_container: 2
2025-06-02 18:10:48,588:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:10:48,589:INFO:create_model() successfully completed......................................
2025-06-02 18:10:49,931:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:49,931:INFO:Creating metrics dataframe
2025-06-02 18:10:49,952:INFO:Initializing AdaBoost Regressor
2025-06-02 18:10:49,954:INFO:Total runtime is 0.9603775223096211 minutes
2025-06-02 18:10:49,965:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:49,966:INFO:Initializing create_model()
2025-06-02 18:10:49,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:49,966:INFO:Checking exceptions
2025-06-02 18:10:49,966:INFO:Importing libraries
2025-06-02 18:10:49,967:INFO:Copying training dataset
2025-06-02 18:10:50,037:INFO:Defining folds
2025-06-02 18:10:50,038:INFO:Declaring metric variables
2025-06-02 18:10:50,052:INFO:Importing untrained model
2025-06-02 18:10:50,064:INFO:AdaBoost Regressor Imported successfully
2025-06-02 18:10:50,087:INFO:Starting cross validation
2025-06-02 18:10:50,092:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:52,435:INFO:Calculating mean and std
2025-06-02 18:10:52,437:INFO:Creating metrics dataframe
2025-06-02 18:10:52,441:INFO:Uploading results into container
2025-06-02 18:10:52,442:INFO:Uploading model into container now
2025-06-02 18:10:52,443:INFO:_master_model_container: 15
2025-06-02 18:10:52,443:INFO:_display_container: 2
2025-06-02 18:10:52,444:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 18:10:52,444:INFO:create_model() successfully completed......................................
2025-06-02 18:10:53,794:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:53,795:INFO:Creating metrics dataframe
2025-06-02 18:10:53,814:INFO:Initializing Gradient Boosting Regressor
2025-06-02 18:10:53,815:INFO:Total runtime is 1.0247423410415648 minutes
2025-06-02 18:10:53,826:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:53,826:INFO:Initializing create_model()
2025-06-02 18:10:53,827:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:53,828:INFO:Checking exceptions
2025-06-02 18:10:53,828:INFO:Importing libraries
2025-06-02 18:10:53,828:INFO:Copying training dataset
2025-06-02 18:10:53,891:INFO:Defining folds
2025-06-02 18:10:53,892:INFO:Declaring metric variables
2025-06-02 18:10:53,907:INFO:Importing untrained model
2025-06-02 18:10:53,921:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 18:10:53,948:INFO:Starting cross validation
2025-06-02 18:10:53,952:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:10:57,844:INFO:Calculating mean and std
2025-06-02 18:10:57,846:INFO:Creating metrics dataframe
2025-06-02 18:10:57,849:INFO:Uploading results into container
2025-06-02 18:10:57,850:INFO:Uploading model into container now
2025-06-02 18:10:57,851:INFO:_master_model_container: 16
2025-06-02 18:10:57,851:INFO:_display_container: 2
2025-06-02 18:10:57,852:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 18:10:57,852:INFO:create_model() successfully completed......................................
2025-06-02 18:10:59,189:INFO:SubProcess create_model() end ==================================
2025-06-02 18:10:59,189:INFO:Creating metrics dataframe
2025-06-02 18:10:59,215:INFO:Initializing Extreme Gradient Boosting
2025-06-02 18:10:59,215:INFO:Total runtime is 1.1147290587425231 minutes
2025-06-02 18:10:59,225:INFO:SubProcess create_model() called ==================================
2025-06-02 18:10:59,226:INFO:Initializing create_model()
2025-06-02 18:10:59,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:10:59,227:INFO:Checking exceptions
2025-06-02 18:10:59,227:INFO:Importing libraries
2025-06-02 18:10:59,227:INFO:Copying training dataset
2025-06-02 18:10:59,501:INFO:Defining folds
2025-06-02 18:10:59,502:INFO:Declaring metric variables
2025-06-02 18:10:59,518:INFO:Importing untrained model
2025-06-02 18:10:59,591:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 18:10:59,703:INFO:Starting cross validation
2025-06-02 18:10:59,709:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:11:02,327:INFO:Calculating mean and std
2025-06-02 18:11:02,329:INFO:Creating metrics dataframe
2025-06-02 18:11:02,333:INFO:Uploading results into container
2025-06-02 18:11:02,334:INFO:Uploading model into container now
2025-06-02 18:11:02,335:INFO:_master_model_container: 17
2025-06-02 18:11:02,335:INFO:_display_container: 2
2025-06-02 18:11:02,340:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 18:11:02,340:INFO:create_model() successfully completed......................................
2025-06-02 18:11:03,666:INFO:SubProcess create_model() end ==================================
2025-06-02 18:11:03,667:INFO:Creating metrics dataframe
2025-06-02 18:11:03,695:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 18:11:03,696:INFO:Total runtime is 1.189414091904958 minutes
2025-06-02 18:11:03,704:INFO:SubProcess create_model() called ==================================
2025-06-02 18:11:03,705:INFO:Initializing create_model()
2025-06-02 18:11:03,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:11:03,705:INFO:Checking exceptions
2025-06-02 18:11:03,706:INFO:Importing libraries
2025-06-02 18:11:03,707:INFO:Copying training dataset
2025-06-02 18:11:03,776:INFO:Defining folds
2025-06-02 18:11:03,777:INFO:Declaring metric variables
2025-06-02 18:11:03,789:INFO:Importing untrained model
2025-06-02 18:11:03,801:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 18:11:03,830:INFO:Starting cross validation
2025-06-02 18:11:03,833:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:11:06,230:INFO:Calculating mean and std
2025-06-02 18:11:06,232:INFO:Creating metrics dataframe
2025-06-02 18:11:06,238:INFO:Uploading results into container
2025-06-02 18:11:06,241:INFO:Uploading model into container now
2025-06-02 18:11:06,242:INFO:_master_model_container: 18
2025-06-02 18:11:06,242:INFO:_display_container: 2
2025-06-02 18:11:06,244:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:11:06,245:INFO:create_model() successfully completed......................................
2025-06-02 18:11:07,680:INFO:SubProcess create_model() end ==================================
2025-06-02 18:11:07,680:INFO:Creating metrics dataframe
2025-06-02 18:11:07,702:INFO:Initializing CatBoost Regressor
2025-06-02 18:11:07,702:INFO:Total runtime is 1.2561879277229309 minutes
2025-06-02 18:11:07,715:INFO:SubProcess create_model() called ==================================
2025-06-02 18:11:07,715:INFO:Initializing create_model()
2025-06-02 18:11:07,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:11:07,716:INFO:Checking exceptions
2025-06-02 18:11:07,717:INFO:Importing libraries
2025-06-02 18:11:07,717:INFO:Copying training dataset
2025-06-02 18:11:07,783:INFO:Defining folds
2025-06-02 18:11:07,783:INFO:Declaring metric variables
2025-06-02 18:11:07,797:INFO:Importing untrained model
2025-06-02 18:11:07,816:INFO:CatBoost Regressor Imported successfully
2025-06-02 18:11:07,845:INFO:Starting cross validation
2025-06-02 18:11:07,850:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:11:31,648:INFO:Calculating mean and std
2025-06-02 18:11:31,650:INFO:Creating metrics dataframe
2025-06-02 18:11:31,655:INFO:Uploading results into container
2025-06-02 18:11:31,656:INFO:Uploading model into container now
2025-06-02 18:11:31,658:INFO:_master_model_container: 19
2025-06-02 18:11:31,658:INFO:_display_container: 2
2025-06-02 18:11:31,659:INFO:<catboost.core.CatBoostRegressor object at 0x000001B7026468C0>
2025-06-02 18:11:31,660:INFO:create_model() successfully completed......................................
2025-06-02 18:11:33,226:INFO:SubProcess create_model() end ==================================
2025-06-02 18:11:33,226:INFO:Creating metrics dataframe
2025-06-02 18:11:33,252:INFO:Initializing Dummy Regressor
2025-06-02 18:11:33,253:INFO:Total runtime is 1.6820353269577026 minutes
2025-06-02 18:11:33,270:INFO:SubProcess create_model() called ==================================
2025-06-02 18:11:33,271:INFO:Initializing create_model()
2025-06-02 18:11:33,271:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70223DED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:11:33,271:INFO:Checking exceptions
2025-06-02 18:11:33,271:INFO:Importing libraries
2025-06-02 18:11:33,272:INFO:Copying training dataset
2025-06-02 18:11:33,419:INFO:Defining folds
2025-06-02 18:11:33,419:INFO:Declaring metric variables
2025-06-02 18:11:33,440:INFO:Importing untrained model
2025-06-02 18:11:33,462:INFO:Dummy Regressor Imported successfully
2025-06-02 18:11:33,507:INFO:Starting cross validation
2025-06-02 18:11:33,511:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:11:37,516:INFO:Calculating mean and std
2025-06-02 18:11:37,541:INFO:Creating metrics dataframe
2025-06-02 18:11:37,547:INFO:Uploading results into container
2025-06-02 18:11:37,550:INFO:Uploading model into container now
2025-06-02 18:11:37,551:INFO:_master_model_container: 20
2025-06-02 18:11:37,551:INFO:_display_container: 2
2025-06-02 18:11:37,552:INFO:DummyRegressor()
2025-06-02 18:11:37,552:INFO:create_model() successfully completed......................................
2025-06-02 18:11:40,569:INFO:SubProcess create_model() end ==================================
2025-06-02 18:11:40,569:INFO:Creating metrics dataframe
2025-06-02 18:11:40,678:INFO:Initializing create_model()
2025-06-02 18:11:40,678:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:11:40,679:INFO:Checking exceptions
2025-06-02 18:11:40,691:INFO:Importing libraries
2025-06-02 18:11:40,693:INFO:Copying training dataset
2025-06-02 18:11:40,817:INFO:Defining folds
2025-06-02 18:11:40,817:INFO:Declaring metric variables
2025-06-02 18:11:40,818:INFO:Importing untrained model
2025-06-02 18:11:40,818:INFO:Declaring custom model
2025-06-02 18:11:40,820:INFO:Extra Trees Regressor Imported successfully
2025-06-02 18:11:40,826:INFO:Cross validation set to False
2025-06-02 18:11:40,826:INFO:Fitting Model
2025-06-02 18:11:43,221:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:11:43,221:INFO:create_model() successfully completed......................................
2025-06-02 18:11:44,794:INFO:Initializing create_model()
2025-06-02 18:11:44,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=<catboost.core.CatBoostRegressor object at 0x000001B7026468C0>, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:11:44,795:INFO:Checking exceptions
2025-06-02 18:11:44,800:INFO:Importing libraries
2025-06-02 18:11:44,801:INFO:Copying training dataset
2025-06-02 18:11:44,880:INFO:Defining folds
2025-06-02 18:11:44,880:INFO:Declaring metric variables
2025-06-02 18:11:44,881:INFO:Importing untrained model
2025-06-02 18:11:44,881:INFO:Declaring custom model
2025-06-02 18:11:44,883:INFO:CatBoost Regressor Imported successfully
2025-06-02 18:11:44,885:INFO:Cross validation set to False
2025-06-02 18:11:44,886:INFO:Fitting Model
2025-06-02 18:11:52,437:INFO:<catboost.core.CatBoostRegressor object at 0x000001B7024D9330>
2025-06-02 18:11:52,438:INFO:create_model() successfully completed......................................
2025-06-02 18:11:53,809:INFO:Initializing create_model()
2025-06-02 18:11:53,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:11:53,810:INFO:Checking exceptions
2025-06-02 18:11:53,814:INFO:Importing libraries
2025-06-02 18:11:53,815:INFO:Copying training dataset
2025-06-02 18:11:53,900:INFO:Defining folds
2025-06-02 18:11:53,900:INFO:Declaring metric variables
2025-06-02 18:11:53,900:INFO:Importing untrained model
2025-06-02 18:11:53,901:INFO:Declaring custom model
2025-06-02 18:11:53,905:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 18:11:53,909:INFO:Cross validation set to False
2025-06-02 18:11:53,909:INFO:Fitting Model
2025-06-02 18:11:54,945:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 18:11:54,946:INFO:create_model() successfully completed......................................
2025-06-02 18:11:56,353:INFO:_master_model_container: 20
2025-06-02 18:11:56,354:INFO:_display_container: 2
2025-06-02 18:11:56,356:INFO:[ExtraTreesRegressor(n_jobs=-1, random_state=123), <catboost.core.CatBoostRegressor object at 0x000001B7024D9330>, XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)]
2025-06-02 18:11:56,357:INFO:compare_models() successfully completed......................................
2025-06-02 18:11:56,466:INFO:Initializing tune_model()
2025-06-02 18:11:56,466:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>)
2025-06-02 18:11:56,466:INFO:Checking exceptions
2025-06-02 18:11:56,467:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 18:11:56,517:INFO:Copying training dataset
2025-06-02 18:11:56,576:INFO:Checking base model
2025-06-02 18:11:56,577:INFO:Base model : Extra Trees Regressor
2025-06-02 18:11:56,587:INFO:Declaring metric variables
2025-06-02 18:11:56,600:INFO:Defining Hyperparameters
2025-06-02 18:11:58,155:INFO:Tuning with n_jobs=-1
2025-06-02 18:11:58,173:INFO:Initializing skopt.BayesSearchCV
2025-06-02 18:15:53,883:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', False), ('actual_estimator__criterion', 'absolute_error'), ('actual_estimator__max_depth', 11), ('actual_estimator__max_features', 0.4556655086335653), ('actual_estimator__min_impurity_decrease', 0.00012891733508622256), ('actual_estimator__min_samples_leaf', 1), ('actual_estimator__min_samples_split', 9), ('actual_estimator__n_estimators', 11)])
2025-06-02 18:15:53,889:INFO:Hyperparameter search completed
2025-06-02 18:15:53,889:INFO:SubProcess create_model() called ==================================
2025-06-02 18:15:53,893:INFO:Initializing create_model()
2025-06-02 18:15:53,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6FB122CB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bootstrap': False, 'criterion': 'absolute_error', 'max_depth': 11, 'max_features': 0.4556655086335653, 'min_impurity_decrease': 0.00012891733508622256, 'min_samples_leaf': 1, 'min_samples_split': 9, 'n_estimators': 11})
2025-06-02 18:15:53,894:INFO:Checking exceptions
2025-06-02 18:15:53,894:INFO:Importing libraries
2025-06-02 18:15:53,894:INFO:Copying training dataset
2025-06-02 18:15:53,962:INFO:Defining folds
2025-06-02 18:15:53,963:INFO:Declaring metric variables
2025-06-02 18:15:53,975:INFO:Importing untrained model
2025-06-02 18:15:53,976:INFO:Declaring custom model
2025-06-02 18:15:53,989:INFO:Extra Trees Regressor Imported successfully
2025-06-02 18:15:54,013:INFO:Starting cross validation
2025-06-02 18:15:54,017:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:16:03,500:INFO:Calculating mean and std
2025-06-02 18:16:03,501:INFO:Creating metrics dataframe
2025-06-02 18:16:03,513:INFO:Finalizing model
2025-06-02 18:16:07,106:INFO:Uploading results into container
2025-06-02 18:16:07,109:INFO:Uploading model into container now
2025-06-02 18:16:07,111:INFO:_master_model_container: 21
2025-06-02 18:16:07,112:INFO:_display_container: 3
2025-06-02 18:16:07,113:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=11,
                    max_features=0.4556655086335653,
                    min_impurity_decrease=0.00012891733508622256,
                    min_samples_split=9, n_estimators=11, n_jobs=-1,
                    random_state=123)
2025-06-02 18:16:07,114:INFO:create_model() successfully completed......................................
2025-06-02 18:16:08,846:INFO:SubProcess create_model() end ==================================
2025-06-02 18:16:08,848:INFO:choose_better activated
2025-06-02 18:16:08,858:INFO:SubProcess create_model() called ==================================
2025-06-02 18:16:08,859:INFO:Initializing create_model()
2025-06-02 18:16:08,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:16:08,860:INFO:Checking exceptions
2025-06-02 18:16:08,863:INFO:Importing libraries
2025-06-02 18:16:08,864:INFO:Copying training dataset
2025-06-02 18:16:08,928:INFO:Defining folds
2025-06-02 18:16:08,929:INFO:Declaring metric variables
2025-06-02 18:16:08,929:INFO:Importing untrained model
2025-06-02 18:16:08,929:INFO:Declaring custom model
2025-06-02 18:16:08,931:INFO:Extra Trees Regressor Imported successfully
2025-06-02 18:16:08,932:INFO:Starting cross validation
2025-06-02 18:16:08,936:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:16:15,734:INFO:Calculating mean and std
2025-06-02 18:16:15,735:INFO:Creating metrics dataframe
2025-06-02 18:16:15,739:INFO:Finalizing model
2025-06-02 18:16:17,513:INFO:Uploading results into container
2025-06-02 18:16:17,515:INFO:Uploading model into container now
2025-06-02 18:16:17,516:INFO:_master_model_container: 22
2025-06-02 18:16:17,516:INFO:_display_container: 4
2025-06-02 18:16:17,516:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:16:17,516:INFO:create_model() successfully completed......................................
2025-06-02 18:16:18,836:INFO:SubProcess create_model() end ==================================
2025-06-02 18:16:18,836:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 0.1685
2025-06-02 18:16:18,837:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=11,
                    max_features=0.4556655086335653,
                    min_impurity_decrease=0.00012891733508622256,
                    min_samples_split=9, n_estimators=11, n_jobs=-1,
                    random_state=123) result for MAE is 0.1947
2025-06-02 18:16:18,838:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 18:16:18,838:INFO:choose_better completed
2025-06-02 18:16:18,838:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 18:16:18,853:INFO:_master_model_container: 22
2025-06-02 18:16:18,854:INFO:_display_container: 3
2025-06-02 18:16:18,855:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:16:18,856:INFO:tune_model() successfully completed......................................
2025-06-02 18:16:20,260:INFO:Initializing finalize_model()
2025-06-02 18:16:20,260:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 18:16:20,261:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:16:20,319:INFO:Initializing create_model()
2025-06-02 18:16:20,319:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:16:20,319:INFO:Checking exceptions
2025-06-02 18:16:20,321:INFO:Importing libraries
2025-06-02 18:16:20,322:INFO:Copying training dataset
2025-06-02 18:16:20,327:INFO:Defining folds
2025-06-02 18:16:20,328:INFO:Declaring metric variables
2025-06-02 18:16:20,328:INFO:Importing untrained model
2025-06-02 18:16:20,328:INFO:Declaring custom model
2025-06-02 18:16:20,329:INFO:Extra Trees Regressor Imported successfully
2025-06-02 18:16:20,332:INFO:Cross validation set to False
2025-06-02 18:16:20,332:INFO:Fitting Model
2025-06-02 18:16:22,529:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 18:16:22,529:INFO:create_model() successfully completed......................................
2025-06-02 18:16:23,908:INFO:_master_model_container: 22
2025-06-02 18:16:23,908:INFO:_display_container: 3
2025-06-02 18:16:23,921:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 18:16:23,921:INFO:finalize_model() successfully completed......................................
2025-06-02 18:16:25,243:INFO:Initializing save_model()
2025-06-02 18:16:25,243:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model_mae, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 18:16:25,243:INFO:Adding model into prep_pipe
2025-06-02 18:16:25,243:WARNING:Only Model saved as it was a pipeline.
2025-06-02 18:16:25,387:INFO:formation_energy_final_model_mae.pkl saved in current working directory
2025-06-02 18:16:25,402:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 18:16:25,402:INFO:save_model() successfully completed......................................
2025-06-02 18:16:26,747:INFO:Initializing load_model()
2025-06-02 18:16:26,747:INFO:load_model(model_name=formation_energy_final_model_mae, platform=None, authentication=None, verbose=True)
2025-06-02 18:16:28,272:INFO:Initializing get_config()
2025-06-02 18:16:28,272:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, variable=X_test)
2025-06-02 18:16:28,273:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 18:16:28,273:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 18:16:28,346:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
4439                        8.0                       13.0  \
1634                       26.0                       39.0   
2803                       41.0                       57.0   
15                         30.0                       30.0   
924                        12.0                       14.0   
...                         ...                        ...   
717                         1.0                        1.0   
1329                       27.0                       72.0   
2669                       28.0                       31.0   
253                        83.0                       83.0   
3622                        8.0                       23.0   

      MagpieData range Number  MagpieData mean Number   
4439                      5.0               10.000000  \
1634                     13.0               27.218750   
2803                     16.0               53.000000   
15                        0.0               30.000000   
924                       2.0               13.272727   
...                       ...                     ...   
717                       0.0                1.000000   
1329                     45.0               37.000000   
2669                      3.0               28.750000   
253                       0.0               83.000000   
3622                     15.0               12.285714   

      MagpieData avg_dev Number  MagpieData mode Number   
4439                   2.400000                     8.0  \
1634                   2.208984                    26.0   
2803                   6.000000                    57.0   
15                     0.000000                    30.0   
924                    0.925620                    14.0   
...                         ...                     ...   
717                    0.000000                     1.0   
1329                  15.555555                    27.0   
2669                   1.125000                    28.0   
253                    0.000000                    83.0   
3622                   6.122449                     8.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
4439                                73.0                                87.0  \
1634                                12.0                                55.0   
2803                                13.0                                47.0   
15                                  69.0                                69.0   
924                                 68.0                                78.0   
...                                  ...                                 ...   
717                                 92.0                                92.0   
1329                                45.0                                58.0   
2669                                61.0                                74.0   
253                                 86.0                                86.0   
3622                                46.0                                87.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
4439                              14.0                        81.400002  ...  \
1634                              43.0                        50.968750  ...   
2803                              34.0                        21.500000  ...   
15                                 0.0                        69.000000  ...   
924                               10.0                        74.363640  ...   
...                                ...                              ...  ...   
717                                0.0                        92.000000  ...   
1329                              13.0                        55.111111  ...   
2669                              13.0                        64.250000  ...   
253                                0.0                        86.000000  ...   
3622                              41.0                        75.285713  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
4439                 7.0                   0             2.0  \
1634                 6.0                   1             2.0   
2803                 4.0                   1            16.0   
15                   7.0                   0             2.0   
924                  7.0                   0             2.0   
...                  ...                 ...             ...   
717                  7.0                   1             2.0   
1329                 6.0                   1             4.0   
2669                 4.0                   1            16.0   
253                  3.0                   1            24.0   
3622                 7.0                   0             1.0   

      crystal_system_cubic  crystal_system_hexagonal   
4439                 False                     False  \
1634                 False                     False   
2803                 False                     False   
15                   False                     False   
924                  False                     False   
...                    ...                       ...   
717                  False                     False   
1329                 False                     False   
2669                 False                     False   
253                  False                     False   
3622                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
4439                      False                        False  \
1634                       True                        False   
2803                      False                        False   
15                        False                        False   
924                       False                        False   
...                         ...                          ...   
717                       False                        False   
1329                       True                        False   
2669                      False                        False   
253                       False                        False   
3622                      False                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
4439                      False                      True  \
1634                      False                     False   
2803                       True                     False   
15                        False                      True   
924                       False                      True   
...                         ...                       ...   
717                       False                      True   
1329                      False                     False   
2669                       True                     False   
253                       False                     False   
3622                      False                      True   

      crystal_system_trigonal  
4439                    False  
1634                    False  
2803                    False  
15                      False  
924                     False  
...                       ...  
717                     False  
1329                    False  
2669                    False  
253                      True  
3622                    False  

[1120 rows x 146 columns]
2025-06-02 18:16:28,348:INFO:get_config() successfully completed......................................
2025-06-02 18:16:28,353:INFO:Initializing get_config()
2025-06-02 18:16:28,353:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, variable=y_test)
2025-06-02 18:16:28,354:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 18:16:28,354:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 18:16:28,374:INFO:Variable:  returned as 4439   -3.160679
1634    0.001061
2803    0.354103
15      0.055069
924     0.183300
          ...   
717     1.188433
1329   -0.222675
2669   -0.245426
253     0.000000
3622   -1.777082
Name: target, Length: 1120, dtype: float32
2025-06-02 18:16:28,375:INFO:get_config() successfully completed......................................
2025-06-02 18:16:28,394:INFO:Initializing predict_model()
2025-06-02 18:16:28,394:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B70268CC40>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B702EFAE60>)
2025-06-02 18:16:28,394:INFO:Checking exceptions
2025-06-02 18:16:28,394:INFO:Preloading libraries
2025-06-02 18:16:28,398:INFO:Set up data.
2025-06-02 18:16:28,476:INFO:Set up index.
2025-06-02 18:41:11,417:INFO:PyCaret RegressionExperiment
2025-06-02 18:41:11,424:INFO:Logging name: reg-default-name
2025-06-02 18:41:11,424:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 18:41:11,425:INFO:version 3.3.2
2025-06-02 18:41:11,425:INFO:Initializing setup()
2025-06-02 18:41:11,425:INFO:self.USI: f7ee
2025-06-02 18:41:11,426:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 18:41:11,427:INFO:Checking environment
2025-06-02 18:41:11,429:INFO:python_version: 3.10.16
2025-06-02 18:41:11,429:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 18:41:11,430:INFO:machine: AMD64
2025-06-02 18:41:11,431:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 18:41:11,468:INFO:Memory: svmem(total=6378008576, available=845111296, percent=86.7, used=5532897280, free=845111296)
2025-06-02 18:41:11,470:INFO:Physical Core: 4
2025-06-02 18:41:11,470:INFO:Logical Core: 8
2025-06-02 18:41:11,471:INFO:Checking libraries
2025-06-02 18:41:11,472:INFO:System:
2025-06-02 18:41:11,472:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 18:41:11,472:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 18:41:11,473:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 18:41:11,473:INFO:PyCaret required dependencies:
2025-06-02 18:41:11,478:INFO:                 pip: 25.1
2025-06-02 18:41:11,478:INFO:          setuptools: 78.1.1
2025-06-02 18:41:11,478:INFO:             pycaret: 3.3.2
2025-06-02 18:41:11,478:INFO:             IPython: 8.37.0
2025-06-02 18:41:11,478:INFO:          ipywidgets: 8.1.7
2025-06-02 18:41:11,478:INFO:                tqdm: 4.67.1
2025-06-02 18:41:11,478:INFO:               numpy: 1.26.4
2025-06-02 18:41:11,478:INFO:              pandas: 2.0.1
2025-06-02 18:41:11,478:INFO:              jinja2: 3.1.6
2025-06-02 18:41:11,479:INFO:               scipy: 1.10.1
2025-06-02 18:41:11,479:INFO:              joblib: 1.3.2
2025-06-02 18:41:11,479:INFO:             sklearn: 1.4.2
2025-06-02 18:41:11,479:INFO:                pyod: 2.0.5
2025-06-02 18:41:11,479:INFO:            imblearn: 0.13.0
2025-06-02 18:41:11,479:INFO:   category_encoders: 2.7.0
2025-06-02 18:41:11,479:INFO:            lightgbm: 4.6.0
2025-06-02 18:41:11,479:INFO:               numba: 0.61.0
2025-06-02 18:41:11,479:INFO:            requests: 2.32.3
2025-06-02 18:41:11,479:INFO:          matplotlib: 3.7.1
2025-06-02 18:41:11,479:INFO:          scikitplot: 0.3.7
2025-06-02 18:41:11,479:INFO:         yellowbrick: 1.5
2025-06-02 18:41:11,480:INFO:              plotly: 6.1.2
2025-06-02 18:41:11,480:INFO:    plotly-resampler: Not installed
2025-06-02 18:41:11,480:INFO:             kaleido: 0.2.1
2025-06-02 18:41:11,480:INFO:           schemdraw: 0.15
2025-06-02 18:41:11,480:INFO:         statsmodels: 0.14.4
2025-06-02 18:41:11,480:INFO:              sktime: 0.26.0
2025-06-02 18:41:11,480:INFO:               tbats: 1.1.3
2025-06-02 18:41:11,480:INFO:            pmdarima: 2.0.4
2025-06-02 18:41:11,480:INFO:              psutil: 7.0.0
2025-06-02 18:41:11,480:INFO:          markupsafe: 2.1.2
2025-06-02 18:41:11,480:INFO:             pickle5: Not installed
2025-06-02 18:41:11,480:INFO:         cloudpickle: 3.1.1
2025-06-02 18:41:11,481:INFO:         deprecation: 2.1.0
2025-06-02 18:41:11,481:INFO:              xxhash: 3.5.0
2025-06-02 18:41:11,481:INFO:           wurlitzer: Not installed
2025-06-02 18:41:11,481:INFO:PyCaret optional dependencies:
2025-06-02 18:41:11,483:INFO:                shap: 0.44.1
2025-06-02 18:41:11,483:INFO:           interpret: 0.6.9
2025-06-02 18:41:11,483:INFO:                umap: 0.5.7
2025-06-02 18:41:11,484:INFO:     ydata_profiling: 4.16.1
2025-06-02 18:41:11,484:INFO:  explainerdashboard: 0.4.8
2025-06-02 18:41:11,484:INFO:             autoviz: Not installed
2025-06-02 18:41:11,484:INFO:           fairlearn: 0.7.0
2025-06-02 18:41:11,484:INFO:          deepchecks: Not installed
2025-06-02 18:41:11,484:INFO:             xgboost: 3.0.2
2025-06-02 18:41:11,484:INFO:            catboost: 1.2.8
2025-06-02 18:41:11,484:INFO:              kmodes: 0.12.2
2025-06-02 18:41:11,484:INFO:             mlxtend: 0.23.4
2025-06-02 18:41:11,484:INFO:       statsforecast: 1.5.0
2025-06-02 18:41:11,484:INFO:        tune_sklearn: Not installed
2025-06-02 18:41:11,485:INFO:                 ray: Not installed
2025-06-02 18:41:11,485:INFO:            hyperopt: 0.2.7
2025-06-02 18:41:11,485:INFO:              optuna: 4.3.0
2025-06-02 18:41:11,485:INFO:               skopt: 0.10.2
2025-06-02 18:41:11,485:INFO:              mlflow: 2.22.0
2025-06-02 18:41:11,485:INFO:              gradio: 5.32.0
2025-06-02 18:41:11,485:INFO:             fastapi: 0.115.12
2025-06-02 18:41:11,485:INFO:             uvicorn: 0.34.3
2025-06-02 18:41:11,485:INFO:              m2cgen: 0.10.0
2025-06-02 18:41:11,485:INFO:           evidently: 0.4.40
2025-06-02 18:41:11,486:INFO:               fugue: 0.8.5
2025-06-02 18:41:11,486:INFO:           streamlit: Not installed
2025-06-02 18:41:11,486:INFO:             prophet: Not installed
2025-06-02 18:41:11,486:INFO:None
2025-06-02 18:41:11,487:INFO:Set up data.
2025-06-02 18:41:11,819:INFO:Set up folding strategy.
2025-06-02 18:41:11,822:INFO:Set up train/test split.
2025-06-02 18:41:12,009:INFO:Set up index.
2025-06-02 18:41:12,018:INFO:Assigning column types.
2025-06-02 18:41:12,086:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 18:41:12,094:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,104:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,114:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,323:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,417:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:41:12,431:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:41:12,436:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,443:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,451:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,614:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,698:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,699:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:41:12,703:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:41:12,704:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 18:41:12,712:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,719:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,860:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,952:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,953:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:41:12,957:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:41:12,965:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 18:41:12,972:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:41:13,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:41:13,213:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:41:13,213:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:41:13,218:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:41:13,219:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 18:41:13,233:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:41:13,381:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:41:13,470:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:41:13,471:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:41:13,475:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:41:13,491:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 18:41:13,633:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:41:13,726:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:41:13,727:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:41:13,734:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:41:13,735:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 18:41:13,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:41:14,021:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:41:14,022:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:41:14,027:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:41:14,197:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:41:14,290:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 18:41:14,291:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:41:14,295:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:41:14,296:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 18:41:14,449:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:41:14,528:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:41:14,532:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:41:14,694:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 18:41:14,770:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:41:14,774:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:41:14,775:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 18:41:15,014:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:41:15,020:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:41:15,271:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:41:15,275:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:41:15,296:INFO:Preparing preprocessing pipeline...
2025-06-02 18:41:15,296:INFO:Set up simple imputation.
2025-06-02 18:41:15,297:INFO:Set up removing multicollinearity.
2025-06-02 18:41:15,305:INFO:Set up column name cleaning.
2025-06-02 18:41:15,630:INFO:Finished creating preprocessing pipeline.
2025-06-02 18:41:15,657:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 18:41:15,658:INFO:Creating final display dataframe.
2025-06-02 18:41:16,153:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4478, 147)
4        Transformed data shape        (4478, 98)
5   Transformed train set shape        (3358, 98)
6    Transformed test set shape        (1120, 98)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              f7ee
2025-06-02 18:41:16,376:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:41:16,381:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:41:16,600:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 18:41:16,605:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 18:41:16,610:INFO:setup() successfully completed in 5.35s...............
2025-06-02 18:41:16,781:INFO:Initializing compare_models()
2025-06-02 18:41:16,781:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 18:41:16,781:INFO:Checking exceptions
2025-06-02 18:41:16,803:INFO:Preparing display monitor
2025-06-02 18:41:17,040:INFO:Initializing Linear Regression
2025-06-02 18:41:17,042:INFO:Total runtime is 1.6661485036214194e-05 minutes
2025-06-02 18:41:17,067:INFO:SubProcess create_model() called ==================================
2025-06-02 18:41:17,072:INFO:Initializing create_model()
2025-06-02 18:41:17,072:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:41:17,073:INFO:Checking exceptions
2025-06-02 18:41:17,074:INFO:Importing libraries
2025-06-02 18:41:17,074:INFO:Copying training dataset
2025-06-02 18:41:17,196:INFO:Defining folds
2025-06-02 18:41:17,197:INFO:Declaring metric variables
2025-06-02 18:41:17,214:INFO:Importing untrained model
2025-06-02 18:41:17,227:INFO:Linear Regression Imported successfully
2025-06-02 18:41:17,257:INFO:Starting cross validation
2025-06-02 18:41:17,267:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:41:33,277:INFO:Calculating mean and std
2025-06-02 18:41:33,289:INFO:Creating metrics dataframe
2025-06-02 18:41:33,311:INFO:Uploading results into container
2025-06-02 18:41:33,315:INFO:Uploading model into container now
2025-06-02 18:41:33,333:INFO:_master_model_container: 1
2025-06-02 18:41:33,334:INFO:_display_container: 2
2025-06-02 18:41:33,334:INFO:LinearRegression(n_jobs=-1)
2025-06-02 18:41:33,335:INFO:create_model() successfully completed......................................
2025-06-02 18:41:49,001:INFO:SubProcess create_model() end ==================================
2025-06-02 18:41:49,002:INFO:Creating metrics dataframe
2025-06-02 18:41:49,040:INFO:Initializing Lasso Regression
2025-06-02 18:41:49,040:INFO:Total runtime is 0.533330750465393 minutes
2025-06-02 18:41:49,055:INFO:SubProcess create_model() called ==================================
2025-06-02 18:41:49,057:INFO:Initializing create_model()
2025-06-02 18:41:49,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:41:49,058:INFO:Checking exceptions
2025-06-02 18:41:49,058:INFO:Importing libraries
2025-06-02 18:41:49,058:INFO:Copying training dataset
2025-06-02 18:41:49,153:INFO:Defining folds
2025-06-02 18:41:49,153:INFO:Declaring metric variables
2025-06-02 18:41:49,165:INFO:Importing untrained model
2025-06-02 18:41:49,179:INFO:Lasso Regression Imported successfully
2025-06-02 18:41:49,206:INFO:Starting cross validation
2025-06-02 18:41:49,212:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:42:01,661:INFO:Calculating mean and std
2025-06-02 18:42:01,664:INFO:Creating metrics dataframe
2025-06-02 18:42:01,676:INFO:Uploading results into container
2025-06-02 18:42:01,678:INFO:Uploading model into container now
2025-06-02 18:42:01,680:INFO:_master_model_container: 2
2025-06-02 18:42:01,681:INFO:_display_container: 2
2025-06-02 18:42:01,683:INFO:Lasso(random_state=123)
2025-06-02 18:42:01,684:INFO:create_model() successfully completed......................................
2025-06-02 18:42:03,640:INFO:SubProcess create_model() end ==================================
2025-06-02 18:42:03,642:INFO:Creating metrics dataframe
2025-06-02 18:42:03,660:INFO:Initializing Ridge Regression
2025-06-02 18:42:03,661:INFO:Total runtime is 0.7770235379536946 minutes
2025-06-02 18:42:03,672:INFO:SubProcess create_model() called ==================================
2025-06-02 18:42:03,673:INFO:Initializing create_model()
2025-06-02 18:42:03,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:42:03,674:INFO:Checking exceptions
2025-06-02 18:42:03,674:INFO:Importing libraries
2025-06-02 18:42:03,674:INFO:Copying training dataset
2025-06-02 18:42:03,747:INFO:Defining folds
2025-06-02 18:42:03,747:INFO:Declaring metric variables
2025-06-02 18:42:03,763:INFO:Importing untrained model
2025-06-02 18:42:03,777:INFO:Ridge Regression Imported successfully
2025-06-02 18:42:03,804:INFO:Starting cross validation
2025-06-02 18:42:03,810:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:42:04,409:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.98589e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 18:42:04,525:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.19864e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 18:42:04,558:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.48483e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 18:42:04,593:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14793e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 18:42:04,659:INFO:Calculating mean and std
2025-06-02 18:42:04,662:INFO:Creating metrics dataframe
2025-06-02 18:42:04,666:INFO:Uploading results into container
2025-06-02 18:42:04,667:INFO:Uploading model into container now
2025-06-02 18:42:04,668:INFO:_master_model_container: 3
2025-06-02 18:42:04,668:INFO:_display_container: 2
2025-06-02 18:42:04,669:INFO:Ridge(random_state=123)
2025-06-02 18:42:04,671:INFO:create_model() successfully completed......................................
2025-06-02 18:42:06,049:INFO:SubProcess create_model() end ==================================
2025-06-02 18:42:06,049:INFO:Creating metrics dataframe
2025-06-02 18:42:06,063:INFO:Initializing Elastic Net
2025-06-02 18:42:06,063:INFO:Total runtime is 0.8170633276303608 minutes
2025-06-02 18:42:06,074:INFO:SubProcess create_model() called ==================================
2025-06-02 18:42:06,075:INFO:Initializing create_model()
2025-06-02 18:42:06,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:42:06,076:INFO:Checking exceptions
2025-06-02 18:42:06,077:INFO:Importing libraries
2025-06-02 18:42:06,077:INFO:Copying training dataset
2025-06-02 18:42:06,135:INFO:Defining folds
2025-06-02 18:42:06,136:INFO:Declaring metric variables
2025-06-02 18:42:06,150:INFO:Importing untrained model
2025-06-02 18:42:06,164:INFO:Elastic Net Imported successfully
2025-06-02 18:42:06,189:INFO:Starting cross validation
2025-06-02 18:42:06,194:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:42:06,991:INFO:Calculating mean and std
2025-06-02 18:42:06,993:INFO:Creating metrics dataframe
2025-06-02 18:42:06,996:INFO:Uploading results into container
2025-06-02 18:42:06,997:INFO:Uploading model into container now
2025-06-02 18:42:06,998:INFO:_master_model_container: 4
2025-06-02 18:42:06,998:INFO:_display_container: 2
2025-06-02 18:42:06,999:INFO:ElasticNet(random_state=123)
2025-06-02 18:42:06,999:INFO:create_model() successfully completed......................................
2025-06-02 18:42:08,315:INFO:SubProcess create_model() end ==================================
2025-06-02 18:42:08,316:INFO:Creating metrics dataframe
2025-06-02 18:42:08,329:INFO:Initializing Least Angle Regression
2025-06-02 18:42:08,330:INFO:Total runtime is 0.8548406521479288 minutes
2025-06-02 18:42:08,341:INFO:SubProcess create_model() called ==================================
2025-06-02 18:42:08,342:INFO:Initializing create_model()
2025-06-02 18:42:08,342:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:42:08,342:INFO:Checking exceptions
2025-06-02 18:42:08,344:INFO:Importing libraries
2025-06-02 18:42:08,344:INFO:Copying training dataset
2025-06-02 18:42:08,402:INFO:Defining folds
2025-06-02 18:42:08,403:INFO:Declaring metric variables
2025-06-02 18:42:08,418:INFO:Importing untrained model
2025-06-02 18:42:08,429:INFO:Least Angle Regression Imported successfully
2025-06-02 18:42:08,451:INFO:Starting cross validation
2025-06-02 18:42:08,455:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:42:09,221:INFO:Calculating mean and std
2025-06-02 18:42:09,223:INFO:Creating metrics dataframe
2025-06-02 18:42:09,226:INFO:Uploading results into container
2025-06-02 18:42:09,227:INFO:Uploading model into container now
2025-06-02 18:42:09,228:INFO:_master_model_container: 5
2025-06-02 18:42:09,228:INFO:_display_container: 2
2025-06-02 18:42:09,229:INFO:Lars(random_state=123)
2025-06-02 18:42:09,230:INFO:create_model() successfully completed......................................
2025-06-02 18:42:10,553:INFO:SubProcess create_model() end ==================================
2025-06-02 18:42:10,554:INFO:Creating metrics dataframe
2025-06-02 18:42:10,573:INFO:Initializing Lasso Least Angle Regression
2025-06-02 18:42:10,574:INFO:Total runtime is 0.892234977086385 minutes
2025-06-02 18:42:10,584:INFO:SubProcess create_model() called ==================================
2025-06-02 18:42:10,585:INFO:Initializing create_model()
2025-06-02 18:42:10,586:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:42:10,586:INFO:Checking exceptions
2025-06-02 18:42:10,587:INFO:Importing libraries
2025-06-02 18:42:10,588:INFO:Copying training dataset
2025-06-02 18:42:10,647:INFO:Defining folds
2025-06-02 18:42:10,647:INFO:Declaring metric variables
2025-06-02 18:42:10,660:INFO:Importing untrained model
2025-06-02 18:42:10,673:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 18:42:10,697:INFO:Starting cross validation
2025-06-02 18:42:10,701:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:42:11,428:INFO:Calculating mean and std
2025-06-02 18:42:11,430:INFO:Creating metrics dataframe
2025-06-02 18:42:11,434:INFO:Uploading results into container
2025-06-02 18:42:11,434:INFO:Uploading model into container now
2025-06-02 18:42:11,436:INFO:_master_model_container: 6
2025-06-02 18:42:11,436:INFO:_display_container: 2
2025-06-02 18:42:11,437:INFO:LassoLars(random_state=123)
2025-06-02 18:42:11,437:INFO:create_model() successfully completed......................................
2025-06-02 18:42:12,796:INFO:SubProcess create_model() end ==================================
2025-06-02 18:42:12,796:INFO:Creating metrics dataframe
2025-06-02 18:42:12,812:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 18:42:12,812:INFO:Total runtime is 0.9295332034428914 minutes
2025-06-02 18:42:12,821:INFO:SubProcess create_model() called ==================================
2025-06-02 18:42:12,822:INFO:Initializing create_model()
2025-06-02 18:42:12,822:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:42:12,823:INFO:Checking exceptions
2025-06-02 18:42:12,823:INFO:Importing libraries
2025-06-02 18:42:12,824:INFO:Copying training dataset
2025-06-02 18:42:12,880:INFO:Defining folds
2025-06-02 18:42:12,881:INFO:Declaring metric variables
2025-06-02 18:42:12,893:INFO:Importing untrained model
2025-06-02 18:42:12,904:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 18:42:12,926:INFO:Starting cross validation
2025-06-02 18:42:12,930:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:42:14,433:INFO:Calculating mean and std
2025-06-02 18:42:14,439:INFO:Creating metrics dataframe
2025-06-02 18:42:14,445:INFO:Uploading results into container
2025-06-02 18:42:14,447:INFO:Uploading model into container now
2025-06-02 18:42:14,448:INFO:_master_model_container: 7
2025-06-02 18:42:14,449:INFO:_display_container: 2
2025-06-02 18:42:14,449:INFO:OrthogonalMatchingPursuit()
2025-06-02 18:42:14,450:INFO:create_model() successfully completed......................................
2025-06-02 18:42:18,864:INFO:SubProcess create_model() end ==================================
2025-06-02 18:42:18,865:INFO:Creating metrics dataframe
2025-06-02 18:42:18,901:INFO:Initializing Bayesian Ridge
2025-06-02 18:42:18,902:INFO:Total runtime is 1.0310449759165445 minutes
2025-06-02 18:42:18,923:INFO:SubProcess create_model() called ==================================
2025-06-02 18:42:18,925:INFO:Initializing create_model()
2025-06-02 18:42:18,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:42:18,926:INFO:Checking exceptions
2025-06-02 18:42:18,926:INFO:Importing libraries
2025-06-02 18:42:18,926:INFO:Copying training dataset
2025-06-02 18:42:19,073:INFO:Defining folds
2025-06-02 18:42:19,074:INFO:Declaring metric variables
2025-06-02 18:42:19,094:INFO:Importing untrained model
2025-06-02 18:42:19,112:INFO:Bayesian Ridge Imported successfully
2025-06-02 18:42:19,148:INFO:Starting cross validation
2025-06-02 18:42:19,155:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:42:20,822:INFO:Calculating mean and std
2025-06-02 18:42:20,825:INFO:Creating metrics dataframe
2025-06-02 18:42:20,829:INFO:Uploading results into container
2025-06-02 18:42:20,830:INFO:Uploading model into container now
2025-06-02 18:42:20,831:INFO:_master_model_container: 8
2025-06-02 18:42:20,831:INFO:_display_container: 2
2025-06-02 18:42:20,832:INFO:BayesianRidge()
2025-06-02 18:42:20,832:INFO:create_model() successfully completed......................................
2025-06-02 18:42:22,863:INFO:SubProcess create_model() end ==================================
2025-06-02 18:42:22,864:INFO:Creating metrics dataframe
2025-06-02 18:42:22,884:INFO:Initializing Passive Aggressive Regressor
2025-06-02 18:42:22,886:INFO:Total runtime is 1.0974273920059203 minutes
2025-06-02 18:42:22,897:INFO:SubProcess create_model() called ==================================
2025-06-02 18:42:22,898:INFO:Initializing create_model()
2025-06-02 18:42:22,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:42:22,898:INFO:Checking exceptions
2025-06-02 18:42:22,898:INFO:Importing libraries
2025-06-02 18:42:22,899:INFO:Copying training dataset
2025-06-02 18:42:22,966:INFO:Defining folds
2025-06-02 18:42:22,967:INFO:Declaring metric variables
2025-06-02 18:42:22,978:INFO:Importing untrained model
2025-06-02 18:42:22,990:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 18:42:23,009:INFO:Starting cross validation
2025-06-02 18:42:23,012:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:42:23,967:INFO:Calculating mean and std
2025-06-02 18:42:23,969:INFO:Creating metrics dataframe
2025-06-02 18:42:23,973:INFO:Uploading results into container
2025-06-02 18:42:23,974:INFO:Uploading model into container now
2025-06-02 18:42:23,974:INFO:_master_model_container: 9
2025-06-02 18:42:23,974:INFO:_display_container: 2
2025-06-02 18:42:23,975:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 18:42:23,976:INFO:create_model() successfully completed......................................
2025-06-02 18:42:25,472:INFO:SubProcess create_model() end ==================================
2025-06-02 18:42:25,472:INFO:Creating metrics dataframe
2025-06-02 18:42:25,491:INFO:Initializing Huber Regressor
2025-06-02 18:42:25,491:INFO:Total runtime is 1.1408632357915243 minutes
2025-06-02 18:42:25,501:INFO:SubProcess create_model() called ==================================
2025-06-02 18:42:25,501:INFO:Initializing create_model()
2025-06-02 18:42:25,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:42:25,502:INFO:Checking exceptions
2025-06-02 18:42:25,503:INFO:Importing libraries
2025-06-02 18:42:25,504:INFO:Copying training dataset
2025-06-02 18:42:25,584:INFO:Defining folds
2025-06-02 18:42:25,585:INFO:Declaring metric variables
2025-06-02 18:42:25,598:INFO:Importing untrained model
2025-06-02 18:42:25,611:INFO:Huber Regressor Imported successfully
2025-06-02 18:42:25,643:INFO:Starting cross validation
2025-06-02 18:42:25,647:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:42:27,466:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:42:27,466:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:42:27,497:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:42:27,574:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:42:27,632:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 18:42:27,676:INFO:Calculating mean and std
2025-06-02 18:42:27,679:INFO:Creating metrics dataframe
2025-06-02 18:42:27,683:INFO:Uploading results into container
2025-06-02 18:42:27,684:INFO:Uploading model into container now
2025-06-02 18:42:27,685:INFO:_master_model_container: 10
2025-06-02 18:42:27,686:INFO:_display_container: 2
2025-06-02 18:42:27,686:INFO:HuberRegressor()
2025-06-02 18:42:27,687:INFO:create_model() successfully completed......................................
2025-06-02 18:42:29,086:INFO:SubProcess create_model() end ==================================
2025-06-02 18:42:29,087:INFO:Creating metrics dataframe
2025-06-02 18:42:29,111:INFO:Initializing K Neighbors Regressor
2025-06-02 18:42:29,111:INFO:Total runtime is 1.201195474465688 minutes
2025-06-02 18:42:29,124:INFO:SubProcess create_model() called ==================================
2025-06-02 18:42:29,125:INFO:Initializing create_model()
2025-06-02 18:42:29,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:42:29,125:INFO:Checking exceptions
2025-06-02 18:42:29,125:INFO:Importing libraries
2025-06-02 18:42:29,126:INFO:Copying training dataset
2025-06-02 18:42:29,197:INFO:Defining folds
2025-06-02 18:42:29,198:INFO:Declaring metric variables
2025-06-02 18:42:29,212:INFO:Importing untrained model
2025-06-02 18:42:29,225:INFO:K Neighbors Regressor Imported successfully
2025-06-02 18:42:29,258:INFO:Starting cross validation
2025-06-02 18:42:29,263:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:42:30,348:INFO:Calculating mean and std
2025-06-02 18:42:30,350:INFO:Creating metrics dataframe
2025-06-02 18:42:30,355:INFO:Uploading results into container
2025-06-02 18:42:30,357:INFO:Uploading model into container now
2025-06-02 18:42:30,358:INFO:_master_model_container: 11
2025-06-02 18:42:30,359:INFO:_display_container: 2
2025-06-02 18:42:30,360:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 18:42:30,360:INFO:create_model() successfully completed......................................
2025-06-02 18:42:31,754:INFO:SubProcess create_model() end ==================================
2025-06-02 18:42:31,755:INFO:Creating metrics dataframe
2025-06-02 18:42:31,778:INFO:Initializing Decision Tree Regressor
2025-06-02 18:42:31,778:INFO:Total runtime is 1.2456345876057944 minutes
2025-06-02 18:42:31,789:INFO:SubProcess create_model() called ==================================
2025-06-02 18:42:31,790:INFO:Initializing create_model()
2025-06-02 18:42:31,790:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:42:31,791:INFO:Checking exceptions
2025-06-02 18:42:31,791:INFO:Importing libraries
2025-06-02 18:42:31,792:INFO:Copying training dataset
2025-06-02 18:42:31,876:INFO:Defining folds
2025-06-02 18:42:31,876:INFO:Declaring metric variables
2025-06-02 18:42:31,893:INFO:Importing untrained model
2025-06-02 18:42:31,908:INFO:Decision Tree Regressor Imported successfully
2025-06-02 18:42:31,935:INFO:Starting cross validation
2025-06-02 18:42:31,941:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:42:32,933:INFO:Calculating mean and std
2025-06-02 18:42:32,935:INFO:Creating metrics dataframe
2025-06-02 18:42:32,938:INFO:Uploading results into container
2025-06-02 18:42:32,940:INFO:Uploading model into container now
2025-06-02 18:42:32,941:INFO:_master_model_container: 12
2025-06-02 18:42:32,941:INFO:_display_container: 2
2025-06-02 18:42:32,942:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 18:42:32,942:INFO:create_model() successfully completed......................................
2025-06-02 18:42:34,330:INFO:SubProcess create_model() end ==================================
2025-06-02 18:42:34,330:INFO:Creating metrics dataframe
2025-06-02 18:42:34,356:INFO:Initializing Random Forest Regressor
2025-06-02 18:42:34,357:INFO:Total runtime is 1.288616991043091 minutes
2025-06-02 18:42:34,368:INFO:SubProcess create_model() called ==================================
2025-06-02 18:42:34,369:INFO:Initializing create_model()
2025-06-02 18:42:34,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:42:34,369:INFO:Checking exceptions
2025-06-02 18:42:34,370:INFO:Importing libraries
2025-06-02 18:42:34,371:INFO:Copying training dataset
2025-06-02 18:42:34,456:INFO:Defining folds
2025-06-02 18:42:34,457:INFO:Declaring metric variables
2025-06-02 18:42:34,471:INFO:Importing untrained model
2025-06-02 18:42:34,486:INFO:Random Forest Regressor Imported successfully
2025-06-02 18:42:34,514:INFO:Starting cross validation
2025-06-02 18:42:34,520:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:42:44,600:INFO:Calculating mean and std
2025-06-02 18:42:44,603:INFO:Creating metrics dataframe
2025-06-02 18:42:44,608:INFO:Uploading results into container
2025-06-02 18:42:44,609:INFO:Uploading model into container now
2025-06-02 18:42:44,610:INFO:_master_model_container: 13
2025-06-02 18:42:44,610:INFO:_display_container: 2
2025-06-02 18:42:44,611:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:42:44,611:INFO:create_model() successfully completed......................................
2025-06-02 18:42:46,149:INFO:SubProcess create_model() end ==================================
2025-06-02 18:42:46,149:INFO:Creating metrics dataframe
2025-06-02 18:42:46,180:INFO:Initializing Extra Trees Regressor
2025-06-02 18:42:46,181:INFO:Total runtime is 1.4856887578964235 minutes
2025-06-02 18:42:46,191:INFO:SubProcess create_model() called ==================================
2025-06-02 18:42:46,192:INFO:Initializing create_model()
2025-06-02 18:42:46,192:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:42:46,192:INFO:Checking exceptions
2025-06-02 18:42:46,192:INFO:Importing libraries
2025-06-02 18:42:46,192:INFO:Copying training dataset
2025-06-02 18:42:46,259:INFO:Defining folds
2025-06-02 18:42:46,260:INFO:Declaring metric variables
2025-06-02 18:42:46,271:INFO:Importing untrained model
2025-06-02 18:42:46,281:INFO:Extra Trees Regressor Imported successfully
2025-06-02 18:42:46,300:INFO:Starting cross validation
2025-06-02 18:42:46,304:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:42:53,422:INFO:Calculating mean and std
2025-06-02 18:42:53,426:INFO:Creating metrics dataframe
2025-06-02 18:42:53,430:INFO:Uploading results into container
2025-06-02 18:42:53,431:INFO:Uploading model into container now
2025-06-02 18:42:53,432:INFO:_master_model_container: 14
2025-06-02 18:42:53,433:INFO:_display_container: 2
2025-06-02 18:42:53,434:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:42:53,434:INFO:create_model() successfully completed......................................
2025-06-02 18:42:55,238:INFO:SubProcess create_model() end ==================================
2025-06-02 18:42:55,239:INFO:Creating metrics dataframe
2025-06-02 18:42:55,290:INFO:Initializing AdaBoost Regressor
2025-06-02 18:42:55,291:INFO:Total runtime is 1.6375141859054567 minutes
2025-06-02 18:42:55,310:INFO:SubProcess create_model() called ==================================
2025-06-02 18:42:55,311:INFO:Initializing create_model()
2025-06-02 18:42:55,311:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:42:55,311:INFO:Checking exceptions
2025-06-02 18:42:55,311:INFO:Importing libraries
2025-06-02 18:42:55,312:INFO:Copying training dataset
2025-06-02 18:42:55,537:INFO:Defining folds
2025-06-02 18:42:55,538:INFO:Declaring metric variables
2025-06-02 18:42:55,561:INFO:Importing untrained model
2025-06-02 18:42:55,577:INFO:AdaBoost Regressor Imported successfully
2025-06-02 18:42:55,611:INFO:Starting cross validation
2025-06-02 18:42:55,616:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:42:59,636:INFO:Calculating mean and std
2025-06-02 18:42:59,639:INFO:Creating metrics dataframe
2025-06-02 18:42:59,643:INFO:Uploading results into container
2025-06-02 18:42:59,644:INFO:Uploading model into container now
2025-06-02 18:42:59,645:INFO:_master_model_container: 15
2025-06-02 18:42:59,645:INFO:_display_container: 2
2025-06-02 18:42:59,645:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 18:42:59,646:INFO:create_model() successfully completed......................................
2025-06-02 18:43:01,710:INFO:SubProcess create_model() end ==================================
2025-06-02 18:43:01,711:INFO:Creating metrics dataframe
2025-06-02 18:43:01,746:INFO:Initializing Gradient Boosting Regressor
2025-06-02 18:43:01,747:INFO:Total runtime is 1.7451297720273338 minutes
2025-06-02 18:43:01,763:INFO:SubProcess create_model() called ==================================
2025-06-02 18:43:01,764:INFO:Initializing create_model()
2025-06-02 18:43:01,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:43:01,765:INFO:Checking exceptions
2025-06-02 18:43:01,765:INFO:Importing libraries
2025-06-02 18:43:01,766:INFO:Copying training dataset
2025-06-02 18:43:01,851:INFO:Defining folds
2025-06-02 18:43:01,851:INFO:Declaring metric variables
2025-06-02 18:43:01,864:INFO:Importing untrained model
2025-06-02 18:43:01,876:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 18:43:01,900:INFO:Starting cross validation
2025-06-02 18:43:01,904:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:43:06,228:INFO:Calculating mean and std
2025-06-02 18:43:06,230:INFO:Creating metrics dataframe
2025-06-02 18:43:06,234:INFO:Uploading results into container
2025-06-02 18:43:06,235:INFO:Uploading model into container now
2025-06-02 18:43:06,236:INFO:_master_model_container: 16
2025-06-02 18:43:06,236:INFO:_display_container: 2
2025-06-02 18:43:06,238:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 18:43:06,239:INFO:create_model() successfully completed......................................
2025-06-02 18:43:07,678:INFO:SubProcess create_model() end ==================================
2025-06-02 18:43:07,678:INFO:Creating metrics dataframe
2025-06-02 18:43:07,708:INFO:Initializing Extreme Gradient Boosting
2025-06-02 18:43:07,709:INFO:Total runtime is 1.8444932579994204 minutes
2025-06-02 18:43:07,719:INFO:SubProcess create_model() called ==================================
2025-06-02 18:43:07,720:INFO:Initializing create_model()
2025-06-02 18:43:07,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:43:07,722:INFO:Checking exceptions
2025-06-02 18:43:07,722:INFO:Importing libraries
2025-06-02 18:43:07,722:INFO:Copying training dataset
2025-06-02 18:43:07,796:INFO:Defining folds
2025-06-02 18:43:07,796:INFO:Declaring metric variables
2025-06-02 18:43:07,809:INFO:Importing untrained model
2025-06-02 18:43:07,826:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 18:43:07,852:INFO:Starting cross validation
2025-06-02 18:43:07,856:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:43:10,278:INFO:Calculating mean and std
2025-06-02 18:43:10,281:INFO:Creating metrics dataframe
2025-06-02 18:43:10,286:INFO:Uploading results into container
2025-06-02 18:43:10,288:INFO:Uploading model into container now
2025-06-02 18:43:10,289:INFO:_master_model_container: 17
2025-06-02 18:43:10,290:INFO:_display_container: 2
2025-06-02 18:43:10,295:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 18:43:10,296:INFO:create_model() successfully completed......................................
2025-06-02 18:43:11,705:INFO:SubProcess create_model() end ==================================
2025-06-02 18:43:11,705:INFO:Creating metrics dataframe
2025-06-02 18:43:11,729:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 18:43:11,730:INFO:Total runtime is 1.911504677931468 minutes
2025-06-02 18:43:11,741:INFO:SubProcess create_model() called ==================================
2025-06-02 18:43:11,742:INFO:Initializing create_model()
2025-06-02 18:43:11,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:43:11,743:INFO:Checking exceptions
2025-06-02 18:43:11,743:INFO:Importing libraries
2025-06-02 18:43:11,744:INFO:Copying training dataset
2025-06-02 18:43:11,826:INFO:Defining folds
2025-06-02 18:43:11,827:INFO:Declaring metric variables
2025-06-02 18:43:11,843:INFO:Importing untrained model
2025-06-02 18:43:11,860:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 18:43:11,891:INFO:Starting cross validation
2025-06-02 18:43:11,896:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 18:43:13,904:INFO:Calculating mean and std
2025-06-02 18:43:13,907:INFO:Creating metrics dataframe
2025-06-02 18:43:13,911:INFO:Uploading results into container
2025-06-02 18:43:13,913:INFO:Uploading model into container now
2025-06-02 18:43:13,914:INFO:_master_model_container: 18
2025-06-02 18:43:13,914:INFO:_display_container: 2
2025-06-02 18:43:13,916:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 18:43:13,916:INFO:create_model() successfully completed......................................
2025-06-02 18:43:15,390:INFO:SubProcess create_model() end ==================================
2025-06-02 18:43:15,391:INFO:Creating metrics dataframe
2025-06-02 18:43:15,413:INFO:Initializing CatBoost Regressor
2025-06-02 18:43:15,413:INFO:Total runtime is 1.9728902459144595 minutes
2025-06-02 18:43:15,424:INFO:SubProcess create_model() called ==================================
2025-06-02 18:43:15,425:INFO:Initializing create_model()
2025-06-02 18:43:15,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7051AFB20>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6EFF2E920>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 18:43:15,425:INFO:Checking exceptions
2025-06-02 18:43:15,426:INFO:Importing libraries
2025-06-02 18:43:15,426:INFO:Copying training dataset
2025-06-02 18:43:15,491:INFO:Defining folds
2025-06-02 18:43:15,491:INFO:Declaring metric variables
2025-06-02 18:43:15,507:INFO:Importing untrained model
2025-06-02 18:43:15,537:INFO:CatBoost Regressor Imported successfully
2025-06-02 18:43:15,574:INFO:Starting cross validation
2025-06-02 18:43:15,579:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:06:48,019:INFO:PyCaret RegressionExperiment
2025-06-02 19:06:48,024:INFO:Logging name: reg-default-name
2025-06-02 19:06:48,025:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 19:06:48,025:INFO:version 3.3.2
2025-06-02 19:06:48,025:INFO:Initializing setup()
2025-06-02 19:06:48,025:INFO:self.USI: 53b8
2025-06-02 19:06:48,026:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 19:06:48,027:INFO:Checking environment
2025-06-02 19:06:48,029:INFO:python_version: 3.10.16
2025-06-02 19:06:48,029:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 19:06:48,030:INFO:machine: AMD64
2025-06-02 19:06:48,032:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 19:06:48,051:INFO:Memory: svmem(total=6378008576, available=761864192, percent=88.1, used=5616144384, free=761864192)
2025-06-02 19:06:48,052:INFO:Physical Core: 4
2025-06-02 19:06:48,053:INFO:Logical Core: 8
2025-06-02 19:06:48,053:INFO:Checking libraries
2025-06-02 19:06:48,056:INFO:System:
2025-06-02 19:06:48,057:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 19:06:48,057:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 19:06:48,057:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 19:06:48,057:INFO:PyCaret required dependencies:
2025-06-02 19:06:48,064:INFO:                 pip: 25.1
2025-06-02 19:06:48,065:INFO:          setuptools: 78.1.1
2025-06-02 19:06:48,065:INFO:             pycaret: 3.3.2
2025-06-02 19:06:48,065:INFO:             IPython: 8.37.0
2025-06-02 19:06:48,065:INFO:          ipywidgets: 8.1.7
2025-06-02 19:06:48,065:INFO:                tqdm: 4.67.1
2025-06-02 19:06:48,065:INFO:               numpy: 1.26.4
2025-06-02 19:06:48,065:INFO:              pandas: 2.0.1
2025-06-02 19:06:48,065:INFO:              jinja2: 3.1.6
2025-06-02 19:06:48,065:INFO:               scipy: 1.10.1
2025-06-02 19:06:48,066:INFO:              joblib: 1.3.2
2025-06-02 19:06:48,066:INFO:             sklearn: 1.4.2
2025-06-02 19:06:48,066:INFO:                pyod: 2.0.5
2025-06-02 19:06:48,066:INFO:            imblearn: 0.13.0
2025-06-02 19:06:48,066:INFO:   category_encoders: 2.7.0
2025-06-02 19:06:48,066:INFO:            lightgbm: 4.6.0
2025-06-02 19:06:48,066:INFO:               numba: 0.61.0
2025-06-02 19:06:48,066:INFO:            requests: 2.32.3
2025-06-02 19:06:48,066:INFO:          matplotlib: 3.7.1
2025-06-02 19:06:48,066:INFO:          scikitplot: 0.3.7
2025-06-02 19:06:48,066:INFO:         yellowbrick: 1.5
2025-06-02 19:06:48,067:INFO:              plotly: 6.1.2
2025-06-02 19:06:48,067:INFO:    plotly-resampler: Not installed
2025-06-02 19:06:48,067:INFO:             kaleido: 0.2.1
2025-06-02 19:06:48,067:INFO:           schemdraw: 0.15
2025-06-02 19:06:48,067:INFO:         statsmodels: 0.14.4
2025-06-02 19:06:48,067:INFO:              sktime: 0.26.0
2025-06-02 19:06:48,067:INFO:               tbats: 1.1.3
2025-06-02 19:06:48,067:INFO:            pmdarima: 2.0.4
2025-06-02 19:06:48,067:INFO:              psutil: 7.0.0
2025-06-02 19:06:48,067:INFO:          markupsafe: 2.1.2
2025-06-02 19:06:48,067:INFO:             pickle5: Not installed
2025-06-02 19:06:48,068:INFO:         cloudpickle: 3.1.1
2025-06-02 19:06:48,068:INFO:         deprecation: 2.1.0
2025-06-02 19:06:48,068:INFO:              xxhash: 3.5.0
2025-06-02 19:06:48,068:INFO:           wurlitzer: Not installed
2025-06-02 19:06:48,068:INFO:PyCaret optional dependencies:
2025-06-02 19:06:48,072:INFO:                shap: 0.44.1
2025-06-02 19:06:48,072:INFO:           interpret: 0.6.9
2025-06-02 19:06:48,072:INFO:                umap: 0.5.7
2025-06-02 19:06:48,072:INFO:     ydata_profiling: 4.16.1
2025-06-02 19:06:48,072:INFO:  explainerdashboard: 0.4.8
2025-06-02 19:06:48,072:INFO:             autoviz: Not installed
2025-06-02 19:06:48,072:INFO:           fairlearn: 0.7.0
2025-06-02 19:06:48,072:INFO:          deepchecks: Not installed
2025-06-02 19:06:48,072:INFO:             xgboost: 3.0.2
2025-06-02 19:06:48,073:INFO:            catboost: 1.2.8
2025-06-02 19:06:48,073:INFO:              kmodes: 0.12.2
2025-06-02 19:06:48,073:INFO:             mlxtend: 0.23.4
2025-06-02 19:06:48,073:INFO:       statsforecast: 1.5.0
2025-06-02 19:06:48,073:INFO:        tune_sklearn: Not installed
2025-06-02 19:06:48,073:INFO:                 ray: Not installed
2025-06-02 19:06:48,073:INFO:            hyperopt: 0.2.7
2025-06-02 19:06:48,073:INFO:              optuna: 4.3.0
2025-06-02 19:06:48,074:INFO:               skopt: 0.10.2
2025-06-02 19:06:48,074:INFO:              mlflow: 2.22.0
2025-06-02 19:06:48,074:INFO:              gradio: 5.32.0
2025-06-02 19:06:48,074:INFO:             fastapi: 0.115.12
2025-06-02 19:06:48,074:INFO:             uvicorn: 0.34.3
2025-06-02 19:06:48,074:INFO:              m2cgen: 0.10.0
2025-06-02 19:06:48,074:INFO:           evidently: 0.4.40
2025-06-02 19:06:48,074:INFO:               fugue: 0.8.5
2025-06-02 19:06:48,074:INFO:           streamlit: Not installed
2025-06-02 19:06:48,074:INFO:             prophet: Not installed
2025-06-02 19:06:48,075:INFO:None
2025-06-02 19:06:48,075:INFO:Set up data.
2025-06-02 19:06:48,374:INFO:Set up folding strategy.
2025-06-02 19:06:48,382:INFO:Set up train/test split.
2025-06-02 19:06:48,542:INFO:Set up index.
2025-06-02 19:06:48,551:INFO:Assigning column types.
2025-06-02 19:06:48,614:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 19:06:48,625:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 19:06:48,638:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:06:48,649:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:06:48,856:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:06:48,966:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:06:48,981:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:06:49,004:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:06:49,012:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 19:06:49,025:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:06:49,035:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:06:49,224:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:06:49,335:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:06:49,336:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:06:49,342:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:06:49,343:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 19:06:49,355:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:06:49,364:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:06:49,544:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:06:49,638:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:06:49,639:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:06:49,643:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:06:49,656:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:06:49,664:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:06:49,813:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:06:49,894:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:06:49,895:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:06:49,900:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:06:49,901:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 19:06:49,915:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:06:50,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:06:50,168:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:06:50,169:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:06:50,174:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:06:50,190:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:06:50,368:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:06:50,468:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:06:50,468:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:06:50,473:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:06:50,475:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 19:06:50,649:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:06:50,732:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:06:50,733:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:06:50,740:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:06:50,926:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:06:51,006:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:06:51,007:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:06:51,011:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:06:51,012:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 19:06:51,208:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:06:51,302:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:06:51,307:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:06:51,517:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:06:51,597:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:06:51,601:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:06:51,602:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 19:06:51,863:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:06:51,868:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:06:52,132:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:06:52,137:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:06:52,169:INFO:Preparing preprocessing pipeline...
2025-06-02 19:06:52,169:INFO:Set up simple imputation.
2025-06-02 19:06:52,172:INFO:Set up removing multicollinearity.
2025-06-02 19:06:52,180:INFO:Set up column name cleaning.
2025-06-02 19:06:53,008:INFO:Finished creating preprocessing pipeline.
2025-06-02 19:06:53,028:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 19:06:53,028:INFO:Creating final display dataframe.
2025-06-02 19:06:54,414:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4200, 147)
4        Transformed data shape        (4200, 94)
5   Transformed train set shape        (3150, 94)
6    Transformed test set shape        (1050, 94)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              53b8
2025-06-02 19:06:54,642:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:06:54,646:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:06:54,877:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:06:54,881:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:06:54,889:INFO:setup() successfully completed in 7.09s...............
2025-06-02 19:06:54,892:INFO:Initializing compare_models()
2025-06-02 19:06:54,892:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7052F3940>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B7052F3940>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 19:06:54,892:INFO:Checking exceptions
2025-06-02 19:06:54,912:INFO:Preparing display monitor
2025-06-02 19:06:55,131:INFO:Initializing Linear Regression
2025-06-02 19:06:55,132:INFO:Total runtime is 3.332297007242839e-05 minutes
2025-06-02 19:06:55,146:INFO:SubProcess create_model() called ==================================
2025-06-02 19:06:55,153:INFO:Initializing create_model()
2025-06-02 19:06:55,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7052F3940>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B718A174C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:06:55,154:INFO:Checking exceptions
2025-06-02 19:06:55,155:INFO:Importing libraries
2025-06-02 19:06:55,155:INFO:Copying training dataset
2025-06-02 19:06:55,253:INFO:Defining folds
2025-06-02 19:06:55,253:INFO:Declaring metric variables
2025-06-02 19:06:55,266:INFO:Importing untrained model
2025-06-02 19:06:55,282:INFO:Linear Regression Imported successfully
2025-06-02 19:06:55,311:INFO:Starting cross validation
2025-06-02 19:06:55,323:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:07:18,248:INFO:Calculating mean and std
2025-06-02 19:07:18,263:INFO:Creating metrics dataframe
2025-06-02 19:07:18,285:INFO:Uploading results into container
2025-06-02 19:07:18,290:INFO:Uploading model into container now
2025-06-02 19:07:18,303:INFO:_master_model_container: 1
2025-06-02 19:07:18,304:INFO:_display_container: 2
2025-06-02 19:07:18,305:INFO:LinearRegression(n_jobs=-1)
2025-06-02 19:07:18,305:INFO:create_model() successfully completed......................................
2025-06-02 19:07:34,349:INFO:SubProcess create_model() end ==================================
2025-06-02 19:07:34,350:INFO:Creating metrics dataframe
2025-06-02 19:07:34,382:INFO:Initializing Lasso Regression
2025-06-02 19:07:34,383:INFO:Total runtime is 0.6542196075121561 minutes
2025-06-02 19:07:34,398:INFO:SubProcess create_model() called ==================================
2025-06-02 19:07:34,399:INFO:Initializing create_model()
2025-06-02 19:07:34,399:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7052F3940>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B718A174C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:07:34,400:INFO:Checking exceptions
2025-06-02 19:07:34,400:INFO:Importing libraries
2025-06-02 19:07:34,402:INFO:Copying training dataset
2025-06-02 19:07:34,508:INFO:Defining folds
2025-06-02 19:07:34,509:INFO:Declaring metric variables
2025-06-02 19:07:34,521:INFO:Importing untrained model
2025-06-02 19:07:34,533:INFO:Lasso Regression Imported successfully
2025-06-02 19:07:34,561:INFO:Starting cross validation
2025-06-02 19:07:34,568:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:07:45,778:INFO:Calculating mean and std
2025-06-02 19:07:45,782:INFO:Creating metrics dataframe
2025-06-02 19:07:45,790:INFO:Uploading results into container
2025-06-02 19:07:45,792:INFO:Uploading model into container now
2025-06-02 19:07:45,794:INFO:_master_model_container: 2
2025-06-02 19:07:45,794:INFO:_display_container: 2
2025-06-02 19:07:45,795:INFO:Lasso(random_state=123)
2025-06-02 19:07:45,795:INFO:create_model() successfully completed......................................
2025-06-02 19:07:47,458:INFO:SubProcess create_model() end ==================================
2025-06-02 19:07:47,458:INFO:Creating metrics dataframe
2025-06-02 19:07:47,474:INFO:Initializing Ridge Regression
2025-06-02 19:07:47,474:INFO:Total runtime is 0.8723981857299804 minutes
2025-06-02 19:07:47,488:INFO:SubProcess create_model() called ==================================
2025-06-02 19:07:47,488:INFO:Initializing create_model()
2025-06-02 19:07:47,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7052F3940>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B718A174C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:07:47,489:INFO:Checking exceptions
2025-06-02 19:07:47,490:INFO:Importing libraries
2025-06-02 19:07:47,490:INFO:Copying training dataset
2025-06-02 19:07:47,564:INFO:Defining folds
2025-06-02 19:07:47,565:INFO:Declaring metric variables
2025-06-02 19:07:47,575:INFO:Importing untrained model
2025-06-02 19:07:47,584:INFO:Ridge Regression Imported successfully
2025-06-02 19:07:47,604:INFO:Starting cross validation
2025-06-02 19:07:47,607:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:07:48,539:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.20962e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 19:07:48,797:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.27172e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 19:07:48,958:INFO:Calculating mean and std
2025-06-02 19:07:48,961:INFO:Creating metrics dataframe
2025-06-02 19:07:48,965:INFO:Uploading results into container
2025-06-02 19:07:48,967:INFO:Uploading model into container now
2025-06-02 19:07:48,968:INFO:_master_model_container: 3
2025-06-02 19:07:48,968:INFO:_display_container: 2
2025-06-02 19:07:48,970:INFO:Ridge(random_state=123)
2025-06-02 19:07:48,972:INFO:create_model() successfully completed......................................
2025-06-02 19:07:51,754:INFO:SubProcess create_model() end ==================================
2025-06-02 19:07:51,755:INFO:Creating metrics dataframe
2025-06-02 19:07:51,784:INFO:Initializing Elastic Net
2025-06-02 19:07:51,784:INFO:Total runtime is 0.9442320466041564 minutes
2025-06-02 19:07:51,842:INFO:SubProcess create_model() called ==================================
2025-06-02 19:07:51,843:INFO:Initializing create_model()
2025-06-02 19:07:51,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7052F3940>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B718A174C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:07:51,844:INFO:Checking exceptions
2025-06-02 19:07:51,844:INFO:Importing libraries
2025-06-02 19:07:51,845:INFO:Copying training dataset
2025-06-02 19:07:52,154:INFO:Defining folds
2025-06-02 19:07:52,155:INFO:Declaring metric variables
2025-06-02 19:07:52,173:INFO:Importing untrained model
2025-06-02 19:07:52,191:INFO:Elastic Net Imported successfully
2025-06-02 19:07:52,227:INFO:Starting cross validation
2025-06-02 19:07:52,233:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:07:53,903:INFO:Calculating mean and std
2025-06-02 19:07:53,907:INFO:Creating metrics dataframe
2025-06-02 19:07:53,914:INFO:Uploading results into container
2025-06-02 19:07:53,916:INFO:Uploading model into container now
2025-06-02 19:07:53,917:INFO:_master_model_container: 4
2025-06-02 19:07:53,918:INFO:_display_container: 2
2025-06-02 19:07:53,920:INFO:ElasticNet(random_state=123)
2025-06-02 19:07:53,920:INFO:create_model() successfully completed......................................
2025-06-02 19:07:56,390:INFO:SubProcess create_model() end ==================================
2025-06-02 19:07:56,390:INFO:Creating metrics dataframe
2025-06-02 19:07:56,406:INFO:Initializing Least Angle Regression
2025-06-02 19:07:56,408:INFO:Total runtime is 1.0212923844655353 minutes
2025-06-02 19:07:56,417:INFO:SubProcess create_model() called ==================================
2025-06-02 19:07:56,418:INFO:Initializing create_model()
2025-06-02 19:07:56,419:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7052F3940>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B718A174C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:07:56,419:INFO:Checking exceptions
2025-06-02 19:07:56,420:INFO:Importing libraries
2025-06-02 19:07:56,421:INFO:Copying training dataset
2025-06-02 19:07:56,497:INFO:Defining folds
2025-06-02 19:07:56,497:INFO:Declaring metric variables
2025-06-02 19:07:56,511:INFO:Importing untrained model
2025-06-02 19:07:56,522:INFO:Least Angle Regression Imported successfully
2025-06-02 19:07:56,550:INFO:Starting cross validation
2025-06-02 19:07:56,554:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:07:58,391:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.372e-01, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:07:58,393:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.009e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:07:58,395:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=5.067e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:07:58,413:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.207e+01, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:07:58,497:INFO:Calculating mean and std
2025-06-02 19:07:58,500:INFO:Creating metrics dataframe
2025-06-02 19:07:58,506:INFO:Uploading results into container
2025-06-02 19:07:58,507:INFO:Uploading model into container now
2025-06-02 19:07:58,509:INFO:_master_model_container: 5
2025-06-02 19:07:58,509:INFO:_display_container: 2
2025-06-02 19:07:58,510:INFO:Lars(random_state=123)
2025-06-02 19:07:58,510:INFO:create_model() successfully completed......................................
2025-06-02 19:08:00,023:INFO:SubProcess create_model() end ==================================
2025-06-02 19:08:00,024:INFO:Creating metrics dataframe
2025-06-02 19:08:00,055:INFO:Initializing Lasso Least Angle Regression
2025-06-02 19:08:00,055:INFO:Total runtime is 1.0820760846137998 minutes
2025-06-02 19:08:00,070:INFO:SubProcess create_model() called ==================================
2025-06-02 19:08:00,071:INFO:Initializing create_model()
2025-06-02 19:08:00,072:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7052F3940>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B718A174C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:08:00,073:INFO:Checking exceptions
2025-06-02 19:08:00,073:INFO:Importing libraries
2025-06-02 19:08:00,074:INFO:Copying training dataset
2025-06-02 19:08:00,165:INFO:Defining folds
2025-06-02 19:08:00,166:INFO:Declaring metric variables
2025-06-02 19:08:00,180:INFO:Importing untrained model
2025-06-02 19:08:00,195:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 19:08:00,226:INFO:Starting cross validation
2025-06-02 19:08:00,232:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:08:01,221:INFO:Calculating mean and std
2025-06-02 19:08:01,223:INFO:Creating metrics dataframe
2025-06-02 19:08:01,227:INFO:Uploading results into container
2025-06-02 19:08:01,228:INFO:Uploading model into container now
2025-06-02 19:08:01,229:INFO:_master_model_container: 6
2025-06-02 19:08:01,230:INFO:_display_container: 2
2025-06-02 19:08:01,231:INFO:LassoLars(random_state=123)
2025-06-02 19:08:01,231:INFO:create_model() successfully completed......................................
2025-06-02 19:08:02,926:INFO:SubProcess create_model() end ==================================
2025-06-02 19:08:02,927:INFO:Creating metrics dataframe
2025-06-02 19:08:02,949:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 19:08:02,949:INFO:Total runtime is 1.1303172945976254 minutes
2025-06-02 19:08:02,960:INFO:SubProcess create_model() called ==================================
2025-06-02 19:08:02,960:INFO:Initializing create_model()
2025-06-02 19:08:02,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7052F3940>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B718A174C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:08:02,961:INFO:Checking exceptions
2025-06-02 19:08:02,961:INFO:Importing libraries
2025-06-02 19:08:02,962:INFO:Copying training dataset
2025-06-02 19:08:03,025:INFO:Defining folds
2025-06-02 19:08:03,026:INFO:Declaring metric variables
2025-06-02 19:08:03,035:INFO:Importing untrained model
2025-06-02 19:08:03,045:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 19:08:03,065:INFO:Starting cross validation
2025-06-02 19:08:03,069:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:08:03,946:INFO:Calculating mean and std
2025-06-02 19:08:03,948:INFO:Creating metrics dataframe
2025-06-02 19:08:03,952:INFO:Uploading results into container
2025-06-02 19:08:03,953:INFO:Uploading model into container now
2025-06-02 19:08:03,954:INFO:_master_model_container: 7
2025-06-02 19:08:03,954:INFO:_display_container: 2
2025-06-02 19:08:03,955:INFO:OrthogonalMatchingPursuit()
2025-06-02 19:08:03,955:INFO:create_model() successfully completed......................................
2025-06-02 19:08:05,481:INFO:SubProcess create_model() end ==================================
2025-06-02 19:08:05,482:INFO:Creating metrics dataframe
2025-06-02 19:08:05,508:INFO:Initializing Bayesian Ridge
2025-06-02 19:08:05,508:INFO:Total runtime is 1.1729685743649798 minutes
2025-06-02 19:08:05,520:INFO:SubProcess create_model() called ==================================
2025-06-02 19:08:05,520:INFO:Initializing create_model()
2025-06-02 19:08:05,521:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7052F3940>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B718A174C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:08:05,521:INFO:Checking exceptions
2025-06-02 19:08:05,521:INFO:Importing libraries
2025-06-02 19:08:05,522:INFO:Copying training dataset
2025-06-02 19:08:05,582:INFO:Defining folds
2025-06-02 19:08:05,582:INFO:Declaring metric variables
2025-06-02 19:08:05,592:INFO:Importing untrained model
2025-06-02 19:08:05,601:INFO:Bayesian Ridge Imported successfully
2025-06-02 19:08:05,619:INFO:Starting cross validation
2025-06-02 19:08:05,623:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:08:06,630:INFO:Calculating mean and std
2025-06-02 19:08:06,633:INFO:Creating metrics dataframe
2025-06-02 19:08:06,639:INFO:Uploading results into container
2025-06-02 19:08:06,640:INFO:Uploading model into container now
2025-06-02 19:08:06,641:INFO:_master_model_container: 8
2025-06-02 19:08:06,642:INFO:_display_container: 2
2025-06-02 19:08:06,643:INFO:BayesianRidge()
2025-06-02 19:08:06,644:INFO:create_model() successfully completed......................................
2025-06-02 19:08:08,081:INFO:SubProcess create_model() end ==================================
2025-06-02 19:08:08,082:INFO:Creating metrics dataframe
2025-06-02 19:08:08,099:INFO:Initializing Passive Aggressive Regressor
2025-06-02 19:08:08,100:INFO:Total runtime is 1.2161662419637043 minutes
2025-06-02 19:08:08,111:INFO:SubProcess create_model() called ==================================
2025-06-02 19:08:08,112:INFO:Initializing create_model()
2025-06-02 19:08:08,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7052F3940>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B718A174C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:08:08,113:INFO:Checking exceptions
2025-06-02 19:08:08,113:INFO:Importing libraries
2025-06-02 19:08:08,114:INFO:Copying training dataset
2025-06-02 19:08:08,195:INFO:Defining folds
2025-06-02 19:08:08,196:INFO:Declaring metric variables
2025-06-02 19:08:08,206:INFO:Importing untrained model
2025-06-02 19:08:08,219:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 19:08:08,249:INFO:Starting cross validation
2025-06-02 19:08:08,253:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:08:09,109:INFO:Calculating mean and std
2025-06-02 19:08:09,111:INFO:Creating metrics dataframe
2025-06-02 19:08:09,115:INFO:Uploading results into container
2025-06-02 19:08:09,116:INFO:Uploading model into container now
2025-06-02 19:08:09,117:INFO:_master_model_container: 9
2025-06-02 19:08:09,117:INFO:_display_container: 2
2025-06-02 19:08:09,118:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 19:08:09,119:INFO:create_model() successfully completed......................................
2025-06-02 19:08:10,589:INFO:SubProcess create_model() end ==================================
2025-06-02 19:08:10,589:INFO:Creating metrics dataframe
2025-06-02 19:08:10,609:INFO:Initializing Huber Regressor
2025-06-02 19:08:10,610:INFO:Total runtime is 1.258000099658966 minutes
2025-06-02 19:08:10,619:INFO:SubProcess create_model() called ==================================
2025-06-02 19:08:10,620:INFO:Initializing create_model()
2025-06-02 19:08:10,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7052F3940>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B718A174C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:08:10,620:INFO:Checking exceptions
2025-06-02 19:08:10,621:INFO:Importing libraries
2025-06-02 19:08:10,621:INFO:Copying training dataset
2025-06-02 19:08:10,685:INFO:Defining folds
2025-06-02 19:08:10,685:INFO:Declaring metric variables
2025-06-02 19:08:10,694:INFO:Importing untrained model
2025-06-02 19:08:10,703:INFO:Huber Regressor Imported successfully
2025-06-02 19:08:10,723:INFO:Starting cross validation
2025-06-02 19:08:10,726:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:08:12,529:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:08:12,560:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:08:12,569:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:08:12,606:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:08:12,747:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:08:12,804:INFO:Calculating mean and std
2025-06-02 19:08:12,807:INFO:Creating metrics dataframe
2025-06-02 19:08:12,812:INFO:Uploading results into container
2025-06-02 19:08:12,813:INFO:Uploading model into container now
2025-06-02 19:08:12,814:INFO:_master_model_container: 10
2025-06-02 19:08:12,815:INFO:_display_container: 2
2025-06-02 19:08:12,815:INFO:HuberRegressor()
2025-06-02 19:08:12,816:INFO:create_model() successfully completed......................................
2025-06-02 19:08:14,450:INFO:SubProcess create_model() end ==================================
2025-06-02 19:08:47,988:INFO:PyCaret RegressionExperiment
2025-06-02 19:08:47,989:INFO:Logging name: reg-default-name
2025-06-02 19:08:47,989:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 19:08:47,989:INFO:version 3.3.2
2025-06-02 19:08:47,990:INFO:Initializing setup()
2025-06-02 19:08:47,990:INFO:self.USI: 5503
2025-06-02 19:08:47,992:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 19:08:47,993:INFO:Checking environment
2025-06-02 19:08:47,995:INFO:python_version: 3.10.16
2025-06-02 19:08:47,997:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 19:08:47,998:INFO:machine: AMD64
2025-06-02 19:08:47,998:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 19:08:48,008:INFO:Memory: svmem(total=6378008576, available=134500352, percent=97.9, used=6243508224, free=134500352)
2025-06-02 19:08:48,009:INFO:Physical Core: 4
2025-06-02 19:08:48,009:INFO:Logical Core: 8
2025-06-02 19:08:48,009:INFO:Checking libraries
2025-06-02 19:08:48,009:INFO:System:
2025-06-02 19:08:48,009:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 19:08:48,009:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 19:08:48,009:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 19:08:48,010:INFO:PyCaret required dependencies:
2025-06-02 19:08:48,010:INFO:                 pip: 25.1
2025-06-02 19:08:48,010:INFO:          setuptools: 78.1.1
2025-06-02 19:08:48,010:INFO:             pycaret: 3.3.2
2025-06-02 19:08:48,010:INFO:             IPython: 8.37.0
2025-06-02 19:08:48,010:INFO:          ipywidgets: 8.1.7
2025-06-02 19:08:48,010:INFO:                tqdm: 4.67.1
2025-06-02 19:08:48,010:INFO:               numpy: 1.26.4
2025-06-02 19:08:48,010:INFO:              pandas: 2.0.1
2025-06-02 19:08:48,011:INFO:              jinja2: 3.1.6
2025-06-02 19:08:48,011:INFO:               scipy: 1.10.1
2025-06-02 19:08:48,011:INFO:              joblib: 1.3.2
2025-06-02 19:08:48,011:INFO:             sklearn: 1.4.2
2025-06-02 19:08:48,011:INFO:                pyod: 2.0.5
2025-06-02 19:08:48,011:INFO:            imblearn: 0.13.0
2025-06-02 19:08:48,011:INFO:   category_encoders: 2.7.0
2025-06-02 19:08:48,011:INFO:            lightgbm: 4.6.0
2025-06-02 19:08:48,011:INFO:               numba: 0.61.0
2025-06-02 19:08:48,011:INFO:            requests: 2.32.3
2025-06-02 19:08:48,012:INFO:          matplotlib: 3.7.1
2025-06-02 19:08:48,012:INFO:          scikitplot: 0.3.7
2025-06-02 19:08:48,012:INFO:         yellowbrick: 1.5
2025-06-02 19:08:48,012:INFO:              plotly: 6.1.2
2025-06-02 19:08:48,012:INFO:    plotly-resampler: Not installed
2025-06-02 19:08:48,012:INFO:             kaleido: 0.2.1
2025-06-02 19:08:48,012:INFO:           schemdraw: 0.15
2025-06-02 19:08:48,012:INFO:         statsmodels: 0.14.4
2025-06-02 19:08:48,012:INFO:              sktime: 0.26.0
2025-06-02 19:08:48,013:INFO:               tbats: 1.1.3
2025-06-02 19:08:48,013:INFO:            pmdarima: 2.0.4
2025-06-02 19:08:48,013:INFO:              psutil: 7.0.0
2025-06-02 19:08:48,013:INFO:          markupsafe: 2.1.2
2025-06-02 19:08:48,013:INFO:             pickle5: Not installed
2025-06-02 19:08:48,013:INFO:         cloudpickle: 3.1.1
2025-06-02 19:08:48,013:INFO:         deprecation: 2.1.0
2025-06-02 19:08:48,013:INFO:              xxhash: 3.5.0
2025-06-02 19:08:48,013:INFO:           wurlitzer: Not installed
2025-06-02 19:08:48,013:INFO:PyCaret optional dependencies:
2025-06-02 19:08:48,014:INFO:                shap: 0.44.1
2025-06-02 19:08:48,014:INFO:           interpret: 0.6.9
2025-06-02 19:08:48,014:INFO:                umap: 0.5.7
2025-06-02 19:08:48,014:INFO:     ydata_profiling: 4.16.1
2025-06-02 19:08:48,014:INFO:  explainerdashboard: 0.4.8
2025-06-02 19:08:48,014:INFO:             autoviz: Not installed
2025-06-02 19:08:48,014:INFO:           fairlearn: 0.7.0
2025-06-02 19:08:48,014:INFO:          deepchecks: Not installed
2025-06-02 19:08:48,015:INFO:             xgboost: 3.0.2
2025-06-02 19:08:48,015:INFO:            catboost: 1.2.8
2025-06-02 19:08:48,015:INFO:              kmodes: 0.12.2
2025-06-02 19:08:48,015:INFO:             mlxtend: 0.23.4
2025-06-02 19:08:48,015:INFO:       statsforecast: 1.5.0
2025-06-02 19:08:48,015:INFO:        tune_sklearn: Not installed
2025-06-02 19:08:48,015:INFO:                 ray: Not installed
2025-06-02 19:08:48,015:INFO:            hyperopt: 0.2.7
2025-06-02 19:08:48,016:INFO:              optuna: 4.3.0
2025-06-02 19:08:48,016:INFO:               skopt: 0.10.2
2025-06-02 19:08:48,016:INFO:              mlflow: 2.22.0
2025-06-02 19:08:48,016:INFO:              gradio: 5.32.0
2025-06-02 19:08:48,016:INFO:             fastapi: 0.115.12
2025-06-02 19:08:48,016:INFO:             uvicorn: 0.34.3
2025-06-02 19:08:48,016:INFO:              m2cgen: 0.10.0
2025-06-02 19:08:48,017:INFO:           evidently: 0.4.40
2025-06-02 19:08:48,017:INFO:               fugue: 0.8.5
2025-06-02 19:08:48,017:INFO:           streamlit: Not installed
2025-06-02 19:08:48,017:INFO:             prophet: Not installed
2025-06-02 19:08:48,017:INFO:None
2025-06-02 19:08:48,017:INFO:Set up data.
2025-06-02 19:08:48,351:INFO:Set up folding strategy.
2025-06-02 19:08:48,351:INFO:Set up train/test split.
2025-06-02 19:08:48,500:INFO:Set up index.
2025-06-02 19:08:48,503:INFO:Assigning column types.
2025-06-02 19:08:48,584:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 19:08:48,585:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 19:08:48,596:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:08:48,608:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:08:48,795:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:08:48,881:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:08:48,883:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:08:48,890:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:08:48,892:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 19:08:48,900:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:08:48,909:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:08:49,084:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:08:49,168:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:08:49,169:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:08:49,174:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:08:49,175:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 19:08:49,182:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:08:49,190:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:08:49,332:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:08:49,461:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:08:49,463:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:08:49,470:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:08:49,487:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:08:49,500:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:08:49,771:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:08:49,897:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:08:49,899:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:08:49,905:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:08:49,907:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 19:08:49,923:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:08:50,073:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:08:50,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:08:50,147:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:08:50,152:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:08:50,169:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:08:50,316:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:08:50,424:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:08:50,425:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:08:50,431:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:08:50,432:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 19:08:50,619:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:08:50,695:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:08:50,696:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:08:50,700:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:08:50,856:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:08:50,940:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:08:50,941:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:08:50,945:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:08:50,946:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 19:08:51,105:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:08:51,181:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:08:51,185:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:08:51,343:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:08:51,430:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:08:51,436:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:08:51,438:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 19:08:51,689:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:08:51,693:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:08:51,926:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:08:51,931:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:08:51,935:INFO:Preparing preprocessing pipeline...
2025-06-02 19:08:51,935:INFO:Set up simple imputation.
2025-06-02 19:08:51,935:INFO:Set up removing multicollinearity.
2025-06-02 19:08:51,946:INFO:Set up column name cleaning.
2025-06-02 19:08:53,281:INFO:Finished creating preprocessing pipeline.
2025-06-02 19:08:53,295:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 19:08:53,296:INFO:Creating final display dataframe.
2025-06-02 19:08:54,657:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4200, 147)
4        Transformed data shape        (4200, 94)
5   Transformed train set shape        (3360, 94)
6    Transformed test set shape         (840, 94)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              5503
2025-06-02 19:08:54,921:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:08:54,925:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:08:55,193:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:08:55,197:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:08:55,199:INFO:setup() successfully completed in 7.25s...............
2025-06-02 19:08:55,200:INFO:Initializing compare_models()
2025-06-02 19:08:55,200:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 19:08:55,200:INFO:Checking exceptions
2025-06-02 19:08:55,234:INFO:Preparing display monitor
2025-06-02 19:08:55,296:INFO:Initializing Linear Regression
2025-06-02 19:08:55,296:INFO:Total runtime is 0.0 minutes
2025-06-02 19:08:55,306:INFO:SubProcess create_model() called ==================================
2025-06-02 19:08:55,307:INFO:Initializing create_model()
2025-06-02 19:08:55,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:08:55,307:INFO:Checking exceptions
2025-06-02 19:08:55,308:INFO:Importing libraries
2025-06-02 19:08:55,308:INFO:Copying training dataset
2025-06-02 19:08:55,381:INFO:Defining folds
2025-06-02 19:08:55,382:INFO:Declaring metric variables
2025-06-02 19:08:55,393:INFO:Importing untrained model
2025-06-02 19:08:55,401:INFO:Linear Regression Imported successfully
2025-06-02 19:08:55,424:INFO:Starting cross validation
2025-06-02 19:08:55,428:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:08:57,107:INFO:Calculating mean and std
2025-06-02 19:08:57,111:INFO:Creating metrics dataframe
2025-06-02 19:08:57,117:INFO:Uploading results into container
2025-06-02 19:08:57,118:INFO:Uploading model into container now
2025-06-02 19:08:57,120:INFO:_master_model_container: 1
2025-06-02 19:08:57,120:INFO:_display_container: 2
2025-06-02 19:08:57,121:INFO:LinearRegression(n_jobs=-1)
2025-06-02 19:08:57,121:INFO:create_model() successfully completed......................................
2025-06-02 19:08:59,295:INFO:SubProcess create_model() end ==================================
2025-06-02 19:08:59,296:INFO:Creating metrics dataframe
2025-06-02 19:08:59,315:INFO:Initializing Lasso Regression
2025-06-02 19:08:59,315:INFO:Total runtime is 0.06698416074117025 minutes
2025-06-02 19:08:59,332:INFO:SubProcess create_model() called ==================================
2025-06-02 19:08:59,333:INFO:Initializing create_model()
2025-06-02 19:08:59,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:08:59,334:INFO:Checking exceptions
2025-06-02 19:08:59,336:INFO:Importing libraries
2025-06-02 19:08:59,336:INFO:Copying training dataset
2025-06-02 19:08:59,444:INFO:Defining folds
2025-06-02 19:08:59,444:INFO:Declaring metric variables
2025-06-02 19:08:59,462:INFO:Importing untrained model
2025-06-02 19:08:59,480:INFO:Lasso Regression Imported successfully
2025-06-02 19:08:59,517:INFO:Starting cross validation
2025-06-02 19:08:59,524:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:09:01,439:INFO:Calculating mean and std
2025-06-02 19:09:01,444:INFO:Creating metrics dataframe
2025-06-02 19:09:01,453:INFO:Uploading results into container
2025-06-02 19:09:01,455:INFO:Uploading model into container now
2025-06-02 19:09:01,457:INFO:_master_model_container: 2
2025-06-02 19:09:01,457:INFO:_display_container: 2
2025-06-02 19:09:01,461:INFO:Lasso(random_state=123)
2025-06-02 19:09:01,461:INFO:create_model() successfully completed......................................
2025-06-02 19:09:04,760:INFO:SubProcess create_model() end ==================================
2025-06-02 19:09:04,761:INFO:Creating metrics dataframe
2025-06-02 19:09:04,787:INFO:Initializing Ridge Regression
2025-06-02 19:09:04,788:INFO:Total runtime is 0.15818830728530886 minutes
2025-06-02 19:09:04,801:INFO:SubProcess create_model() called ==================================
2025-06-02 19:09:04,802:INFO:Initializing create_model()
2025-06-02 19:09:04,802:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:09:04,803:INFO:Checking exceptions
2025-06-02 19:09:04,803:INFO:Importing libraries
2025-06-02 19:09:04,804:INFO:Copying training dataset
2025-06-02 19:09:04,904:INFO:Defining folds
2025-06-02 19:09:04,905:INFO:Declaring metric variables
2025-06-02 19:09:04,921:INFO:Importing untrained model
2025-06-02 19:09:04,937:INFO:Ridge Regression Imported successfully
2025-06-02 19:09:04,973:INFO:Starting cross validation
2025-06-02 19:09:04,979:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:09:06,215:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.16862e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 19:09:06,217:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.02554e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 19:09:06,278:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.19149e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 19:09:06,309:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.67603e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 19:09:06,445:INFO:Calculating mean and std
2025-06-02 19:09:06,464:INFO:Creating metrics dataframe
2025-06-02 19:09:06,475:INFO:Uploading results into container
2025-06-02 19:09:06,478:INFO:Uploading model into container now
2025-06-02 19:09:06,479:INFO:_master_model_container: 3
2025-06-02 19:09:06,479:INFO:_display_container: 2
2025-06-02 19:09:06,480:INFO:Ridge(random_state=123)
2025-06-02 19:09:06,481:INFO:create_model() successfully completed......................................
2025-06-02 19:09:08,927:INFO:SubProcess create_model() end ==================================
2025-06-02 19:09:08,927:INFO:Creating metrics dataframe
2025-06-02 19:09:08,958:INFO:Initializing Elastic Net
2025-06-02 19:09:08,958:INFO:Total runtime is 0.22769576311111453 minutes
2025-06-02 19:09:09,010:INFO:SubProcess create_model() called ==================================
2025-06-02 19:09:09,011:INFO:Initializing create_model()
2025-06-02 19:09:09,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:09:09,012:INFO:Checking exceptions
2025-06-02 19:09:09,013:INFO:Importing libraries
2025-06-02 19:09:09,013:INFO:Copying training dataset
2025-06-02 19:09:09,456:INFO:Defining folds
2025-06-02 19:09:09,457:INFO:Declaring metric variables
2025-06-02 19:09:09,476:INFO:Importing untrained model
2025-06-02 19:09:09,509:INFO:Elastic Net Imported successfully
2025-06-02 19:09:09,555:INFO:Starting cross validation
2025-06-02 19:09:09,561:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:09:11,255:INFO:Calculating mean and std
2025-06-02 19:09:11,258:INFO:Creating metrics dataframe
2025-06-02 19:09:11,263:INFO:Uploading results into container
2025-06-02 19:09:11,264:INFO:Uploading model into container now
2025-06-02 19:09:11,266:INFO:_master_model_container: 4
2025-06-02 19:09:11,266:INFO:_display_container: 2
2025-06-02 19:09:11,267:INFO:ElasticNet(random_state=123)
2025-06-02 19:09:11,267:INFO:create_model() successfully completed......................................
2025-06-02 19:09:13,447:INFO:SubProcess create_model() end ==================================
2025-06-02 19:09:13,447:INFO:Creating metrics dataframe
2025-06-02 19:09:13,470:INFO:Initializing Least Angle Regression
2025-06-02 19:09:13,471:INFO:Total runtime is 0.3029199322064718 minutes
2025-06-02 19:09:13,486:INFO:SubProcess create_model() called ==================================
2025-06-02 19:09:13,488:INFO:Initializing create_model()
2025-06-02 19:09:13,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:09:13,489:INFO:Checking exceptions
2025-06-02 19:09:13,489:INFO:Importing libraries
2025-06-02 19:09:13,489:INFO:Copying training dataset
2025-06-02 19:09:13,573:INFO:Defining folds
2025-06-02 19:09:13,573:INFO:Declaring metric variables
2025-06-02 19:09:13,587:INFO:Importing untrained model
2025-06-02 19:09:13,602:INFO:Least Angle Regression Imported successfully
2025-06-02 19:09:13,633:INFO:Starting cross validation
2025-06-02 19:09:13,637:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:09:14,638:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.521e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:09:14,640:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.134e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:09:14,641:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.026e-01, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:09:14,645:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.783e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:09:14,648:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.704e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:09:14,649:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.931e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:09:14,650:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=7.775e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:09:14,654:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.576e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:09:14,656:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.424e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:09:14,660:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.748e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:09:14,662:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.674e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:09:14,665:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.486e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:09:14,667:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.601e+01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:09:14,673:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.179e+02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:09:14,804:INFO:Calculating mean and std
2025-06-02 19:09:14,807:INFO:Creating metrics dataframe
2025-06-02 19:09:14,812:INFO:Uploading results into container
2025-06-02 19:09:14,813:INFO:Uploading model into container now
2025-06-02 19:09:14,814:INFO:_master_model_container: 5
2025-06-02 19:09:14,814:INFO:_display_container: 2
2025-06-02 19:09:14,816:INFO:Lars(random_state=123)
2025-06-02 19:09:14,816:INFO:create_model() successfully completed......................................
2025-06-02 19:09:16,628:INFO:SubProcess create_model() end ==================================
2025-06-02 19:09:16,628:INFO:Creating metrics dataframe
2025-06-02 19:09:16,650:INFO:Initializing Lasso Least Angle Regression
2025-06-02 19:09:16,651:INFO:Total runtime is 0.355911393960317 minutes
2025-06-02 19:09:16,667:INFO:SubProcess create_model() called ==================================
2025-06-02 19:09:16,668:INFO:Initializing create_model()
2025-06-02 19:09:16,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:09:16,670:INFO:Checking exceptions
2025-06-02 19:09:16,671:INFO:Importing libraries
2025-06-02 19:09:16,671:INFO:Copying training dataset
2025-06-02 19:09:16,743:INFO:Defining folds
2025-06-02 19:09:16,744:INFO:Declaring metric variables
2025-06-02 19:09:16,758:INFO:Importing untrained model
2025-06-02 19:09:16,768:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 19:09:16,827:INFO:Starting cross validation
2025-06-02 19:09:16,833:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:09:18,028:INFO:Calculating mean and std
2025-06-02 19:09:18,032:INFO:Creating metrics dataframe
2025-06-02 19:09:18,039:INFO:Uploading results into container
2025-06-02 19:09:18,041:INFO:Uploading model into container now
2025-06-02 19:09:18,043:INFO:_master_model_container: 6
2025-06-02 19:09:18,043:INFO:_display_container: 2
2025-06-02 19:09:18,044:INFO:LassoLars(random_state=123)
2025-06-02 19:09:18,044:INFO:create_model() successfully completed......................................
2025-06-02 19:09:19,857:INFO:SubProcess create_model() end ==================================
2025-06-02 19:09:19,857:INFO:Creating metrics dataframe
2025-06-02 19:09:19,875:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 19:09:19,875:INFO:Total runtime is 0.4096510847409567 minutes
2025-06-02 19:09:19,885:INFO:SubProcess create_model() called ==================================
2025-06-02 19:09:19,888:INFO:Initializing create_model()
2025-06-02 19:09:19,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:09:19,890:INFO:Checking exceptions
2025-06-02 19:09:19,890:INFO:Importing libraries
2025-06-02 19:09:19,891:INFO:Copying training dataset
2025-06-02 19:09:19,967:INFO:Defining folds
2025-06-02 19:09:19,968:INFO:Declaring metric variables
2025-06-02 19:09:19,981:INFO:Importing untrained model
2025-06-02 19:09:19,995:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 19:09:20,022:INFO:Starting cross validation
2025-06-02 19:09:20,025:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:09:21,012:INFO:Calculating mean and std
2025-06-02 19:09:21,015:INFO:Creating metrics dataframe
2025-06-02 19:09:21,020:INFO:Uploading results into container
2025-06-02 19:09:21,021:INFO:Uploading model into container now
2025-06-02 19:09:21,022:INFO:_master_model_container: 7
2025-06-02 19:09:21,023:INFO:_display_container: 2
2025-06-02 19:09:21,024:INFO:OrthogonalMatchingPursuit()
2025-06-02 19:09:21,024:INFO:create_model() successfully completed......................................
2025-06-02 19:09:23,097:INFO:SubProcess create_model() end ==================================
2025-06-02 19:09:23,097:INFO:Creating metrics dataframe
2025-06-02 19:09:23,117:INFO:Initializing Bayesian Ridge
2025-06-02 19:09:23,117:INFO:Total runtime is 0.4636709292729696 minutes
2025-06-02 19:09:23,130:INFO:SubProcess create_model() called ==================================
2025-06-02 19:09:23,131:INFO:Initializing create_model()
2025-06-02 19:09:23,131:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:09:23,132:INFO:Checking exceptions
2025-06-02 19:09:23,132:INFO:Importing libraries
2025-06-02 19:09:23,132:INFO:Copying training dataset
2025-06-02 19:09:23,208:INFO:Defining folds
2025-06-02 19:09:23,209:INFO:Declaring metric variables
2025-06-02 19:09:23,225:INFO:Importing untrained model
2025-06-02 19:09:23,237:INFO:Bayesian Ridge Imported successfully
2025-06-02 19:09:23,261:INFO:Starting cross validation
2025-06-02 19:09:23,266:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:09:24,657:INFO:Calculating mean and std
2025-06-02 19:09:24,661:INFO:Creating metrics dataframe
2025-06-02 19:09:24,668:INFO:Uploading results into container
2025-06-02 19:09:24,673:INFO:Uploading model into container now
2025-06-02 19:09:24,675:INFO:_master_model_container: 8
2025-06-02 19:09:24,675:INFO:_display_container: 2
2025-06-02 19:09:24,676:INFO:BayesianRidge()
2025-06-02 19:09:24,677:INFO:create_model() successfully completed......................................
2025-06-02 19:09:27,248:INFO:SubProcess create_model() end ==================================
2025-06-02 19:09:27,248:INFO:Creating metrics dataframe
2025-06-02 19:09:27,277:INFO:Initializing Passive Aggressive Regressor
2025-06-02 19:09:27,279:INFO:Total runtime is 0.5330476085344951 minutes
2025-06-02 19:09:27,294:INFO:SubProcess create_model() called ==================================
2025-06-02 19:09:27,296:INFO:Initializing create_model()
2025-06-02 19:09:27,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:09:27,297:INFO:Checking exceptions
2025-06-02 19:09:27,298:INFO:Importing libraries
2025-06-02 19:09:27,298:INFO:Copying training dataset
2025-06-02 19:09:27,406:INFO:Defining folds
2025-06-02 19:09:27,407:INFO:Declaring metric variables
2025-06-02 19:09:27,423:INFO:Importing untrained model
2025-06-02 19:09:27,435:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 19:09:27,471:INFO:Starting cross validation
2025-06-02 19:09:27,474:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:09:28,845:INFO:Calculating mean and std
2025-06-02 19:09:28,849:INFO:Creating metrics dataframe
2025-06-02 19:09:28,858:INFO:Uploading results into container
2025-06-02 19:09:28,860:INFO:Uploading model into container now
2025-06-02 19:09:28,862:INFO:_master_model_container: 9
2025-06-02 19:09:28,862:INFO:_display_container: 2
2025-06-02 19:09:28,863:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 19:09:28,864:INFO:create_model() successfully completed......................................
2025-06-02 19:09:31,291:INFO:SubProcess create_model() end ==================================
2025-06-02 19:09:31,292:INFO:Creating metrics dataframe
2025-06-02 19:09:31,322:INFO:Initializing Huber Regressor
2025-06-02 19:09:31,323:INFO:Total runtime is 0.6004493554433187 minutes
2025-06-02 19:09:31,344:INFO:SubProcess create_model() called ==================================
2025-06-02 19:09:31,344:INFO:Initializing create_model()
2025-06-02 19:09:31,345:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:09:31,345:INFO:Checking exceptions
2025-06-02 19:09:31,345:INFO:Importing libraries
2025-06-02 19:09:31,345:INFO:Copying training dataset
2025-06-02 19:09:31,442:INFO:Defining folds
2025-06-02 19:09:31,442:INFO:Declaring metric variables
2025-06-02 19:09:31,457:INFO:Importing untrained model
2025-06-02 19:09:31,472:INFO:Huber Regressor Imported successfully
2025-06-02 19:09:31,494:INFO:Starting cross validation
2025-06-02 19:09:31,498:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:09:35,009:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:09:35,062:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:09:35,101:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:09:35,163:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:09:35,308:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:09:35,399:INFO:Calculating mean and std
2025-06-02 19:09:35,404:INFO:Creating metrics dataframe
2025-06-02 19:09:35,409:INFO:Uploading results into container
2025-06-02 19:09:35,410:INFO:Uploading model into container now
2025-06-02 19:09:35,412:INFO:_master_model_container: 10
2025-06-02 19:09:35,412:INFO:_display_container: 2
2025-06-02 19:09:35,413:INFO:HuberRegressor()
2025-06-02 19:09:35,413:INFO:create_model() successfully completed......................................
2025-06-02 19:09:37,901:INFO:SubProcess create_model() end ==================================
2025-06-02 19:09:37,901:INFO:Creating metrics dataframe
2025-06-02 19:09:37,926:INFO:Initializing K Neighbors Regressor
2025-06-02 19:09:37,926:INFO:Total runtime is 0.7105026284853617 minutes
2025-06-02 19:09:37,937:INFO:SubProcess create_model() called ==================================
2025-06-02 19:09:37,938:INFO:Initializing create_model()
2025-06-02 19:09:37,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:09:37,938:INFO:Checking exceptions
2025-06-02 19:09:37,939:INFO:Importing libraries
2025-06-02 19:09:37,939:INFO:Copying training dataset
2025-06-02 19:09:38,031:INFO:Defining folds
2025-06-02 19:09:38,032:INFO:Declaring metric variables
2025-06-02 19:09:38,046:INFO:Importing untrained model
2025-06-02 19:09:38,059:INFO:K Neighbors Regressor Imported successfully
2025-06-02 19:09:38,086:INFO:Starting cross validation
2025-06-02 19:09:38,092:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:09:39,587:INFO:Calculating mean and std
2025-06-02 19:09:39,590:INFO:Creating metrics dataframe
2025-06-02 19:09:39,594:INFO:Uploading results into container
2025-06-02 19:09:39,595:INFO:Uploading model into container now
2025-06-02 19:09:39,597:INFO:_master_model_container: 11
2025-06-02 19:09:39,597:INFO:_display_container: 2
2025-06-02 19:09:39,597:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 19:09:39,598:INFO:create_model() successfully completed......................................
2025-06-02 19:09:41,299:INFO:SubProcess create_model() end ==================================
2025-06-02 19:09:41,300:INFO:Creating metrics dataframe
2025-06-02 19:09:41,345:INFO:Initializing Decision Tree Regressor
2025-06-02 19:09:41,345:INFO:Total runtime is 0.7674796024958292 minutes
2025-06-02 19:09:41,363:INFO:SubProcess create_model() called ==================================
2025-06-02 19:09:41,364:INFO:Initializing create_model()
2025-06-02 19:09:41,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:09:41,365:INFO:Checking exceptions
2025-06-02 19:09:41,365:INFO:Importing libraries
2025-06-02 19:09:41,366:INFO:Copying training dataset
2025-06-02 19:09:41,492:INFO:Defining folds
2025-06-02 19:09:41,493:INFO:Declaring metric variables
2025-06-02 19:09:41,512:INFO:Importing untrained model
2025-06-02 19:09:41,531:INFO:Decision Tree Regressor Imported successfully
2025-06-02 19:09:41,567:INFO:Starting cross validation
2025-06-02 19:09:41,573:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:09:43,487:INFO:Calculating mean and std
2025-06-02 19:09:43,490:INFO:Creating metrics dataframe
2025-06-02 19:09:43,495:INFO:Uploading results into container
2025-06-02 19:09:43,497:INFO:Uploading model into container now
2025-06-02 19:09:43,498:INFO:_master_model_container: 12
2025-06-02 19:09:43,498:INFO:_display_container: 2
2025-06-02 19:09:43,499:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 19:09:43,499:INFO:create_model() successfully completed......................................
2025-06-02 19:09:45,753:INFO:SubProcess create_model() end ==================================
2025-06-02 19:09:45,754:INFO:Creating metrics dataframe
2025-06-02 19:09:45,785:INFO:Initializing Random Forest Regressor
2025-06-02 19:09:45,785:INFO:Total runtime is 0.8414712111155191 minutes
2025-06-02 19:09:45,800:INFO:SubProcess create_model() called ==================================
2025-06-02 19:09:45,801:INFO:Initializing create_model()
2025-06-02 19:09:45,801:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:09:45,802:INFO:Checking exceptions
2025-06-02 19:09:45,802:INFO:Importing libraries
2025-06-02 19:09:45,804:INFO:Copying training dataset
2025-06-02 19:09:45,908:INFO:Defining folds
2025-06-02 19:09:45,909:INFO:Declaring metric variables
2025-06-02 19:09:45,923:INFO:Importing untrained model
2025-06-02 19:09:45,940:INFO:Random Forest Regressor Imported successfully
2025-06-02 19:09:45,964:INFO:Starting cross validation
2025-06-02 19:09:45,969:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:09:58,794:INFO:Calculating mean and std
2025-06-02 19:09:58,797:INFO:Creating metrics dataframe
2025-06-02 19:09:58,805:INFO:Uploading results into container
2025-06-02 19:09:58,807:INFO:Uploading model into container now
2025-06-02 19:09:58,808:INFO:_master_model_container: 13
2025-06-02 19:09:58,809:INFO:_display_container: 2
2025-06-02 19:09:58,810:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:09:58,811:INFO:create_model() successfully completed......................................
2025-06-02 19:10:00,508:INFO:SubProcess create_model() end ==================================
2025-06-02 19:10:00,509:INFO:Creating metrics dataframe
2025-06-02 19:10:00,534:INFO:Initializing Extra Trees Regressor
2025-06-02 19:10:00,535:INFO:Total runtime is 1.0873060822486877 minutes
2025-06-02 19:10:00,550:INFO:SubProcess create_model() called ==================================
2025-06-02 19:10:00,550:INFO:Initializing create_model()
2025-06-02 19:10:00,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:10:00,552:INFO:Checking exceptions
2025-06-02 19:10:00,552:INFO:Importing libraries
2025-06-02 19:10:00,553:INFO:Copying training dataset
2025-06-02 19:10:00,625:INFO:Defining folds
2025-06-02 19:10:00,625:INFO:Declaring metric variables
2025-06-02 19:10:00,641:INFO:Importing untrained model
2025-06-02 19:10:00,655:INFO:Extra Trees Regressor Imported successfully
2025-06-02 19:10:00,680:INFO:Starting cross validation
2025-06-02 19:10:00,685:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:10:07,522:INFO:Calculating mean and std
2025-06-02 19:10:07,525:INFO:Creating metrics dataframe
2025-06-02 19:10:07,530:INFO:Uploading results into container
2025-06-02 19:10:07,531:INFO:Uploading model into container now
2025-06-02 19:10:07,532:INFO:_master_model_container: 14
2025-06-02 19:10:07,533:INFO:_display_container: 2
2025-06-02 19:10:07,534:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:10:07,534:INFO:create_model() successfully completed......................................
2025-06-02 19:10:09,297:INFO:SubProcess create_model() end ==================================
2025-06-02 19:10:09,297:INFO:Creating metrics dataframe
2025-06-02 19:10:09,326:INFO:Initializing AdaBoost Regressor
2025-06-02 19:10:09,328:INFO:Total runtime is 1.2338581442832948 minutes
2025-06-02 19:10:09,339:INFO:SubProcess create_model() called ==================================
2025-06-02 19:10:09,340:INFO:Initializing create_model()
2025-06-02 19:10:09,340:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:10:09,341:INFO:Checking exceptions
2025-06-02 19:10:09,341:INFO:Importing libraries
2025-06-02 19:10:09,341:INFO:Copying training dataset
2025-06-02 19:10:09,398:INFO:Defining folds
2025-06-02 19:10:09,399:INFO:Declaring metric variables
2025-06-02 19:10:09,413:INFO:Importing untrained model
2025-06-02 19:10:09,427:INFO:AdaBoost Regressor Imported successfully
2025-06-02 19:10:09,449:INFO:Starting cross validation
2025-06-02 19:10:09,454:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:10:11,464:INFO:Calculating mean and std
2025-06-02 19:10:11,467:INFO:Creating metrics dataframe
2025-06-02 19:10:11,471:INFO:Uploading results into container
2025-06-02 19:10:11,472:INFO:Uploading model into container now
2025-06-02 19:10:11,473:INFO:_master_model_container: 15
2025-06-02 19:10:11,473:INFO:_display_container: 2
2025-06-02 19:10:11,474:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 19:10:11,474:INFO:create_model() successfully completed......................................
2025-06-02 19:10:12,908:INFO:SubProcess create_model() end ==================================
2025-06-02 19:10:12,909:INFO:Creating metrics dataframe
2025-06-02 19:10:12,930:INFO:Initializing Gradient Boosting Regressor
2025-06-02 19:10:12,931:INFO:Total runtime is 1.293912974993388 minutes
2025-06-02 19:10:12,942:INFO:SubProcess create_model() called ==================================
2025-06-02 19:10:12,943:INFO:Initializing create_model()
2025-06-02 19:10:12,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:10:12,944:INFO:Checking exceptions
2025-06-02 19:10:12,944:INFO:Importing libraries
2025-06-02 19:10:12,944:INFO:Copying training dataset
2025-06-02 19:10:13,004:INFO:Defining folds
2025-06-02 19:10:13,004:INFO:Declaring metric variables
2025-06-02 19:10:13,017:INFO:Importing untrained model
2025-06-02 19:10:13,033:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 19:10:13,057:INFO:Starting cross validation
2025-06-02 19:10:13,064:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:10:16,751:INFO:Calculating mean and std
2025-06-02 19:10:16,754:INFO:Creating metrics dataframe
2025-06-02 19:10:16,758:INFO:Uploading results into container
2025-06-02 19:10:16,759:INFO:Uploading model into container now
2025-06-02 19:10:16,760:INFO:_master_model_container: 16
2025-06-02 19:10:16,761:INFO:_display_container: 2
2025-06-02 19:10:16,761:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 19:10:16,762:INFO:create_model() successfully completed......................................
2025-06-02 19:10:18,193:INFO:SubProcess create_model() end ==================================
2025-06-02 19:10:18,193:INFO:Creating metrics dataframe
2025-06-02 19:10:18,223:INFO:Initializing Extreme Gradient Boosting
2025-06-02 19:10:18,223:INFO:Total runtime is 1.3821127851804098 minutes
2025-06-02 19:10:18,234:INFO:SubProcess create_model() called ==================================
2025-06-02 19:10:18,235:INFO:Initializing create_model()
2025-06-02 19:10:18,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:10:18,238:INFO:Checking exceptions
2025-06-02 19:10:18,238:INFO:Importing libraries
2025-06-02 19:10:18,239:INFO:Copying training dataset
2025-06-02 19:10:18,300:INFO:Defining folds
2025-06-02 19:10:18,301:INFO:Declaring metric variables
2025-06-02 19:10:18,316:INFO:Importing untrained model
2025-06-02 19:10:18,330:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 19:10:18,353:INFO:Starting cross validation
2025-06-02 19:10:18,358:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:10:20,669:INFO:Calculating mean and std
2025-06-02 19:10:20,672:INFO:Creating metrics dataframe
2025-06-02 19:10:20,676:INFO:Uploading results into container
2025-06-02 19:10:20,677:INFO:Uploading model into container now
2025-06-02 19:10:20,678:INFO:_master_model_container: 17
2025-06-02 19:10:20,678:INFO:_display_container: 2
2025-06-02 19:10:20,682:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 19:10:20,682:INFO:create_model() successfully completed......................................
2025-06-02 19:10:22,251:INFO:SubProcess create_model() end ==================================
2025-06-02 19:10:22,251:INFO:Creating metrics dataframe
2025-06-02 19:10:22,288:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 19:10:22,288:INFO:Total runtime is 1.4498592456181845 minutes
2025-06-02 19:10:22,298:INFO:SubProcess create_model() called ==================================
2025-06-02 19:10:22,298:INFO:Initializing create_model()
2025-06-02 19:10:22,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:10:22,299:INFO:Checking exceptions
2025-06-02 19:10:22,299:INFO:Importing libraries
2025-06-02 19:10:22,300:INFO:Copying training dataset
2025-06-02 19:10:22,370:INFO:Defining folds
2025-06-02 19:10:22,371:INFO:Declaring metric variables
2025-06-02 19:10:22,383:INFO:Importing untrained model
2025-06-02 19:10:22,398:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 19:10:22,422:INFO:Starting cross validation
2025-06-02 19:10:22,426:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:10:24,646:INFO:Calculating mean and std
2025-06-02 19:10:24,648:INFO:Creating metrics dataframe
2025-06-02 19:10:24,655:INFO:Uploading results into container
2025-06-02 19:10:24,657:INFO:Uploading model into container now
2025-06-02 19:10:24,658:INFO:_master_model_container: 18
2025-06-02 19:10:24,658:INFO:_display_container: 2
2025-06-02 19:10:24,659:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:10:24,660:INFO:create_model() successfully completed......................................
2025-06-02 19:10:26,166:INFO:SubProcess create_model() end ==================================
2025-06-02 19:10:26,167:INFO:Creating metrics dataframe
2025-06-02 19:10:26,195:INFO:Initializing CatBoost Regressor
2025-06-02 19:10:26,195:INFO:Total runtime is 1.5149849613507589 minutes
2025-06-02 19:10:26,207:INFO:SubProcess create_model() called ==================================
2025-06-02 19:10:26,208:INFO:Initializing create_model()
2025-06-02 19:10:26,208:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:10:26,208:INFO:Checking exceptions
2025-06-02 19:10:26,208:INFO:Importing libraries
2025-06-02 19:10:26,208:INFO:Copying training dataset
2025-06-02 19:10:26,290:INFO:Defining folds
2025-06-02 19:10:26,291:INFO:Declaring metric variables
2025-06-02 19:10:26,312:INFO:Importing untrained model
2025-06-02 19:10:26,343:INFO:CatBoost Regressor Imported successfully
2025-06-02 19:10:26,368:INFO:Starting cross validation
2025-06-02 19:10:26,376:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:10:55,363:INFO:Calculating mean and std
2025-06-02 19:10:55,365:INFO:Creating metrics dataframe
2025-06-02 19:10:55,370:INFO:Uploading results into container
2025-06-02 19:10:55,371:INFO:Uploading model into container now
2025-06-02 19:10:55,372:INFO:_master_model_container: 19
2025-06-02 19:10:55,372:INFO:_display_container: 2
2025-06-02 19:10:55,373:INFO:<catboost.core.CatBoostRegressor object at 0x000001B718E31990>
2025-06-02 19:10:55,373:INFO:create_model() successfully completed......................................
2025-06-02 19:10:56,981:INFO:SubProcess create_model() end ==================================
2025-06-02 19:10:56,982:INFO:Creating metrics dataframe
2025-06-02 19:10:57,013:INFO:Initializing Dummy Regressor
2025-06-02 19:10:57,013:INFO:Total runtime is 2.028615061442057 minutes
2025-06-02 19:10:57,027:INFO:SubProcess create_model() called ==================================
2025-06-02 19:10:57,028:INFO:Initializing create_model()
2025-06-02 19:10:57,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6DC9BAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:10:57,028:INFO:Checking exceptions
2025-06-02 19:10:57,029:INFO:Importing libraries
2025-06-02 19:10:57,029:INFO:Copying training dataset
2025-06-02 19:10:57,152:INFO:Defining folds
2025-06-02 19:10:57,155:INFO:Declaring metric variables
2025-06-02 19:10:57,164:INFO:Importing untrained model
2025-06-02 19:10:57,178:INFO:Dummy Regressor Imported successfully
2025-06-02 19:10:57,201:INFO:Starting cross validation
2025-06-02 19:10:57,207:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:10:59,462:INFO:Calculating mean and std
2025-06-02 19:10:59,465:INFO:Creating metrics dataframe
2025-06-02 19:10:59,469:INFO:Uploading results into container
2025-06-02 19:10:59,471:INFO:Uploading model into container now
2025-06-02 19:10:59,472:INFO:_master_model_container: 20
2025-06-02 19:10:59,472:INFO:_display_container: 2
2025-06-02 19:10:59,473:INFO:DummyRegressor()
2025-06-02 19:10:59,473:INFO:create_model() successfully completed......................................
2025-06-02 19:11:01,272:INFO:SubProcess create_model() end ==================================
2025-06-02 19:11:01,273:INFO:Creating metrics dataframe
2025-06-02 19:11:01,370:INFO:Initializing create_model()
2025-06-02 19:11:01,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:11:01,372:INFO:Checking exceptions
2025-06-02 19:11:01,401:INFO:Importing libraries
2025-06-02 19:11:01,402:INFO:Copying training dataset
2025-06-02 19:11:01,538:INFO:Defining folds
2025-06-02 19:11:01,539:INFO:Declaring metric variables
2025-06-02 19:11:01,539:INFO:Importing untrained model
2025-06-02 19:11:01,539:INFO:Declaring custom model
2025-06-02 19:11:01,541:INFO:Extra Trees Regressor Imported successfully
2025-06-02 19:11:01,546:INFO:Cross validation set to False
2025-06-02 19:11:01,547:INFO:Fitting Model
2025-06-02 19:11:03,642:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:11:03,642:INFO:create_model() successfully completed......................................
2025-06-02 19:11:05,154:INFO:Initializing create_model()
2025-06-02 19:11:05,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=<catboost.core.CatBoostRegressor object at 0x000001B718E31990>, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:11:05,155:INFO:Checking exceptions
2025-06-02 19:11:05,161:INFO:Importing libraries
2025-06-02 19:11:05,162:INFO:Copying training dataset
2025-06-02 19:11:05,256:INFO:Defining folds
2025-06-02 19:11:05,256:INFO:Declaring metric variables
2025-06-02 19:11:05,257:INFO:Importing untrained model
2025-06-02 19:11:05,257:INFO:Declaring custom model
2025-06-02 19:11:05,259:INFO:CatBoost Regressor Imported successfully
2025-06-02 19:11:05,262:INFO:Cross validation set to False
2025-06-02 19:11:05,262:INFO:Fitting Model
2025-06-02 19:11:12,162:INFO:<catboost.core.CatBoostRegressor object at 0x000001B71000B7F0>
2025-06-02 19:11:12,163:INFO:create_model() successfully completed......................................
2025-06-02 19:11:13,692:INFO:Initializing create_model()
2025-06-02 19:11:13,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:11:13,693:INFO:Checking exceptions
2025-06-02 19:11:13,701:INFO:Importing libraries
2025-06-02 19:11:13,704:INFO:Copying training dataset
2025-06-02 19:11:13,765:INFO:Defining folds
2025-06-02 19:11:13,765:INFO:Declaring metric variables
2025-06-02 19:11:13,765:INFO:Importing untrained model
2025-06-02 19:11:13,766:INFO:Declaring custom model
2025-06-02 19:11:13,768:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 19:11:13,770:INFO:Cross validation set to False
2025-06-02 19:11:13,771:INFO:Fitting Model
2025-06-02 19:11:14,693:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 19:11:14,693:INFO:create_model() successfully completed......................................
2025-06-02 19:11:16,238:INFO:_master_model_container: 20
2025-06-02 19:11:16,238:INFO:_display_container: 2
2025-06-02 19:11:16,242:INFO:[ExtraTreesRegressor(n_jobs=-1, random_state=123), <catboost.core.CatBoostRegressor object at 0x000001B71000B7F0>, XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)]
2025-06-02 19:11:16,242:INFO:compare_models() successfully completed......................................
2025-06-02 19:11:16,410:INFO:Initializing tune_model()
2025-06-02 19:11:16,410:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>)
2025-06-02 19:11:16,410:INFO:Checking exceptions
2025-06-02 19:11:16,410:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 19:11:16,475:INFO:Copying training dataset
2025-06-02 19:11:16,540:INFO:Checking base model
2025-06-02 19:11:16,540:INFO:Base model : Extra Trees Regressor
2025-06-02 19:11:16,552:INFO:Declaring metric variables
2025-06-02 19:11:16,564:INFO:Defining Hyperparameters
2025-06-02 19:11:18,369:INFO:Tuning with n_jobs=-1
2025-06-02 19:11:18,389:INFO:Initializing skopt.BayesSearchCV
2025-06-02 19:15:23,549:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', False), ('actual_estimator__criterion', 'absolute_error'), ('actual_estimator__max_depth', 11), ('actual_estimator__max_features', 0.4556655086335653), ('actual_estimator__min_impurity_decrease', 0.00012891733508622256), ('actual_estimator__min_samples_leaf', 1), ('actual_estimator__min_samples_split', 9), ('actual_estimator__n_estimators', 11)])
2025-06-02 19:15:23,554:INFO:Hyperparameter search completed
2025-06-02 19:15:23,554:INFO:SubProcess create_model() called ==================================
2025-06-02 19:15:23,558:INFO:Initializing create_model()
2025-06-02 19:15:23,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B70FF46110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bootstrap': False, 'criterion': 'absolute_error', 'max_depth': 11, 'max_features': 0.4556655086335653, 'min_impurity_decrease': 0.00012891733508622256, 'min_samples_leaf': 1, 'min_samples_split': 9, 'n_estimators': 11})
2025-06-02 19:15:23,559:INFO:Checking exceptions
2025-06-02 19:15:23,559:INFO:Importing libraries
2025-06-02 19:15:23,560:INFO:Copying training dataset
2025-06-02 19:15:23,734:INFO:Defining folds
2025-06-02 19:15:23,735:INFO:Declaring metric variables
2025-06-02 19:15:23,766:INFO:Importing untrained model
2025-06-02 19:15:23,766:INFO:Declaring custom model
2025-06-02 19:15:23,788:INFO:Extra Trees Regressor Imported successfully
2025-06-02 19:15:23,815:INFO:Starting cross validation
2025-06-02 19:15:23,821:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:15:34,602:INFO:Calculating mean and std
2025-06-02 19:15:34,605:INFO:Creating metrics dataframe
2025-06-02 19:15:34,627:INFO:Finalizing model
2025-06-02 19:15:38,209:INFO:Uploading results into container
2025-06-02 19:15:38,214:INFO:Uploading model into container now
2025-06-02 19:15:38,218:INFO:_master_model_container: 21
2025-06-02 19:15:38,218:INFO:_display_container: 3
2025-06-02 19:15:38,221:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=11,
                    max_features=0.4556655086335653,
                    min_impurity_decrease=0.00012891733508622256,
                    min_samples_split=9, n_estimators=11, n_jobs=-1,
                    random_state=123)
2025-06-02 19:15:38,222:INFO:create_model() successfully completed......................................
2025-06-02 19:15:41,635:INFO:SubProcess create_model() end ==================================
2025-06-02 19:15:41,636:INFO:choose_better activated
2025-06-02 19:15:41,648:INFO:SubProcess create_model() called ==================================
2025-06-02 19:15:41,649:INFO:Initializing create_model()
2025-06-02 19:15:41,650:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:15:41,651:INFO:Checking exceptions
2025-06-02 19:15:41,660:INFO:Importing libraries
2025-06-02 19:15:41,661:INFO:Copying training dataset
2025-06-02 19:15:41,737:INFO:Defining folds
2025-06-02 19:15:41,737:INFO:Declaring metric variables
2025-06-02 19:15:41,738:INFO:Importing untrained model
2025-06-02 19:15:41,738:INFO:Declaring custom model
2025-06-02 19:15:41,739:INFO:Extra Trees Regressor Imported successfully
2025-06-02 19:15:41,739:INFO:Starting cross validation
2025-06-02 19:15:41,743:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:15:50,355:INFO:Calculating mean and std
2025-06-02 19:15:50,356:INFO:Creating metrics dataframe
2025-06-02 19:15:50,359:INFO:Finalizing model
2025-06-02 19:15:52,331:INFO:Uploading results into container
2025-06-02 19:15:52,332:INFO:Uploading model into container now
2025-06-02 19:15:52,333:INFO:_master_model_container: 22
2025-06-02 19:15:52,333:INFO:_display_container: 4
2025-06-02 19:15:52,334:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:15:52,335:INFO:create_model() successfully completed......................................
2025-06-02 19:15:53,859:INFO:SubProcess create_model() end ==================================
2025-06-02 19:15:53,860:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 0.1837
2025-06-02 19:15:53,862:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=11,
                    max_features=0.4556655086335653,
                    min_impurity_decrease=0.00012891733508622256,
                    min_samples_split=9, n_estimators=11, n_jobs=-1,
                    random_state=123) result for MAE is 0.2069
2025-06-02 19:15:53,862:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 19:15:53,862:INFO:choose_better completed
2025-06-02 19:15:53,863:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 19:15:53,901:INFO:_master_model_container: 22
2025-06-02 19:15:53,902:INFO:_display_container: 3
2025-06-02 19:15:53,906:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:15:53,906:INFO:tune_model() successfully completed......................................
2025-06-02 19:15:55,462:INFO:Initializing finalize_model()
2025-06-02 19:15:55,462:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 19:15:55,463:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:15:55,547:INFO:Initializing create_model()
2025-06-02 19:15:55,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:15:55,548:INFO:Checking exceptions
2025-06-02 19:15:55,550:INFO:Importing libraries
2025-06-02 19:15:55,550:INFO:Copying training dataset
2025-06-02 19:15:55,560:INFO:Defining folds
2025-06-02 19:15:55,560:INFO:Declaring metric variables
2025-06-02 19:15:55,561:INFO:Importing untrained model
2025-06-02 19:15:55,561:INFO:Declaring custom model
2025-06-02 19:15:55,562:INFO:Extra Trees Regressor Imported successfully
2025-06-02 19:15:55,564:INFO:Cross validation set to False
2025-06-02 19:15:55,564:INFO:Fitting Model
2025-06-02 19:15:57,939:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 19:15:57,940:INFO:create_model() successfully completed......................................
2025-06-02 19:15:59,470:INFO:_master_model_container: 22
2025-06-02 19:15:59,470:INFO:_display_container: 3
2025-06-02 19:15:59,492:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 19:15:59,492:INFO:finalize_model() successfully completed......................................
2025-06-02 19:16:01,390:INFO:Initializing save_model()
2025-06-02 19:16:01,391:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model_mae, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 19:16:01,391:INFO:Adding model into prep_pipe
2025-06-02 19:16:01,391:WARNING:Only Model saved as it was a pipeline.
2025-06-02 19:16:01,598:INFO:formation_energy_final_model_mae.pkl saved in current working directory
2025-06-02 19:16:01,627:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-02 19:16:01,628:INFO:save_model() successfully completed......................................
2025-06-02 19:16:03,140:INFO:Initializing load_model()
2025-06-02 19:16:03,140:INFO:load_model(model_name=formation_energy_final_model_mae, platform=None, authentication=None, verbose=True)
2025-06-02 19:16:03,799:INFO:Initializing get_config()
2025-06-02 19:16:03,799:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, variable=X_test)
2025-06-02 19:16:03,799:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 19:16:03,799:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 19:16:03,846:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
2030                       22.0                       46.0  \
3043                        8.0                       50.0   
3552                        8.0                       50.0   
380                        12.0                       12.0   
730                        58.0                       58.0   
...                         ...                        ...   
2572                        4.0                       14.0   
3757                        8.0                       26.0   
2377                        3.0                       50.0   
3499                        5.0                        8.0   
2893                       11.0                       21.0   

      MagpieData range Number  MagpieData mean Number   
2030                     24.0                34.00000  \
3043                     42.0                29.00000   
3552                     42.0                22.00000   
380                       0.0                12.00000   
730                       0.0                58.00000   
...                       ...                     ...   
2572                     10.0                 6.50000   
3757                     18.0                16.87324   
2377                     47.0                36.57143   
3499                      3.0                 6.80000   
2893                     10.0                18.50000   

      MagpieData avg_dev Number  MagpieData mode Number   
2030                  12.000000                    22.0  \
3043                  21.000000                     8.0   
3552                  18.666666                     8.0   
380                    0.000000                    12.0   
730                    0.000000                    58.0   
...                         ...                     ...   
2572                   3.750000                     4.0   
3757                   8.998215                     8.0   
2377                  19.183674                    50.0   
3499                   1.440000                     8.0   
2893                   3.750000                    21.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
2030                                43.0                                62.0  \
3043                                80.0                                87.0   
3552                                80.0                                87.0   
380                                 68.0                                68.0   
730                                 15.0                                15.0   
...                                  ...                                 ...   
2572                                67.0                                78.0   
3757                                55.0                                87.0   
2377                                 1.0                                80.0   
3499                                72.0                                87.0   
2893                                 2.0                                11.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
2030                              19.0                        52.500000  ...  \
3043                               7.0                        83.500000  ...   
3552                               7.0                        84.666664  ...   
380                                0.0                        68.000000  ...   
730                                0.0                        15.000000  ...   
...                                ...                              ...  ...   
2572                              11.0                        69.750000  ...   
3757                              32.0                        71.225349  ...   
2377                              79.0                        57.428570  ...   
3499                              15.0                        81.000000  ...   
2893                               9.0                         8.750000  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
2030                 4.0                   1            32.0  \
3043                 4.0                   1            32.0   
3552                 7.0                   0             2.0   
380                  2.0                   1            48.0   
730                  5.0                   1             8.0   
...                  ...                 ...             ...   
2572                 4.0                   1            32.0   
3757                 7.0                   0             1.0   
2377                 4.0                   1            32.0   
3499                 7.0                   0             2.0   
2893                 4.0                   1            16.0   

      crystal_system_cubic  crystal_system_hexagonal   
2030                 False                     False  \
3043                 False                     False   
3552                 False                     False   
380                  False                      True   
730                  False                     False   
...                    ...                       ...   
2572                 False                     False   
3757                 False                     False   
2377                 False                     False   
3499                 False                     False   
2893                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
2030                      False                        False  \
3043                      False                        False   
3552                      False                        False   
380                       False                        False   
730                       False                         True   
...                         ...                          ...   
2572                      False                        False   
3757                      False                        False   
2377                      False                        False   
3499                      False                        False   
2893                      False                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
2030                       True                     False  \
3043                       True                     False   
3552                      False                      True   
380                       False                     False   
730                       False                     False   
...                         ...                       ...   
2572                       True                     False   
3757                      False                      True   
2377                       True                     False   
3499                      False                      True   
2893                       True                     False   

      crystal_system_trigonal  
2030                    False  
3043                    False  
3552                    False  
380                     False  
730                     False  
...                       ...  
2572                    False  
3757                    False  
2377                    False  
3499                    False  
2893                    False  

[840 rows x 146 columns]
2025-06-02 19:16:03,847:INFO:get_config() successfully completed......................................
2025-06-02 19:16:03,856:INFO:Initializing get_config()
2025-06-02 19:16:03,856:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, variable=y_test)
2025-06-02 19:16:03,856:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 19:16:03,856:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 19:16:03,875:INFO:Variable:  returned as 2030   -0.527454
3043   -1.184208
3552   -1.604446
380     0.000000
730     0.034720
          ...   
2572    0.287101
3757   -0.714046
2377   -0.181563
3499   -2.675962
2893    0.382292
Name: target, Length: 840, dtype: float32
2025-06-02 19:16:03,875:INFO:get_config() successfully completed......................................
2025-06-02 19:16:03,877:INFO:Initializing get_config()
2025-06-02 19:16:03,878:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, variable=X_train)
2025-06-02 19:16:03,878:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-06-02 19:16:03,879:WARNING:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-06-02 19:16:03,932:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
3860                       52.0                       57.0  \
1975                       16.0                       71.0   
3260                        7.0                       20.0   
4063                       12.0                       14.0   
1778                        8.0                       22.0   
...                         ...                        ...   
1593                        9.0                       27.0   
4060                       12.0                       14.0   
1346                       12.0                       57.0   
3454                       12.0                       72.0   
3582                       16.0                       30.0   

      MagpieData range Number  MagpieData mean Number   
3860                      5.0               53.666668  \
1975                     55.0               38.000000   
3260                     13.0               14.526316   
4063                      2.0               13.142858   
1778                     14.0               12.666667   
...                       ...                     ...   
1593                     18.0               13.500000   
4060                      2.0               13.142858   
1346                     45.0               42.000000   
3454                     60.0               57.000000   
3582                     14.0               23.000000   

      MagpieData avg_dev Number  MagpieData mode Number   
3860                   2.222222                    52.0  \
1975                  26.400000                    16.0   
3260                   6.337950                    20.0   
4063                   0.979592                    14.0   
1778                   6.222222                     8.0   
...                         ...                     ...   
1593                   6.750000                     9.0   
4060                   0.979592                    14.0   
1346                  20.000000                    57.0   
3454                  22.500000                    72.0   
3582                   7.000000                    16.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
3860                                13.0                                90.0  \
1975                                41.0                                88.0   
3260                                 7.0                                82.0   
4063                                68.0                                78.0   
1778                                43.0                                87.0   
...                                  ...                                 ...   
1593                                58.0                                93.0   
4060                                68.0                                78.0   
1346                                13.0                                68.0   
3454                                45.0                                68.0   
3582                                69.0                                88.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
3860                              77.0                        64.333336  ...  \
1975                              47.0                        69.199997  ...   
3260                              75.0                        38.578949  ...   
4063                              10.0                        73.714287  ...   
1778                              44.0                        72.333336  ...   
...                                ...                              ...  ...   
1593                              35.0                        84.250000  ...   
4060                              10.0                        73.714287  ...   
1346                              55.0                        31.333334  ...   
3454                              23.0                        50.750000  ...   
3582                              19.0                        78.500000  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
3860                 6.0                   0             4.0  \
1975                 4.0                   0            16.0   
3260                 4.0                   1            16.0   
4063                 7.0                   0             2.0   
1778                 6.0                   1             8.0   
...                  ...                 ...             ...   
1593                 7.0                   0             1.0   
4060                 7.0                   0             2.0   
1346                 6.0                   1             4.0   
3454                 4.0                   1            32.0   
3582                 7.0                   0             2.0   

      crystal_system_cubic  crystal_system_hexagonal   
3860                 False                     False  \
1975                 False                     False   
3260                 False                     False   
4063                 False                     False   
1778                 False                     False   
...                    ...                       ...   
1593                 False                     False   
4060                 False                     False   
1346                 False                     False   
3454                 False                     False   
3582                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
3860                       True                        False  \
1975                      False                        False   
3260                      False                        False   
4063                      False                        False   
1778                       True                        False   
...                         ...                          ...   
1593                      False                        False   
4060                      False                        False   
1346                       True                        False   
3454                      False                        False   
3582                      False                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
3860                      False                     False  \
1975                       True                     False   
3260                       True                     False   
4063                      False                      True   
1778                      False                     False   
...                         ...                       ...   
1593                      False                      True   
4060                      False                      True   
1346                      False                     False   
3454                       True                     False   
3582                      False                      True   

      crystal_system_trigonal  
3860                    False  
1975                    False  
3260                    False  
4063                    False  
1778                    False  
...                       ...  
1593                    False  
4060                    False  
1346                    False  
3454                    False  
3582                    False  

[3360 rows x 146 columns]
2025-06-02 19:16:03,932:INFO:get_config() successfully completed......................................
2025-06-02 19:16:03,933:INFO:Initializing get_config()
2025-06-02 19:16:03,933:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, variable=y_train)
2025-06-02 19:16:03,934:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-06-02 19:16:03,934:WARNING:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-06-02 19:16:03,955:INFO:Variable:  returned as 3860   -1.682671
1975   -2.290768
3260   -0.733346
4063    0.160167
1778   -3.501638
          ...   
1593   -2.136502
4060    0.130419
1346   -0.006684
3454    0.086073
3582   -0.543908
Name: target, Length: 3360, dtype: float32
2025-06-02 19:16:03,955:INFO:get_config() successfully completed......................................
2025-06-02 19:16:03,976:INFO:Initializing predict_model()
2025-06-02 19:16:03,976:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718ABFDC0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B718F19240>)
2025-06-02 19:16:03,976:INFO:Checking exceptions
2025-06-02 19:16:03,976:INFO:Preloading libraries
2025-06-02 19:16:03,979:INFO:Set up data.
2025-06-02 19:16:04,069:INFO:Set up index.
2025-06-02 19:18:04,766:INFO:PyCaret RegressionExperiment
2025-06-02 19:18:04,767:INFO:Logging name: reg-default-name
2025-06-02 19:18:04,767:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 19:18:04,767:INFO:version 3.3.2
2025-06-02 19:18:04,767:INFO:Initializing setup()
2025-06-02 19:18:04,767:INFO:self.USI: 3e73
2025-06-02 19:18:04,767:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 19:18:04,768:INFO:Checking environment
2025-06-02 19:18:04,768:INFO:python_version: 3.10.16
2025-06-02 19:18:04,768:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 19:18:04,769:INFO:machine: AMD64
2025-06-02 19:18:04,769:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 19:18:04,792:INFO:Memory: svmem(total=6378008576, available=1035755520, percent=83.8, used=5342253056, free=1035755520)
2025-06-02 19:18:04,793:INFO:Physical Core: 4
2025-06-02 19:18:04,793:INFO:Logical Core: 8
2025-06-02 19:18:04,793:INFO:Checking libraries
2025-06-02 19:18:04,793:INFO:System:
2025-06-02 19:18:04,794:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 19:18:04,794:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 19:18:04,794:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 19:18:04,794:INFO:PyCaret required dependencies:
2025-06-02 19:18:04,794:INFO:                 pip: 25.1
2025-06-02 19:18:04,795:INFO:          setuptools: 78.1.1
2025-06-02 19:18:04,795:INFO:             pycaret: 3.3.2
2025-06-02 19:18:04,795:INFO:             IPython: 8.37.0
2025-06-02 19:18:04,795:INFO:          ipywidgets: 8.1.7
2025-06-02 19:18:04,795:INFO:                tqdm: 4.67.1
2025-06-02 19:18:04,795:INFO:               numpy: 1.26.4
2025-06-02 19:18:04,795:INFO:              pandas: 2.0.1
2025-06-02 19:18:04,795:INFO:              jinja2: 3.1.6
2025-06-02 19:18:04,795:INFO:               scipy: 1.10.1
2025-06-02 19:18:04,795:INFO:              joblib: 1.3.2
2025-06-02 19:18:04,795:INFO:             sklearn: 1.4.2
2025-06-02 19:18:04,796:INFO:                pyod: 2.0.5
2025-06-02 19:18:04,796:INFO:            imblearn: 0.13.0
2025-06-02 19:18:04,796:INFO:   category_encoders: 2.7.0
2025-06-02 19:18:04,796:INFO:            lightgbm: 4.6.0
2025-06-02 19:18:04,796:INFO:               numba: 0.61.0
2025-06-02 19:18:04,796:INFO:            requests: 2.32.3
2025-06-02 19:18:04,796:INFO:          matplotlib: 3.7.1
2025-06-02 19:18:04,796:INFO:          scikitplot: 0.3.7
2025-06-02 19:18:04,796:INFO:         yellowbrick: 1.5
2025-06-02 19:18:04,796:INFO:              plotly: 6.1.2
2025-06-02 19:18:04,796:INFO:    plotly-resampler: Not installed
2025-06-02 19:18:04,797:INFO:             kaleido: 0.2.1
2025-06-02 19:18:04,797:INFO:           schemdraw: 0.15
2025-06-02 19:18:04,797:INFO:         statsmodels: 0.14.4
2025-06-02 19:18:04,797:INFO:              sktime: 0.26.0
2025-06-02 19:18:04,797:INFO:               tbats: 1.1.3
2025-06-02 19:18:04,797:INFO:            pmdarima: 2.0.4
2025-06-02 19:18:04,797:INFO:              psutil: 7.0.0
2025-06-02 19:18:04,797:INFO:          markupsafe: 2.1.2
2025-06-02 19:18:04,797:INFO:             pickle5: Not installed
2025-06-02 19:18:04,797:INFO:         cloudpickle: 3.1.1
2025-06-02 19:18:04,797:INFO:         deprecation: 2.1.0
2025-06-02 19:18:04,797:INFO:              xxhash: 3.5.0
2025-06-02 19:18:04,797:INFO:           wurlitzer: Not installed
2025-06-02 19:18:04,798:INFO:PyCaret optional dependencies:
2025-06-02 19:18:04,798:INFO:                shap: 0.44.1
2025-06-02 19:18:04,798:INFO:           interpret: 0.6.9
2025-06-02 19:18:04,798:INFO:                umap: 0.5.7
2025-06-02 19:18:04,798:INFO:     ydata_profiling: 4.16.1
2025-06-02 19:18:04,798:INFO:  explainerdashboard: 0.4.8
2025-06-02 19:18:04,798:INFO:             autoviz: Not installed
2025-06-02 19:18:04,798:INFO:           fairlearn: 0.7.0
2025-06-02 19:18:04,798:INFO:          deepchecks: Not installed
2025-06-02 19:18:04,798:INFO:             xgboost: 3.0.2
2025-06-02 19:18:04,799:INFO:            catboost: 1.2.8
2025-06-02 19:18:04,799:INFO:              kmodes: 0.12.2
2025-06-02 19:18:04,799:INFO:             mlxtend: 0.23.4
2025-06-02 19:18:04,799:INFO:       statsforecast: 1.5.0
2025-06-02 19:18:04,799:INFO:        tune_sklearn: Not installed
2025-06-02 19:18:04,799:INFO:                 ray: Not installed
2025-06-02 19:18:04,799:INFO:            hyperopt: 0.2.7
2025-06-02 19:18:04,799:INFO:              optuna: 4.3.0
2025-06-02 19:18:04,799:INFO:               skopt: 0.10.2
2025-06-02 19:18:04,799:INFO:              mlflow: 2.22.0
2025-06-02 19:18:04,799:INFO:              gradio: 5.32.0
2025-06-02 19:18:04,799:INFO:             fastapi: 0.115.12
2025-06-02 19:18:04,800:INFO:             uvicorn: 0.34.3
2025-06-02 19:18:04,800:INFO:              m2cgen: 0.10.0
2025-06-02 19:18:04,800:INFO:           evidently: 0.4.40
2025-06-02 19:18:04,800:INFO:               fugue: 0.8.5
2025-06-02 19:18:04,800:INFO:           streamlit: Not installed
2025-06-02 19:18:04,800:INFO:             prophet: Not installed
2025-06-02 19:18:04,800:INFO:None
2025-06-02 19:18:04,800:INFO:Set up data.
2025-06-02 19:18:04,988:INFO:Set up folding strategy.
2025-06-02 19:18:04,988:INFO:Set up train/test split.
2025-06-02 19:18:05,093:INFO:Set up index.
2025-06-02 19:18:05,101:INFO:Assigning column types.
2025-06-02 19:18:05,174:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 19:18:05,175:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 19:18:05,183:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:18:05,195:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:18:05,388:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:18:05,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:18:05,489:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:18:05,496:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:18:05,498:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 19:18:05,505:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:18:05,513:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:18:05,710:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:18:05,813:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:18:05,814:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:18:05,819:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:18:05,820:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 19:18:05,828:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:18:05,835:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:18:05,997:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:18:06,111:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:18:06,113:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:18:06,118:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:18:06,131:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:18:06,140:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:18:06,331:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:18:06,449:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:18:06,451:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:18:06,459:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:18:06,462:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 19:18:06,483:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:18:06,686:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:18:06,790:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:18:06,792:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:18:06,799:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:18:06,827:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:18:07,211:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:18:07,440:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:18:07,441:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:18:07,447:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:18:07,449:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 19:18:07,640:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:18:07,742:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:18:07,744:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:18:07,754:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:18:07,982:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:18:08,074:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:18:08,075:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:18:08,080:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:18:08,081:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 19:18:08,259:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:18:08,368:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:18:08,373:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:18:08,550:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:18:08,630:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:18:08,634:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:18:08,636:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 19:18:08,902:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:18:08,908:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:18:09,146:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:18:09,150:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:18:09,153:INFO:Preparing preprocessing pipeline...
2025-06-02 19:18:09,153:INFO:Set up simple imputation.
2025-06-02 19:18:09,154:INFO:Set up removing multicollinearity.
2025-06-02 19:18:09,161:INFO:Set up column name cleaning.
2025-06-02 19:18:09,480:INFO:Finished creating preprocessing pipeline.
2025-06-02 19:18:09,499:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 19:18:09,499:INFO:Creating final display dataframe.
2025-06-02 19:18:09,928:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4200, 147)
4        Transformed data shape        (4200, 94)
5   Transformed train set shape        (3360, 94)
6    Transformed test set shape         (840, 94)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              3e73
2025-06-02 19:18:10,242:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:18:10,248:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:18:10,502:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:18:10,508:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:18:10,510:INFO:setup() successfully completed in 5.79s...............
2025-06-02 19:18:10,597:INFO:Initializing compare_models()
2025-06-02 19:18:10,597:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-02 19:18:10,597:INFO:Checking exceptions
2025-06-02 19:18:10,624:INFO:Preparing display monitor
2025-06-02 19:18:10,678:INFO:Initializing Linear Regression
2025-06-02 19:18:10,678:INFO:Total runtime is 0.0 minutes
2025-06-02 19:18:10,688:INFO:SubProcess create_model() called ==================================
2025-06-02 19:18:10,689:INFO:Initializing create_model()
2025-06-02 19:18:10,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:18:10,689:INFO:Checking exceptions
2025-06-02 19:18:10,690:INFO:Importing libraries
2025-06-02 19:18:10,690:INFO:Copying training dataset
2025-06-02 19:18:10,770:INFO:Defining folds
2025-06-02 19:18:10,770:INFO:Declaring metric variables
2025-06-02 19:18:10,782:INFO:Importing untrained model
2025-06-02 19:18:10,829:INFO:Linear Regression Imported successfully
2025-06-02 19:18:10,869:INFO:Starting cross validation
2025-06-02 19:18:10,876:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:18:12,151:INFO:Calculating mean and std
2025-06-02 19:18:12,155:INFO:Creating metrics dataframe
2025-06-02 19:18:12,159:INFO:Uploading results into container
2025-06-02 19:18:12,160:INFO:Uploading model into container now
2025-06-02 19:18:12,162:INFO:_master_model_container: 1
2025-06-02 19:18:12,162:INFO:_display_container: 2
2025-06-02 19:18:12,164:INFO:LinearRegression(n_jobs=-1)
2025-06-02 19:18:12,164:INFO:create_model() successfully completed......................................
2025-06-02 19:18:13,720:INFO:SubProcess create_model() end ==================================
2025-06-02 19:18:13,720:INFO:Creating metrics dataframe
2025-06-02 19:18:13,735:INFO:Initializing Lasso Regression
2025-06-02 19:18:13,735:INFO:Total runtime is 0.050954782962799074 minutes
2025-06-02 19:18:13,744:INFO:SubProcess create_model() called ==================================
2025-06-02 19:18:13,745:INFO:Initializing create_model()
2025-06-02 19:18:13,745:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:18:13,746:INFO:Checking exceptions
2025-06-02 19:18:13,747:INFO:Importing libraries
2025-06-02 19:18:13,747:INFO:Copying training dataset
2025-06-02 19:18:13,827:INFO:Defining folds
2025-06-02 19:18:13,827:INFO:Declaring metric variables
2025-06-02 19:18:13,842:INFO:Importing untrained model
2025-06-02 19:18:13,853:INFO:Lasso Regression Imported successfully
2025-06-02 19:18:13,878:INFO:Starting cross validation
2025-06-02 19:18:13,883:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:18:15,039:INFO:Calculating mean and std
2025-06-02 19:18:15,043:INFO:Creating metrics dataframe
2025-06-02 19:18:15,048:INFO:Uploading results into container
2025-06-02 19:18:15,049:INFO:Uploading model into container now
2025-06-02 19:18:15,051:INFO:_master_model_container: 2
2025-06-02 19:18:15,051:INFO:_display_container: 2
2025-06-02 19:18:15,052:INFO:Lasso(random_state=123)
2025-06-02 19:18:15,053:INFO:create_model() successfully completed......................................
2025-06-02 19:18:16,655:INFO:SubProcess create_model() end ==================================
2025-06-02 19:18:16,655:INFO:Creating metrics dataframe
2025-06-02 19:18:16,673:INFO:Initializing Ridge Regression
2025-06-02 19:18:16,674:INFO:Total runtime is 0.09993557135264079 minutes
2025-06-02 19:18:16,683:INFO:SubProcess create_model() called ==================================
2025-06-02 19:18:16,684:INFO:Initializing create_model()
2025-06-02 19:18:16,684:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:18:16,686:INFO:Checking exceptions
2025-06-02 19:18:16,687:INFO:Importing libraries
2025-06-02 19:18:16,687:INFO:Copying training dataset
2025-06-02 19:18:16,751:INFO:Defining folds
2025-06-02 19:18:16,752:INFO:Declaring metric variables
2025-06-02 19:18:16,764:INFO:Importing untrained model
2025-06-02 19:18:16,779:INFO:Ridge Regression Imported successfully
2025-06-02 19:18:16,805:INFO:Starting cross validation
2025-06-02 19:18:16,810:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:18:17,465:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.02554e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 19:18:17,486:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.16862e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 19:18:17,510:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.19149e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 19:18:17,531:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.67603e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-02 19:18:17,594:INFO:Calculating mean and std
2025-06-02 19:18:17,596:INFO:Creating metrics dataframe
2025-06-02 19:18:17,602:INFO:Uploading results into container
2025-06-02 19:18:17,603:INFO:Uploading model into container now
2025-06-02 19:18:17,604:INFO:_master_model_container: 3
2025-06-02 19:18:17,604:INFO:_display_container: 2
2025-06-02 19:18:17,605:INFO:Ridge(random_state=123)
2025-06-02 19:18:17,605:INFO:create_model() successfully completed......................................
2025-06-02 19:18:18,998:INFO:SubProcess create_model() end ==================================
2025-06-02 19:18:18,998:INFO:Creating metrics dataframe
2025-06-02 19:18:19,014:INFO:Initializing Elastic Net
2025-06-02 19:18:19,014:INFO:Total runtime is 0.13894643386205038 minutes
2025-06-02 19:18:19,024:INFO:SubProcess create_model() called ==================================
2025-06-02 19:18:19,025:INFO:Initializing create_model()
2025-06-02 19:18:19,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:18:19,025:INFO:Checking exceptions
2025-06-02 19:18:19,026:INFO:Importing libraries
2025-06-02 19:18:19,026:INFO:Copying training dataset
2025-06-02 19:18:19,085:INFO:Defining folds
2025-06-02 19:18:19,085:INFO:Declaring metric variables
2025-06-02 19:18:19,097:INFO:Importing untrained model
2025-06-02 19:18:19,109:INFO:Elastic Net Imported successfully
2025-06-02 19:18:19,131:INFO:Starting cross validation
2025-06-02 19:18:19,135:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:18:20,238:INFO:Calculating mean and std
2025-06-02 19:18:20,240:INFO:Creating metrics dataframe
2025-06-02 19:18:20,243:INFO:Uploading results into container
2025-06-02 19:18:20,244:INFO:Uploading model into container now
2025-06-02 19:18:20,244:INFO:_master_model_container: 4
2025-06-02 19:18:20,245:INFO:_display_container: 2
2025-06-02 19:18:20,246:INFO:ElasticNet(random_state=123)
2025-06-02 19:18:20,247:INFO:create_model() successfully completed......................................
2025-06-02 19:18:21,625:INFO:SubProcess create_model() end ==================================
2025-06-02 19:18:21,626:INFO:Creating metrics dataframe
2025-06-02 19:18:21,647:INFO:Initializing Least Angle Regression
2025-06-02 19:18:21,649:INFO:Total runtime is 0.182853897412618 minutes
2025-06-02 19:18:21,666:INFO:SubProcess create_model() called ==================================
2025-06-02 19:18:21,667:INFO:Initializing create_model()
2025-06-02 19:18:21,668:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:18:21,668:INFO:Checking exceptions
2025-06-02 19:18:21,668:INFO:Importing libraries
2025-06-02 19:18:21,670:INFO:Copying training dataset
2025-06-02 19:18:21,759:INFO:Defining folds
2025-06-02 19:18:21,760:INFO:Declaring metric variables
2025-06-02 19:18:21,776:INFO:Importing untrained model
2025-06-02 19:18:21,794:INFO:Least Angle Regression Imported successfully
2025-06-02 19:18:21,824:INFO:Starting cross validation
2025-06-02 19:18:21,828:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:18:22,471:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.521e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:18:22,473:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.134e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:18:22,474:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.026e-01, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:18:22,479:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.783e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:18:22,482:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.704e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:18:22,484:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.931e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:18:22,485:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=7.775e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:18:22,487:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.576e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:18:22,488:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.424e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:18:22,491:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.748e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:18:22,494:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.674e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:18:22,497:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.486e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:18:22,498:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.601e+01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:18:22,502:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.179e+02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-02 19:18:22,664:INFO:Calculating mean and std
2025-06-02 19:18:22,666:INFO:Creating metrics dataframe
2025-06-02 19:18:22,670:INFO:Uploading results into container
2025-06-02 19:18:22,671:INFO:Uploading model into container now
2025-06-02 19:18:22,672:INFO:_master_model_container: 5
2025-06-02 19:18:22,672:INFO:_display_container: 2
2025-06-02 19:18:22,674:INFO:Lars(random_state=123)
2025-06-02 19:18:22,674:INFO:create_model() successfully completed......................................
2025-06-02 19:18:24,078:INFO:SubProcess create_model() end ==================================
2025-06-02 19:18:24,078:INFO:Creating metrics dataframe
2025-06-02 19:18:24,096:INFO:Initializing Lasso Least Angle Regression
2025-06-02 19:18:24,096:INFO:Total runtime is 0.2236346960067749 minutes
2025-06-02 19:18:24,106:INFO:SubProcess create_model() called ==================================
2025-06-02 19:18:24,106:INFO:Initializing create_model()
2025-06-02 19:18:24,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:18:24,107:INFO:Checking exceptions
2025-06-02 19:18:24,107:INFO:Importing libraries
2025-06-02 19:18:24,108:INFO:Copying training dataset
2025-06-02 19:18:24,164:INFO:Defining folds
2025-06-02 19:18:24,164:INFO:Declaring metric variables
2025-06-02 19:18:24,177:INFO:Importing untrained model
2025-06-02 19:18:24,189:INFO:Lasso Least Angle Regression Imported successfully
2025-06-02 19:18:24,212:INFO:Starting cross validation
2025-06-02 19:18:24,216:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:18:24,959:INFO:Calculating mean and std
2025-06-02 19:18:24,962:INFO:Creating metrics dataframe
2025-06-02 19:18:24,965:INFO:Uploading results into container
2025-06-02 19:18:24,966:INFO:Uploading model into container now
2025-06-02 19:18:24,968:INFO:_master_model_container: 6
2025-06-02 19:18:24,968:INFO:_display_container: 2
2025-06-02 19:18:24,969:INFO:LassoLars(random_state=123)
2025-06-02 19:18:24,970:INFO:create_model() successfully completed......................................
2025-06-02 19:18:26,356:INFO:SubProcess create_model() end ==================================
2025-06-02 19:18:26,357:INFO:Creating metrics dataframe
2025-06-02 19:18:26,371:INFO:Initializing Orthogonal Matching Pursuit
2025-06-02 19:18:26,371:INFO:Total runtime is 0.2615496834119161 minutes
2025-06-02 19:18:26,383:INFO:SubProcess create_model() called ==================================
2025-06-02 19:18:26,384:INFO:Initializing create_model()
2025-06-02 19:18:26,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:18:26,386:INFO:Checking exceptions
2025-06-02 19:18:26,386:INFO:Importing libraries
2025-06-02 19:18:26,386:INFO:Copying training dataset
2025-06-02 19:18:26,444:INFO:Defining folds
2025-06-02 19:18:26,444:INFO:Declaring metric variables
2025-06-02 19:18:26,456:INFO:Importing untrained model
2025-06-02 19:18:26,471:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-02 19:18:26,492:INFO:Starting cross validation
2025-06-02 19:18:26,496:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:18:27,320:INFO:Calculating mean and std
2025-06-02 19:18:27,322:INFO:Creating metrics dataframe
2025-06-02 19:18:27,326:INFO:Uploading results into container
2025-06-02 19:18:27,327:INFO:Uploading model into container now
2025-06-02 19:18:27,328:INFO:_master_model_container: 7
2025-06-02 19:18:27,329:INFO:_display_container: 2
2025-06-02 19:18:27,329:INFO:OrthogonalMatchingPursuit()
2025-06-02 19:18:27,330:INFO:create_model() successfully completed......................................
2025-06-02 19:18:28,719:INFO:SubProcess create_model() end ==================================
2025-06-02 19:18:28,719:INFO:Creating metrics dataframe
2025-06-02 19:18:28,736:INFO:Initializing Bayesian Ridge
2025-06-02 19:18:28,737:INFO:Total runtime is 0.30099345445632936 minutes
2025-06-02 19:18:28,748:INFO:SubProcess create_model() called ==================================
2025-06-02 19:18:28,748:INFO:Initializing create_model()
2025-06-02 19:18:28,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:18:28,749:INFO:Checking exceptions
2025-06-02 19:18:28,749:INFO:Importing libraries
2025-06-02 19:18:28,750:INFO:Copying training dataset
2025-06-02 19:18:28,808:INFO:Defining folds
2025-06-02 19:18:28,808:INFO:Declaring metric variables
2025-06-02 19:18:28,820:INFO:Importing untrained model
2025-06-02 19:18:28,832:INFO:Bayesian Ridge Imported successfully
2025-06-02 19:18:28,852:INFO:Starting cross validation
2025-06-02 19:18:28,856:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:18:29,604:INFO:Calculating mean and std
2025-06-02 19:18:29,606:INFO:Creating metrics dataframe
2025-06-02 19:18:29,609:INFO:Uploading results into container
2025-06-02 19:18:29,610:INFO:Uploading model into container now
2025-06-02 19:18:29,612:INFO:_master_model_container: 8
2025-06-02 19:18:29,612:INFO:_display_container: 2
2025-06-02 19:18:29,613:INFO:BayesianRidge()
2025-06-02 19:18:29,613:INFO:create_model() successfully completed......................................
2025-06-02 19:18:30,986:INFO:SubProcess create_model() end ==================================
2025-06-02 19:18:30,987:INFO:Creating metrics dataframe
2025-06-02 19:18:31,005:INFO:Initializing Passive Aggressive Regressor
2025-06-02 19:18:31,005:INFO:Total runtime is 0.33878748416900634 minutes
2025-06-02 19:18:31,016:INFO:SubProcess create_model() called ==================================
2025-06-02 19:18:31,017:INFO:Initializing create_model()
2025-06-02 19:18:31,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:18:31,018:INFO:Checking exceptions
2025-06-02 19:18:31,019:INFO:Importing libraries
2025-06-02 19:18:31,019:INFO:Copying training dataset
2025-06-02 19:18:31,081:INFO:Defining folds
2025-06-02 19:18:31,082:INFO:Declaring metric variables
2025-06-02 19:18:31,097:INFO:Importing untrained model
2025-06-02 19:18:31,110:INFO:Passive Aggressive Regressor Imported successfully
2025-06-02 19:18:31,132:INFO:Starting cross validation
2025-06-02 19:18:31,137:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:18:31,905:INFO:Calculating mean and std
2025-06-02 19:18:31,907:INFO:Creating metrics dataframe
2025-06-02 19:18:31,911:INFO:Uploading results into container
2025-06-02 19:18:31,913:INFO:Uploading model into container now
2025-06-02 19:18:31,914:INFO:_master_model_container: 9
2025-06-02 19:18:31,914:INFO:_display_container: 2
2025-06-02 19:18:31,915:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-02 19:18:31,916:INFO:create_model() successfully completed......................................
2025-06-02 19:18:33,366:INFO:SubProcess create_model() end ==================================
2025-06-02 19:18:33,366:INFO:Creating metrics dataframe
2025-06-02 19:18:33,385:INFO:Initializing Huber Regressor
2025-06-02 19:18:33,385:INFO:Total runtime is 0.3784534414609273 minutes
2025-06-02 19:18:33,394:INFO:SubProcess create_model() called ==================================
2025-06-02 19:18:33,395:INFO:Initializing create_model()
2025-06-02 19:18:33,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:18:33,396:INFO:Checking exceptions
2025-06-02 19:18:33,396:INFO:Importing libraries
2025-06-02 19:18:33,397:INFO:Copying training dataset
2025-06-02 19:18:33,457:INFO:Defining folds
2025-06-02 19:18:33,458:INFO:Declaring metric variables
2025-06-02 19:18:33,473:INFO:Importing untrained model
2025-06-02 19:18:33,486:INFO:Huber Regressor Imported successfully
2025-06-02 19:18:33,508:INFO:Starting cross validation
2025-06-02 19:18:33,512:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:18:35,015:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:18:35,021:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:18:35,069:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:18:35,135:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:18:35,175:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-02 19:18:35,234:INFO:Calculating mean and std
2025-06-02 19:18:35,237:INFO:Creating metrics dataframe
2025-06-02 19:18:35,240:INFO:Uploading results into container
2025-06-02 19:18:35,241:INFO:Uploading model into container now
2025-06-02 19:18:35,242:INFO:_master_model_container: 10
2025-06-02 19:18:35,243:INFO:_display_container: 2
2025-06-02 19:18:35,243:INFO:HuberRegressor()
2025-06-02 19:18:35,244:INFO:create_model() successfully completed......................................
2025-06-02 19:18:36,637:INFO:SubProcess create_model() end ==================================
2025-06-02 19:18:36,637:INFO:Creating metrics dataframe
2025-06-02 19:18:36,653:INFO:Initializing K Neighbors Regressor
2025-06-02 19:18:36,654:INFO:Total runtime is 0.4329314112663269 minutes
2025-06-02 19:18:36,665:INFO:SubProcess create_model() called ==================================
2025-06-02 19:18:36,666:INFO:Initializing create_model()
2025-06-02 19:18:36,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:18:36,667:INFO:Checking exceptions
2025-06-02 19:18:36,667:INFO:Importing libraries
2025-06-02 19:18:36,668:INFO:Copying training dataset
2025-06-02 19:18:36,729:INFO:Defining folds
2025-06-02 19:18:36,730:INFO:Declaring metric variables
2025-06-02 19:18:36,742:INFO:Importing untrained model
2025-06-02 19:18:36,753:INFO:K Neighbors Regressor Imported successfully
2025-06-02 19:18:36,776:INFO:Starting cross validation
2025-06-02 19:18:36,781:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:18:38,336:INFO:Calculating mean and std
2025-06-02 19:18:38,338:INFO:Creating metrics dataframe
2025-06-02 19:18:38,342:INFO:Uploading results into container
2025-06-02 19:18:38,343:INFO:Uploading model into container now
2025-06-02 19:18:38,343:INFO:_master_model_container: 11
2025-06-02 19:18:38,344:INFO:_display_container: 2
2025-06-02 19:18:38,344:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-02 19:18:38,345:INFO:create_model() successfully completed......................................
2025-06-02 19:18:39,734:INFO:SubProcess create_model() end ==================================
2025-06-02 19:18:39,735:INFO:Creating metrics dataframe
2025-06-02 19:18:39,753:INFO:Initializing Decision Tree Regressor
2025-06-02 19:18:39,753:INFO:Total runtime is 0.48458125193913776 minutes
2025-06-02 19:18:39,772:INFO:SubProcess create_model() called ==================================
2025-06-02 19:18:39,775:INFO:Initializing create_model()
2025-06-02 19:18:39,775:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:18:39,776:INFO:Checking exceptions
2025-06-02 19:18:39,776:INFO:Importing libraries
2025-06-02 19:18:39,776:INFO:Copying training dataset
2025-06-02 19:18:39,926:INFO:Defining folds
2025-06-02 19:18:39,927:INFO:Declaring metric variables
2025-06-02 19:18:39,954:INFO:Importing untrained model
2025-06-02 19:18:39,971:INFO:Decision Tree Regressor Imported successfully
2025-06-02 19:18:39,997:INFO:Starting cross validation
2025-06-02 19:18:40,001:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:18:41,115:INFO:Calculating mean and std
2025-06-02 19:18:41,118:INFO:Creating metrics dataframe
2025-06-02 19:18:41,125:INFO:Uploading results into container
2025-06-02 19:18:41,127:INFO:Uploading model into container now
2025-06-02 19:18:41,128:INFO:_master_model_container: 12
2025-06-02 19:18:41,128:INFO:_display_container: 2
2025-06-02 19:18:41,129:INFO:DecisionTreeRegressor(random_state=123)
2025-06-02 19:18:41,130:INFO:create_model() successfully completed......................................
2025-06-02 19:18:42,522:INFO:SubProcess create_model() end ==================================
2025-06-02 19:18:42,523:INFO:Creating metrics dataframe
2025-06-02 19:18:42,546:INFO:Initializing Random Forest Regressor
2025-06-02 19:18:42,546:INFO:Total runtime is 0.531138527393341 minutes
2025-06-02 19:18:42,558:INFO:SubProcess create_model() called ==================================
2025-06-02 19:18:42,559:INFO:Initializing create_model()
2025-06-02 19:18:42,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:18:42,560:INFO:Checking exceptions
2025-06-02 19:18:42,560:INFO:Importing libraries
2025-06-02 19:18:42,560:INFO:Copying training dataset
2025-06-02 19:18:42,620:INFO:Defining folds
2025-06-02 19:18:42,620:INFO:Declaring metric variables
2025-06-02 19:18:42,637:INFO:Importing untrained model
2025-06-02 19:18:42,652:INFO:Random Forest Regressor Imported successfully
2025-06-02 19:18:42,690:INFO:Starting cross validation
2025-06-02 19:18:42,694:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:18:51,959:INFO:Calculating mean and std
2025-06-02 19:18:51,962:INFO:Creating metrics dataframe
2025-06-02 19:18:51,966:INFO:Uploading results into container
2025-06-02 19:18:51,967:INFO:Uploading model into container now
2025-06-02 19:18:51,967:INFO:_master_model_container: 13
2025-06-02 19:18:51,968:INFO:_display_container: 2
2025-06-02 19:18:51,969:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:18:51,969:INFO:create_model() successfully completed......................................
2025-06-02 19:18:53,370:INFO:SubProcess create_model() end ==================================
2025-06-02 19:18:53,371:INFO:Creating metrics dataframe
2025-06-02 19:18:53,397:INFO:Initializing Extra Trees Regressor
2025-06-02 19:18:53,397:INFO:Total runtime is 0.7119913856188456 minutes
2025-06-02 19:18:53,409:INFO:SubProcess create_model() called ==================================
2025-06-02 19:18:53,410:INFO:Initializing create_model()
2025-06-02 19:18:53,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:18:53,411:INFO:Checking exceptions
2025-06-02 19:18:53,411:INFO:Importing libraries
2025-06-02 19:18:53,412:INFO:Copying training dataset
2025-06-02 19:18:53,468:INFO:Defining folds
2025-06-02 19:18:53,469:INFO:Declaring metric variables
2025-06-02 19:18:53,481:INFO:Importing untrained model
2025-06-02 19:18:53,492:INFO:Extra Trees Regressor Imported successfully
2025-06-02 19:18:53,514:INFO:Starting cross validation
2025-06-02 19:18:53,518:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:18:59,445:INFO:Calculating mean and std
2025-06-02 19:18:59,447:INFO:Creating metrics dataframe
2025-06-02 19:18:59,454:INFO:Uploading results into container
2025-06-02 19:18:59,455:INFO:Uploading model into container now
2025-06-02 19:18:59,456:INFO:_master_model_container: 14
2025-06-02 19:18:59,457:INFO:_display_container: 2
2025-06-02 19:18:59,458:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:18:59,458:INFO:create_model() successfully completed......................................
2025-06-02 19:19:01,062:INFO:SubProcess create_model() end ==================================
2025-06-02 19:19:01,062:INFO:Creating metrics dataframe
2025-06-02 19:19:01,088:INFO:Initializing AdaBoost Regressor
2025-06-02 19:19:01,088:INFO:Total runtime is 0.8401764790217081 minutes
2025-06-02 19:19:01,105:INFO:SubProcess create_model() called ==================================
2025-06-02 19:19:01,106:INFO:Initializing create_model()
2025-06-02 19:19:01,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:19:01,106:INFO:Checking exceptions
2025-06-02 19:19:01,107:INFO:Importing libraries
2025-06-02 19:19:01,107:INFO:Copying training dataset
2025-06-02 19:19:01,171:INFO:Defining folds
2025-06-02 19:19:01,172:INFO:Declaring metric variables
2025-06-02 19:19:01,190:INFO:Importing untrained model
2025-06-02 19:19:01,204:INFO:AdaBoost Regressor Imported successfully
2025-06-02 19:19:01,229:INFO:Starting cross validation
2025-06-02 19:19:01,234:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:19:03,604:INFO:Calculating mean and std
2025-06-02 19:19:03,606:INFO:Creating metrics dataframe
2025-06-02 19:19:03,610:INFO:Uploading results into container
2025-06-02 19:19:03,611:INFO:Uploading model into container now
2025-06-02 19:19:03,612:INFO:_master_model_container: 15
2025-06-02 19:19:03,612:INFO:_display_container: 2
2025-06-02 19:19:03,613:INFO:AdaBoostRegressor(random_state=123)
2025-06-02 19:19:03,614:INFO:create_model() successfully completed......................................
2025-06-02 19:19:04,985:INFO:SubProcess create_model() end ==================================
2025-06-02 19:19:04,985:INFO:Creating metrics dataframe
2025-06-02 19:19:05,004:INFO:Initializing Gradient Boosting Regressor
2025-06-02 19:19:05,004:INFO:Total runtime is 0.9054426670074462 minutes
2025-06-02 19:19:05,013:INFO:SubProcess create_model() called ==================================
2025-06-02 19:19:05,014:INFO:Initializing create_model()
2025-06-02 19:19:05,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:19:05,015:INFO:Checking exceptions
2025-06-02 19:19:05,015:INFO:Importing libraries
2025-06-02 19:19:05,016:INFO:Copying training dataset
2025-06-02 19:19:05,082:INFO:Defining folds
2025-06-02 19:19:05,082:INFO:Declaring metric variables
2025-06-02 19:19:05,096:INFO:Importing untrained model
2025-06-02 19:19:05,109:INFO:Gradient Boosting Regressor Imported successfully
2025-06-02 19:19:05,131:INFO:Starting cross validation
2025-06-02 19:19:05,135:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:19:08,523:INFO:Calculating mean and std
2025-06-02 19:19:08,525:INFO:Creating metrics dataframe
2025-06-02 19:19:08,529:INFO:Uploading results into container
2025-06-02 19:19:08,530:INFO:Uploading model into container now
2025-06-02 19:19:08,531:INFO:_master_model_container: 16
2025-06-02 19:19:08,531:INFO:_display_container: 2
2025-06-02 19:19:08,532:INFO:GradientBoostingRegressor(random_state=123)
2025-06-02 19:19:08,533:INFO:create_model() successfully completed......................................
2025-06-02 19:19:09,937:INFO:SubProcess create_model() end ==================================
2025-06-02 19:19:09,937:INFO:Creating metrics dataframe
2025-06-02 19:19:09,962:INFO:Initializing Extreme Gradient Boosting
2025-06-02 19:19:09,962:INFO:Total runtime is 0.9880765279134114 minutes
2025-06-02 19:19:09,973:INFO:SubProcess create_model() called ==================================
2025-06-02 19:19:09,974:INFO:Initializing create_model()
2025-06-02 19:19:09,974:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:19:09,974:INFO:Checking exceptions
2025-06-02 19:19:09,975:INFO:Importing libraries
2025-06-02 19:19:09,975:INFO:Copying training dataset
2025-06-02 19:19:10,034:INFO:Defining folds
2025-06-02 19:19:10,035:INFO:Declaring metric variables
2025-06-02 19:19:10,045:INFO:Importing untrained model
2025-06-02 19:19:10,060:INFO:Extreme Gradient Boosting Imported successfully
2025-06-02 19:19:10,081:INFO:Starting cross validation
2025-06-02 19:19:10,085:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:19:12,560:INFO:Calculating mean and std
2025-06-02 19:19:12,563:INFO:Creating metrics dataframe
2025-06-02 19:19:12,567:INFO:Uploading results into container
2025-06-02 19:19:12,568:INFO:Uploading model into container now
2025-06-02 19:19:12,570:INFO:_master_model_container: 17
2025-06-02 19:19:12,570:INFO:_display_container: 2
2025-06-02 19:19:12,575:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-02 19:19:12,575:INFO:create_model() successfully completed......................................
2025-06-02 19:19:13,987:INFO:SubProcess create_model() end ==================================
2025-06-02 19:19:13,987:INFO:Creating metrics dataframe
2025-06-02 19:19:14,008:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 19:19:14,008:INFO:Total runtime is 1.0554977178573608 minutes
2025-06-02 19:19:14,021:INFO:SubProcess create_model() called ==================================
2025-06-02 19:19:14,022:INFO:Initializing create_model()
2025-06-02 19:19:14,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:19:14,023:INFO:Checking exceptions
2025-06-02 19:19:14,023:INFO:Importing libraries
2025-06-02 19:19:14,024:INFO:Copying training dataset
2025-06-02 19:19:14,084:INFO:Defining folds
2025-06-02 19:19:14,085:INFO:Declaring metric variables
2025-06-02 19:19:14,100:INFO:Importing untrained model
2025-06-02 19:19:14,112:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 19:19:14,133:INFO:Starting cross validation
2025-06-02 19:19:14,137:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:19:15,792:INFO:Calculating mean and std
2025-06-02 19:19:15,794:INFO:Creating metrics dataframe
2025-06-02 19:19:15,799:INFO:Uploading results into container
2025-06-02 19:19:15,800:INFO:Uploading model into container now
2025-06-02 19:19:15,802:INFO:_master_model_container: 18
2025-06-02 19:19:15,802:INFO:_display_container: 2
2025-06-02 19:19:15,804:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:19:15,804:INFO:create_model() successfully completed......................................
2025-06-02 19:19:17,202:INFO:SubProcess create_model() end ==================================
2025-06-02 19:19:17,203:INFO:Creating metrics dataframe
2025-06-02 19:19:17,225:INFO:Initializing CatBoost Regressor
2025-06-02 19:19:17,226:INFO:Total runtime is 1.1091453274091085 minutes
2025-06-02 19:19:17,236:INFO:SubProcess create_model() called ==================================
2025-06-02 19:19:17,237:INFO:Initializing create_model()
2025-06-02 19:19:17,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:19:17,237:INFO:Checking exceptions
2025-06-02 19:19:17,238:INFO:Importing libraries
2025-06-02 19:19:17,238:INFO:Copying training dataset
2025-06-02 19:19:17,297:INFO:Defining folds
2025-06-02 19:19:17,298:INFO:Declaring metric variables
2025-06-02 19:19:17,313:INFO:Importing untrained model
2025-06-02 19:19:17,325:INFO:CatBoost Regressor Imported successfully
2025-06-02 19:19:17,345:INFO:Starting cross validation
2025-06-02 19:19:17,351:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:19:40,329:INFO:Calculating mean and std
2025-06-02 19:19:40,331:INFO:Creating metrics dataframe
2025-06-02 19:19:40,336:INFO:Uploading results into container
2025-06-02 19:19:40,338:INFO:Uploading model into container now
2025-06-02 19:19:40,339:INFO:_master_model_container: 19
2025-06-02 19:19:40,339:INFO:_display_container: 2
2025-06-02 19:19:40,339:INFO:<catboost.core.CatBoostRegressor object at 0x000001B7193CA920>
2025-06-02 19:19:40,340:INFO:create_model() successfully completed......................................
2025-06-02 19:19:41,811:INFO:SubProcess create_model() end ==================================
2025-06-02 19:19:41,812:INFO:Creating metrics dataframe
2025-06-02 19:19:41,837:INFO:Initializing Dummy Regressor
2025-06-02 19:19:41,837:INFO:Total runtime is 1.5193169871966044 minutes
2025-06-02 19:19:41,849:INFO:SubProcess create_model() called ==================================
2025-06-02 19:19:41,850:INFO:Initializing create_model()
2025-06-02 19:19:41,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:19:41,850:INFO:Checking exceptions
2025-06-02 19:19:41,851:INFO:Importing libraries
2025-06-02 19:19:41,851:INFO:Copying training dataset
2025-06-02 19:19:41,910:INFO:Defining folds
2025-06-02 19:19:41,911:INFO:Declaring metric variables
2025-06-02 19:19:41,926:INFO:Importing untrained model
2025-06-02 19:19:41,937:INFO:Dummy Regressor Imported successfully
2025-06-02 19:19:41,962:INFO:Starting cross validation
2025-06-02 19:19:41,966:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:19:42,705:INFO:Calculating mean and std
2025-06-02 19:19:42,708:INFO:Creating metrics dataframe
2025-06-02 19:19:42,712:INFO:Uploading results into container
2025-06-02 19:19:42,713:INFO:Uploading model into container now
2025-06-02 19:19:42,715:INFO:_master_model_container: 20
2025-06-02 19:19:42,716:INFO:_display_container: 2
2025-06-02 19:19:42,716:INFO:DummyRegressor()
2025-06-02 19:19:42,717:INFO:create_model() successfully completed......................................
2025-06-02 19:19:44,124:INFO:SubProcess create_model() end ==================================
2025-06-02 19:19:44,125:INFO:Creating metrics dataframe
2025-06-02 19:19:44,176:INFO:Initializing create_model()
2025-06-02 19:19:44,177:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:19:44,177:INFO:Checking exceptions
2025-06-02 19:19:44,184:INFO:Importing libraries
2025-06-02 19:19:44,184:INFO:Copying training dataset
2025-06-02 19:19:44,245:INFO:Defining folds
2025-06-02 19:19:44,246:INFO:Declaring metric variables
2025-06-02 19:19:44,246:INFO:Importing untrained model
2025-06-02 19:19:44,246:INFO:Declaring custom model
2025-06-02 19:19:44,248:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 19:19:44,250:INFO:Cross validation set to False
2025-06-02 19:19:44,250:INFO:Fitting Model
2025-06-02 19:19:44,679:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 19:19:44,699:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017098 seconds.
2025-06-02 19:19:44,700:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 19:19:44,701:INFO:[LightGBM] [Info] Total Bins 6086
2025-06-02 19:19:44,719:INFO:[LightGBM] [Info] Number of data points in the train set: 3360, number of used features: 93
2025-06-02 19:19:44,721:INFO:[LightGBM] [Info] Start training from score -0.416868
2025-06-02 19:19:44,904:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:19:44,904:INFO:create_model() successfully completed......................................
2025-06-02 19:19:46,328:INFO:Initializing create_model()
2025-06-02 19:19:46,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=<catboost.core.CatBoostRegressor object at 0x000001B7193CA920>, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:19:46,329:INFO:Checking exceptions
2025-06-02 19:19:46,334:INFO:Importing libraries
2025-06-02 19:19:46,334:INFO:Copying training dataset
2025-06-02 19:19:46,398:INFO:Defining folds
2025-06-02 19:19:46,398:INFO:Declaring metric variables
2025-06-02 19:19:46,398:INFO:Importing untrained model
2025-06-02 19:19:46,398:INFO:Declaring custom model
2025-06-02 19:19:46,399:INFO:CatBoost Regressor Imported successfully
2025-06-02 19:19:46,401:INFO:Cross validation set to False
2025-06-02 19:19:46,401:INFO:Fitting Model
2025-06-02 19:19:52,857:INFO:<catboost.core.CatBoostRegressor object at 0x000001B704E5FF10>
2025-06-02 19:19:52,857:INFO:create_model() successfully completed......................................
2025-06-02 19:19:54,288:INFO:Initializing create_model()
2025-06-02 19:19:54,289:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:19:54,289:INFO:Checking exceptions
2025-06-02 19:19:54,293:INFO:Importing libraries
2025-06-02 19:19:54,294:INFO:Copying training dataset
2025-06-02 19:19:54,362:INFO:Defining folds
2025-06-02 19:19:54,363:INFO:Declaring metric variables
2025-06-02 19:19:54,363:INFO:Importing untrained model
2025-06-02 19:19:54,363:INFO:Declaring custom model
2025-06-02 19:19:54,364:INFO:Random Forest Regressor Imported successfully
2025-06-02 19:19:54,366:INFO:Cross validation set to False
2025-06-02 19:19:54,367:INFO:Fitting Model
2025-06-02 19:19:57,023:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:19:57,023:INFO:create_model() successfully completed......................................
2025-06-02 19:19:58,518:INFO:_master_model_container: 20
2025-06-02 19:19:58,518:INFO:_display_container: 2
2025-06-02 19:19:58,520:INFO:[LGBMRegressor(n_jobs=-1, random_state=123), <catboost.core.CatBoostRegressor object at 0x000001B704E5FF10>, RandomForestRegressor(n_jobs=-1, random_state=123)]
2025-06-02 19:19:58,521:INFO:compare_models() successfully completed......................................
2025-06-02 19:19:58,577:INFO:Initializing tune_model()
2025-06-02 19:19:58,577:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>)
2025-06-02 19:19:58,577:INFO:Checking exceptions
2025-06-02 19:19:58,577:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-02 19:19:58,649:INFO:Copying training dataset
2025-06-02 19:19:58,703:INFO:Checking base model
2025-06-02 19:19:58,703:INFO:Base model : Light Gradient Boosting Machine
2025-06-02 19:19:58,715:INFO:Declaring metric variables
2025-06-02 19:19:58,729:INFO:Defining Hyperparameters
2025-06-02 19:20:01,086:INFO:Tuning with n_jobs=-1
2025-06-02 19:20:01,109:INFO:Initializing skopt.BayesSearchCV
2025-06-02 19:20:23,097:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.8608120752388259), ('actual_estimator__bagging_freq', 1), ('actual_estimator__feature_fraction', 0.4284489606984907), ('actual_estimator__learning_rate', 0.016133245419918712), ('actual_estimator__min_child_samples', 95), ('actual_estimator__min_split_gain', 0.8209314243567916), ('actual_estimator__n_estimators', 239), ('actual_estimator__num_leaves', 183), ('actual_estimator__reg_alpha', 8.662569304197528e-07), ('actual_estimator__reg_lambda', 5.001062744294253e-06)])
2025-06-02 19:20:23,099:INFO:Hyperparameter search completed
2025-06-02 19:20:23,100:INFO:SubProcess create_model() called ==================================
2025-06-02 19:20:23,102:INFO:Initializing create_model()
2025-06-02 19:20:23,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B6E474B910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.8608120752388259, 'bagging_freq': 1, 'feature_fraction': 0.4284489606984907, 'learning_rate': 0.016133245419918712, 'min_child_samples': 95, 'min_split_gain': 0.8209314243567916, 'n_estimators': 239, 'num_leaves': 183, 'reg_alpha': 8.662569304197528e-07, 'reg_lambda': 5.001062744294253e-06})
2025-06-02 19:20:23,102:INFO:Checking exceptions
2025-06-02 19:20:23,103:INFO:Importing libraries
2025-06-02 19:20:23,103:INFO:Copying training dataset
2025-06-02 19:20:23,178:INFO:Defining folds
2025-06-02 19:20:23,179:INFO:Declaring metric variables
2025-06-02 19:20:23,189:INFO:Importing untrained model
2025-06-02 19:20:23,189:INFO:Declaring custom model
2025-06-02 19:20:23,205:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 19:20:23,232:INFO:Starting cross validation
2025-06-02 19:20:23,237:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:20:25,050:INFO:Calculating mean and std
2025-06-02 19:20:25,051:INFO:Creating metrics dataframe
2025-06-02 19:20:25,065:INFO:Finalizing model
2025-06-02 19:20:25,440:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 19:20:25,440:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 19:20:25,440:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 19:20:25,467:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 19:20:25,468:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-02 19:20:25,468:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-02 19:20:25,468:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-02 19:20:25,478:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005534 seconds.
2025-06-02 19:20:25,478:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 19:20:25,478:INFO:[LightGBM] [Info] Total Bins 6075
2025-06-02 19:20:25,517:INFO:[LightGBM] [Info] Number of data points in the train set: 3360, number of used features: 91
2025-06-02 19:20:25,519:INFO:[LightGBM] [Info] Start training from score -0.416868
2025-06-02 19:20:25,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-02 19:20:25,775:INFO:Uploading results into container
2025-06-02 19:20:25,778:INFO:Uploading model into container now
2025-06-02 19:20:25,779:INFO:_master_model_container: 21
2025-06-02 19:20:25,780:INFO:_display_container: 3
2025-06-02 19:20:25,783:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06)
2025-06-02 19:20:25,784:INFO:create_model() successfully completed......................................
2025-06-02 19:20:27,552:INFO:SubProcess create_model() end ==================================
2025-06-02 19:20:27,552:INFO:choose_better activated
2025-06-02 19:20:27,563:INFO:SubProcess create_model() called ==================================
2025-06-02 19:20:27,564:INFO:Initializing create_model()
2025-06-02 19:20:27,565:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:20:27,565:INFO:Checking exceptions
2025-06-02 19:20:27,569:INFO:Importing libraries
2025-06-02 19:20:27,569:INFO:Copying training dataset
2025-06-02 19:20:27,638:INFO:Defining folds
2025-06-02 19:20:27,638:INFO:Declaring metric variables
2025-06-02 19:20:27,639:INFO:Importing untrained model
2025-06-02 19:20:27,639:INFO:Declaring custom model
2025-06-02 19:20:27,641:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 19:20:27,641:INFO:Starting cross validation
2025-06-02 19:20:27,644:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:20:29,426:INFO:Calculating mean and std
2025-06-02 19:20:29,427:INFO:Creating metrics dataframe
2025-06-02 19:20:29,430:INFO:Finalizing model
2025-06-02 19:20:29,838:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 19:20:29,843:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003327 seconds.
2025-06-02 19:20:29,843:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-02 19:20:29,843:INFO:[LightGBM] [Info] Total Bins 6086
2025-06-02 19:20:29,844:INFO:[LightGBM] [Info] Number of data points in the train set: 3360, number of used features: 93
2025-06-02 19:20:29,845:INFO:[LightGBM] [Info] Start training from score -0.416868
2025-06-02 19:20:30,009:INFO:Uploading results into container
2025-06-02 19:20:30,010:INFO:Uploading model into container now
2025-06-02 19:20:30,011:INFO:_master_model_container: 22
2025-06-02 19:20:30,011:INFO:_display_container: 4
2025-06-02 19:20:30,012:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:20:30,012:INFO:create_model() successfully completed......................................
2025-06-02 19:20:31,414:INFO:SubProcess create_model() end ==================================
2025-06-02 19:20:31,415:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8514
2025-06-02 19:20:31,417:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06) result for R2 is 0.7832
2025-06-02 19:20:31,418:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-06-02 19:20:31,418:INFO:choose_better completed
2025-06-02 19:20:31,418:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 19:20:31,440:INFO:_master_model_container: 22
2025-06-02 19:20:31,440:INFO:_display_container: 3
2025-06-02 19:20:31,441:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:20:31,442:INFO:tune_model() successfully completed......................................
2025-06-02 19:20:32,849:INFO:Initializing finalize_model()
2025-06-02 19:20:32,849:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-02 19:20:32,850:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-02 19:20:32,905:INFO:Initializing create_model()
2025-06-02 19:20:32,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:20:32,906:INFO:Checking exceptions
2025-06-02 19:20:32,908:INFO:Importing libraries
2025-06-02 19:20:32,908:INFO:Copying training dataset
2025-06-02 19:20:32,914:INFO:Defining folds
2025-06-02 19:20:32,914:INFO:Declaring metric variables
2025-06-02 19:20:32,914:INFO:Importing untrained model
2025-06-02 19:20:32,914:INFO:Declaring custom model
2025-06-02 19:20:32,916:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 19:20:32,919:INFO:Cross validation set to False
2025-06-02 19:20:32,919:INFO:Fitting Model
2025-06-02 19:20:33,327:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-02 19:20:33,347:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002716 seconds.
2025-06-02 19:20:33,347:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-06-02 19:20:33,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-06-02 19:20:33,348:INFO:[LightGBM] [Info] Total Bins 6533
2025-06-02 19:20:33,351:INFO:[LightGBM] [Info] Number of data points in the train set: 4200, number of used features: 93
2025-06-02 19:20:33,353:INFO:[LightGBM] [Info] Start training from score -0.411860
2025-06-02 19:20:33,559:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 19:20:33,559:INFO:create_model() successfully completed......................................
2025-06-02 19:20:34,946:INFO:_master_model_container: 22
2025-06-02 19:20:34,947:INFO:_display_container: 3
2025-06-02 19:20:34,963:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 19:20:34,964:INFO:finalize_model() successfully completed......................................
2025-06-02 19:20:36,374:INFO:Initializing save_model()
2025-06-02 19:20:36,374:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-02 19:20:36,374:INFO:Adding model into prep_pipe
2025-06-02 19:20:36,374:WARNING:Only Model saved as it was a pipeline.
2025-06-02 19:20:36,397:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-02 19:20:36,421:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-02 19:20:36,421:INFO:save_model() successfully completed......................................
2025-06-02 19:20:37,837:INFO:Initializing load_model()
2025-06-02 19:20:37,837:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-02 19:20:37,979:INFO:Initializing get_config()
2025-06-02 19:20:37,979:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, variable=X_test)
2025-06-02 19:20:37,979:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-02 19:20:37,979:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-02 19:20:38,028:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
2030                       22.0                       46.0  \
3043                        8.0                       50.0   
3552                        8.0                       50.0   
380                        12.0                       12.0   
730                        58.0                       58.0   
...                         ...                        ...   
2572                        4.0                       14.0   
3757                        8.0                       26.0   
2377                        3.0                       50.0   
3499                        5.0                        8.0   
2893                       11.0                       21.0   

      MagpieData range Number  MagpieData mean Number   
2030                     24.0                34.00000  \
3043                     42.0                29.00000   
3552                     42.0                22.00000   
380                       0.0                12.00000   
730                       0.0                58.00000   
...                       ...                     ...   
2572                     10.0                 6.50000   
3757                     18.0                16.87324   
2377                     47.0                36.57143   
3499                      3.0                 6.80000   
2893                     10.0                18.50000   

      MagpieData avg_dev Number  MagpieData mode Number   
2030                  12.000000                    22.0  \
3043                  21.000000                     8.0   
3552                  18.666666                     8.0   
380                    0.000000                    12.0   
730                    0.000000                    58.0   
...                         ...                     ...   
2572                   3.750000                     4.0   
3757                   8.998215                     8.0   
2377                  19.183674                    50.0   
3499                   1.440000                     8.0   
2893                   3.750000                    21.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
2030                                43.0                                62.0  \
3043                                80.0                                87.0   
3552                                80.0                                87.0   
380                                 68.0                                68.0   
730                                 15.0                                15.0   
...                                  ...                                 ...   
2572                                67.0                                78.0   
3757                                55.0                                87.0   
2377                                 1.0                                80.0   
3499                                72.0                                87.0   
2893                                 2.0                                11.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
2030                              19.0                        52.500000  ...  \
3043                               7.0                        83.500000  ...   
3552                               7.0                        84.666664  ...   
380                                0.0                        68.000000  ...   
730                                0.0                        15.000000  ...   
...                                ...                              ...  ...   
2572                              11.0                        69.750000  ...   
3757                              32.0                        71.225349  ...   
2377                              79.0                        57.428570  ...   
3499                              15.0                        81.000000  ...   
2893                               9.0                         8.750000  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
2030                 4.0                   1            32.0  \
3043                 4.0                   1            32.0   
3552                 7.0                   0             2.0   
380                  2.0                   1            48.0   
730                  5.0                   1             8.0   
...                  ...                 ...             ...   
2572                 4.0                   1            32.0   
3757                 7.0                   0             1.0   
2377                 4.0                   1            32.0   
3499                 7.0                   0             2.0   
2893                 4.0                   1            16.0   

      crystal_system_cubic  crystal_system_hexagonal   
2030                 False                     False  \
3043                 False                     False   
3552                 False                     False   
380                  False                      True   
730                  False                     False   
...                    ...                       ...   
2572                 False                     False   
3757                 False                     False   
2377                 False                     False   
3499                 False                     False   
2893                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
2030                      False                        False  \
3043                      False                        False   
3552                      False                        False   
380                       False                        False   
730                       False                         True   
...                         ...                          ...   
2572                      False                        False   
3757                      False                        False   
2377                      False                        False   
3499                      False                        False   
2893                      False                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
2030                       True                     False  \
3043                       True                     False   
3552                      False                      True   
380                       False                     False   
730                       False                     False   
...                         ...                       ...   
2572                       True                     False   
3757                      False                      True   
2377                       True                     False   
3499                      False                      True   
2893                       True                     False   

      crystal_system_trigonal  
2030                    False  
3043                    False  
3552                    False  
380                     False  
730                     False  
...                       ...  
2572                    False  
3757                    False  
2377                    False  
3499                    False  
2893                    False  

[840 rows x 146 columns]
2025-06-02 19:20:38,028:INFO:get_config() successfully completed......................................
2025-06-02 19:20:38,036:INFO:Initializing get_config()
2025-06-02 19:20:38,036:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, variable=y_test)
2025-06-02 19:20:38,037:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-02 19:20:38,037:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-02 19:20:38,053:INFO:Variable:  returned as 2030   -0.527454
3043   -1.184208
3552   -1.604446
380     0.000000
730     0.034720
          ...   
2572    0.287101
3757   -0.714046
2377   -0.181563
3499   -2.675962
2893    0.382292
Name: target, Length: 840, dtype: float32
2025-06-02 19:20:38,053:INFO:get_config() successfully completed......................................
2025-06-02 19:20:38,054:INFO:Initializing get_config()
2025-06-02 19:20:38,054:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, variable=X_train)
2025-06-02 19:20:38,054:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-06-02 19:20:38,054:WARNING:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-06-02 19:20:38,098:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
3860                       52.0                       57.0  \
1975                       16.0                       71.0   
3260                        7.0                       20.0   
4063                       12.0                       14.0   
1778                        8.0                       22.0   
...                         ...                        ...   
1593                        9.0                       27.0   
4060                       12.0                       14.0   
1346                       12.0                       57.0   
3454                       12.0                       72.0   
3582                       16.0                       30.0   

      MagpieData range Number  MagpieData mean Number   
3860                      5.0               53.666668  \
1975                     55.0               38.000000   
3260                     13.0               14.526316   
4063                      2.0               13.142858   
1778                     14.0               12.666667   
...                       ...                     ...   
1593                     18.0               13.500000   
4060                      2.0               13.142858   
1346                     45.0               42.000000   
3454                     60.0               57.000000   
3582                     14.0               23.000000   

      MagpieData avg_dev Number  MagpieData mode Number   
3860                   2.222222                    52.0  \
1975                  26.400000                    16.0   
3260                   6.337950                    20.0   
4063                   0.979592                    14.0   
1778                   6.222222                     8.0   
...                         ...                     ...   
1593                   6.750000                     9.0   
4060                   0.979592                    14.0   
1346                  20.000000                    57.0   
3454                  22.500000                    72.0   
3582                   7.000000                    16.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
3860                                13.0                                90.0  \
1975                                41.0                                88.0   
3260                                 7.0                                82.0   
4063                                68.0                                78.0   
1778                                43.0                                87.0   
...                                  ...                                 ...   
1593                                58.0                                93.0   
4060                                68.0                                78.0   
1346                                13.0                                68.0   
3454                                45.0                                68.0   
3582                                69.0                                88.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
3860                              77.0                        64.333336  ...  \
1975                              47.0                        69.199997  ...   
3260                              75.0                        38.578949  ...   
4063                              10.0                        73.714287  ...   
1778                              44.0                        72.333336  ...   
...                                ...                              ...  ...   
1593                              35.0                        84.250000  ...   
4060                              10.0                        73.714287  ...   
1346                              55.0                        31.333334  ...   
3454                              23.0                        50.750000  ...   
3582                              19.0                        78.500000  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
3860                 6.0                   0             4.0  \
1975                 4.0                   0            16.0   
3260                 4.0                   1            16.0   
4063                 7.0                   0             2.0   
1778                 6.0                   1             8.0   
...                  ...                 ...             ...   
1593                 7.0                   0             1.0   
4060                 7.0                   0             2.0   
1346                 6.0                   1             4.0   
3454                 4.0                   1            32.0   
3582                 7.0                   0             2.0   

      crystal_system_cubic  crystal_system_hexagonal   
3860                 False                     False  \
1975                 False                     False   
3260                 False                     False   
4063                 False                     False   
1778                 False                     False   
...                    ...                       ...   
1593                 False                     False   
4060                 False                     False   
1346                 False                     False   
3454                 False                     False   
3582                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
3860                       True                        False  \
1975                      False                        False   
3260                      False                        False   
4063                      False                        False   
1778                       True                        False   
...                         ...                          ...   
1593                      False                        False   
4060                      False                        False   
1346                       True                        False   
3454                      False                        False   
3582                      False                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
3860                      False                     False  \
1975                       True                     False   
3260                       True                     False   
4063                      False                      True   
1778                      False                     False   
...                         ...                       ...   
1593                      False                      True   
4060                      False                      True   
1346                      False                     False   
3454                       True                     False   
3582                      False                      True   

      crystal_system_trigonal  
3860                    False  
1975                    False  
3260                    False  
4063                    False  
1778                    False  
...                       ...  
1593                    False  
4060                    False  
1346                    False  
3454                    False  
3582                    False  

[3360 rows x 146 columns]
2025-06-02 19:20:38,099:INFO:get_config() successfully completed......................................
2025-06-02 19:20:38,099:INFO:Initializing get_config()
2025-06-02 19:20:38,099:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, variable=y_train)
2025-06-02 19:20:38,099:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-06-02 19:20:38,099:WARNING:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-06-02 19:20:38,114:INFO:Variable:  returned as 3860   -1.682671
1975   -2.290768
3260   -0.733346
4063    0.160167
1778   -3.501638
          ...   
1593   -2.136502
4060    0.130419
1346   -0.006684
3454    0.086073
3582   -0.543908
Name: target, Length: 3360, dtype: float32
2025-06-02 19:20:38,114:INFO:get_config() successfully completed......................................
2025-06-02 19:20:38,131:INFO:Initializing predict_model()
2025-06-02 19:20:38,131:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71928FEB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B701FBE290>)
2025-06-02 19:20:38,132:INFO:Checking exceptions
2025-06-02 19:20:38,132:INFO:Preloading libraries
2025-06-02 19:20:38,136:INFO:Set up data.
2025-06-02 19:20:38,201:INFO:Set up index.
2025-06-02 19:34:48,759:INFO:PyCaret RegressionExperiment
2025-06-02 19:34:48,762:INFO:Logging name: reg-default-name
2025-06-02 19:34:48,762:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 19:34:48,762:INFO:version 3.3.2
2025-06-02 19:34:48,762:INFO:Initializing setup()
2025-06-02 19:34:48,762:INFO:self.USI: 82f9
2025-06-02 19:34:48,762:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 19:34:48,763:INFO:Checking environment
2025-06-02 19:34:48,764:INFO:python_version: 3.10.16
2025-06-02 19:34:48,765:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 19:34:48,766:INFO:machine: AMD64
2025-06-02 19:34:48,766:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 19:34:48,782:INFO:Memory: svmem(total=6378008576, available=909934592, percent=85.7, used=5468073984, free=909934592)
2025-06-02 19:34:48,783:INFO:Physical Core: 4
2025-06-02 19:34:48,784:INFO:Logical Core: 8
2025-06-02 19:34:48,785:INFO:Checking libraries
2025-06-02 19:34:48,787:INFO:System:
2025-06-02 19:34:48,788:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 19:34:48,788:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 19:34:48,788:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 19:34:48,789:INFO:PyCaret required dependencies:
2025-06-02 19:34:48,795:INFO:                 pip: 25.1
2025-06-02 19:34:48,796:INFO:          setuptools: 78.1.1
2025-06-02 19:34:48,796:INFO:             pycaret: 3.3.2
2025-06-02 19:34:48,796:INFO:             IPython: 8.37.0
2025-06-02 19:34:48,796:INFO:          ipywidgets: 8.1.7
2025-06-02 19:34:48,796:INFO:                tqdm: 4.67.1
2025-06-02 19:34:48,796:INFO:               numpy: 1.26.4
2025-06-02 19:34:48,796:INFO:              pandas: 2.0.1
2025-06-02 19:34:48,796:INFO:              jinja2: 3.1.6
2025-06-02 19:34:48,796:INFO:               scipy: 1.10.1
2025-06-02 19:34:48,796:INFO:              joblib: 1.3.2
2025-06-02 19:34:48,797:INFO:             sklearn: 1.4.2
2025-06-02 19:34:48,797:INFO:                pyod: 2.0.5
2025-06-02 19:34:48,797:INFO:            imblearn: 0.13.0
2025-06-02 19:34:48,797:INFO:   category_encoders: 2.7.0
2025-06-02 19:34:48,797:INFO:            lightgbm: 4.6.0
2025-06-02 19:34:48,797:INFO:               numba: 0.61.0
2025-06-02 19:34:48,797:INFO:            requests: 2.32.3
2025-06-02 19:34:48,797:INFO:          matplotlib: 3.7.1
2025-06-02 19:34:48,797:INFO:          scikitplot: 0.3.7
2025-06-02 19:34:48,797:INFO:         yellowbrick: 1.5
2025-06-02 19:34:48,797:INFO:              plotly: 6.1.2
2025-06-02 19:34:48,797:INFO:    plotly-resampler: Not installed
2025-06-02 19:34:48,798:INFO:             kaleido: 0.2.1
2025-06-02 19:34:48,798:INFO:           schemdraw: 0.15
2025-06-02 19:34:48,798:INFO:         statsmodels: 0.14.4
2025-06-02 19:34:48,798:INFO:              sktime: 0.26.0
2025-06-02 19:34:48,798:INFO:               tbats: 1.1.3
2025-06-02 19:34:48,798:INFO:            pmdarima: 2.0.4
2025-06-02 19:34:48,798:INFO:              psutil: 7.0.0
2025-06-02 19:34:48,798:INFO:          markupsafe: 2.1.2
2025-06-02 19:34:48,798:INFO:             pickle5: Not installed
2025-06-02 19:34:48,798:INFO:         cloudpickle: 3.1.1
2025-06-02 19:34:48,798:INFO:         deprecation: 2.1.0
2025-06-02 19:34:48,798:INFO:              xxhash: 3.5.0
2025-06-02 19:34:48,798:INFO:           wurlitzer: Not installed
2025-06-02 19:34:48,799:INFO:PyCaret optional dependencies:
2025-06-02 19:34:48,800:INFO:                shap: 0.44.1
2025-06-02 19:34:48,801:INFO:           interpret: 0.6.9
2025-06-02 19:34:48,801:INFO:                umap: 0.5.7
2025-06-02 19:34:48,801:INFO:     ydata_profiling: 4.16.1
2025-06-02 19:34:48,801:INFO:  explainerdashboard: 0.4.8
2025-06-02 19:34:48,801:INFO:             autoviz: Not installed
2025-06-02 19:34:48,801:INFO:           fairlearn: 0.7.0
2025-06-02 19:34:48,802:INFO:          deepchecks: Not installed
2025-06-02 19:34:48,802:INFO:             xgboost: 3.0.2
2025-06-02 19:34:48,802:INFO:            catboost: 1.2.8
2025-06-02 19:34:48,802:INFO:              kmodes: 0.12.2
2025-06-02 19:34:48,802:INFO:             mlxtend: 0.23.4
2025-06-02 19:34:48,802:INFO:       statsforecast: 1.5.0
2025-06-02 19:34:48,802:INFO:        tune_sklearn: Not installed
2025-06-02 19:34:48,803:INFO:                 ray: Not installed
2025-06-02 19:34:48,803:INFO:            hyperopt: 0.2.7
2025-06-02 19:34:48,803:INFO:              optuna: 4.3.0
2025-06-02 19:34:48,803:INFO:               skopt: 0.10.2
2025-06-02 19:34:48,803:INFO:              mlflow: 2.22.0
2025-06-02 19:34:48,803:INFO:              gradio: 5.32.0
2025-06-02 19:34:48,803:INFO:             fastapi: 0.115.12
2025-06-02 19:34:48,803:INFO:             uvicorn: 0.34.3
2025-06-02 19:34:48,803:INFO:              m2cgen: 0.10.0
2025-06-02 19:34:48,803:INFO:           evidently: 0.4.40
2025-06-02 19:34:48,804:INFO:               fugue: 0.8.5
2025-06-02 19:34:48,804:INFO:           streamlit: Not installed
2025-06-02 19:34:48,804:INFO:             prophet: Not installed
2025-06-02 19:34:48,804:INFO:None
2025-06-02 19:34:48,805:INFO:Set up data.
2025-06-02 19:34:49,026:INFO:Set up folding strategy.
2025-06-02 19:34:49,028:INFO:Set up train/test split.
2025-06-02 19:34:49,126:INFO:Set up index.
2025-06-02 19:34:49,135:INFO:Assigning column types.
2025-06-02 19:34:49,211:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 19:34:49,219:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 19:34:49,230:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:34:49,245:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:34:49,399:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:34:49,488:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:34:49,495:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:34:49,506:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:34:49,509:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 19:34:49,516:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:34:49,523:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:34:49,676:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:34:49,754:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:34:49,755:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:34:49,759:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:34:49,760:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 19:34:49,768:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:34:49,775:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:34:49,912:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:34:49,990:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:34:49,991:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:34:49,995:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:34:50,003:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:34:50,010:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:34:50,146:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:34:50,223:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:34:50,224:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:34:50,228:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:34:50,229:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 19:34:50,248:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:34:50,388:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:34:50,470:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:34:50,471:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:34:50,475:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:34:50,490:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:34:50,626:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:34:50,713:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:34:50,714:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:34:50,718:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:34:50,720:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 19:34:50,866:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:34:50,945:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:34:50,946:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:34:50,952:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:34:51,106:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:34:51,186:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:34:51,187:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:34:51,191:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:34:51,192:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 19:34:51,340:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:34:51,419:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:34:51,424:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:34:51,574:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:34:51,658:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:34:51,662:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:34:51,663:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 19:34:51,895:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:34:51,900:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:34:52,119:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:34:52,124:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:34:52,147:INFO:Preparing preprocessing pipeline...
2025-06-02 19:34:52,147:INFO:Set up simple imputation.
2025-06-02 19:34:52,149:INFO:Set up removing multicollinearity.
2025-06-02 19:34:52,157:INFO:Set up column name cleaning.
2025-06-02 19:34:52,389:INFO:Finished creating preprocessing pipeline.
2025-06-02 19:34:52,409:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 19:34:52,409:INFO:Creating final display dataframe.
2025-06-02 19:34:52,856:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4200, 147)
4        Transformed data shape        (4200, 94)
5   Transformed train set shape        (3360, 94)
6    Transformed test set shape         (840, 94)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              82f9
2025-06-02 19:34:53,083:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:34:53,087:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:34:53,315:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:34:53,320:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:34:53,326:INFO:setup() successfully completed in 4.73s...............
2025-06-02 19:34:53,437:INFO:Initializing evaluate_model()
2025-06-02 19:34:53,437:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7032E78E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-06-02 19:34:53,516:INFO:Initializing plot_model()
2025-06-02 19:34:53,516:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7032E78E0>, system=True)
2025-06-02 19:34:53,516:INFO:Checking exceptions
2025-06-02 19:34:53,799:INFO:Preloading libraries
2025-06-02 19:34:54,287:INFO:Copying training dataset
2025-06-02 19:34:54,287:INFO:Plot type: pipeline
2025-06-02 19:34:55,009:INFO:Visual Rendered Successfully
2025-06-02 19:35:06,164:INFO:plot_model() successfully completed......................................
2025-06-02 19:36:10,341:INFO:Initializing plot_model()
2025-06-02 19:36:10,342:INFO:plot_model(plot=parameter, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7032E78E0>, system=True)
2025-06-02 19:36:10,342:INFO:Checking exceptions
2025-06-02 19:36:10,661:INFO:Preloading libraries
2025-06-02 19:36:10,971:INFO:Copying training dataset
2025-06-02 19:36:10,971:INFO:Plot type: parameter
2025-06-02 19:36:10,993:INFO:Visual Rendered Successfully
2025-06-02 19:36:12,770:INFO:plot_model() successfully completed......................................
2025-06-02 19:38:58,298:INFO:Initializing plot_model()
2025-06-02 19:38:58,299:INFO:plot_model(plot=residuals, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7032E78E0>, system=True)
2025-06-02 19:38:58,299:INFO:Checking exceptions
2025-06-02 19:38:58,385:INFO:Preloading libraries
2025-06-02 19:38:58,478:INFO:Copying training dataset
2025-06-02 19:38:58,479:INFO:Plot type: residuals
2025-06-02 19:38:59,130:INFO:Fitting Model
2025-06-02 19:38:59,132:WARNING:X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names

2025-06-02 19:39:05,168:INFO:Initializing plot_model()
2025-06-02 19:39:05,168:INFO:plot_model(plot=error, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7032E78E0>, system=True)
2025-06-02 19:39:05,169:INFO:Checking exceptions
2025-06-02 19:39:05,254:INFO:Preloading libraries
2025-06-02 19:39:05,379:INFO:Copying training dataset
2025-06-02 19:39:05,380:INFO:Plot type: error
2025-06-02 19:39:05,781:INFO:Fitting Model
2025-06-02 19:39:05,782:WARNING:X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names

2025-06-02 19:39:05,782:INFO:Scoring test/hold-out set
2025-06-02 19:39:28,729:INFO:Initializing plot_model()
2025-06-02 19:39:28,730:INFO:plot_model(plot=cooks, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7032E78E0>, system=True)
2025-06-02 19:39:28,730:INFO:Checking exceptions
2025-06-02 19:39:28,813:INFO:Preloading libraries
2025-06-02 19:39:29,028:INFO:Copying training dataset
2025-06-02 19:39:29,029:INFO:Plot type: cooks
2025-06-02 19:39:29,571:INFO:Fitting Model
2025-06-02 19:39:35,514:INFO:Initializing plot_model()
2025-06-02 19:39:35,514:INFO:plot_model(plot=rfe, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7032E78E0>, system=True)
2025-06-02 19:39:35,514:INFO:Checking exceptions
2025-06-02 19:39:35,590:INFO:Preloading libraries
2025-06-02 19:39:35,703:INFO:Copying training dataset
2025-06-02 19:39:35,703:INFO:Plot type: rfe
2025-06-02 19:39:36,140:INFO:Fitting Model
2025-06-02 19:47:06,499:INFO:Initializing plot_model()
2025-06-02 19:47:06,507:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7032E78E0>, system=True)
2025-06-02 19:47:06,507:INFO:Checking exceptions
2025-06-02 19:47:07,765:INFO:Preloading libraries
2025-06-02 19:47:08,030:INFO:Copying training dataset
2025-06-02 19:47:08,030:INFO:Plot type: pipeline
2025-06-02 19:47:08,531:INFO:Visual Rendered Successfully
2025-06-02 19:47:23,102:INFO:plot_model() successfully completed......................................
2025-06-02 19:49:26,349:INFO:PyCaret RegressionExperiment
2025-06-02 19:49:26,349:INFO:Logging name: reg-default-name
2025-06-02 19:49:26,351:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 19:49:26,351:INFO:version 3.3.2
2025-06-02 19:49:26,352:INFO:Initializing setup()
2025-06-02 19:49:26,352:INFO:self.USI: 1456
2025-06-02 19:49:26,353:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 19:49:26,353:INFO:Checking environment
2025-06-02 19:49:26,355:INFO:python_version: 3.10.16
2025-06-02 19:49:26,357:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 19:49:26,357:INFO:machine: AMD64
2025-06-02 19:49:26,357:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 19:49:26,367:INFO:Memory: svmem(total=6378008576, available=753795072, percent=88.2, used=5624213504, free=753795072)
2025-06-02 19:49:26,368:INFO:Physical Core: 4
2025-06-02 19:49:26,368:INFO:Logical Core: 8
2025-06-02 19:49:26,368:INFO:Checking libraries
2025-06-02 19:49:26,369:INFO:System:
2025-06-02 19:49:26,369:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 19:49:26,369:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 19:49:26,369:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 19:49:26,370:INFO:PyCaret required dependencies:
2025-06-02 19:49:26,370:INFO:                 pip: 25.1
2025-06-02 19:49:26,370:INFO:          setuptools: 78.1.1
2025-06-02 19:49:26,370:INFO:             pycaret: 3.3.2
2025-06-02 19:49:26,370:INFO:             IPython: 8.37.0
2025-06-02 19:49:26,370:INFO:          ipywidgets: 8.1.7
2025-06-02 19:49:26,371:INFO:                tqdm: 4.67.1
2025-06-02 19:49:26,371:INFO:               numpy: 1.26.4
2025-06-02 19:49:26,371:INFO:              pandas: 2.0.1
2025-06-02 19:49:26,371:INFO:              jinja2: 3.1.6
2025-06-02 19:49:26,371:INFO:               scipy: 1.10.1
2025-06-02 19:49:26,371:INFO:              joblib: 1.3.2
2025-06-02 19:49:26,371:INFO:             sklearn: 1.4.2
2025-06-02 19:49:26,371:INFO:                pyod: 2.0.5
2025-06-02 19:49:26,372:INFO:            imblearn: 0.13.0
2025-06-02 19:49:26,372:INFO:   category_encoders: 2.7.0
2025-06-02 19:49:26,372:INFO:            lightgbm: 4.6.0
2025-06-02 19:49:26,372:INFO:               numba: 0.61.0
2025-06-02 19:49:26,373:INFO:            requests: 2.32.3
2025-06-02 19:49:26,373:INFO:          matplotlib: 3.7.1
2025-06-02 19:49:26,373:INFO:          scikitplot: 0.3.7
2025-06-02 19:49:26,373:INFO:         yellowbrick: 1.5
2025-06-02 19:49:26,373:INFO:              plotly: 6.1.2
2025-06-02 19:49:26,373:INFO:    plotly-resampler: Not installed
2025-06-02 19:49:26,373:INFO:             kaleido: 0.2.1
2025-06-02 19:49:26,374:INFO:           schemdraw: 0.15
2025-06-02 19:49:26,374:INFO:         statsmodels: 0.14.4
2025-06-02 19:49:26,374:INFO:              sktime: 0.26.0
2025-06-02 19:49:26,374:INFO:               tbats: 1.1.3
2025-06-02 19:49:26,374:INFO:            pmdarima: 2.0.4
2025-06-02 19:49:26,374:INFO:              psutil: 7.0.0
2025-06-02 19:49:26,374:INFO:          markupsafe: 2.1.2
2025-06-02 19:49:26,376:INFO:             pickle5: Not installed
2025-06-02 19:49:26,376:INFO:         cloudpickle: 3.1.1
2025-06-02 19:49:26,376:INFO:         deprecation: 2.1.0
2025-06-02 19:49:26,376:INFO:              xxhash: 3.5.0
2025-06-02 19:49:26,376:INFO:           wurlitzer: Not installed
2025-06-02 19:49:26,376:INFO:PyCaret optional dependencies:
2025-06-02 19:49:26,377:INFO:                shap: 0.44.1
2025-06-02 19:49:26,377:INFO:           interpret: 0.6.9
2025-06-02 19:49:26,377:INFO:                umap: 0.5.7
2025-06-02 19:49:26,377:INFO:     ydata_profiling: 4.16.1
2025-06-02 19:49:26,377:INFO:  explainerdashboard: 0.4.8
2025-06-02 19:49:26,377:INFO:             autoviz: Not installed
2025-06-02 19:49:26,377:INFO:           fairlearn: 0.7.0
2025-06-02 19:49:26,377:INFO:          deepchecks: Not installed
2025-06-02 19:49:26,377:INFO:             xgboost: 3.0.2
2025-06-02 19:49:26,377:INFO:            catboost: 1.2.8
2025-06-02 19:49:26,378:INFO:              kmodes: 0.12.2
2025-06-02 19:49:26,378:INFO:             mlxtend: 0.23.4
2025-06-02 19:49:26,378:INFO:       statsforecast: 1.5.0
2025-06-02 19:49:26,378:INFO:        tune_sklearn: Not installed
2025-06-02 19:49:26,378:INFO:                 ray: Not installed
2025-06-02 19:49:26,378:INFO:            hyperopt: 0.2.7
2025-06-02 19:49:26,378:INFO:              optuna: 4.3.0
2025-06-02 19:49:26,378:INFO:               skopt: 0.10.2
2025-06-02 19:49:26,378:INFO:              mlflow: 2.22.0
2025-06-02 19:49:26,378:INFO:              gradio: 5.32.0
2025-06-02 19:49:26,378:INFO:             fastapi: 0.115.12
2025-06-02 19:49:26,379:INFO:             uvicorn: 0.34.3
2025-06-02 19:49:26,379:INFO:              m2cgen: 0.10.0
2025-06-02 19:49:26,379:INFO:           evidently: 0.4.40
2025-06-02 19:49:26,379:INFO:               fugue: 0.8.5
2025-06-02 19:49:26,379:INFO:           streamlit: Not installed
2025-06-02 19:49:26,379:INFO:             prophet: Not installed
2025-06-02 19:49:26,379:INFO:None
2025-06-02 19:49:26,379:INFO:Set up data.
2025-06-02 19:49:26,582:INFO:Set up folding strategy.
2025-06-02 19:49:26,582:INFO:Set up train/test split.
2025-06-02 19:49:26,701:INFO:Set up index.
2025-06-02 19:49:26,715:INFO:Assigning column types.
2025-06-02 19:49:26,798:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 19:49:26,799:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 19:49:26,820:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:49:26,840:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:49:27,162:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:49:27,353:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:49:27,356:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:49:27,369:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:49:27,372:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 19:49:27,394:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:49:27,413:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:49:27,736:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:49:27,933:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:49:27,936:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:49:27,945:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:49:27,947:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 19:49:27,964:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:49:27,989:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:49:28,343:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:49:28,566:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:49:28,569:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:49:28,582:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:49:28,606:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:49:28,629:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:49:28,988:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:49:29,193:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:49:29,195:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:49:29,208:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:49:29,211:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 19:49:29,261:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:49:29,646:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:49:29,849:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:49:29,851:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:49:29,863:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:49:29,904:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:49:30,293:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:49:30,521:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:49:30,524:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:49:30,532:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:49:30,537:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 19:49:30,831:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:49:30,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:49:30,947:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:49:30,954:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:49:31,160:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:49:31,272:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:49:31,281:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:49:31,290:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:49:31,291:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 19:49:31,565:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:49:31,676:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:49:31,686:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:49:32,000:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:49:32,126:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:49:32,131:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:49:32,133:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 19:49:32,521:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:49:32,535:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:49:33,065:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:49:33,078:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:49:33,089:INFO:Preparing preprocessing pipeline...
2025-06-02 19:49:33,089:INFO:Set up simple imputation.
2025-06-02 19:49:33,089:INFO:Set up removing multicollinearity.
2025-06-02 19:49:33,105:INFO:Set up column name cleaning.
2025-06-02 19:49:33,528:INFO:Finished creating preprocessing pipeline.
2025-06-02 19:49:33,563:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 19:49:33,564:INFO:Creating final display dataframe.
2025-06-02 19:49:34,632:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4200, 147)
4        Transformed data shape        (4200, 94)
5   Transformed train set shape        (3360, 94)
6    Transformed test set shape         (840, 94)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              1456
2025-06-02 19:49:35,075:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:49:35,082:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:49:35,498:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:49:35,507:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:49:35,512:INFO:setup() successfully completed in 9.22s...............
2025-06-02 19:49:35,543:INFO:Initializing evaluate_model()
2025-06-02 19:49:35,543:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71A2E1450>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-06-02 19:49:35,687:INFO:Initializing plot_model()
2025-06-02 19:49:35,688:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71A2E1450>, system=True)
2025-06-02 19:49:35,688:INFO:Checking exceptions
2025-06-02 19:49:35,932:INFO:Preloading libraries
2025-06-02 19:49:36,197:INFO:Copying training dataset
2025-06-02 19:49:36,198:INFO:Plot type: pipeline
2025-06-02 19:49:36,525:INFO:Visual Rendered Successfully
2025-06-02 19:49:38,826:INFO:plot_model() successfully completed......................................
2025-06-02 19:50:54,076:INFO:PyCaret RegressionExperiment
2025-06-02 19:50:54,076:INFO:Logging name: reg-default-name
2025-06-02 19:50:54,076:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 19:50:54,077:INFO:version 3.3.2
2025-06-02 19:50:54,077:INFO:Initializing setup()
2025-06-02 19:50:54,077:INFO:self.USI: 656f
2025-06-02 19:50:54,078:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 19:50:54,078:INFO:Checking environment
2025-06-02 19:50:54,079:INFO:python_version: 3.10.16
2025-06-02 19:50:54,080:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 19:50:54,080:INFO:machine: AMD64
2025-06-02 19:50:54,081:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 19:50:54,110:INFO:Memory: svmem(total=6378008576, available=337076224, percent=94.7, used=6040932352, free=337076224)
2025-06-02 19:50:54,111:INFO:Physical Core: 4
2025-06-02 19:50:54,111:INFO:Logical Core: 8
2025-06-02 19:50:54,111:INFO:Checking libraries
2025-06-02 19:50:54,111:INFO:System:
2025-06-02 19:50:54,111:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 19:50:54,112:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 19:50:54,112:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 19:50:54,112:INFO:PyCaret required dependencies:
2025-06-02 19:50:54,113:INFO:                 pip: 25.1
2025-06-02 19:50:54,113:INFO:          setuptools: 78.1.1
2025-06-02 19:50:54,113:INFO:             pycaret: 3.3.2
2025-06-02 19:50:54,113:INFO:             IPython: 8.37.0
2025-06-02 19:50:54,113:INFO:          ipywidgets: 8.1.7
2025-06-02 19:50:54,114:INFO:                tqdm: 4.67.1
2025-06-02 19:50:54,114:INFO:               numpy: 1.26.4
2025-06-02 19:50:54,114:INFO:              pandas: 2.0.1
2025-06-02 19:50:54,114:INFO:              jinja2: 3.1.6
2025-06-02 19:50:54,114:INFO:               scipy: 1.10.1
2025-06-02 19:50:54,114:INFO:              joblib: 1.3.2
2025-06-02 19:50:54,114:INFO:             sklearn: 1.4.2
2025-06-02 19:50:54,114:INFO:                pyod: 2.0.5
2025-06-02 19:50:54,114:INFO:            imblearn: 0.13.0
2025-06-02 19:50:54,114:INFO:   category_encoders: 2.7.0
2025-06-02 19:50:54,114:INFO:            lightgbm: 4.6.0
2025-06-02 19:50:54,114:INFO:               numba: 0.61.0
2025-06-02 19:50:54,115:INFO:            requests: 2.32.3
2025-06-02 19:50:54,115:INFO:          matplotlib: 3.7.1
2025-06-02 19:50:54,115:INFO:          scikitplot: 0.3.7
2025-06-02 19:50:54,115:INFO:         yellowbrick: 1.5
2025-06-02 19:50:54,115:INFO:              plotly: 6.1.2
2025-06-02 19:50:54,115:INFO:    plotly-resampler: Not installed
2025-06-02 19:50:54,115:INFO:             kaleido: 0.2.1
2025-06-02 19:50:54,116:INFO:           schemdraw: 0.15
2025-06-02 19:50:54,116:INFO:         statsmodels: 0.14.4
2025-06-02 19:50:54,116:INFO:              sktime: 0.26.0
2025-06-02 19:50:54,117:INFO:               tbats: 1.1.3
2025-06-02 19:50:54,117:INFO:            pmdarima: 2.0.4
2025-06-02 19:50:54,118:INFO:              psutil: 7.0.0
2025-06-02 19:50:54,118:INFO:          markupsafe: 2.1.2
2025-06-02 19:50:54,118:INFO:             pickle5: Not installed
2025-06-02 19:50:54,120:INFO:         cloudpickle: 3.1.1
2025-06-02 19:50:54,120:INFO:         deprecation: 2.1.0
2025-06-02 19:50:54,120:INFO:              xxhash: 3.5.0
2025-06-02 19:50:54,120:INFO:           wurlitzer: Not installed
2025-06-02 19:50:54,120:INFO:PyCaret optional dependencies:
2025-06-02 19:50:54,120:INFO:                shap: 0.44.1
2025-06-02 19:50:54,121:INFO:           interpret: 0.6.9
2025-06-02 19:50:54,121:INFO:                umap: 0.5.7
2025-06-02 19:50:54,121:INFO:     ydata_profiling: 4.16.1
2025-06-02 19:50:54,121:INFO:  explainerdashboard: 0.4.8
2025-06-02 19:50:54,121:INFO:             autoviz: Not installed
2025-06-02 19:50:54,121:INFO:           fairlearn: 0.7.0
2025-06-02 19:50:54,121:INFO:          deepchecks: Not installed
2025-06-02 19:50:54,122:INFO:             xgboost: 3.0.2
2025-06-02 19:50:54,122:INFO:            catboost: 1.2.8
2025-06-02 19:50:54,122:INFO:              kmodes: 0.12.2
2025-06-02 19:50:54,122:INFO:             mlxtend: 0.23.4
2025-06-02 19:50:54,122:INFO:       statsforecast: 1.5.0
2025-06-02 19:50:54,122:INFO:        tune_sklearn: Not installed
2025-06-02 19:50:54,122:INFO:                 ray: Not installed
2025-06-02 19:50:54,123:INFO:            hyperopt: 0.2.7
2025-06-02 19:50:54,123:INFO:              optuna: 4.3.0
2025-06-02 19:50:54,123:INFO:               skopt: 0.10.2
2025-06-02 19:50:54,123:INFO:              mlflow: 2.22.0
2025-06-02 19:50:54,123:INFO:              gradio: 5.32.0
2025-06-02 19:50:54,123:INFO:             fastapi: 0.115.12
2025-06-02 19:50:54,124:INFO:             uvicorn: 0.34.3
2025-06-02 19:50:54,124:INFO:              m2cgen: 0.10.0
2025-06-02 19:50:54,124:INFO:           evidently: 0.4.40
2025-06-02 19:50:54,124:INFO:               fugue: 0.8.5
2025-06-02 19:50:54,124:INFO:           streamlit: Not installed
2025-06-02 19:50:54,124:INFO:             prophet: Not installed
2025-06-02 19:50:54,124:INFO:None
2025-06-02 19:50:54,125:INFO:Set up data.
2025-06-02 19:50:54,495:INFO:Set up folding strategy.
2025-06-02 19:50:54,496:INFO:Set up train/test split.
2025-06-02 19:50:54,627:INFO:Set up index.
2025-06-02 19:50:54,634:INFO:Assigning column types.
2025-06-02 19:50:54,742:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 19:50:54,744:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 19:50:54,759:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:50:54,779:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:50:55,182:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:50:55,387:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:50:55,389:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:50:55,398:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:50:55,402:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 19:50:55,416:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:50:55,428:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:50:55,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:50:55,938:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:50:55,939:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:50:55,953:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:50:55,955:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 19:50:55,974:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:50:55,989:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:50:56,256:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:50:56,366:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:50:56,367:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:50:56,376:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:50:56,396:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 19:50:56,419:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:50:56,778:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:50:56,986:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:50:56,988:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:50:56,997:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:50:56,999:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 19:50:57,039:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:50:57,431:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:50:57,633:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:50:57,635:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:50:57,643:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:50:57,673:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 19:50:57,991:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:50:58,194:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:50:58,197:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:50:58,209:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:50:58,212:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 19:50:58,602:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:50:58,809:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:50:58,811:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:50:58,819:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:50:59,208:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:50:59,427:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:50:59,429:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:50:59,441:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:50:59,444:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 19:50:59,875:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:51:00,098:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:51:00,108:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:51:00,471:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 19:51:00,603:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:51:00,611:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:51:00,614:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 19:51:00,988:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:51:00,994:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:51:01,378:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:51:01,387:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:51:01,413:INFO:Preparing preprocessing pipeline...
2025-06-02 19:51:01,413:INFO:Set up simple imputation.
2025-06-02 19:51:01,415:INFO:Set up removing multicollinearity.
2025-06-02 19:51:01,429:INFO:Set up column name cleaning.
2025-06-02 19:51:01,736:INFO:Finished creating preprocessing pipeline.
2025-06-02 19:51:01,766:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 19:51:01,766:INFO:Creating final display dataframe.
2025-06-02 19:51:02,642:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4200, 147)
4        Transformed data shape        (4200, 94)
5   Transformed train set shape        (3360, 94)
6    Transformed test set shape         (840, 94)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              656f
2025-06-02 19:51:03,167:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:51:03,176:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:51:03,611:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 19:51:03,616:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 19:51:03,622:INFO:setup() successfully completed in 9.65s...............
2025-06-02 19:51:03,791:INFO:Initializing evaluate_model()
2025-06-02 19:51:03,792:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B72A6DECE0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-06-02 19:51:03,896:INFO:Initializing plot_model()
2025-06-02 19:51:03,897:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B72A6DECE0>, system=True)
2025-06-02 19:51:03,897:INFO:Checking exceptions
2025-06-02 19:51:03,952:INFO:Preloading libraries
2025-06-02 19:51:03,995:INFO:Copying training dataset
2025-06-02 19:51:03,995:INFO:Plot type: pipeline
2025-06-02 19:51:04,766:INFO:Visual Rendered Successfully
2025-06-02 19:51:09,254:INFO:plot_model() successfully completed......................................
2025-06-02 19:52:33,037:INFO:Initializing plot_model()
2025-06-02 19:52:33,044:INFO:plot_model(plot=learning, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B72A6DECE0>, system=True)
2025-06-02 19:52:33,045:INFO:Checking exceptions
2025-06-02 19:52:33,302:INFO:Preloading libraries
2025-06-02 19:52:33,368:INFO:Copying training dataset
2025-06-02 19:52:33,368:INFO:Plot type: learning
2025-06-02 19:52:34,020:INFO:Fitting Model
2025-06-02 19:52:59,102:INFO:Visual Rendered Successfully
2025-06-02 19:53:14,783:INFO:plot_model() successfully completed......................................
2025-06-02 19:54:37,101:INFO:Initializing plot_model()
2025-06-02 19:54:37,103:INFO:plot_model(plot=learning, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B71A2E1450>, system=True)
2025-06-02 19:54:37,103:INFO:Checking exceptions
2025-06-02 19:54:37,485:INFO:Preloading libraries
2025-06-02 19:54:38,053:INFO:Copying training dataset
2025-06-02 19:54:38,053:INFO:Plot type: learning
2025-06-02 19:54:38,455:INFO:Fitting Model
2025-06-02 19:55:26,722:INFO:Visual Rendered Successfully
2025-06-02 19:55:34,203:INFO:plot_model() successfully completed......................................
2025-06-02 20:10:06,101:INFO:PyCaret RegressionExperiment
2025-06-02 20:10:06,106:INFO:Logging name: reg-default-name
2025-06-02 20:10:06,107:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 20:10:06,107:INFO:version 3.3.2
2025-06-02 20:10:06,107:INFO:Initializing setup()
2025-06-02 20:10:06,107:INFO:self.USI: 25da
2025-06-02 20:10:06,108:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 20:10:06,109:INFO:Checking environment
2025-06-02 20:10:06,110:INFO:python_version: 3.10.16
2025-06-02 20:10:06,110:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 20:10:06,111:INFO:machine: AMD64
2025-06-02 20:10:06,111:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 20:10:06,128:INFO:Memory: svmem(total=6378008576, available=815837184, percent=87.2, used=5562171392, free=815837184)
2025-06-02 20:10:06,129:INFO:Physical Core: 4
2025-06-02 20:10:06,129:INFO:Logical Core: 8
2025-06-02 20:10:06,130:INFO:Checking libraries
2025-06-02 20:10:06,130:INFO:System:
2025-06-02 20:10:06,131:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 20:10:06,131:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 20:10:06,131:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 20:10:06,131:INFO:PyCaret required dependencies:
2025-06-02 20:10:06,139:INFO:                 pip: 25.1
2025-06-02 20:10:06,139:INFO:          setuptools: 78.1.1
2025-06-02 20:10:06,139:INFO:             pycaret: 3.3.2
2025-06-02 20:10:06,139:INFO:             IPython: 8.37.0
2025-06-02 20:10:06,139:INFO:          ipywidgets: 8.1.7
2025-06-02 20:10:06,139:INFO:                tqdm: 4.67.1
2025-06-02 20:10:06,139:INFO:               numpy: 1.26.4
2025-06-02 20:10:06,139:INFO:              pandas: 2.0.1
2025-06-02 20:10:06,139:INFO:              jinja2: 3.1.6
2025-06-02 20:10:06,139:INFO:               scipy: 1.10.1
2025-06-02 20:10:06,140:INFO:              joblib: 1.3.2
2025-06-02 20:10:06,140:INFO:             sklearn: 1.4.2
2025-06-02 20:10:06,140:INFO:                pyod: 2.0.5
2025-06-02 20:10:06,140:INFO:            imblearn: 0.13.0
2025-06-02 20:10:06,140:INFO:   category_encoders: 2.7.0
2025-06-02 20:10:06,140:INFO:            lightgbm: 4.6.0
2025-06-02 20:10:06,140:INFO:               numba: 0.61.0
2025-06-02 20:10:06,140:INFO:            requests: 2.32.3
2025-06-02 20:10:06,140:INFO:          matplotlib: 3.7.1
2025-06-02 20:10:06,140:INFO:          scikitplot: 0.3.7
2025-06-02 20:10:06,140:INFO:         yellowbrick: 1.5
2025-06-02 20:10:06,140:INFO:              plotly: 6.1.2
2025-06-02 20:10:06,140:INFO:    plotly-resampler: Not installed
2025-06-02 20:10:06,141:INFO:             kaleido: 0.2.1
2025-06-02 20:10:06,141:INFO:           schemdraw: 0.15
2025-06-02 20:10:06,141:INFO:         statsmodels: 0.14.4
2025-06-02 20:10:06,141:INFO:              sktime: 0.26.0
2025-06-02 20:10:06,141:INFO:               tbats: 1.1.3
2025-06-02 20:10:06,141:INFO:            pmdarima: 2.0.4
2025-06-02 20:10:06,141:INFO:              psutil: 7.0.0
2025-06-02 20:10:06,141:INFO:          markupsafe: 2.1.2
2025-06-02 20:10:06,141:INFO:             pickle5: Not installed
2025-06-02 20:10:06,141:INFO:         cloudpickle: 3.1.1
2025-06-02 20:10:06,141:INFO:         deprecation: 2.1.0
2025-06-02 20:10:06,141:INFO:              xxhash: 3.5.0
2025-06-02 20:10:06,142:INFO:           wurlitzer: Not installed
2025-06-02 20:10:06,142:INFO:PyCaret optional dependencies:
2025-06-02 20:10:06,143:INFO:                shap: 0.44.1
2025-06-02 20:10:06,143:INFO:           interpret: 0.6.9
2025-06-02 20:10:06,144:INFO:                umap: 0.5.7
2025-06-02 20:10:06,144:INFO:     ydata_profiling: 4.16.1
2025-06-02 20:10:06,144:INFO:  explainerdashboard: 0.4.8
2025-06-02 20:10:06,144:INFO:             autoviz: Not installed
2025-06-02 20:10:06,144:INFO:           fairlearn: 0.7.0
2025-06-02 20:10:06,144:INFO:          deepchecks: Not installed
2025-06-02 20:10:06,144:INFO:             xgboost: 3.0.2
2025-06-02 20:10:06,144:INFO:            catboost: 1.2.8
2025-06-02 20:10:06,144:INFO:              kmodes: 0.12.2
2025-06-02 20:10:06,145:INFO:             mlxtend: 0.23.4
2025-06-02 20:10:06,145:INFO:       statsforecast: 1.5.0
2025-06-02 20:10:06,145:INFO:        tune_sklearn: Not installed
2025-06-02 20:10:06,145:INFO:                 ray: Not installed
2025-06-02 20:10:06,145:INFO:            hyperopt: 0.2.7
2025-06-02 20:10:06,145:INFO:              optuna: 4.3.0
2025-06-02 20:10:06,145:INFO:               skopt: 0.10.2
2025-06-02 20:10:06,145:INFO:              mlflow: 2.22.0
2025-06-02 20:10:06,145:INFO:              gradio: 5.32.0
2025-06-02 20:10:06,145:INFO:             fastapi: 0.115.12
2025-06-02 20:10:06,146:INFO:             uvicorn: 0.34.3
2025-06-02 20:10:06,146:INFO:              m2cgen: 0.10.0
2025-06-02 20:10:06,146:INFO:           evidently: 0.4.40
2025-06-02 20:10:06,146:INFO:               fugue: 0.8.5
2025-06-02 20:10:06,146:INFO:           streamlit: Not installed
2025-06-02 20:10:06,146:INFO:             prophet: Not installed
2025-06-02 20:10:06,146:INFO:None
2025-06-02 20:10:06,148:INFO:Set up data.
2025-06-02 20:10:06,448:INFO:Set up folding strategy.
2025-06-02 20:10:06,451:INFO:Set up train/test split.
2025-06-02 20:10:06,580:INFO:Set up index.
2025-06-02 20:10:06,590:INFO:Assigning column types.
2025-06-02 20:10:06,665:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 20:10:06,672:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 20:10:06,683:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:10:06,696:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:10:06,888:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:10:06,990:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:10:06,997:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:10:07,010:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:10:07,014:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 20:10:07,021:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:10:07,028:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:10:07,173:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:10:07,256:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:10:07,257:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:10:07,261:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:10:07,262:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 20:10:07,269:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:10:07,278:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:10:07,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:10:07,524:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:10:07,524:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:10:07,528:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:10:07,536:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:10:07,544:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:10:07,707:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:10:07,801:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:10:07,802:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:10:07,807:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:10:07,808:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 20:10:07,823:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:10:07,965:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:10:08,061:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:10:08,062:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:10:08,066:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:10:08,082:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:10:08,226:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:10:08,305:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:10:08,306:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:10:08,310:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:10:08,312:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 20:10:08,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:10:08,563:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:10:08,564:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:10:08,569:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:10:08,733:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:10:08,819:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:10:08,820:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:10:08,824:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:10:08,825:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 20:10:08,986:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:10:09,073:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:10:09,077:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:10:09,247:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:10:09,340:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:10:09,344:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:10:09,345:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 20:10:09,606:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:10:09,611:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:10:09,868:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:10:09,873:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:10:09,891:INFO:Preparing preprocessing pipeline...
2025-06-02 20:10:09,891:INFO:Set up simple imputation.
2025-06-02 20:10:09,893:INFO:Set up removing multicollinearity.
2025-06-02 20:10:09,903:INFO:Set up column name cleaning.
2025-06-02 20:10:10,164:INFO:Finished creating preprocessing pipeline.
2025-06-02 20:10:10,194:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 20:10:10,194:INFO:Creating final display dataframe.
2025-06-02 20:10:10,671:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4200, 147)
4        Transformed data shape        (4200, 94)
5   Transformed train set shape        (3360, 94)
6    Transformed test set shape         (840, 94)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              25da
2025-06-02 20:10:10,924:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:10:10,929:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:10:11,163:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:10:11,167:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:10:11,174:INFO:setup() successfully completed in 5.33s...............
2025-06-02 20:10:11,194:INFO:Initializing evaluate_model()
2025-06-02 20:10:11,194:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718939FF0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-06-02 20:10:11,290:INFO:Initializing plot_model()
2025-06-02 20:10:11,290:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718939FF0>, system=True)
2025-06-02 20:10:11,290:INFO:Checking exceptions
2025-06-02 20:10:11,477:INFO:Preloading libraries
2025-06-02 20:10:11,793:INFO:Copying training dataset
2025-06-02 20:10:11,794:INFO:Plot type: pipeline
2025-06-02 20:10:12,300:INFO:Visual Rendered Successfully
2025-06-02 20:10:24,449:INFO:plot_model() successfully completed......................................
2025-06-02 20:11:53,534:INFO:PyCaret RegressionExperiment
2025-06-02 20:11:53,535:INFO:Logging name: reg-default-name
2025-06-02 20:11:53,535:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 20:11:53,535:INFO:version 3.3.2
2025-06-02 20:11:53,535:INFO:Initializing setup()
2025-06-02 20:11:53,535:INFO:self.USI: 0aa1
2025-06-02 20:11:53,535:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 20:11:53,536:INFO:Checking environment
2025-06-02 20:11:53,536:INFO:python_version: 3.10.16
2025-06-02 20:11:53,536:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 20:11:53,537:INFO:machine: AMD64
2025-06-02 20:11:53,537:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 20:11:53,544:INFO:Memory: svmem(total=6378008576, available=400986112, percent=93.7, used=5977022464, free=400986112)
2025-06-02 20:11:53,544:INFO:Physical Core: 4
2025-06-02 20:11:53,544:INFO:Logical Core: 8
2025-06-02 20:11:53,544:INFO:Checking libraries
2025-06-02 20:11:53,544:INFO:System:
2025-06-02 20:11:53,545:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 20:11:53,545:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 20:11:53,545:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 20:11:53,545:INFO:PyCaret required dependencies:
2025-06-02 20:11:53,545:INFO:                 pip: 25.1
2025-06-02 20:11:53,545:INFO:          setuptools: 78.1.1
2025-06-02 20:11:53,545:INFO:             pycaret: 3.3.2
2025-06-02 20:11:53,545:INFO:             IPython: 8.37.0
2025-06-02 20:11:53,545:INFO:          ipywidgets: 8.1.7
2025-06-02 20:11:53,545:INFO:                tqdm: 4.67.1
2025-06-02 20:11:53,546:INFO:               numpy: 1.26.4
2025-06-02 20:11:53,546:INFO:              pandas: 2.0.1
2025-06-02 20:11:53,546:INFO:              jinja2: 3.1.6
2025-06-02 20:11:53,546:INFO:               scipy: 1.10.1
2025-06-02 20:11:53,546:INFO:              joblib: 1.3.2
2025-06-02 20:11:53,546:INFO:             sklearn: 1.4.2
2025-06-02 20:11:53,546:INFO:                pyod: 2.0.5
2025-06-02 20:11:53,546:INFO:            imblearn: 0.13.0
2025-06-02 20:11:53,546:INFO:   category_encoders: 2.7.0
2025-06-02 20:11:53,546:INFO:            lightgbm: 4.6.0
2025-06-02 20:11:53,546:INFO:               numba: 0.61.0
2025-06-02 20:11:53,546:INFO:            requests: 2.32.3
2025-06-02 20:11:53,547:INFO:          matplotlib: 3.7.1
2025-06-02 20:11:53,547:INFO:          scikitplot: 0.3.7
2025-06-02 20:11:53,547:INFO:         yellowbrick: 1.5
2025-06-02 20:11:53,547:INFO:              plotly: 6.1.2
2025-06-02 20:11:53,547:INFO:    plotly-resampler: Not installed
2025-06-02 20:11:53,547:INFO:             kaleido: 0.2.1
2025-06-02 20:11:53,547:INFO:           schemdraw: 0.15
2025-06-02 20:11:53,547:INFO:         statsmodels: 0.14.4
2025-06-02 20:11:53,547:INFO:              sktime: 0.26.0
2025-06-02 20:11:53,547:INFO:               tbats: 1.1.3
2025-06-02 20:11:53,547:INFO:            pmdarima: 2.0.4
2025-06-02 20:11:53,547:INFO:              psutil: 7.0.0
2025-06-02 20:11:53,548:INFO:          markupsafe: 2.1.2
2025-06-02 20:11:53,548:INFO:             pickle5: Not installed
2025-06-02 20:11:53,548:INFO:         cloudpickle: 3.1.1
2025-06-02 20:11:53,548:INFO:         deprecation: 2.1.0
2025-06-02 20:11:53,548:INFO:              xxhash: 3.5.0
2025-06-02 20:11:53,548:INFO:           wurlitzer: Not installed
2025-06-02 20:11:53,548:INFO:PyCaret optional dependencies:
2025-06-02 20:11:53,548:INFO:                shap: 0.44.1
2025-06-02 20:11:53,548:INFO:           interpret: 0.6.9
2025-06-02 20:11:53,548:INFO:                umap: 0.5.7
2025-06-02 20:11:53,548:INFO:     ydata_profiling: 4.16.1
2025-06-02 20:11:53,548:INFO:  explainerdashboard: 0.4.8
2025-06-02 20:11:53,548:INFO:             autoviz: Not installed
2025-06-02 20:11:53,549:INFO:           fairlearn: 0.7.0
2025-06-02 20:11:53,549:INFO:          deepchecks: Not installed
2025-06-02 20:11:53,549:INFO:             xgboost: 3.0.2
2025-06-02 20:11:53,549:INFO:            catboost: 1.2.8
2025-06-02 20:11:53,549:INFO:              kmodes: 0.12.2
2025-06-02 20:11:53,549:INFO:             mlxtend: 0.23.4
2025-06-02 20:11:53,549:INFO:       statsforecast: 1.5.0
2025-06-02 20:11:53,549:INFO:        tune_sklearn: Not installed
2025-06-02 20:11:53,549:INFO:                 ray: Not installed
2025-06-02 20:11:53,549:INFO:            hyperopt: 0.2.7
2025-06-02 20:11:53,549:INFO:              optuna: 4.3.0
2025-06-02 20:11:53,549:INFO:               skopt: 0.10.2
2025-06-02 20:11:53,549:INFO:              mlflow: 2.22.0
2025-06-02 20:11:53,550:INFO:              gradio: 5.32.0
2025-06-02 20:11:53,550:INFO:             fastapi: 0.115.12
2025-06-02 20:11:53,550:INFO:             uvicorn: 0.34.3
2025-06-02 20:11:53,550:INFO:              m2cgen: 0.10.0
2025-06-02 20:11:53,550:INFO:           evidently: 0.4.40
2025-06-02 20:11:53,550:INFO:               fugue: 0.8.5
2025-06-02 20:11:53,550:INFO:           streamlit: Not installed
2025-06-02 20:11:53,550:INFO:             prophet: Not installed
2025-06-02 20:11:53,550:INFO:None
2025-06-02 20:11:53,550:INFO:Set up data.
2025-06-02 20:11:53,819:INFO:Set up folding strategy.
2025-06-02 20:11:53,819:INFO:Set up train/test split.
2025-06-02 20:11:53,972:INFO:Set up index.
2025-06-02 20:11:53,993:INFO:Assigning column types.
2025-06-02 20:11:54,069:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 20:11:54,070:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,082:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,091:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,263:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,336:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,337:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:11:54,343:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:11:54,345:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,353:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,361:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,499:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,579:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,580:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:11:54,588:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:11:54,589:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 20:11:54,597:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,605:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,769:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,861:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,862:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:11:54,867:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:11:54,878:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:11:54,890:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:11:55,039:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:11:55,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:11:55,131:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:11:55,138:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:11:55,140:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 20:11:55,159:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:11:55,333:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:11:55,412:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:11:55,413:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:11:55,417:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:11:55,433:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:11:55,574:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:11:55,657:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:11:55,658:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:11:55,663:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:11:55,665:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 20:11:55,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:11:55,948:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:11:55,950:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:11:55,956:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:11:56,117:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:11:56,192:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:11:56,192:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:11:56,196:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:11:56,197:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 20:11:56,356:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:11:56,434:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:11:56,438:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:11:56,589:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:11:56,662:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:11:56,667:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:11:56,668:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 20:11:56,917:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:11:56,922:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:11:57,160:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:11:57,164:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:11:57,170:INFO:Preparing preprocessing pipeline...
2025-06-02 20:11:57,170:INFO:Set up simple imputation.
2025-06-02 20:11:57,170:INFO:Set up removing multicollinearity.
2025-06-02 20:11:57,181:INFO:Set up column name cleaning.
2025-06-02 20:11:57,392:INFO:Finished creating preprocessing pipeline.
2025-06-02 20:11:57,408:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 20:11:57,408:INFO:Creating final display dataframe.
2025-06-02 20:11:57,841:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4200, 147)
4        Transformed data shape        (4200, 94)
5   Transformed train set shape        (3360, 94)
6    Transformed test set shape         (840, 94)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              0aa1
2025-06-02 20:11:58,086:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:11:58,090:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:11:58,318:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:11:58,322:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:11:58,324:INFO:setup() successfully completed in 4.83s...............
2025-06-02 20:11:58,346:INFO:Initializing evaluate_model()
2025-06-02 20:11:58,346:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B715C0F550>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-06-02 20:11:58,418:INFO:Initializing plot_model()
2025-06-02 20:11:58,418:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B715C0F550>, system=True)
2025-06-02 20:11:58,419:INFO:Checking exceptions
2025-06-02 20:11:58,459:INFO:Preloading libraries
2025-06-02 20:11:58,517:INFO:Copying training dataset
2025-06-02 20:11:58,517:INFO:Plot type: pipeline
2025-06-02 20:11:58,803:INFO:Visual Rendered Successfully
2025-06-02 20:12:00,469:INFO:plot_model() successfully completed......................................
2025-06-02 20:18:16,889:INFO:Initializing plot_model()
2025-06-02 20:18:16,889:INFO:plot_model(plot=learning, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B715C0F550>, system=True)
2025-06-02 20:18:16,890:INFO:Checking exceptions
2025-06-02 20:18:16,944:INFO:Preloading libraries
2025-06-02 20:18:16,968:INFO:Copying training dataset
2025-06-02 20:18:16,969:INFO:Plot type: learning
2025-06-02 20:18:17,537:INFO:Fitting Model
2025-06-02 20:18:36,960:INFO:Visual Rendered Successfully
2025-06-02 20:18:42,277:INFO:plot_model() successfully completed......................................
2025-06-02 20:24:18,465:INFO:Initializing plot_model()
2025-06-02 20:24:18,465:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B718939FF0>, system=True)
2025-06-02 20:24:18,466:INFO:Checking exceptions
2025-06-02 20:24:18,701:INFO:Preloading libraries
2025-06-02 20:24:19,170:INFO:Copying training dataset
2025-06-02 20:24:19,170:INFO:Plot type: feature_all
2025-06-02 20:24:19,278:WARNING:No coef_ found. Trying feature_importances_
2025-06-02 20:24:20,774:INFO:Visual Rendered Successfully
2025-06-02 20:24:22,429:INFO:plot_model() successfully completed......................................
2025-06-02 20:26:01,376:INFO:PyCaret RegressionExperiment
2025-06-02 20:26:01,377:INFO:Logging name: reg-default-name
2025-06-02 20:26:01,377:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 20:26:01,378:INFO:version 3.3.2
2025-06-02 20:26:01,378:INFO:Initializing setup()
2025-06-02 20:26:01,378:INFO:self.USI: 05c3
2025-06-02 20:26:01,378:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 20:26:01,378:INFO:Checking environment
2025-06-02 20:26:01,378:INFO:python_version: 3.10.16
2025-06-02 20:26:01,378:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 20:26:01,378:INFO:machine: AMD64
2025-06-02 20:26:01,379:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 20:26:01,387:INFO:Memory: svmem(total=6378008576, available=676347904, percent=89.4, used=5701660672, free=676347904)
2025-06-02 20:26:01,388:INFO:Physical Core: 4
2025-06-02 20:26:01,388:INFO:Logical Core: 8
2025-06-02 20:26:01,388:INFO:Checking libraries
2025-06-02 20:26:01,388:INFO:System:
2025-06-02 20:26:01,388:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 20:26:01,388:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 20:26:01,388:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 20:26:01,389:INFO:PyCaret required dependencies:
2025-06-02 20:26:01,389:INFO:                 pip: 25.1
2025-06-02 20:26:01,389:INFO:          setuptools: 78.1.1
2025-06-02 20:26:01,389:INFO:             pycaret: 3.3.2
2025-06-02 20:26:01,389:INFO:             IPython: 8.37.0
2025-06-02 20:26:01,389:INFO:          ipywidgets: 8.1.7
2025-06-02 20:26:01,389:INFO:                tqdm: 4.67.1
2025-06-02 20:26:01,389:INFO:               numpy: 1.26.4
2025-06-02 20:26:01,389:INFO:              pandas: 2.0.1
2025-06-02 20:26:01,390:INFO:              jinja2: 3.1.6
2025-06-02 20:26:01,390:INFO:               scipy: 1.10.1
2025-06-02 20:26:01,390:INFO:              joblib: 1.3.2
2025-06-02 20:26:01,390:INFO:             sklearn: 1.4.2
2025-06-02 20:26:01,390:INFO:                pyod: 2.0.5
2025-06-02 20:26:01,390:INFO:            imblearn: 0.13.0
2025-06-02 20:26:01,390:INFO:   category_encoders: 2.7.0
2025-06-02 20:26:01,390:INFO:            lightgbm: 4.6.0
2025-06-02 20:26:01,390:INFO:               numba: 0.61.0
2025-06-02 20:26:01,391:INFO:            requests: 2.32.3
2025-06-02 20:26:01,391:INFO:          matplotlib: 3.7.1
2025-06-02 20:26:01,391:INFO:          scikitplot: 0.3.7
2025-06-02 20:26:01,391:INFO:         yellowbrick: 1.5
2025-06-02 20:26:01,391:INFO:              plotly: 6.1.2
2025-06-02 20:26:01,391:INFO:    plotly-resampler: Not installed
2025-06-02 20:26:01,391:INFO:             kaleido: 0.2.1
2025-06-02 20:26:01,391:INFO:           schemdraw: 0.15
2025-06-02 20:26:01,392:INFO:         statsmodels: 0.14.4
2025-06-02 20:26:01,392:INFO:              sktime: 0.26.0
2025-06-02 20:26:01,392:INFO:               tbats: 1.1.3
2025-06-02 20:26:01,392:INFO:            pmdarima: 2.0.4
2025-06-02 20:26:01,392:INFO:              psutil: 7.0.0
2025-06-02 20:26:01,392:INFO:          markupsafe: 2.1.2
2025-06-02 20:26:01,392:INFO:             pickle5: Not installed
2025-06-02 20:26:01,393:INFO:         cloudpickle: 3.1.1
2025-06-02 20:26:01,393:INFO:         deprecation: 2.1.0
2025-06-02 20:26:01,393:INFO:              xxhash: 3.5.0
2025-06-02 20:26:01,393:INFO:           wurlitzer: Not installed
2025-06-02 20:26:01,393:INFO:PyCaret optional dependencies:
2025-06-02 20:26:01,393:INFO:                shap: 0.44.1
2025-06-02 20:26:01,393:INFO:           interpret: 0.6.9
2025-06-02 20:26:01,393:INFO:                umap: 0.5.7
2025-06-02 20:26:01,393:INFO:     ydata_profiling: 4.16.1
2025-06-02 20:26:01,393:INFO:  explainerdashboard: 0.4.8
2025-06-02 20:26:01,394:INFO:             autoviz: Not installed
2025-06-02 20:26:01,394:INFO:           fairlearn: 0.7.0
2025-06-02 20:26:01,394:INFO:          deepchecks: Not installed
2025-06-02 20:26:01,394:INFO:             xgboost: 3.0.2
2025-06-02 20:26:01,394:INFO:            catboost: 1.2.8
2025-06-02 20:26:01,394:INFO:              kmodes: 0.12.2
2025-06-02 20:26:01,394:INFO:             mlxtend: 0.23.4
2025-06-02 20:26:01,394:INFO:       statsforecast: 1.5.0
2025-06-02 20:26:01,394:INFO:        tune_sklearn: Not installed
2025-06-02 20:26:01,394:INFO:                 ray: Not installed
2025-06-02 20:26:01,394:INFO:            hyperopt: 0.2.7
2025-06-02 20:26:01,394:INFO:              optuna: 4.3.0
2025-06-02 20:26:01,394:INFO:               skopt: 0.10.2
2025-06-02 20:26:01,395:INFO:              mlflow: 2.22.0
2025-06-02 20:26:01,395:INFO:              gradio: 5.32.0
2025-06-02 20:26:01,395:INFO:             fastapi: 0.115.12
2025-06-02 20:26:01,395:INFO:             uvicorn: 0.34.3
2025-06-02 20:26:01,395:INFO:              m2cgen: 0.10.0
2025-06-02 20:26:01,395:INFO:           evidently: 0.4.40
2025-06-02 20:26:01,395:INFO:               fugue: 0.8.5
2025-06-02 20:26:01,395:INFO:           streamlit: Not installed
2025-06-02 20:26:01,395:INFO:             prophet: Not installed
2025-06-02 20:26:01,396:INFO:None
2025-06-02 20:26:01,396:INFO:Set up data.
2025-06-02 20:26:01,515:INFO:Set up folding strategy.
2025-06-02 20:26:01,515:INFO:Set up train/test split.
2025-06-02 20:26:01,599:INFO:Set up index.
2025-06-02 20:26:01,602:INFO:Assigning column types.
2025-06-02 20:26:01,676:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 20:26:01,677:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 20:26:01,687:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:26:01,694:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:26:01,845:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:26:01,932:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:26:01,934:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:26:01,938:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:26:01,939:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 20:26:01,947:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:26:01,954:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:26:02,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:26:02,207:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:26:02,208:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:26:02,212:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:26:02,213:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 20:26:02,220:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:26:02,228:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:26:02,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:26:02,465:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:26:02,466:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:26:02,470:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:26:02,479:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:26:02,486:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:26:02,638:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:26:02,725:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:26:02,726:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:26:02,730:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:26:02,732:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 20:26:02,747:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:26:02,895:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:26:02,971:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:26:02,972:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:26:02,976:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:26:02,992:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:26:03,134:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:26:03,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:26:03,227:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:26:03,231:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:26:03,232:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 20:26:03,385:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:26:03,472:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:26:03,472:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:26:03,477:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:26:03,644:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:26:03,732:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:26:03,733:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:26:03,738:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:26:03,740:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 20:26:03,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:26:04,017:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:26:04,025:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:26:04,209:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:26:04,302:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:26:04,307:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:26:04,308:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 20:26:04,566:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:26:04,573:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:26:04,820:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:26:04,825:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:26:04,830:INFO:Preparing preprocessing pipeline...
2025-06-02 20:26:04,830:INFO:Set up simple imputation.
2025-06-02 20:26:04,830:INFO:Set up removing multicollinearity.
2025-06-02 20:26:04,843:INFO:Set up column name cleaning.
2025-06-02 20:26:05,035:INFO:Finished creating preprocessing pipeline.
2025-06-02 20:26:05,047:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 20:26:05,047:INFO:Creating final display dataframe.
2025-06-02 20:26:05,507:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4200, 147)
4        Transformed data shape        (4200, 94)
5   Transformed train set shape        (3360, 94)
6    Transformed test set shape         (840, 94)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              05c3
2025-06-02 20:26:05,756:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:26:05,764:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:26:06,026:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:26:06,030:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:26:06,032:INFO:setup() successfully completed in 4.72s...............
2025-06-02 20:26:06,062:INFO:Initializing evaluate_model()
2025-06-02 20:26:06,062:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7140D1DB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-06-02 20:26:06,121:INFO:Initializing plot_model()
2025-06-02 20:26:06,121:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7140D1DB0>, system=True)
2025-06-02 20:26:06,121:INFO:Checking exceptions
2025-06-02 20:26:06,223:INFO:Preloading libraries
2025-06-02 20:26:06,360:INFO:Copying training dataset
2025-06-02 20:26:06,360:INFO:Plot type: pipeline
2025-06-02 20:26:06,621:INFO:Visual Rendered Successfully
2025-06-02 20:26:08,376:INFO:plot_model() successfully completed......................................
2025-06-02 20:26:23,141:INFO:Initializing plot_model()
2025-06-02 20:26:23,142:INFO:plot_model(plot=vc, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7140D1DB0>, system=True)
2025-06-02 20:26:23,142:INFO:Checking exceptions
2025-06-02 20:26:23,229:INFO:Preloading libraries
2025-06-02 20:26:23,299:INFO:Copying training dataset
2025-06-02 20:26:23,299:INFO:Plot type: vc
2025-06-02 20:26:23,300:INFO:Determining param_name
2025-06-02 20:26:23,300:INFO:param_name: max_depth
2025-06-02 20:26:23,724:INFO:Fitting Model
2025-06-02 20:26:53,116:INFO:Visual Rendered Successfully
2025-06-02 20:26:59,845:INFO:plot_model() successfully completed......................................
2025-06-02 20:28:48,303:INFO:PyCaret RegressionExperiment
2025-06-02 20:28:48,303:INFO:Logging name: reg-default-name
2025-06-02 20:28:48,304:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-02 20:28:48,304:INFO:version 3.3.2
2025-06-02 20:28:48,304:INFO:Initializing setup()
2025-06-02 20:28:48,304:INFO:self.USI: 3b78
2025-06-02 20:28:48,304:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'X_test', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'fold_generator', 'y_train', 'transform_target_param', 'idx', '_ml_usecase', 'y', 'target_param', 'USI', 'n_jobs_param', 'y_test', 'X_train', 'X', 'exp_name_log', 'log_plots_param', 'memory', 'exp_id', 'gpu_param', 'pipeline', 'html_param', 'logging_param'}
2025-06-02 20:28:48,304:INFO:Checking environment
2025-06-02 20:28:48,305:INFO:python_version: 3.10.16
2025-06-02 20:28:48,305:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-02 20:28:48,305:INFO:machine: AMD64
2025-06-02 20:28:48,305:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-02 20:28:48,312:INFO:Memory: svmem(total=6378008576, available=1092104192, percent=82.9, used=5285904384, free=1092104192)
2025-06-02 20:28:48,312:INFO:Physical Core: 4
2025-06-02 20:28:48,312:INFO:Logical Core: 8
2025-06-02 20:28:48,312:INFO:Checking libraries
2025-06-02 20:28:48,312:INFO:System:
2025-06-02 20:28:48,312:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-02 20:28:48,313:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-02 20:28:48,313:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-02 20:28:48,313:INFO:PyCaret required dependencies:
2025-06-02 20:28:48,313:INFO:                 pip: 25.1
2025-06-02 20:28:48,313:INFO:          setuptools: 78.1.1
2025-06-02 20:28:48,313:INFO:             pycaret: 3.3.2
2025-06-02 20:28:48,313:INFO:             IPython: 8.37.0
2025-06-02 20:28:48,313:INFO:          ipywidgets: 8.1.7
2025-06-02 20:28:48,313:INFO:                tqdm: 4.67.1
2025-06-02 20:28:48,313:INFO:               numpy: 1.26.4
2025-06-02 20:28:48,313:INFO:              pandas: 2.0.1
2025-06-02 20:28:48,314:INFO:              jinja2: 3.1.6
2025-06-02 20:28:48,314:INFO:               scipy: 1.10.1
2025-06-02 20:28:48,314:INFO:              joblib: 1.3.2
2025-06-02 20:28:48,314:INFO:             sklearn: 1.4.2
2025-06-02 20:28:48,314:INFO:                pyod: 2.0.5
2025-06-02 20:28:48,314:INFO:            imblearn: 0.13.0
2025-06-02 20:28:48,314:INFO:   category_encoders: 2.7.0
2025-06-02 20:28:48,314:INFO:            lightgbm: 4.6.0
2025-06-02 20:28:48,314:INFO:               numba: 0.61.0
2025-06-02 20:28:48,314:INFO:            requests: 2.32.3
2025-06-02 20:28:48,315:INFO:          matplotlib: 3.7.1
2025-06-02 20:28:48,315:INFO:          scikitplot: 0.3.7
2025-06-02 20:28:48,315:INFO:         yellowbrick: 1.5
2025-06-02 20:28:48,315:INFO:              plotly: 6.1.2
2025-06-02 20:28:48,315:INFO:    plotly-resampler: Not installed
2025-06-02 20:28:48,315:INFO:             kaleido: 0.2.1
2025-06-02 20:28:48,315:INFO:           schemdraw: 0.15
2025-06-02 20:28:48,315:INFO:         statsmodels: 0.14.4
2025-06-02 20:28:48,315:INFO:              sktime: 0.26.0
2025-06-02 20:28:48,316:INFO:               tbats: 1.1.3
2025-06-02 20:28:48,316:INFO:            pmdarima: 2.0.4
2025-06-02 20:28:48,316:INFO:              psutil: 7.0.0
2025-06-02 20:28:48,316:INFO:          markupsafe: 2.1.2
2025-06-02 20:28:48,316:INFO:             pickle5: Not installed
2025-06-02 20:28:48,316:INFO:         cloudpickle: 3.1.1
2025-06-02 20:28:48,316:INFO:         deprecation: 2.1.0
2025-06-02 20:28:48,316:INFO:              xxhash: 3.5.0
2025-06-02 20:28:48,316:INFO:           wurlitzer: Not installed
2025-06-02 20:28:48,316:INFO:PyCaret optional dependencies:
2025-06-02 20:28:48,316:INFO:                shap: 0.44.1
2025-06-02 20:28:48,317:INFO:           interpret: 0.6.9
2025-06-02 20:28:48,317:INFO:                umap: 0.5.7
2025-06-02 20:28:48,317:INFO:     ydata_profiling: 4.16.1
2025-06-02 20:28:48,317:INFO:  explainerdashboard: 0.4.8
2025-06-02 20:28:48,317:INFO:             autoviz: Not installed
2025-06-02 20:28:48,317:INFO:           fairlearn: 0.7.0
2025-06-02 20:28:48,317:INFO:          deepchecks: Not installed
2025-06-02 20:28:48,317:INFO:             xgboost: 3.0.2
2025-06-02 20:28:48,317:INFO:            catboost: 1.2.8
2025-06-02 20:28:48,317:INFO:              kmodes: 0.12.2
2025-06-02 20:28:48,317:INFO:             mlxtend: 0.23.4
2025-06-02 20:28:48,317:INFO:       statsforecast: 1.5.0
2025-06-02 20:28:48,318:INFO:        tune_sklearn: Not installed
2025-06-02 20:28:48,318:INFO:                 ray: Not installed
2025-06-02 20:28:48,318:INFO:            hyperopt: 0.2.7
2025-06-02 20:28:48,318:INFO:              optuna: 4.3.0
2025-06-02 20:28:48,318:INFO:               skopt: 0.10.2
2025-06-02 20:28:48,318:INFO:              mlflow: 2.22.0
2025-06-02 20:28:48,318:INFO:              gradio: 5.32.0
2025-06-02 20:28:48,318:INFO:             fastapi: 0.115.12
2025-06-02 20:28:48,318:INFO:             uvicorn: 0.34.3
2025-06-02 20:28:48,318:INFO:              m2cgen: 0.10.0
2025-06-02 20:28:48,318:INFO:           evidently: 0.4.40
2025-06-02 20:28:48,318:INFO:               fugue: 0.8.5
2025-06-02 20:28:48,318:INFO:           streamlit: Not installed
2025-06-02 20:28:48,319:INFO:             prophet: Not installed
2025-06-02 20:28:48,319:INFO:None
2025-06-02 20:28:48,319:INFO:Set up data.
2025-06-02 20:28:48,492:INFO:Set up folding strategy.
2025-06-02 20:28:48,492:INFO:Set up train/test split.
2025-06-02 20:28:48,584:INFO:Set up index.
2025-06-02 20:28:48,593:INFO:Assigning column types.
2025-06-02 20:28:48,676:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 20:28:48,677:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 20:28:48,688:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:28:48,699:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:28:48,900:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:28:49,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:28:49,011:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:28:49,018:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:28:49,021:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-02 20:28:49,033:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:28:49,045:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:28:49,239:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:28:49,350:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:28:49,351:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:28:49,356:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:28:49,357:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-02 20:28:49,370:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:28:49,380:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:28:49,572:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:28:49,727:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:28:49,729:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:28:49,740:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:28:49,758:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-02 20:28:49,772:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:28:50,042:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:28:50,163:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:28:50,165:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:28:50,171:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:28:50,172:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-02 20:28:50,192:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:28:50,394:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:28:50,503:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:28:50,504:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:28:50,510:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:28:50,532:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-02 20:28:50,718:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:28:50,801:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:28:50,803:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:28:50,810:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:28:50,811:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-02 20:28:50,991:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:28:51,088:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:28:51,089:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:28:51,094:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:28:51,288:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:28:51,382:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:28:51,384:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:28:51,388:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:28:51,389:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 20:28:51,566:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:28:51,648:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:28:51,654:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:28:51,829:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-02 20:28:51,915:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:28:51,922:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:28:51,923:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-02 20:28:52,201:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:28:52,206:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:28:52,455:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:28:52,459:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:28:52,462:INFO:Preparing preprocessing pipeline...
2025-06-02 20:28:52,462:INFO:Set up simple imputation.
2025-06-02 20:28:52,462:INFO:Set up removing multicollinearity.
2025-06-02 20:28:52,469:INFO:Set up column name cleaning.
2025-06-02 20:28:52,665:INFO:Finished creating preprocessing pipeline.
2025-06-02 20:28:52,679:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-02 20:28:52,679:INFO:Creating final display dataframe.
2025-06-02 20:28:53,140:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4200, 147)
4        Transformed data shape        (4200, 94)
5   Transformed train set shape        (3360, 94)
6    Transformed test set shape         (840, 94)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              3b78
2025-06-02 20:28:53,401:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:28:53,406:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:28:53,677:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-02 20:28:53,682:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-02 20:28:53,685:INFO:setup() successfully completed in 5.42s...............
2025-06-02 20:28:53,705:INFO:Initializing evaluate_model()
2025-06-02 20:28:53,705:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7193ECA30>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-06-02 20:28:53,778:INFO:Initializing plot_model()
2025-06-02 20:28:53,779:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B7193ECA30>, system=True)
2025-06-02 20:28:53,780:INFO:Checking exceptions
2025-06-02 20:28:53,836:INFO:Preloading libraries
2025-06-02 20:28:53,896:INFO:Copying training dataset
2025-06-02 20:28:53,896:INFO:Plot type: pipeline
2025-06-02 20:28:54,452:INFO:Visual Rendered Successfully
2025-06-02 20:28:57,064:INFO:plot_model() successfully completed......................................
2025-06-14 14:24:03,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 14:24:03,470:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 14:24:03,470:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 14:24:03,470:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-21 14:42:05,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-21 14:42:05,624:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-21 14:42:05,624:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-21 14:42:05,624:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-21 14:42:25,712:WARNING:MagpieData(impute_nan=False):
In a future release, impute_nan will be set to True by default.
                    This means that features that are missing or are NaNs for elements
                    from the data source will be replaced by the average of that value
                    over the available elements.
                    This avoids NaNs after featurization that are often replaced by
                    dataset-dependent averages.

2025-06-21 14:50:25,945:INFO:PyCaret RegressionExperiment
2025-06-21 14:50:25,946:INFO:Logging name: reg-default-name
2025-06-21 14:50:25,946:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-21 14:50:25,946:INFO:version 3.3.2
2025-06-21 14:50:25,946:INFO:Initializing setup()
2025-06-21 14:50:25,947:INFO:self.USI: ffc7
2025-06-21 14:50:25,947:INFO:self._variable_keys: {'exp_id', 'gpu_param', 'y', 'y_test', 'X_train', 'USI', 'logging_param', 'fold_generator', 'gpu_n_jobs_param', 'fold_groups_param', 'html_param', 'target_param', 'seed', 'idx', '_ml_usecase', 'n_jobs_param', 'data', 'transform_target_param', 'exp_name_log', 'X', 'X_test', 'log_plots_param', 'y_train', 'memory', 'fold_shuffle_param', '_available_plots', 'pipeline'}
2025-06-21 14:50:25,947:INFO:Checking environment
2025-06-21 14:50:25,957:INFO:python_version: 3.10.16
2025-06-21 14:50:25,959:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-21 14:50:25,959:INFO:machine: AMD64
2025-06-21 14:50:25,959:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-21 14:50:25,968:INFO:Memory: svmem(total=6378008576, available=1324142592, percent=79.2, used=5053865984, free=1324142592)
2025-06-21 14:50:25,969:INFO:Physical Core: 4
2025-06-21 14:50:25,969:INFO:Logical Core: 8
2025-06-21 14:50:25,969:INFO:Checking libraries
2025-06-21 14:50:25,970:INFO:System:
2025-06-21 14:50:25,970:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-21 14:50:25,970:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-21 14:50:25,970:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-21 14:50:25,970:INFO:PyCaret required dependencies:
2025-06-21 14:50:28,266:INFO:                 pip: 25.1
2025-06-21 14:50:28,266:INFO:          setuptools: 78.1.1
2025-06-21 14:50:28,266:INFO:             pycaret: 3.3.2
2025-06-21 14:50:28,266:INFO:             IPython: 8.37.0
2025-06-21 14:50:28,267:INFO:          ipywidgets: 8.1.7
2025-06-21 14:50:28,267:INFO:                tqdm: 4.67.1
2025-06-21 14:50:28,267:INFO:               numpy: 1.26.4
2025-06-21 14:50:28,267:INFO:              pandas: 2.0.1
2025-06-21 14:50:28,267:INFO:              jinja2: 3.1.6
2025-06-21 14:50:28,267:INFO:               scipy: 1.10.1
2025-06-21 14:50:28,267:INFO:              joblib: 1.3.2
2025-06-21 14:50:28,267:INFO:             sklearn: 1.4.2
2025-06-21 14:50:28,267:INFO:                pyod: 2.0.5
2025-06-21 14:50:28,268:INFO:            imblearn: 0.13.0
2025-06-21 14:50:28,269:INFO:   category_encoders: 2.7.0
2025-06-21 14:50:28,269:INFO:            lightgbm: 4.6.0
2025-06-21 14:50:28,269:INFO:               numba: 0.61.0
2025-06-21 14:50:28,269:INFO:            requests: 2.32.3
2025-06-21 14:50:28,269:INFO:          matplotlib: 3.7.1
2025-06-21 14:50:28,269:INFO:          scikitplot: 0.3.7
2025-06-21 14:50:28,270:INFO:         yellowbrick: 1.5
2025-06-21 14:50:28,270:INFO:              plotly: 6.1.2
2025-06-21 14:50:28,270:INFO:    plotly-resampler: Not installed
2025-06-21 14:50:28,270:INFO:             kaleido: 0.2.1
2025-06-21 14:50:28,270:INFO:           schemdraw: 0.15
2025-06-21 14:50:28,270:INFO:         statsmodels: 0.14.4
2025-06-21 14:50:28,271:INFO:              sktime: 0.26.0
2025-06-21 14:50:28,271:INFO:               tbats: 1.1.3
2025-06-21 14:50:28,271:INFO:            pmdarima: 2.0.4
2025-06-21 14:50:28,271:INFO:              psutil: 7.0.0
2025-06-21 14:50:28,271:INFO:          markupsafe: 2.1.2
2025-06-21 14:50:28,272:INFO:             pickle5: Not installed
2025-06-21 14:50:28,272:INFO:         cloudpickle: 3.1.1
2025-06-21 14:50:28,272:INFO:         deprecation: 2.1.0
2025-06-21 14:50:28,272:INFO:              xxhash: 3.5.0
2025-06-21 14:50:28,272:INFO:           wurlitzer: Not installed
2025-06-21 14:50:28,272:INFO:PyCaret optional dependencies:
2025-06-21 14:50:34,769:INFO:                shap: 0.44.1
2025-06-21 14:50:34,769:INFO:           interpret: 0.6.9
2025-06-21 14:50:34,769:INFO:                umap: 0.5.7
2025-06-21 14:50:34,770:INFO:     ydata_profiling: 4.16.1
2025-06-21 14:50:34,770:INFO:  explainerdashboard: 0.4.8
2025-06-21 14:50:34,770:INFO:             autoviz: Not installed
2025-06-21 14:50:34,770:INFO:           fairlearn: 0.7.0
2025-06-21 14:50:34,770:INFO:          deepchecks: Not installed
2025-06-21 14:50:34,770:INFO:             xgboost: 3.0.2
2025-06-21 14:50:34,770:INFO:            catboost: 1.2.8
2025-06-21 14:50:34,770:INFO:              kmodes: 0.12.2
2025-06-21 14:50:34,770:INFO:             mlxtend: 0.23.4
2025-06-21 14:50:34,771:INFO:       statsforecast: 1.5.0
2025-06-21 14:50:34,771:INFO:        tune_sklearn: Not installed
2025-06-21 14:50:34,771:INFO:                 ray: Not installed
2025-06-21 14:50:34,771:INFO:            hyperopt: 0.2.7
2025-06-21 14:50:34,771:INFO:              optuna: 4.3.0
2025-06-21 14:50:34,771:INFO:               skopt: 0.10.2
2025-06-21 14:50:34,771:INFO:              mlflow: 2.22.0
2025-06-21 14:50:34,771:INFO:              gradio: 5.32.0
2025-06-21 14:50:34,771:INFO:             fastapi: 0.115.12
2025-06-21 14:50:34,771:INFO:             uvicorn: 0.34.3
2025-06-21 14:50:34,772:INFO:              m2cgen: 0.10.0
2025-06-21 14:50:34,772:INFO:           evidently: 0.4.40
2025-06-21 14:50:34,772:INFO:               fugue: 0.8.5
2025-06-21 14:50:34,772:INFO:           streamlit: Not installed
2025-06-21 14:50:34,772:INFO:             prophet: Not installed
2025-06-21 14:50:34,772:INFO:None
2025-06-21 14:50:34,772:INFO:Set up data.
2025-06-21 14:50:34,849:INFO:Set up folding strategy.
2025-06-21 14:50:34,850:INFO:Set up train/test split.
2025-06-21 14:50:34,899:INFO:Set up index.
2025-06-21 14:50:34,901:INFO:Assigning column types.
2025-06-21 14:50:34,953:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-21 14:50:34,954:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-21 14:50:34,965:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 14:50:34,972:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,103:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,182:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,183:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:50:35,188:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:50:35,329:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,336:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,343:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,468:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,538:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,539:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:50:35,543:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:50:35,544:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-21 14:50:35,550:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,560:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,695:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,769:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,769:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:50:35,774:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:50:35,782:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,790:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,921:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,996:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:50:35,996:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:50:36,000:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:50:36,001:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-21 14:50:36,015:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 14:50:36,151:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:50:36,222:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:50:36,223:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:50:36,227:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:50:36,242:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 14:50:36,368:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:50:36,443:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:50:36,443:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:50:36,447:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:50:36,448:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-21 14:50:36,590:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:50:36,665:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:50:36,666:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:50:36,670:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:50:36,814:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:50:36,891:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:50:36,892:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:50:36,898:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:50:36,899:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-21 14:50:37,075:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:50:37,155:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:50:37,160:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:50:37,314:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:50:37,389:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:50:37,393:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:50:37,394:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-21 14:50:37,623:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:50:37,627:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:50:37,846:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:50:37,850:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:50:37,855:INFO:Preparing preprocessing pipeline...
2025-06-21 14:50:37,856:INFO:Set up simple imputation.
2025-06-21 14:50:37,856:INFO:Set up removing multicollinearity.
2025-06-21 14:50:37,866:INFO:Set up column name cleaning.
2025-06-21 14:50:38,396:INFO:Finished creating preprocessing pipeline.
2025-06-21 14:50:38,408:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-21 14:50:38,409:INFO:Creating final display dataframe.
2025-06-21 14:50:39,562:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4200, 147)
4        Transformed data shape        (4200, 95)
5   Transformed train set shape        (3360, 95)
6    Transformed test set shape         (840, 95)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              ffc7
2025-06-21 14:50:39,800:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:50:39,807:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:50:40,061:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:50:40,065:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:50:40,066:INFO:setup() successfully completed in 14.24s...............
2025-06-21 14:50:40,066:INFO:Initializing compare_models()
2025-06-21 14:50:40,066:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-21 14:50:40,067:INFO:Checking exceptions
2025-06-21 14:50:40,092:INFO:Preparing display monitor
2025-06-21 14:50:40,158:INFO:Initializing Linear Regression
2025-06-21 14:50:40,158:INFO:Total runtime is 0.0 minutes
2025-06-21 14:50:40,175:INFO:SubProcess create_model() called ==================================
2025-06-21 14:50:40,176:INFO:Initializing create_model()
2025-06-21 14:50:40,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:50:40,177:INFO:Checking exceptions
2025-06-21 14:50:40,177:INFO:Importing libraries
2025-06-21 14:50:40,177:INFO:Copying training dataset
2025-06-21 14:50:40,283:INFO:Defining folds
2025-06-21 14:50:40,283:INFO:Declaring metric variables
2025-06-21 14:50:40,310:INFO:Importing untrained model
2025-06-21 14:50:40,327:INFO:Linear Regression Imported successfully
2025-06-21 14:50:40,359:INFO:Starting cross validation
2025-06-21 14:50:40,382:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:50:55,230:INFO:Calculating mean and std
2025-06-21 14:50:55,259:INFO:Creating metrics dataframe
2025-06-21 14:50:55,277:INFO:Uploading results into container
2025-06-21 14:50:55,301:INFO:Uploading model into container now
2025-06-21 14:50:55,307:INFO:_master_model_container: 1
2025-06-21 14:50:55,308:INFO:_display_container: 2
2025-06-21 14:50:55,309:INFO:LinearRegression(n_jobs=-1)
2025-06-21 14:50:55,310:INFO:create_model() successfully completed......................................
2025-06-21 14:50:56,595:INFO:SubProcess create_model() end ==================================
2025-06-21 14:50:56,595:INFO:Creating metrics dataframe
2025-06-21 14:50:56,607:INFO:Initializing Lasso Regression
2025-06-21 14:50:56,607:INFO:Total runtime is 0.27415344715118406 minutes
2025-06-21 14:50:56,616:INFO:SubProcess create_model() called ==================================
2025-06-21 14:50:56,617:INFO:Initializing create_model()
2025-06-21 14:50:56,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:50:56,618:INFO:Checking exceptions
2025-06-21 14:50:56,619:INFO:Importing libraries
2025-06-21 14:50:56,619:INFO:Copying training dataset
2025-06-21 14:50:56,744:INFO:Defining folds
2025-06-21 14:50:56,744:INFO:Declaring metric variables
2025-06-21 14:50:56,756:INFO:Importing untrained model
2025-06-21 14:50:56,769:INFO:Lasso Regression Imported successfully
2025-06-21 14:50:56,799:INFO:Starting cross validation
2025-06-21 14:50:56,803:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:08,765:INFO:Calculating mean and std
2025-06-21 14:51:08,772:INFO:Creating metrics dataframe
2025-06-21 14:51:08,779:INFO:Uploading results into container
2025-06-21 14:51:08,781:INFO:Uploading model into container now
2025-06-21 14:51:08,782:INFO:_master_model_container: 2
2025-06-21 14:51:08,783:INFO:_display_container: 2
2025-06-21 14:51:08,783:INFO:Lasso(random_state=123)
2025-06-21 14:51:08,784:INFO:create_model() successfully completed......................................
2025-06-21 14:51:09,374:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:09,374:INFO:Creating metrics dataframe
2025-06-21 14:51:09,390:INFO:Initializing Ridge Regression
2025-06-21 14:51:09,391:INFO:Total runtime is 0.48721905549367267 minutes
2025-06-21 14:51:09,401:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:09,401:INFO:Initializing create_model()
2025-06-21 14:51:09,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:09,402:INFO:Checking exceptions
2025-06-21 14:51:09,402:INFO:Importing libraries
2025-06-21 14:51:09,403:INFO:Copying training dataset
2025-06-21 14:51:09,495:INFO:Defining folds
2025-06-21 14:51:09,498:INFO:Declaring metric variables
2025-06-21 14:51:09,516:INFO:Importing untrained model
2025-06-21 14:51:09,533:INFO:Ridge Regression Imported successfully
2025-06-21 14:51:09,555:INFO:Starting cross validation
2025-06-21 14:51:09,559:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:10,605:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.80305e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-21 14:51:10,850:INFO:Calculating mean and std
2025-06-21 14:51:10,855:INFO:Creating metrics dataframe
2025-06-21 14:51:10,867:INFO:Uploading results into container
2025-06-21 14:51:10,868:INFO:Uploading model into container now
2025-06-21 14:51:10,870:INFO:_master_model_container: 3
2025-06-21 14:51:10,871:INFO:_display_container: 2
2025-06-21 14:51:10,872:INFO:Ridge(random_state=123)
2025-06-21 14:51:10,872:INFO:create_model() successfully completed......................................
2025-06-21 14:51:11,555:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:11,556:INFO:Creating metrics dataframe
2025-06-21 14:51:11,573:INFO:Initializing Elastic Net
2025-06-21 14:51:11,573:INFO:Total runtime is 0.5235859751701355 minutes
2025-06-21 14:51:11,583:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:11,584:INFO:Initializing create_model()
2025-06-21 14:51:11,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:11,585:INFO:Checking exceptions
2025-06-21 14:51:11,585:INFO:Importing libraries
2025-06-21 14:51:11,586:INFO:Copying training dataset
2025-06-21 14:51:11,667:INFO:Defining folds
2025-06-21 14:51:11,668:INFO:Declaring metric variables
2025-06-21 14:51:11,682:INFO:Importing untrained model
2025-06-21 14:51:11,694:INFO:Elastic Net Imported successfully
2025-06-21 14:51:11,718:INFO:Starting cross validation
2025-06-21 14:51:11,722:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:12,585:INFO:Calculating mean and std
2025-06-21 14:51:12,588:INFO:Creating metrics dataframe
2025-06-21 14:51:12,592:INFO:Uploading results into container
2025-06-21 14:51:12,594:INFO:Uploading model into container now
2025-06-21 14:51:12,595:INFO:_master_model_container: 4
2025-06-21 14:51:12,595:INFO:_display_container: 2
2025-06-21 14:51:12,596:INFO:ElasticNet(random_state=123)
2025-06-21 14:51:12,596:INFO:create_model() successfully completed......................................
2025-06-21 14:51:13,082:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:13,083:INFO:Creating metrics dataframe
2025-06-21 14:51:13,097:INFO:Initializing Least Angle Regression
2025-06-21 14:51:13,097:INFO:Total runtime is 0.5489711801211039 minutes
2025-06-21 14:51:13,105:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:13,107:INFO:Initializing create_model()
2025-06-21 14:51:13,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:13,108:INFO:Checking exceptions
2025-06-21 14:51:13,108:INFO:Importing libraries
2025-06-21 14:51:13,108:INFO:Copying training dataset
2025-06-21 14:51:13,176:INFO:Defining folds
2025-06-21 14:51:13,177:INFO:Declaring metric variables
2025-06-21 14:51:13,188:INFO:Importing untrained model
2025-06-21 14:51:13,200:INFO:Least Angle Regression Imported successfully
2025-06-21 14:51:13,227:INFO:Starting cross validation
2025-06-21 14:51:13,232:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:14,045:INFO:Calculating mean and std
2025-06-21 14:51:14,047:INFO:Creating metrics dataframe
2025-06-21 14:51:14,050:INFO:Uploading results into container
2025-06-21 14:51:14,051:INFO:Uploading model into container now
2025-06-21 14:51:14,052:INFO:_master_model_container: 5
2025-06-21 14:51:14,052:INFO:_display_container: 2
2025-06-21 14:51:14,054:INFO:Lars(random_state=123)
2025-06-21 14:51:14,054:INFO:create_model() successfully completed......................................
2025-06-21 14:51:14,542:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:14,542:INFO:Creating metrics dataframe
2025-06-21 14:51:14,557:INFO:Initializing Lasso Least Angle Regression
2025-06-21 14:51:14,558:INFO:Total runtime is 0.5733236908912659 minutes
2025-06-21 14:51:14,566:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:14,567:INFO:Initializing create_model()
2025-06-21 14:51:14,567:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:14,567:INFO:Checking exceptions
2025-06-21 14:51:14,567:INFO:Importing libraries
2025-06-21 14:51:14,567:INFO:Copying training dataset
2025-06-21 14:51:14,637:INFO:Defining folds
2025-06-21 14:51:14,638:INFO:Declaring metric variables
2025-06-21 14:51:14,651:INFO:Importing untrained model
2025-06-21 14:51:14,662:INFO:Lasso Least Angle Regression Imported successfully
2025-06-21 14:51:14,683:INFO:Starting cross validation
2025-06-21 14:51:14,687:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:15,440:INFO:Calculating mean and std
2025-06-21 14:51:15,442:INFO:Creating metrics dataframe
2025-06-21 14:51:15,446:INFO:Uploading results into container
2025-06-21 14:51:15,447:INFO:Uploading model into container now
2025-06-21 14:51:15,448:INFO:_master_model_container: 6
2025-06-21 14:51:15,448:INFO:_display_container: 2
2025-06-21 14:51:15,449:INFO:LassoLars(random_state=123)
2025-06-21 14:51:15,449:INFO:create_model() successfully completed......................................
2025-06-21 14:51:15,928:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:15,928:INFO:Creating metrics dataframe
2025-06-21 14:51:15,948:INFO:Initializing Orthogonal Matching Pursuit
2025-06-21 14:51:15,949:INFO:Total runtime is 0.5965195059776306 minutes
2025-06-21 14:51:15,963:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:15,964:INFO:Initializing create_model()
2025-06-21 14:51:15,965:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:15,965:INFO:Checking exceptions
2025-06-21 14:51:15,965:INFO:Importing libraries
2025-06-21 14:51:15,966:INFO:Copying training dataset
2025-06-21 14:51:16,024:INFO:Defining folds
2025-06-21 14:51:16,024:INFO:Declaring metric variables
2025-06-21 14:51:16,035:INFO:Importing untrained model
2025-06-21 14:51:16,047:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-21 14:51:16,073:INFO:Starting cross validation
2025-06-21 14:51:16,077:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:16,935:INFO:Calculating mean and std
2025-06-21 14:51:16,937:INFO:Creating metrics dataframe
2025-06-21 14:51:16,942:INFO:Uploading results into container
2025-06-21 14:51:16,943:INFO:Uploading model into container now
2025-06-21 14:51:16,944:INFO:_master_model_container: 7
2025-06-21 14:51:16,944:INFO:_display_container: 2
2025-06-21 14:51:16,945:INFO:OrthogonalMatchingPursuit()
2025-06-21 14:51:16,945:INFO:create_model() successfully completed......................................
2025-06-21 14:51:17,567:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:17,568:INFO:Creating metrics dataframe
2025-06-21 14:51:17,588:INFO:Initializing Bayesian Ridge
2025-06-21 14:51:17,588:INFO:Total runtime is 0.6238215088844299 minutes
2025-06-21 14:51:17,603:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:17,604:INFO:Initializing create_model()
2025-06-21 14:51:17,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:17,605:INFO:Checking exceptions
2025-06-21 14:51:17,605:INFO:Importing libraries
2025-06-21 14:51:17,606:INFO:Copying training dataset
2025-06-21 14:51:17,681:INFO:Defining folds
2025-06-21 14:51:17,681:INFO:Declaring metric variables
2025-06-21 14:51:17,693:INFO:Importing untrained model
2025-06-21 14:51:17,704:INFO:Bayesian Ridge Imported successfully
2025-06-21 14:51:17,726:INFO:Starting cross validation
2025-06-21 14:51:17,730:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:18,594:INFO:Calculating mean and std
2025-06-21 14:51:18,596:INFO:Creating metrics dataframe
2025-06-21 14:51:18,599:INFO:Uploading results into container
2025-06-21 14:51:18,600:INFO:Uploading model into container now
2025-06-21 14:51:18,601:INFO:_master_model_container: 8
2025-06-21 14:51:18,601:INFO:_display_container: 2
2025-06-21 14:51:18,602:INFO:BayesianRidge()
2025-06-21 14:51:18,602:INFO:create_model() successfully completed......................................
2025-06-21 14:51:19,107:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:19,107:INFO:Creating metrics dataframe
2025-06-21 14:51:19,123:INFO:Initializing Passive Aggressive Regressor
2025-06-21 14:51:19,123:INFO:Total runtime is 0.6494199196497599 minutes
2025-06-21 14:51:19,132:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:19,133:INFO:Initializing create_model()
2025-06-21 14:51:19,134:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:19,134:INFO:Checking exceptions
2025-06-21 14:51:19,134:INFO:Importing libraries
2025-06-21 14:51:19,135:INFO:Copying training dataset
2025-06-21 14:51:19,202:INFO:Defining folds
2025-06-21 14:51:19,203:INFO:Declaring metric variables
2025-06-21 14:51:19,216:INFO:Importing untrained model
2025-06-21 14:51:19,227:INFO:Passive Aggressive Regressor Imported successfully
2025-06-21 14:51:19,251:INFO:Starting cross validation
2025-06-21 14:51:19,255:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:20,149:INFO:Calculating mean and std
2025-06-21 14:51:20,152:INFO:Creating metrics dataframe
2025-06-21 14:51:20,156:INFO:Uploading results into container
2025-06-21 14:51:20,157:INFO:Uploading model into container now
2025-06-21 14:51:20,158:INFO:_master_model_container: 9
2025-06-21 14:51:20,159:INFO:_display_container: 2
2025-06-21 14:51:20,159:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-21 14:51:20,160:INFO:create_model() successfully completed......................................
2025-06-21 14:51:20,686:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:20,687:INFO:Creating metrics dataframe
2025-06-21 14:51:20,707:INFO:Initializing Huber Regressor
2025-06-21 14:51:20,707:INFO:Total runtime is 0.6758052150408427 minutes
2025-06-21 14:51:20,718:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:20,719:INFO:Initializing create_model()
2025-06-21 14:51:20,720:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:20,720:INFO:Checking exceptions
2025-06-21 14:51:20,721:INFO:Importing libraries
2025-06-21 14:51:20,721:INFO:Copying training dataset
2025-06-21 14:51:20,797:INFO:Defining folds
2025-06-21 14:51:20,798:INFO:Declaring metric variables
2025-06-21 14:51:20,809:INFO:Importing untrained model
2025-06-21 14:51:20,821:INFO:Huber Regressor Imported successfully
2025-06-21 14:51:20,843:INFO:Starting cross validation
2025-06-21 14:51:20,848:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:22,578:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-21 14:51:22,594:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-21 14:51:22,595:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-21 14:51:22,606:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-21 14:51:22,658:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-21 14:51:22,722:INFO:Calculating mean and std
2025-06-21 14:51:22,724:INFO:Creating metrics dataframe
2025-06-21 14:51:22,728:INFO:Uploading results into container
2025-06-21 14:51:22,729:INFO:Uploading model into container now
2025-06-21 14:51:22,729:INFO:_master_model_container: 10
2025-06-21 14:51:22,730:INFO:_display_container: 2
2025-06-21 14:51:22,730:INFO:HuberRegressor()
2025-06-21 14:51:22,730:INFO:create_model() successfully completed......................................
2025-06-21 14:51:23,235:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:23,235:INFO:Creating metrics dataframe
2025-06-21 14:51:23,255:INFO:Initializing K Neighbors Regressor
2025-06-21 14:51:23,256:INFO:Total runtime is 0.7182877580324809 minutes
2025-06-21 14:51:23,266:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:23,267:INFO:Initializing create_model()
2025-06-21 14:51:23,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:23,268:INFO:Checking exceptions
2025-06-21 14:51:23,268:INFO:Importing libraries
2025-06-21 14:51:23,268:INFO:Copying training dataset
2025-06-21 14:51:23,331:INFO:Defining folds
2025-06-21 14:51:23,331:INFO:Declaring metric variables
2025-06-21 14:51:23,343:INFO:Importing untrained model
2025-06-21 14:51:23,353:INFO:K Neighbors Regressor Imported successfully
2025-06-21 14:51:23,379:INFO:Starting cross validation
2025-06-21 14:51:23,383:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:24,310:INFO:Calculating mean and std
2025-06-21 14:51:24,313:INFO:Creating metrics dataframe
2025-06-21 14:51:24,316:INFO:Uploading results into container
2025-06-21 14:51:24,318:INFO:Uploading model into container now
2025-06-21 14:51:24,319:INFO:_master_model_container: 11
2025-06-21 14:51:24,319:INFO:_display_container: 2
2025-06-21 14:51:24,320:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-21 14:51:24,320:INFO:create_model() successfully completed......................................
2025-06-21 14:51:24,837:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:24,838:INFO:Creating metrics dataframe
2025-06-21 14:51:24,858:INFO:Initializing Decision Tree Regressor
2025-06-21 14:51:24,858:INFO:Total runtime is 0.7449986060460408 minutes
2025-06-21 14:51:24,867:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:24,867:INFO:Initializing create_model()
2025-06-21 14:51:24,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:24,868:INFO:Checking exceptions
2025-06-21 14:51:24,869:INFO:Importing libraries
2025-06-21 14:51:24,869:INFO:Copying training dataset
2025-06-21 14:51:24,956:INFO:Defining folds
2025-06-21 14:51:24,957:INFO:Declaring metric variables
2025-06-21 14:51:24,967:INFO:Importing untrained model
2025-06-21 14:51:24,981:INFO:Decision Tree Regressor Imported successfully
2025-06-21 14:51:25,004:INFO:Starting cross validation
2025-06-21 14:51:25,009:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:26,310:INFO:Calculating mean and std
2025-06-21 14:51:26,312:INFO:Creating metrics dataframe
2025-06-21 14:51:26,317:INFO:Uploading results into container
2025-06-21 14:51:26,318:INFO:Uploading model into container now
2025-06-21 14:51:26,319:INFO:_master_model_container: 12
2025-06-21 14:51:26,320:INFO:_display_container: 2
2025-06-21 14:51:26,321:INFO:DecisionTreeRegressor(random_state=123)
2025-06-21 14:51:26,322:INFO:create_model() successfully completed......................................
2025-06-21 14:51:26,944:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:26,945:INFO:Creating metrics dataframe
2025-06-21 14:51:26,968:INFO:Initializing Random Forest Regressor
2025-06-21 14:51:26,968:INFO:Total runtime is 0.7801671028137207 minutes
2025-06-21 14:51:26,978:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:26,979:INFO:Initializing create_model()
2025-06-21 14:51:26,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:26,979:INFO:Checking exceptions
2025-06-21 14:51:26,980:INFO:Importing libraries
2025-06-21 14:51:26,980:INFO:Copying training dataset
2025-06-21 14:51:27,154:INFO:Defining folds
2025-06-21 14:51:27,154:INFO:Declaring metric variables
2025-06-21 14:51:27,171:INFO:Importing untrained model
2025-06-21 14:51:27,185:INFO:Random Forest Regressor Imported successfully
2025-06-21 14:51:27,215:INFO:Starting cross validation
2025-06-21 14:51:27,219:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:37,865:INFO:Calculating mean and std
2025-06-21 14:51:37,872:INFO:Creating metrics dataframe
2025-06-21 14:51:37,883:INFO:Uploading results into container
2025-06-21 14:51:37,885:INFO:Uploading model into container now
2025-06-21 14:51:37,885:INFO:_master_model_container: 13
2025-06-21 14:51:37,886:INFO:_display_container: 2
2025-06-21 14:51:37,889:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-21 14:51:37,889:INFO:create_model() successfully completed......................................
2025-06-21 14:51:38,699:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:38,699:INFO:Creating metrics dataframe
2025-06-21 14:51:38,730:INFO:Initializing Extra Trees Regressor
2025-06-21 14:51:38,730:INFO:Total runtime is 0.9761974414189657 minutes
2025-06-21 14:51:38,744:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:38,745:INFO:Initializing create_model()
2025-06-21 14:51:38,745:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:38,746:INFO:Checking exceptions
2025-06-21 14:51:38,746:INFO:Importing libraries
2025-06-21 14:51:38,747:INFO:Copying training dataset
2025-06-21 14:51:38,846:INFO:Defining folds
2025-06-21 14:51:38,847:INFO:Declaring metric variables
2025-06-21 14:51:38,862:INFO:Importing untrained model
2025-06-21 14:51:38,872:INFO:Extra Trees Regressor Imported successfully
2025-06-21 14:51:38,904:INFO:Starting cross validation
2025-06-21 14:51:38,908:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:45,637:INFO:Calculating mean and std
2025-06-21 14:51:45,640:INFO:Creating metrics dataframe
2025-06-21 14:51:45,644:INFO:Uploading results into container
2025-06-21 14:51:45,645:INFO:Uploading model into container now
2025-06-21 14:51:45,646:INFO:_master_model_container: 14
2025-06-21 14:51:45,646:INFO:_display_container: 2
2025-06-21 14:51:45,647:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-21 14:51:45,647:INFO:create_model() successfully completed......................................
2025-06-21 14:51:46,183:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:46,183:INFO:Creating metrics dataframe
2025-06-21 14:51:46,203:INFO:Initializing AdaBoost Regressor
2025-06-21 14:51:46,204:INFO:Total runtime is 1.100769321123759 minutes
2025-06-21 14:51:46,212:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:46,213:INFO:Initializing create_model()
2025-06-21 14:51:46,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:46,214:INFO:Checking exceptions
2025-06-21 14:51:46,214:INFO:Importing libraries
2025-06-21 14:51:46,215:INFO:Copying training dataset
2025-06-21 14:51:46,290:INFO:Defining folds
2025-06-21 14:51:46,290:INFO:Declaring metric variables
2025-06-21 14:51:46,304:INFO:Importing untrained model
2025-06-21 14:51:46,314:INFO:AdaBoost Regressor Imported successfully
2025-06-21 14:51:46,340:INFO:Starting cross validation
2025-06-21 14:51:46,344:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:48,648:INFO:Calculating mean and std
2025-06-21 14:51:48,650:INFO:Creating metrics dataframe
2025-06-21 14:51:48,654:INFO:Uploading results into container
2025-06-21 14:51:48,655:INFO:Uploading model into container now
2025-06-21 14:51:48,656:INFO:_master_model_container: 15
2025-06-21 14:51:48,656:INFO:_display_container: 2
2025-06-21 14:51:48,657:INFO:AdaBoostRegressor(random_state=123)
2025-06-21 14:51:48,657:INFO:create_model() successfully completed......................................
2025-06-21 14:51:49,165:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:49,165:INFO:Creating metrics dataframe
2025-06-21 14:51:49,185:INFO:Initializing Gradient Boosting Regressor
2025-06-21 14:51:49,185:INFO:Total runtime is 1.1504473567008973 minutes
2025-06-21 14:51:49,195:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:49,196:INFO:Initializing create_model()
2025-06-21 14:51:49,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:49,197:INFO:Checking exceptions
2025-06-21 14:51:49,197:INFO:Importing libraries
2025-06-21 14:51:49,198:INFO:Copying training dataset
2025-06-21 14:51:49,266:INFO:Defining folds
2025-06-21 14:51:49,267:INFO:Declaring metric variables
2025-06-21 14:51:49,279:INFO:Importing untrained model
2025-06-21 14:51:49,291:INFO:Gradient Boosting Regressor Imported successfully
2025-06-21 14:51:49,314:INFO:Starting cross validation
2025-06-21 14:51:49,318:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:53,426:INFO:Calculating mean and std
2025-06-21 14:51:53,428:INFO:Creating metrics dataframe
2025-06-21 14:51:53,431:INFO:Uploading results into container
2025-06-21 14:51:53,432:INFO:Uploading model into container now
2025-06-21 14:51:53,433:INFO:_master_model_container: 16
2025-06-21 14:51:53,433:INFO:_display_container: 2
2025-06-21 14:51:53,434:INFO:GradientBoostingRegressor(random_state=123)
2025-06-21 14:51:53,434:INFO:create_model() successfully completed......................................
2025-06-21 14:51:54,065:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:54,065:INFO:Creating metrics dataframe
2025-06-21 14:51:54,088:INFO:Initializing Extreme Gradient Boosting
2025-06-21 14:51:54,088:INFO:Total runtime is 1.2321547150611878 minutes
2025-06-21 14:51:54,099:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:54,100:INFO:Initializing create_model()
2025-06-21 14:51:54,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:54,100:INFO:Checking exceptions
2025-06-21 14:51:54,101:INFO:Importing libraries
2025-06-21 14:51:54,101:INFO:Copying training dataset
2025-06-21 14:51:54,172:INFO:Defining folds
2025-06-21 14:51:54,173:INFO:Declaring metric variables
2025-06-21 14:51:54,183:INFO:Importing untrained model
2025-06-21 14:51:54,196:INFO:Extreme Gradient Boosting Imported successfully
2025-06-21 14:51:54,219:INFO:Starting cross validation
2025-06-21 14:51:54,224:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:56,497:INFO:Calculating mean and std
2025-06-21 14:51:56,500:INFO:Creating metrics dataframe
2025-06-21 14:51:56,504:INFO:Uploading results into container
2025-06-21 14:51:56,505:INFO:Uploading model into container now
2025-06-21 14:51:56,506:INFO:_master_model_container: 17
2025-06-21 14:51:56,507:INFO:_display_container: 2
2025-06-21 14:51:56,511:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-21 14:51:56,511:INFO:create_model() successfully completed......................................
2025-06-21 14:51:56,999:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:56,999:INFO:Creating metrics dataframe
2025-06-21 14:51:57,018:INFO:Initializing Light Gradient Boosting Machine
2025-06-21 14:51:57,018:INFO:Total runtime is 1.2809884707132975 minutes
2025-06-21 14:51:57,029:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:57,029:INFO:Initializing create_model()
2025-06-21 14:51:57,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:57,030:INFO:Checking exceptions
2025-06-21 14:51:57,031:INFO:Importing libraries
2025-06-21 14:51:57,031:INFO:Copying training dataset
2025-06-21 14:51:57,114:INFO:Defining folds
2025-06-21 14:51:57,114:INFO:Declaring metric variables
2025-06-21 14:51:57,125:INFO:Importing untrained model
2025-06-21 14:51:57,135:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-21 14:51:57,158:INFO:Starting cross validation
2025-06-21 14:51:57,162:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:51:59,077:INFO:Calculating mean and std
2025-06-21 14:51:59,080:INFO:Creating metrics dataframe
2025-06-21 14:51:59,085:INFO:Uploading results into container
2025-06-21 14:51:59,087:INFO:Uploading model into container now
2025-06-21 14:51:59,088:INFO:_master_model_container: 18
2025-06-21 14:51:59,088:INFO:_display_container: 2
2025-06-21 14:51:59,090:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-21 14:51:59,090:INFO:create_model() successfully completed......................................
2025-06-21 14:51:59,615:INFO:SubProcess create_model() end ==================================
2025-06-21 14:51:59,616:INFO:Creating metrics dataframe
2025-06-21 14:51:59,635:INFO:Initializing CatBoost Regressor
2025-06-21 14:51:59,635:INFO:Total runtime is 1.3246182560920714 minutes
2025-06-21 14:51:59,646:INFO:SubProcess create_model() called ==================================
2025-06-21 14:51:59,647:INFO:Initializing create_model()
2025-06-21 14:51:59,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:51:59,647:INFO:Checking exceptions
2025-06-21 14:51:59,648:INFO:Importing libraries
2025-06-21 14:51:59,648:INFO:Copying training dataset
2025-06-21 14:51:59,721:INFO:Defining folds
2025-06-21 14:51:59,721:INFO:Declaring metric variables
2025-06-21 14:51:59,739:INFO:Importing untrained model
2025-06-21 14:51:59,759:INFO:CatBoost Regressor Imported successfully
2025-06-21 14:51:59,781:INFO:Starting cross validation
2025-06-21 14:51:59,785:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:52:27,288:INFO:Calculating mean and std
2025-06-21 14:52:27,291:INFO:Creating metrics dataframe
2025-06-21 14:52:27,295:INFO:Uploading results into container
2025-06-21 14:52:27,296:INFO:Uploading model into container now
2025-06-21 14:52:27,297:INFO:_master_model_container: 19
2025-06-21 14:52:27,297:INFO:_display_container: 2
2025-06-21 14:52:27,297:INFO:<catboost.core.CatBoostRegressor object at 0x00000205477F8E80>
2025-06-21 14:52:27,298:INFO:create_model() successfully completed......................................
2025-06-21 14:52:27,886:INFO:SubProcess create_model() end ==================================
2025-06-21 14:52:27,886:INFO:Creating metrics dataframe
2025-06-21 14:52:27,909:INFO:Initializing Dummy Regressor
2025-06-21 14:52:27,909:INFO:Total runtime is 1.7958503882090249 minutes
2025-06-21 14:52:27,918:INFO:SubProcess create_model() called ==================================
2025-06-21 14:52:27,918:INFO:Initializing create_model()
2025-06-21 14:52:27,919:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205477E0640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:52:27,919:INFO:Checking exceptions
2025-06-21 14:52:27,920:INFO:Importing libraries
2025-06-21 14:52:27,921:INFO:Copying training dataset
2025-06-21 14:52:27,982:INFO:Defining folds
2025-06-21 14:52:27,983:INFO:Declaring metric variables
2025-06-21 14:52:27,994:INFO:Importing untrained model
2025-06-21 14:52:28,005:INFO:Dummy Regressor Imported successfully
2025-06-21 14:52:28,026:INFO:Starting cross validation
2025-06-21 14:52:28,030:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:52:29,131:INFO:Calculating mean and std
2025-06-21 14:52:29,134:INFO:Creating metrics dataframe
2025-06-21 14:52:29,142:INFO:Uploading results into container
2025-06-21 14:52:29,143:INFO:Uploading model into container now
2025-06-21 14:52:29,145:INFO:_master_model_container: 20
2025-06-21 14:52:29,145:INFO:_display_container: 2
2025-06-21 14:52:29,146:INFO:DummyRegressor()
2025-06-21 14:52:29,146:INFO:create_model() successfully completed......................................
2025-06-21 14:52:29,788:INFO:SubProcess create_model() end ==================================
2025-06-21 14:52:29,789:INFO:Creating metrics dataframe
2025-06-21 14:52:29,838:INFO:Initializing create_model()
2025-06-21 14:52:29,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:52:29,839:INFO:Checking exceptions
2025-06-21 14:52:29,848:INFO:Importing libraries
2025-06-21 14:52:29,849:INFO:Copying training dataset
2025-06-21 14:52:29,912:INFO:Defining folds
2025-06-21 14:52:29,912:INFO:Declaring metric variables
2025-06-21 14:52:29,913:INFO:Importing untrained model
2025-06-21 14:52:29,913:INFO:Declaring custom model
2025-06-21 14:52:29,914:INFO:Extra Trees Regressor Imported successfully
2025-06-21 14:52:29,916:INFO:Cross validation set to False
2025-06-21 14:52:29,916:INFO:Fitting Model
2025-06-21 14:52:31,817:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-21 14:52:31,817:INFO:create_model() successfully completed......................................
2025-06-21 14:52:32,336:INFO:Initializing create_model()
2025-06-21 14:52:32,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=<catboost.core.CatBoostRegressor object at 0x00000205477F8E80>, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:52:32,337:INFO:Checking exceptions
2025-06-21 14:52:32,342:INFO:Importing libraries
2025-06-21 14:52:32,343:INFO:Copying training dataset
2025-06-21 14:52:32,400:INFO:Defining folds
2025-06-21 14:52:32,401:INFO:Declaring metric variables
2025-06-21 14:52:32,401:INFO:Importing untrained model
2025-06-21 14:52:32,401:INFO:Declaring custom model
2025-06-21 14:52:32,402:INFO:CatBoost Regressor Imported successfully
2025-06-21 14:52:32,404:INFO:Cross validation set to False
2025-06-21 14:52:32,404:INFO:Fitting Model
2025-06-21 14:52:39,426:INFO:<catboost.core.CatBoostRegressor object at 0x000002054763B280>
2025-06-21 14:52:39,426:INFO:create_model() successfully completed......................................
2025-06-21 14:52:39,958:INFO:Initializing create_model()
2025-06-21 14:52:39,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:52:39,958:INFO:Checking exceptions
2025-06-21 14:52:39,962:INFO:Importing libraries
2025-06-21 14:52:39,962:INFO:Copying training dataset
2025-06-21 14:52:40,018:INFO:Defining folds
2025-06-21 14:52:40,019:INFO:Declaring metric variables
2025-06-21 14:52:40,019:INFO:Importing untrained model
2025-06-21 14:52:40,019:INFO:Declaring custom model
2025-06-21 14:52:40,021:INFO:Extreme Gradient Boosting Imported successfully
2025-06-21 14:52:40,024:INFO:Cross validation set to False
2025-06-21 14:52:40,024:INFO:Fitting Model
2025-06-21 14:52:40,979:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-21 14:52:40,979:INFO:create_model() successfully completed......................................
2025-06-21 14:52:41,583:INFO:_master_model_container: 20
2025-06-21 14:52:41,584:INFO:_display_container: 2
2025-06-21 14:52:41,587:INFO:[ExtraTreesRegressor(n_jobs=-1, random_state=123), <catboost.core.CatBoostRegressor object at 0x000002054763B280>, XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)]
2025-06-21 14:52:41,587:INFO:compare_models() successfully completed......................................
2025-06-21 14:52:41,590:INFO:Initializing tune_model()
2025-06-21 14:52:41,591:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>)
2025-06-21 14:52:41,591:INFO:Checking exceptions
2025-06-21 14:52:41,591:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-21 14:52:41,780:INFO:Copying training dataset
2025-06-21 14:52:41,830:INFO:Checking base model
2025-06-21 14:52:41,830:INFO:Base model : Extra Trees Regressor
2025-06-21 14:52:41,844:INFO:Declaring metric variables
2025-06-21 14:52:41,871:INFO:Defining Hyperparameters
2025-06-21 14:52:42,478:INFO:Tuning with n_jobs=-1
2025-06-21 14:52:42,489:INFO:Initializing skopt.BayesSearchCV
2025-06-21 14:57:01,926:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', False), ('actual_estimator__criterion', 'absolute_error'), ('actual_estimator__max_depth', 11), ('actual_estimator__max_features', 0.4556655086335653), ('actual_estimator__min_impurity_decrease', 0.00012891733508622256), ('actual_estimator__min_samples_leaf', 1), ('actual_estimator__min_samples_split', 9), ('actual_estimator__n_estimators', 11)])
2025-06-21 14:57:01,938:INFO:Hyperparameter search completed
2025-06-21 14:57:01,938:INFO:SubProcess create_model() called ==================================
2025-06-21 14:57:01,946:INFO:Initializing create_model()
2025-06-21 14:57:01,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020536464340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bootstrap': False, 'criterion': 'absolute_error', 'max_depth': 11, 'max_features': 0.4556655086335653, 'min_impurity_decrease': 0.00012891733508622256, 'min_samples_leaf': 1, 'min_samples_split': 9, 'n_estimators': 11})
2025-06-21 14:57:01,946:INFO:Checking exceptions
2025-06-21 14:57:01,948:INFO:Importing libraries
2025-06-21 14:57:01,948:INFO:Copying training dataset
2025-06-21 14:57:02,057:INFO:Defining folds
2025-06-21 14:57:02,058:INFO:Declaring metric variables
2025-06-21 14:57:02,086:INFO:Importing untrained model
2025-06-21 14:57:02,086:INFO:Declaring custom model
2025-06-21 14:57:02,120:INFO:Extra Trees Regressor Imported successfully
2025-06-21 14:57:02,158:INFO:Starting cross validation
2025-06-21 14:57:02,164:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:57:13,488:INFO:Calculating mean and std
2025-06-21 14:57:13,492:INFO:Creating metrics dataframe
2025-06-21 14:57:13,519:INFO:Finalizing model
2025-06-21 14:57:18,594:INFO:Uploading results into container
2025-06-21 14:57:18,596:INFO:Uploading model into container now
2025-06-21 14:57:18,599:INFO:_master_model_container: 21
2025-06-21 14:57:18,599:INFO:_display_container: 3
2025-06-21 14:57:18,601:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=11,
                    max_features=0.4556655086335653,
                    min_impurity_decrease=0.00012891733508622256,
                    min_samples_split=9, n_estimators=11, n_jobs=-1,
                    random_state=123)
2025-06-21 14:57:18,602:INFO:create_model() successfully completed......................................
2025-06-21 14:57:19,678:INFO:SubProcess create_model() end ==================================
2025-06-21 14:57:19,678:INFO:choose_better activated
2025-06-21 14:57:19,692:INFO:SubProcess create_model() called ==================================
2025-06-21 14:57:19,695:INFO:Initializing create_model()
2025-06-21 14:57:19,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:57:19,696:INFO:Checking exceptions
2025-06-21 14:57:19,700:INFO:Importing libraries
2025-06-21 14:57:19,700:INFO:Copying training dataset
2025-06-21 14:57:19,822:INFO:Defining folds
2025-06-21 14:57:19,822:INFO:Declaring metric variables
2025-06-21 14:57:19,823:INFO:Importing untrained model
2025-06-21 14:57:19,824:INFO:Declaring custom model
2025-06-21 14:57:19,828:INFO:Extra Trees Regressor Imported successfully
2025-06-21 14:57:19,829:INFO:Starting cross validation
2025-06-21 14:57:19,836:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:57:28,003:INFO:Calculating mean and std
2025-06-21 14:57:28,005:INFO:Creating metrics dataframe
2025-06-21 14:57:28,011:INFO:Finalizing model
2025-06-21 14:57:30,883:INFO:Uploading results into container
2025-06-21 14:57:30,885:INFO:Uploading model into container now
2025-06-21 14:57:30,886:INFO:_master_model_container: 22
2025-06-21 14:57:30,887:INFO:_display_container: 4
2025-06-21 14:57:30,888:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-21 14:57:30,889:INFO:create_model() successfully completed......................................
2025-06-21 14:57:31,665:INFO:SubProcess create_model() end ==================================
2025-06-21 14:57:31,667:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 0.1814
2025-06-21 14:57:31,669:INFO:ExtraTreesRegressor(criterion='absolute_error', max_depth=11,
                    max_features=0.4556655086335653,
                    min_impurity_decrease=0.00012891733508622256,
                    min_samples_split=9, n_estimators=11, n_jobs=-1,
                    random_state=123) result for MAE is 0.2118
2025-06-21 14:57:31,671:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2025-06-21 14:57:31,671:INFO:choose_better completed
2025-06-21 14:57:31,672:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-21 14:57:31,705:INFO:_master_model_container: 22
2025-06-21 14:57:31,705:INFO:_display_container: 3
2025-06-21 14:57:31,707:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-21 14:57:31,708:INFO:tune_model() successfully completed......................................
2025-06-21 14:57:32,632:INFO:Initializing finalize_model()
2025-06-21 14:57:32,632:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-21 14:57:32,633:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-21 14:57:32,700:INFO:Initializing create_model()
2025-06-21 14:57:32,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:57:32,701:INFO:Checking exceptions
2025-06-21 14:57:32,705:INFO:Importing libraries
2025-06-21 14:57:32,706:INFO:Copying training dataset
2025-06-21 14:57:32,715:INFO:Defining folds
2025-06-21 14:57:32,715:INFO:Declaring metric variables
2025-06-21 14:57:32,716:INFO:Importing untrained model
2025-06-21 14:57:32,716:INFO:Declaring custom model
2025-06-21 14:57:32,718:INFO:Extra Trees Regressor Imported successfully
2025-06-21 14:57:32,725:INFO:Cross validation set to False
2025-06-21 14:57:32,725:INFO:Fitting Model
2025-06-21 14:57:35,998:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-21 14:57:35,998:INFO:create_model() successfully completed......................................
2025-06-21 14:57:36,750:INFO:_master_model_container: 22
2025-06-21 14:57:36,750:INFO:_display_container: 3
2025-06-21 14:57:36,779:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-21 14:57:36,780:INFO:finalize_model() successfully completed......................................
2025-06-21 14:57:37,532:INFO:Initializing save_model()
2025-06-21 14:57:37,532:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model_mae, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-21 14:57:37,533:INFO:Adding model into prep_pipe
2025-06-21 14:57:37,533:WARNING:Only Model saved as it was a pipeline.
2025-06-21 14:57:37,754:INFO:formation_energy_final_model_mae.pkl saved in current working directory
2025-06-21 14:57:37,777:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2025-06-21 14:57:37,777:INFO:save_model() successfully completed......................................
2025-06-21 14:57:38,464:INFO:Initializing load_model()
2025-06-21 14:57:38,465:INFO:load_model(model_name=formation_energy_final_model_mae, platform=None, authentication=None, verbose=True)
2025-06-21 14:57:39,003:INFO:Initializing get_config()
2025-06-21 14:57:39,003:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, variable=X_test)
2025-06-21 14:57:39,004:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-21 14:57:39,005:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-21 14:57:39,072:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
2030                       28.0                       80.0  \
3043                        8.0                       74.0   
3552                        5.0                        9.0   
380                        25.0                       25.0   
730                        11.0                       11.0   
...                         ...                        ...   
2572                        4.0                       14.0   
3757                        7.0                       20.0   
2377                        5.0                       92.0   
3499                       51.0                       92.0   
2893                       60.0                       91.0   

      MagpieData range Number  MagpieData mean Number   
2030                     52.0               54.000000  \
3043                     66.0               30.000000   
3552                      4.0                7.400000   
380                       0.0               25.000000   
730                       0.0               11.000000   
...                       ...                     ...   
2572                     10.0                6.500000   
3757                     13.0               14.526316   
2377                     87.0               22.400000   
3499                     41.0               64.666664   
2893                     31.0               67.750000   

      MagpieData avg_dev Number  MagpieData mode Number   
2030                  26.000000                    28.0  \
3043                  29.333334                     8.0   
3552                   1.920000                     9.0   
380                    0.000000                    25.0   
730                    0.000000                    11.0   
...                         ...                     ...   
2572                   3.750000                     4.0   
3757                   6.337950                    20.0   
2377                  27.840000                     5.0   
3499                  18.222221                    51.0   
2893                  11.625000                    60.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
2030                                61.0                                71.0  \
3043                                51.0                                87.0   
3552                                72.0                                93.0   
380                                 52.0                                52.0   
730                                  2.0                                 2.0   
...                                  ...                                 ...   
2572                                67.0                                78.0   
3757                                 7.0                                82.0   
2377                                20.0                                72.0   
3499                                20.0                                85.0   
2893                                18.0                                19.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
2030                              10.0                        66.000000  ...  \
3043                              36.0                        75.000000  ...   
3552                              21.0                        84.599998  ...   
380                                0.0                        52.000000  ...   
730                                0.0                         2.000000  ...   
...                                ...                              ...  ...   
2572                              11.0                        69.750000  ...   
3757                              75.0                        38.578949  ...   
2377                              52.0                        61.599998  ...   
3499                              65.0                        63.333332  ...   
2893                               1.0                        18.750000  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
2030                 4.0                   1            32.0  \
3043                 7.0                   0             1.0   
3552                 6.0                   1             8.0   
380                  2.0                   1            48.0   
730                  5.0                   1            16.0   
...                  ...                 ...             ...   
2572                 4.0                   1            32.0   
3757                 4.0                   1            16.0   
2377                 4.0                   1            32.0   
3499                 4.0                   1            16.0   
2893                 4.0                   1            32.0   

      crystal_system_cubic  crystal_system_hexagonal   
2030                 False                     False  \
3043                 False                     False   
3552                 False                     False   
380                  False                      True   
730                  False                     False   
...                    ...                       ...   
2572                 False                     False   
3757                 False                     False   
2377                 False                     False   
3499                 False                     False   
2893                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
2030                      False                        False  \
3043                      False                        False   
3552                       True                        False   
380                       False                        False   
730                       False                         True   
...                         ...                          ...   
2572                      False                        False   
3757                      False                        False   
2377                      False                        False   
3499                      False                        False   
2893                      False                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
2030                       True                     False  \
3043                      False                      True   
3552                      False                     False   
380                       False                     False   
730                       False                     False   
...                         ...                       ...   
2572                       True                     False   
3757                       True                     False   
2377                       True                     False   
3499                       True                     False   
2893                       True                     False   

      crystal_system_trigonal  
2030                    False  
3043                    False  
3552                    False  
380                     False  
730                     False  
...                       ...  
2572                    False  
3757                    False  
2377                    False  
3499                    False  
2893                    False  

[840 rows x 146 columns]
2025-06-21 14:57:39,072:INFO:get_config() successfully completed......................................
2025-06-21 14:57:39,072:INFO:Initializing get_config()
2025-06-21 14:57:39,073:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, variable=y_test)
2025-06-21 14:57:39,073:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-21 14:57:39,073:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-21 14:57:39,092:INFO:Variable:  returned as 2030    0.219228
3043   -1.515973
3552   -2.173735
380     0.052632
730     0.010884
          ...   
2572    0.287101
3757   -0.733346
2377   -0.512027
3499   -0.514500
2893    0.295365
Name: target, Length: 840, dtype: float32
2025-06-21 14:57:39,092:INFO:get_config() successfully completed......................................
2025-06-21 14:57:39,092:INFO:Initializing get_config()
2025-06-21 14:57:39,093:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, variable=X_train)
2025-06-21 14:57:39,093:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-06-21 14:57:39,093:WARNING:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-06-21 14:57:39,160:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
3860                        7.0                       24.0  \
1975                       34.0                       60.0   
3260                       13.0                       16.0   
4063                       12.0                       14.0   
1778                        8.0                       39.0   
...                         ...                        ...   
1593                       14.0                       47.0   
4060                       12.0                       14.0   
1346                       12.0                       39.0   
3454                       27.0                       81.0   
3582                        8.0                       38.0   

      MagpieData range Number  MagpieData mean Number   
3860                     17.0               17.200001  \
1975                     26.0               44.400002   
3260                      3.0               14.800000   
4063                      2.0               13.142858   
1778                     31.0               20.400000   
...                       ...                     ...   
1593                     33.0               22.250000   
4060                      2.0               13.142858   
1346                     27.0               30.000000   
3454                     54.0               67.500000   
3582                     30.0               10.727273   

      MagpieData avg_dev Number  MagpieData mode Number   
3860                   8.160000                    24.0  \
1975                  12.480000                    34.0   
3260                   1.440000                    16.0   
4063                   0.979592                    14.0   
1778                  14.880000                     8.0   
...                         ...                     ...   
1593                  12.375000                    14.0   
4060                   0.979592                    14.0   
1346                  12.000000                    39.0   
3454                  20.250000                    81.0   
3582                   4.958678                     8.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
3860                                49.0                                82.0  \
1975                                19.0                                89.0   
3260                                73.0                                88.0   
4063                                68.0                                78.0   
1778                                12.0                                87.0   
...                                  ...                                 ...   
1593                                65.0                                78.0   
4060                                68.0                                78.0   
1346                                12.0                                68.0   
3454                                58.0                                76.0   
3582                                 8.0                                87.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
3860                              33.0                        62.200001  ...  \
1975                              70.0                        61.000000  ...   
3260                              15.0                        82.000000  ...   
4063                              10.0                        73.714287  ...   
1778                              75.0                        57.000000  ...   
...                                ...                              ...  ...   
1593                              13.0                        74.750000  ...   
4060                              10.0                        73.714287  ...   
1346                              56.0                        30.666666  ...   
3454                              18.0                        71.500000  ...   
3582                              79.0                        79.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
3860                 4.0                   1             8.0  \
1975                 4.0                   0            10.0   
3260                 7.0                   0             2.0   
4063                 7.0                   0             2.0   
1778                 6.0                   1             8.0   
...                  ...                 ...             ...   
1593                 7.0                   1             4.0   
4060                 7.0                   0             2.0   
1346                 6.0                   1             4.0   
3454                 7.0                   0             1.0   
3582                 4.0                   1            32.0   

      crystal_system_cubic  crystal_system_hexagonal   
3860                 False                     False  \
1975                 False                     False   
3260                 False                     False   
4063                 False                     False   
1778                 False                     False   
...                    ...                       ...   
1593                 False                     False   
4060                 False                     False   
1346                 False                     False   
3454                 False                     False   
3582                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
3860                      False                        False  \
1975                      False                        False   
3260                      False                        False   
4063                      False                        False   
1778                       True                        False   
...                         ...                          ...   
1593                      False                        False   
4060                      False                        False   
1346                       True                        False   
3454                      False                        False   
3582                      False                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
3860                       True                     False  \
1975                       True                     False   
3260                      False                      True   
4063                      False                      True   
1778                      False                     False   
...                         ...                       ...   
1593                      False                      True   
4060                      False                      True   
1346                      False                     False   
3454                      False                      True   
3582                       True                     False   

      crystal_system_trigonal  
3860                    False  
1975                    False  
3260                    False  
4063                    False  
1778                    False  
...                       ...  
1593                    False  
4060                    False  
1346                    False  
3454                    False  
3582                    False  

[3360 rows x 146 columns]
2025-06-21 14:57:39,160:INFO:get_config() successfully completed......................................
2025-06-21 14:57:39,161:INFO:Initializing get_config()
2025-06-21 14:57:39,161:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, variable=y_train)
2025-06-21 14:57:39,161:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-06-21 14:57:39,161:WARNING:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-06-21 14:57:39,185:INFO:Variable:  returned as 3860   -0.511424
1975   -2.191013
3260   -0.742211
4063    0.211632
1778   -3.919644
          ...   
1593    0.446244
4060    0.168126
1346    0.018895
3454    0.509697
3582   -0.130854
Name: target, Length: 3360, dtype: float32
2025-06-21 14:57:39,185:INFO:get_config() successfully completed......................................
2025-06-21 14:57:39,208:INFO:Initializing predict_model()
2025-06-21 14:57:39,209:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002053FE66800>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020547983F40>)
2025-06-21 14:57:39,209:INFO:Checking exceptions
2025-06-21 14:57:39,209:INFO:Preloading libraries
2025-06-21 14:57:39,214:INFO:Set up data.
2025-06-21 14:57:39,371:INFO:Set up index.
2025-06-21 14:57:40,541:INFO:PyCaret RegressionExperiment
2025-06-21 14:57:40,542:INFO:Logging name: reg-default-name
2025-06-21 14:57:40,542:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-21 14:57:40,542:INFO:version 3.3.2
2025-06-21 14:57:40,542:INFO:Initializing setup()
2025-06-21 14:57:40,542:INFO:self.USI: a78f
2025-06-21 14:57:40,542:INFO:self._variable_keys: {'exp_id', 'gpu_param', 'y', 'y_test', 'X_train', 'USI', 'logging_param', 'fold_generator', 'gpu_n_jobs_param', 'fold_groups_param', 'html_param', 'target_param', 'seed', 'idx', '_ml_usecase', 'n_jobs_param', 'data', 'transform_target_param', 'exp_name_log', 'X', 'X_test', 'log_plots_param', 'y_train', 'memory', 'fold_shuffle_param', '_available_plots', 'pipeline'}
2025-06-21 14:57:40,543:INFO:Checking environment
2025-06-21 14:57:40,543:INFO:python_version: 3.10.16
2025-06-21 14:57:40,543:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-21 14:57:40,543:INFO:machine: AMD64
2025-06-21 14:57:40,543:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-21 14:57:40,551:INFO:Memory: svmem(total=6378008576, available=935383040, percent=85.3, used=5442625536, free=935383040)
2025-06-21 14:57:40,551:INFO:Physical Core: 4
2025-06-21 14:57:40,551:INFO:Logical Core: 8
2025-06-21 14:57:40,551:INFO:Checking libraries
2025-06-21 14:57:40,552:INFO:System:
2025-06-21 14:57:40,552:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-21 14:57:40,566:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-21 14:57:40,566:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-21 14:57:40,566:INFO:PyCaret required dependencies:
2025-06-21 14:57:40,567:INFO:                 pip: 25.1
2025-06-21 14:57:40,567:INFO:          setuptools: 78.1.1
2025-06-21 14:57:40,567:INFO:             pycaret: 3.3.2
2025-06-21 14:57:40,567:INFO:             IPython: 8.37.0
2025-06-21 14:57:40,567:INFO:          ipywidgets: 8.1.7
2025-06-21 14:57:40,568:INFO:                tqdm: 4.67.1
2025-06-21 14:57:40,568:INFO:               numpy: 1.26.4
2025-06-21 14:57:40,569:INFO:              pandas: 2.0.1
2025-06-21 14:57:40,569:INFO:              jinja2: 3.1.6
2025-06-21 14:57:40,569:INFO:               scipy: 1.10.1
2025-06-21 14:57:40,569:INFO:              joblib: 1.3.2
2025-06-21 14:57:40,569:INFO:             sklearn: 1.4.2
2025-06-21 14:57:40,570:INFO:                pyod: 2.0.5
2025-06-21 14:57:40,570:INFO:            imblearn: 0.13.0
2025-06-21 14:57:40,570:INFO:   category_encoders: 2.7.0
2025-06-21 14:57:40,570:INFO:            lightgbm: 4.6.0
2025-06-21 14:57:40,570:INFO:               numba: 0.61.0
2025-06-21 14:57:40,571:INFO:            requests: 2.32.3
2025-06-21 14:57:40,571:INFO:          matplotlib: 3.7.1
2025-06-21 14:57:40,571:INFO:          scikitplot: 0.3.7
2025-06-21 14:57:40,571:INFO:         yellowbrick: 1.5
2025-06-21 14:57:40,571:INFO:              plotly: 6.1.2
2025-06-21 14:57:40,571:INFO:    plotly-resampler: Not installed
2025-06-21 14:57:40,572:INFO:             kaleido: 0.2.1
2025-06-21 14:57:40,572:INFO:           schemdraw: 0.15
2025-06-21 14:57:40,572:INFO:         statsmodels: 0.14.4
2025-06-21 14:57:40,572:INFO:              sktime: 0.26.0
2025-06-21 14:57:40,572:INFO:               tbats: 1.1.3
2025-06-21 14:57:40,572:INFO:            pmdarima: 2.0.4
2025-06-21 14:57:40,572:INFO:              psutil: 7.0.0
2025-06-21 14:57:40,572:INFO:          markupsafe: 2.1.2
2025-06-21 14:57:40,574:INFO:             pickle5: Not installed
2025-06-21 14:57:40,574:INFO:         cloudpickle: 3.1.1
2025-06-21 14:57:40,574:INFO:         deprecation: 2.1.0
2025-06-21 14:57:40,574:INFO:              xxhash: 3.5.0
2025-06-21 14:57:40,574:INFO:           wurlitzer: Not installed
2025-06-21 14:57:40,574:INFO:PyCaret optional dependencies:
2025-06-21 14:57:40,575:INFO:                shap: 0.44.1
2025-06-21 14:57:40,575:INFO:           interpret: 0.6.9
2025-06-21 14:57:40,575:INFO:                umap: 0.5.7
2025-06-21 14:57:40,575:INFO:     ydata_profiling: 4.16.1
2025-06-21 14:57:40,575:INFO:  explainerdashboard: 0.4.8
2025-06-21 14:57:40,575:INFO:             autoviz: Not installed
2025-06-21 14:57:40,576:INFO:           fairlearn: 0.7.0
2025-06-21 14:57:40,576:INFO:          deepchecks: Not installed
2025-06-21 14:57:40,576:INFO:             xgboost: 3.0.2
2025-06-21 14:57:40,576:INFO:            catboost: 1.2.8
2025-06-21 14:57:40,576:INFO:              kmodes: 0.12.2
2025-06-21 14:57:40,589:INFO:             mlxtend: 0.23.4
2025-06-21 14:57:40,589:INFO:       statsforecast: 1.5.0
2025-06-21 14:57:40,590:INFO:        tune_sklearn: Not installed
2025-06-21 14:57:40,590:INFO:                 ray: Not installed
2025-06-21 14:57:40,590:INFO:            hyperopt: 0.2.7
2025-06-21 14:57:40,590:INFO:              optuna: 4.3.0
2025-06-21 14:57:40,590:INFO:               skopt: 0.10.2
2025-06-21 14:57:40,591:INFO:              mlflow: 2.22.0
2025-06-21 14:57:40,591:INFO:              gradio: 5.32.0
2025-06-21 14:57:40,591:INFO:             fastapi: 0.115.12
2025-06-21 14:57:40,591:INFO:             uvicorn: 0.34.3
2025-06-21 14:57:40,591:INFO:              m2cgen: 0.10.0
2025-06-21 14:57:40,594:INFO:           evidently: 0.4.40
2025-06-21 14:57:40,594:INFO:               fugue: 0.8.5
2025-06-21 14:57:40,594:INFO:           streamlit: Not installed
2025-06-21 14:57:40,594:INFO:             prophet: Not installed
2025-06-21 14:57:40,594:INFO:None
2025-06-21 14:57:40,594:INFO:Set up data.
2025-06-21 14:57:40,874:INFO:Set up folding strategy.
2025-06-21 14:57:40,874:INFO:Set up train/test split.
2025-06-21 14:57:41,021:INFO:Set up index.
2025-06-21 14:57:41,023:INFO:Assigning column types.
2025-06-21 14:57:41,114:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-21 14:57:41,115:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-21 14:57:41,127:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 14:57:41,141:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 14:57:41,349:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:57:41,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:57:41,489:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:57:41,496:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:57:41,498:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-21 14:57:41,509:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 14:57:41,522:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 14:57:41,731:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:57:41,834:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:57:41,836:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:57:41,845:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:57:41,847:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-21 14:57:41,857:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 14:57:41,866:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 14:57:42,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:57:42,170:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:57:42,171:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:57:42,177:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:57:42,187:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 14:57:42,199:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 14:57:42,411:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:57:42,525:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:57:42,527:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:57:42,533:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:57:42,535:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-21 14:57:42,560:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 14:57:42,756:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:57:42,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:57:42,868:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:57:42,877:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:57:42,900:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 14:57:43,115:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:57:43,231:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:57:43,232:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:57:43,241:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:57:43,243:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-21 14:57:43,474:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:57:43,598:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:57:43,599:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:57:43,607:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:57:43,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:57:43,964:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 14:57:43,965:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:57:43,973:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:57:43,975:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-21 14:57:44,195:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:57:44,323:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:57:44,329:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:57:44,592:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 14:57:44,697:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:57:44,704:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:57:44,707:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-21 14:57:45,078:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:57:45,084:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:57:45,440:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:57:45,447:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:57:45,450:INFO:Preparing preprocessing pipeline...
2025-06-21 14:57:45,451:INFO:Set up simple imputation.
2025-06-21 14:57:45,451:INFO:Set up removing multicollinearity.
2025-06-21 14:57:45,465:INFO:Set up column name cleaning.
2025-06-21 14:57:45,868:INFO:Finished creating preprocessing pipeline.
2025-06-21 14:57:45,891:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-21 14:57:45,891:INFO:Creating final display dataframe.
2025-06-21 14:57:46,604:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4200, 147)
4        Transformed data shape        (4200, 95)
5   Transformed train set shape        (3360, 95)
6    Transformed test set shape         (840, 95)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              a78f
2025-06-21 14:57:46,987:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:57:46,993:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:57:47,326:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 14:57:47,332:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 14:57:47,334:INFO:setup() successfully completed in 6.9s...............
2025-06-21 14:57:47,335:INFO:Initializing compare_models()
2025-06-21 14:57:47,335:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-06-21 14:57:47,335:INFO:Checking exceptions
2025-06-21 14:57:47,371:INFO:Preparing display monitor
2025-06-21 14:57:47,468:INFO:Initializing Linear Regression
2025-06-21 14:57:47,471:INFO:Total runtime is 5.004008611043294e-05 minutes
2025-06-21 14:57:47,494:INFO:SubProcess create_model() called ==================================
2025-06-21 14:57:47,495:INFO:Initializing create_model()
2025-06-21 14:57:47,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:57:47,496:INFO:Checking exceptions
2025-06-21 14:57:47,497:INFO:Importing libraries
2025-06-21 14:57:47,498:INFO:Copying training dataset
2025-06-21 14:57:47,610:INFO:Defining folds
2025-06-21 14:57:47,610:INFO:Declaring metric variables
2025-06-21 14:57:47,629:INFO:Importing untrained model
2025-06-21 14:57:47,645:INFO:Linear Regression Imported successfully
2025-06-21 14:57:47,676:INFO:Starting cross validation
2025-06-21 14:57:47,682:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:57:48,911:INFO:Calculating mean and std
2025-06-21 14:57:48,914:INFO:Creating metrics dataframe
2025-06-21 14:57:48,918:INFO:Uploading results into container
2025-06-21 14:57:48,920:INFO:Uploading model into container now
2025-06-21 14:57:48,921:INFO:_master_model_container: 1
2025-06-21 14:57:48,922:INFO:_display_container: 2
2025-06-21 14:57:48,923:INFO:LinearRegression(n_jobs=-1)
2025-06-21 14:57:48,923:INFO:create_model() successfully completed......................................
2025-06-21 14:57:49,661:INFO:SubProcess create_model() end ==================================
2025-06-21 14:57:49,661:INFO:Creating metrics dataframe
2025-06-21 14:57:49,682:INFO:Initializing Lasso Regression
2025-06-21 14:57:49,682:INFO:Total runtime is 0.03689377307891846 minutes
2025-06-21 14:57:49,698:INFO:SubProcess create_model() called ==================================
2025-06-21 14:57:49,699:INFO:Initializing create_model()
2025-06-21 14:57:49,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:57:49,700:INFO:Checking exceptions
2025-06-21 14:57:49,700:INFO:Importing libraries
2025-06-21 14:57:49,701:INFO:Copying training dataset
2025-06-21 14:57:49,789:INFO:Defining folds
2025-06-21 14:57:49,790:INFO:Declaring metric variables
2025-06-21 14:57:49,806:INFO:Importing untrained model
2025-06-21 14:57:49,822:INFO:Lasso Regression Imported successfully
2025-06-21 14:57:49,856:INFO:Starting cross validation
2025-06-21 14:57:49,862:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:57:51,954:INFO:Calculating mean and std
2025-06-21 14:57:51,957:INFO:Creating metrics dataframe
2025-06-21 14:57:51,962:INFO:Uploading results into container
2025-06-21 14:57:51,964:INFO:Uploading model into container now
2025-06-21 14:57:51,965:INFO:_master_model_container: 2
2025-06-21 14:57:51,965:INFO:_display_container: 2
2025-06-21 14:57:51,966:INFO:Lasso(random_state=123)
2025-06-21 14:57:51,966:INFO:create_model() successfully completed......................................
2025-06-21 14:57:52,642:INFO:SubProcess create_model() end ==================================
2025-06-21 14:57:52,643:INFO:Creating metrics dataframe
2025-06-21 14:57:52,657:INFO:Initializing Ridge Regression
2025-06-21 14:57:52,657:INFO:Total runtime is 0.08648697932561239 minutes
2025-06-21 14:57:52,670:INFO:SubProcess create_model() called ==================================
2025-06-21 14:57:52,670:INFO:Initializing create_model()
2025-06-21 14:57:52,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:57:52,673:INFO:Checking exceptions
2025-06-21 14:57:52,673:INFO:Importing libraries
2025-06-21 14:57:52,675:INFO:Copying training dataset
2025-06-21 14:57:52,757:INFO:Defining folds
2025-06-21 14:57:52,757:INFO:Declaring metric variables
2025-06-21 14:57:52,770:INFO:Importing untrained model
2025-06-21 14:57:52,784:INFO:Ridge Regression Imported successfully
2025-06-21 14:57:52,813:INFO:Starting cross validation
2025-06-21 14:57:52,817:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:57:53,639:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.80305e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-21 14:57:53,886:INFO:Calculating mean and std
2025-06-21 14:57:53,889:INFO:Creating metrics dataframe
2025-06-21 14:57:53,894:INFO:Uploading results into container
2025-06-21 14:57:53,895:INFO:Uploading model into container now
2025-06-21 14:57:53,897:INFO:_master_model_container: 3
2025-06-21 14:57:53,897:INFO:_display_container: 2
2025-06-21 14:57:53,898:INFO:Ridge(random_state=123)
2025-06-21 14:57:53,898:INFO:create_model() successfully completed......................................
2025-06-21 14:57:54,546:INFO:SubProcess create_model() end ==================================
2025-06-21 14:57:54,546:INFO:Creating metrics dataframe
2025-06-21 14:57:54,567:INFO:Initializing Elastic Net
2025-06-21 14:57:54,567:INFO:Total runtime is 0.11830551226933797 minutes
2025-06-21 14:57:54,580:INFO:SubProcess create_model() called ==================================
2025-06-21 14:57:54,581:INFO:Initializing create_model()
2025-06-21 14:57:54,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:57:54,582:INFO:Checking exceptions
2025-06-21 14:57:54,582:INFO:Importing libraries
2025-06-21 14:57:54,583:INFO:Copying training dataset
2025-06-21 14:57:54,672:INFO:Defining folds
2025-06-21 14:57:54,673:INFO:Declaring metric variables
2025-06-21 14:57:54,686:INFO:Importing untrained model
2025-06-21 14:57:54,698:INFO:Elastic Net Imported successfully
2025-06-21 14:57:54,724:INFO:Starting cross validation
2025-06-21 14:57:54,729:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:57:55,866:INFO:Calculating mean and std
2025-06-21 14:57:55,869:INFO:Creating metrics dataframe
2025-06-21 14:57:55,874:INFO:Uploading results into container
2025-06-21 14:57:55,875:INFO:Uploading model into container now
2025-06-21 14:57:55,876:INFO:_master_model_container: 4
2025-06-21 14:57:55,877:INFO:_display_container: 2
2025-06-21 14:57:55,877:INFO:ElasticNet(random_state=123)
2025-06-21 14:57:55,878:INFO:create_model() successfully completed......................................
2025-06-21 14:57:56,482:INFO:SubProcess create_model() end ==================================
2025-06-21 14:57:56,482:INFO:Creating metrics dataframe
2025-06-21 14:57:56,500:INFO:Initializing Least Angle Regression
2025-06-21 14:57:56,501:INFO:Total runtime is 0.1505387822786967 minutes
2025-06-21 14:57:56,514:INFO:SubProcess create_model() called ==================================
2025-06-21 14:57:56,515:INFO:Initializing create_model()
2025-06-21 14:57:56,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:57:56,517:INFO:Checking exceptions
2025-06-21 14:57:56,517:INFO:Importing libraries
2025-06-21 14:57:56,518:INFO:Copying training dataset
2025-06-21 14:57:56,596:INFO:Defining folds
2025-06-21 14:57:56,597:INFO:Declaring metric variables
2025-06-21 14:57:56,616:INFO:Importing untrained model
2025-06-21 14:57:56,633:INFO:Least Angle Regression Imported successfully
2025-06-21 14:57:56,668:INFO:Starting cross validation
2025-06-21 14:57:56,675:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:57:57,869:INFO:Calculating mean and std
2025-06-21 14:57:57,872:INFO:Creating metrics dataframe
2025-06-21 14:57:57,876:INFO:Uploading results into container
2025-06-21 14:57:57,877:INFO:Uploading model into container now
2025-06-21 14:57:57,879:INFO:_master_model_container: 5
2025-06-21 14:57:57,879:INFO:_display_container: 2
2025-06-21 14:57:57,881:INFO:Lars(random_state=123)
2025-06-21 14:57:57,881:INFO:create_model() successfully completed......................................
2025-06-21 14:57:58,511:INFO:SubProcess create_model() end ==================================
2025-06-21 14:57:58,512:INFO:Creating metrics dataframe
2025-06-21 14:57:58,532:INFO:Initializing Lasso Least Angle Regression
2025-06-21 14:57:58,532:INFO:Total runtime is 0.18440206845601398 minutes
2025-06-21 14:57:58,548:INFO:SubProcess create_model() called ==================================
2025-06-21 14:57:58,549:INFO:Initializing create_model()
2025-06-21 14:57:58,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:57:58,550:INFO:Checking exceptions
2025-06-21 14:57:58,550:INFO:Importing libraries
2025-06-21 14:57:58,551:INFO:Copying training dataset
2025-06-21 14:57:58,625:INFO:Defining folds
2025-06-21 14:57:58,625:INFO:Declaring metric variables
2025-06-21 14:57:58,639:INFO:Importing untrained model
2025-06-21 14:57:58,653:INFO:Lasso Least Angle Regression Imported successfully
2025-06-21 14:57:58,683:INFO:Starting cross validation
2025-06-21 14:57:58,688:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:57:59,740:INFO:Calculating mean and std
2025-06-21 14:57:59,743:INFO:Creating metrics dataframe
2025-06-21 14:57:59,747:INFO:Uploading results into container
2025-06-21 14:57:59,748:INFO:Uploading model into container now
2025-06-21 14:57:59,749:INFO:_master_model_container: 6
2025-06-21 14:57:59,750:INFO:_display_container: 2
2025-06-21 14:57:59,751:INFO:LassoLars(random_state=123)
2025-06-21 14:57:59,751:INFO:create_model() successfully completed......................................
2025-06-21 14:58:00,617:INFO:SubProcess create_model() end ==================================
2025-06-21 14:58:00,618:INFO:Creating metrics dataframe
2025-06-21 14:58:00,643:INFO:Initializing Orthogonal Matching Pursuit
2025-06-21 14:58:00,644:INFO:Total runtime is 0.21959712505340573 minutes
2025-06-21 14:58:00,658:INFO:SubProcess create_model() called ==================================
2025-06-21 14:58:00,659:INFO:Initializing create_model()
2025-06-21 14:58:00,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:58:00,660:INFO:Checking exceptions
2025-06-21 14:58:00,660:INFO:Importing libraries
2025-06-21 14:58:00,661:INFO:Copying training dataset
2025-06-21 14:58:00,744:INFO:Defining folds
2025-06-21 14:58:00,744:INFO:Declaring metric variables
2025-06-21 14:58:00,760:INFO:Importing untrained model
2025-06-21 14:58:00,772:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-21 14:58:00,800:INFO:Starting cross validation
2025-06-21 14:58:00,805:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:58:02,101:INFO:Calculating mean and std
2025-06-21 14:58:02,104:INFO:Creating metrics dataframe
2025-06-21 14:58:02,108:INFO:Uploading results into container
2025-06-21 14:58:02,109:INFO:Uploading model into container now
2025-06-21 14:58:02,110:INFO:_master_model_container: 7
2025-06-21 14:58:02,111:INFO:_display_container: 2
2025-06-21 14:58:02,112:INFO:OrthogonalMatchingPursuit()
2025-06-21 14:58:02,112:INFO:create_model() successfully completed......................................
2025-06-21 14:58:02,752:INFO:SubProcess create_model() end ==================================
2025-06-21 14:58:02,752:INFO:Creating metrics dataframe
2025-06-21 14:58:02,773:INFO:Initializing Bayesian Ridge
2025-06-21 14:58:02,773:INFO:Total runtime is 0.25508569876352943 minutes
2025-06-21 14:58:02,784:INFO:SubProcess create_model() called ==================================
2025-06-21 14:58:02,785:INFO:Initializing create_model()
2025-06-21 14:58:02,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:58:02,786:INFO:Checking exceptions
2025-06-21 14:58:02,787:INFO:Importing libraries
2025-06-21 14:58:02,787:INFO:Copying training dataset
2025-06-21 14:58:02,871:INFO:Defining folds
2025-06-21 14:58:02,872:INFO:Declaring metric variables
2025-06-21 14:58:02,885:INFO:Importing untrained model
2025-06-21 14:58:02,898:INFO:Bayesian Ridge Imported successfully
2025-06-21 14:58:02,922:INFO:Starting cross validation
2025-06-21 14:58:02,927:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:58:04,531:INFO:Calculating mean and std
2025-06-21 14:58:04,533:INFO:Creating metrics dataframe
2025-06-21 14:58:04,538:INFO:Uploading results into container
2025-06-21 14:58:04,539:INFO:Uploading model into container now
2025-06-21 14:58:04,540:INFO:_master_model_container: 8
2025-06-21 14:58:04,541:INFO:_display_container: 2
2025-06-21 14:58:04,542:INFO:BayesianRidge()
2025-06-21 14:58:04,542:INFO:create_model() successfully completed......................................
2025-06-21 14:58:05,193:INFO:SubProcess create_model() end ==================================
2025-06-21 14:58:05,194:INFO:Creating metrics dataframe
2025-06-21 14:58:05,222:INFO:Initializing Passive Aggressive Regressor
2025-06-21 14:58:05,223:INFO:Total runtime is 0.2958883206049601 minutes
2025-06-21 14:58:05,236:INFO:SubProcess create_model() called ==================================
2025-06-21 14:58:05,237:INFO:Initializing create_model()
2025-06-21 14:58:05,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:58:05,238:INFO:Checking exceptions
2025-06-21 14:58:05,239:INFO:Importing libraries
2025-06-21 14:58:05,239:INFO:Copying training dataset
2025-06-21 14:58:05,338:INFO:Defining folds
2025-06-21 14:58:05,338:INFO:Declaring metric variables
2025-06-21 14:58:05,354:INFO:Importing untrained model
2025-06-21 14:58:05,369:INFO:Passive Aggressive Regressor Imported successfully
2025-06-21 14:58:05,397:INFO:Starting cross validation
2025-06-21 14:58:05,404:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:58:06,493:INFO:Calculating mean and std
2025-06-21 14:58:06,496:INFO:Creating metrics dataframe
2025-06-21 14:58:06,500:INFO:Uploading results into container
2025-06-21 14:58:06,501:INFO:Uploading model into container now
2025-06-21 14:58:06,502:INFO:_master_model_container: 9
2025-06-21 14:58:06,502:INFO:_display_container: 2
2025-06-21 14:58:06,503:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-21 14:58:06,504:INFO:create_model() successfully completed......................................
2025-06-21 14:58:07,118:INFO:SubProcess create_model() end ==================================
2025-06-21 14:58:07,119:INFO:Creating metrics dataframe
2025-06-21 14:58:07,141:INFO:Initializing Huber Regressor
2025-06-21 14:58:07,141:INFO:Total runtime is 0.32787081400553386 minutes
2025-06-21 14:58:07,159:INFO:SubProcess create_model() called ==================================
2025-06-21 14:58:07,160:INFO:Initializing create_model()
2025-06-21 14:58:07,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:58:07,162:INFO:Checking exceptions
2025-06-21 14:58:07,162:INFO:Importing libraries
2025-06-21 14:58:07,162:INFO:Copying training dataset
2025-06-21 14:58:07,245:INFO:Defining folds
2025-06-21 14:58:07,246:INFO:Declaring metric variables
2025-06-21 14:58:07,261:INFO:Importing untrained model
2025-06-21 14:58:07,279:INFO:Huber Regressor Imported successfully
2025-06-21 14:58:07,307:INFO:Starting cross validation
2025-06-21 14:58:07,312:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:58:09,278:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-21 14:58:09,309:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-21 14:58:09,333:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-21 14:58:09,348:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-21 14:58:10,101:WARNING:c:\Users\sayee\miniconda3\envs\formation_env\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-21 14:58:10,181:INFO:Calculating mean and std
2025-06-21 14:58:10,184:INFO:Creating metrics dataframe
2025-06-21 14:58:10,191:INFO:Uploading results into container
2025-06-21 14:58:10,192:INFO:Uploading model into container now
2025-06-21 14:58:10,193:INFO:_master_model_container: 10
2025-06-21 14:58:10,193:INFO:_display_container: 2
2025-06-21 14:58:10,194:INFO:HuberRegressor()
2025-06-21 14:58:10,195:INFO:create_model() successfully completed......................................
2025-06-21 14:58:10,839:INFO:SubProcess create_model() end ==================================
2025-06-21 14:58:10,839:INFO:Creating metrics dataframe
2025-06-21 14:58:10,859:INFO:Initializing K Neighbors Regressor
2025-06-21 14:58:10,859:INFO:Total runtime is 0.389837392171224 minutes
2025-06-21 14:58:10,873:INFO:SubProcess create_model() called ==================================
2025-06-21 14:58:10,874:INFO:Initializing create_model()
2025-06-21 14:58:10,874:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:58:10,874:INFO:Checking exceptions
2025-06-21 14:58:10,875:INFO:Importing libraries
2025-06-21 14:58:10,876:INFO:Copying training dataset
2025-06-21 14:58:10,964:INFO:Defining folds
2025-06-21 14:58:10,964:INFO:Declaring metric variables
2025-06-21 14:58:10,978:INFO:Importing untrained model
2025-06-21 14:58:10,995:INFO:K Neighbors Regressor Imported successfully
2025-06-21 14:58:11,021:INFO:Starting cross validation
2025-06-21 14:58:11,026:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:58:12,213:INFO:Calculating mean and std
2025-06-21 14:58:12,216:INFO:Creating metrics dataframe
2025-06-21 14:58:12,220:INFO:Uploading results into container
2025-06-21 14:58:12,221:INFO:Uploading model into container now
2025-06-21 14:58:12,223:INFO:_master_model_container: 11
2025-06-21 14:58:12,223:INFO:_display_container: 2
2025-06-21 14:58:12,224:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-21 14:58:12,225:INFO:create_model() successfully completed......................................
2025-06-21 14:58:12,832:INFO:SubProcess create_model() end ==================================
2025-06-21 14:58:12,832:INFO:Creating metrics dataframe
2025-06-21 14:58:12,855:INFO:Initializing Decision Tree Regressor
2025-06-21 14:58:12,855:INFO:Total runtime is 0.4231037457784017 minutes
2025-06-21 14:58:12,867:INFO:SubProcess create_model() called ==================================
2025-06-21 14:58:12,868:INFO:Initializing create_model()
2025-06-21 14:58:12,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:58:12,869:INFO:Checking exceptions
2025-06-21 14:58:12,870:INFO:Importing libraries
2025-06-21 14:58:12,870:INFO:Copying training dataset
2025-06-21 14:58:12,944:INFO:Defining folds
2025-06-21 14:58:12,944:INFO:Declaring metric variables
2025-06-21 14:58:12,962:INFO:Importing untrained model
2025-06-21 14:58:12,974:INFO:Decision Tree Regressor Imported successfully
2025-06-21 14:58:13,002:INFO:Starting cross validation
2025-06-21 14:58:13,005:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:58:14,310:INFO:Calculating mean and std
2025-06-21 14:58:14,313:INFO:Creating metrics dataframe
2025-06-21 14:58:14,318:INFO:Uploading results into container
2025-06-21 14:58:14,320:INFO:Uploading model into container now
2025-06-21 14:58:14,321:INFO:_master_model_container: 12
2025-06-21 14:58:14,322:INFO:_display_container: 2
2025-06-21 14:58:14,323:INFO:DecisionTreeRegressor(random_state=123)
2025-06-21 14:58:14,323:INFO:create_model() successfully completed......................................
2025-06-21 14:58:14,946:INFO:SubProcess create_model() end ==================================
2025-06-21 14:58:14,946:INFO:Creating metrics dataframe
2025-06-21 14:58:14,972:INFO:Initializing Random Forest Regressor
2025-06-21 14:58:14,972:INFO:Total runtime is 0.45838740666707356 minutes
2025-06-21 14:58:14,985:INFO:SubProcess create_model() called ==================================
2025-06-21 14:58:14,986:INFO:Initializing create_model()
2025-06-21 14:58:14,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:58:14,986:INFO:Checking exceptions
2025-06-21 14:58:14,986:INFO:Importing libraries
2025-06-21 14:58:14,987:INFO:Copying training dataset
2025-06-21 14:58:15,081:INFO:Defining folds
2025-06-21 14:58:15,082:INFO:Declaring metric variables
2025-06-21 14:58:15,095:INFO:Importing untrained model
2025-06-21 14:58:15,110:INFO:Random Forest Regressor Imported successfully
2025-06-21 14:58:15,138:INFO:Starting cross validation
2025-06-21 14:58:15,143:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:58:26,461:INFO:Calculating mean and std
2025-06-21 14:58:26,464:INFO:Creating metrics dataframe
2025-06-21 14:58:26,469:INFO:Uploading results into container
2025-06-21 14:58:26,470:INFO:Uploading model into container now
2025-06-21 14:58:26,471:INFO:_master_model_container: 13
2025-06-21 14:58:26,472:INFO:_display_container: 2
2025-06-21 14:58:26,472:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-21 14:58:26,473:INFO:create_model() successfully completed......................................
2025-06-21 14:58:27,147:INFO:SubProcess create_model() end ==================================
2025-06-21 14:58:27,148:INFO:Creating metrics dataframe
2025-06-21 14:58:27,177:INFO:Initializing Extra Trees Regressor
2025-06-21 14:58:27,177:INFO:Total runtime is 0.6618141849835714 minutes
2025-06-21 14:58:27,195:INFO:SubProcess create_model() called ==================================
2025-06-21 14:58:27,196:INFO:Initializing create_model()
2025-06-21 14:58:27,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:58:27,197:INFO:Checking exceptions
2025-06-21 14:58:27,197:INFO:Importing libraries
2025-06-21 14:58:27,197:INFO:Copying training dataset
2025-06-21 14:58:27,304:INFO:Defining folds
2025-06-21 14:58:27,304:INFO:Declaring metric variables
2025-06-21 14:58:27,321:INFO:Importing untrained model
2025-06-21 14:58:27,343:INFO:Extra Trees Regressor Imported successfully
2025-06-21 14:58:27,375:INFO:Starting cross validation
2025-06-21 14:58:27,381:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:58:35,426:INFO:Calculating mean and std
2025-06-21 14:58:35,428:INFO:Creating metrics dataframe
2025-06-21 14:58:35,433:INFO:Uploading results into container
2025-06-21 14:58:35,434:INFO:Uploading model into container now
2025-06-21 14:58:35,435:INFO:_master_model_container: 14
2025-06-21 14:58:35,436:INFO:_display_container: 2
2025-06-21 14:58:35,437:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-21 14:58:35,437:INFO:create_model() successfully completed......................................
2025-06-21 14:58:36,011:INFO:SubProcess create_model() end ==================================
2025-06-21 14:58:36,012:INFO:Creating metrics dataframe
2025-06-21 14:58:36,033:INFO:Initializing AdaBoost Regressor
2025-06-21 14:58:36,034:INFO:Total runtime is 0.809434421857198 minutes
2025-06-21 14:58:36,045:INFO:SubProcess create_model() called ==================================
2025-06-21 14:58:36,046:INFO:Initializing create_model()
2025-06-21 14:58:36,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:58:36,047:INFO:Checking exceptions
2025-06-21 14:58:36,048:INFO:Importing libraries
2025-06-21 14:58:36,048:INFO:Copying training dataset
2025-06-21 14:58:36,120:INFO:Defining folds
2025-06-21 14:58:36,121:INFO:Declaring metric variables
2025-06-21 14:58:36,132:INFO:Importing untrained model
2025-06-21 14:58:36,144:INFO:AdaBoost Regressor Imported successfully
2025-06-21 14:58:36,166:INFO:Starting cross validation
2025-06-21 14:58:36,170:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:58:38,717:INFO:Calculating mean and std
2025-06-21 14:58:38,719:INFO:Creating metrics dataframe
2025-06-21 14:58:38,724:INFO:Uploading results into container
2025-06-21 14:58:38,726:INFO:Uploading model into container now
2025-06-21 14:58:38,727:INFO:_master_model_container: 15
2025-06-21 14:58:38,727:INFO:_display_container: 2
2025-06-21 14:58:38,728:INFO:AdaBoostRegressor(random_state=123)
2025-06-21 14:58:38,729:INFO:create_model() successfully completed......................................
2025-06-21 14:58:39,298:INFO:SubProcess create_model() end ==================================
2025-06-21 14:58:39,298:INFO:Creating metrics dataframe
2025-06-21 14:58:39,322:INFO:Initializing Gradient Boosting Regressor
2025-06-21 14:58:39,322:INFO:Total runtime is 0.8642234802246094 minutes
2025-06-21 14:58:39,334:INFO:SubProcess create_model() called ==================================
2025-06-21 14:58:39,335:INFO:Initializing create_model()
2025-06-21 14:58:39,335:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:58:39,336:INFO:Checking exceptions
2025-06-21 14:58:39,337:INFO:Importing libraries
2025-06-21 14:58:39,337:INFO:Copying training dataset
2025-06-21 14:58:39,405:INFO:Defining folds
2025-06-21 14:58:39,405:INFO:Declaring metric variables
2025-06-21 14:58:39,418:INFO:Importing untrained model
2025-06-21 14:58:39,432:INFO:Gradient Boosting Regressor Imported successfully
2025-06-21 14:58:39,458:INFO:Starting cross validation
2025-06-21 14:58:39,462:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:58:43,703:INFO:Calculating mean and std
2025-06-21 14:58:43,705:INFO:Creating metrics dataframe
2025-06-21 14:58:43,710:INFO:Uploading results into container
2025-06-21 14:58:43,712:INFO:Uploading model into container now
2025-06-21 14:58:43,713:INFO:_master_model_container: 16
2025-06-21 14:58:43,713:INFO:_display_container: 2
2025-06-21 14:58:43,714:INFO:GradientBoostingRegressor(random_state=123)
2025-06-21 14:58:43,715:INFO:create_model() successfully completed......................................
2025-06-21 14:58:44,281:INFO:SubProcess create_model() end ==================================
2025-06-21 14:58:44,281:INFO:Creating metrics dataframe
2025-06-21 14:58:44,301:INFO:Initializing Extreme Gradient Boosting
2025-06-21 14:58:44,301:INFO:Total runtime is 0.9472129543622335 minutes
2025-06-21 14:58:44,311:INFO:SubProcess create_model() called ==================================
2025-06-21 14:58:44,312:INFO:Initializing create_model()
2025-06-21 14:58:44,312:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:58:44,313:INFO:Checking exceptions
2025-06-21 14:58:44,313:INFO:Importing libraries
2025-06-21 14:58:44,314:INFO:Copying training dataset
2025-06-21 14:58:44,386:INFO:Defining folds
2025-06-21 14:58:44,387:INFO:Declaring metric variables
2025-06-21 14:58:44,400:INFO:Importing untrained model
2025-06-21 14:58:44,412:INFO:Extreme Gradient Boosting Imported successfully
2025-06-21 14:58:44,454:INFO:Starting cross validation
2025-06-21 14:58:44,460:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:58:47,681:INFO:Calculating mean and std
2025-06-21 14:58:47,683:INFO:Creating metrics dataframe
2025-06-21 14:58:47,687:INFO:Uploading results into container
2025-06-21 14:58:47,688:INFO:Uploading model into container now
2025-06-21 14:58:47,689:INFO:_master_model_container: 17
2025-06-21 14:58:47,689:INFO:_display_container: 2
2025-06-21 14:58:47,692:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-06-21 14:58:47,692:INFO:create_model() successfully completed......................................
2025-06-21 14:58:48,244:INFO:SubProcess create_model() end ==================================
2025-06-21 14:58:48,244:INFO:Creating metrics dataframe
2025-06-21 14:58:48,277:INFO:Initializing Light Gradient Boosting Machine
2025-06-21 14:58:48,277:INFO:Total runtime is 1.0134845137596131 minutes
2025-06-21 14:58:48,288:INFO:SubProcess create_model() called ==================================
2025-06-21 14:58:48,289:INFO:Initializing create_model()
2025-06-21 14:58:48,289:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:58:48,290:INFO:Checking exceptions
2025-06-21 14:58:48,290:INFO:Importing libraries
2025-06-21 14:58:48,291:INFO:Copying training dataset
2025-06-21 14:58:48,383:INFO:Defining folds
2025-06-21 14:58:48,384:INFO:Declaring metric variables
2025-06-21 14:58:48,396:INFO:Importing untrained model
2025-06-21 14:58:48,408:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-21 14:58:48,432:INFO:Starting cross validation
2025-06-21 14:58:48,437:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:58:51,050:INFO:Calculating mean and std
2025-06-21 14:58:51,053:INFO:Creating metrics dataframe
2025-06-21 14:58:51,058:INFO:Uploading results into container
2025-06-21 14:58:51,060:INFO:Uploading model into container now
2025-06-21 14:58:51,061:INFO:_master_model_container: 18
2025-06-21 14:58:51,061:INFO:_display_container: 2
2025-06-21 14:58:51,062:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-21 14:58:51,063:INFO:create_model() successfully completed......................................
2025-06-21 14:58:51,643:INFO:SubProcess create_model() end ==================================
2025-06-21 14:58:51,643:INFO:Creating metrics dataframe
2025-06-21 14:58:51,666:INFO:Initializing CatBoost Regressor
2025-06-21 14:58:51,666:INFO:Total runtime is 1.069955364863078 minutes
2025-06-21 14:58:51,676:INFO:SubProcess create_model() called ==================================
2025-06-21 14:58:51,677:INFO:Initializing create_model()
2025-06-21 14:58:51,677:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:58:51,678:INFO:Checking exceptions
2025-06-21 14:58:51,678:INFO:Importing libraries
2025-06-21 14:58:51,679:INFO:Copying training dataset
2025-06-21 14:58:51,739:INFO:Defining folds
2025-06-21 14:58:51,739:INFO:Declaring metric variables
2025-06-21 14:58:51,749:INFO:Importing untrained model
2025-06-21 14:58:51,760:INFO:CatBoost Regressor Imported successfully
2025-06-21 14:58:51,784:INFO:Starting cross validation
2025-06-21 14:58:51,789:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:59:23,662:INFO:Calculating mean and std
2025-06-21 14:59:23,666:INFO:Creating metrics dataframe
2025-06-21 14:59:23,670:INFO:Uploading results into container
2025-06-21 14:59:23,671:INFO:Uploading model into container now
2025-06-21 14:59:23,672:INFO:_master_model_container: 19
2025-06-21 14:59:23,673:INFO:_display_container: 2
2025-06-21 14:59:23,673:INFO:<catboost.core.CatBoostRegressor object at 0x0000020547C2F940>
2025-06-21 14:59:23,673:INFO:create_model() successfully completed......................................
2025-06-21 14:59:24,276:INFO:SubProcess create_model() end ==================================
2025-06-21 14:59:24,277:INFO:Creating metrics dataframe
2025-06-21 14:59:24,308:INFO:Initializing Dummy Regressor
2025-06-21 14:59:24,309:INFO:Total runtime is 1.614007906119029 minutes
2025-06-21 14:59:24,320:INFO:SubProcess create_model() called ==================================
2025-06-21 14:59:24,320:INFO:Initializing create_model()
2025-06-21 14:59:24,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:59:24,321:INFO:Checking exceptions
2025-06-21 14:59:24,322:INFO:Importing libraries
2025-06-21 14:59:24,322:INFO:Copying training dataset
2025-06-21 14:59:24,408:INFO:Defining folds
2025-06-21 14:59:24,409:INFO:Declaring metric variables
2025-06-21 14:59:24,423:INFO:Importing untrained model
2025-06-21 14:59:24,435:INFO:Dummy Regressor Imported successfully
2025-06-21 14:59:24,459:INFO:Starting cross validation
2025-06-21 14:59:24,463:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 14:59:25,402:INFO:Calculating mean and std
2025-06-21 14:59:25,405:INFO:Creating metrics dataframe
2025-06-21 14:59:25,409:INFO:Uploading results into container
2025-06-21 14:59:25,411:INFO:Uploading model into container now
2025-06-21 14:59:25,412:INFO:_master_model_container: 20
2025-06-21 14:59:25,412:INFO:_display_container: 2
2025-06-21 14:59:25,413:INFO:DummyRegressor()
2025-06-21 14:59:25,413:INFO:create_model() successfully completed......................................
2025-06-21 14:59:25,954:INFO:SubProcess create_model() end ==================================
2025-06-21 14:59:25,954:INFO:Creating metrics dataframe
2025-06-21 14:59:26,013:INFO:Initializing create_model()
2025-06-21 14:59:26,013:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:59:26,013:INFO:Checking exceptions
2025-06-21 14:59:26,018:INFO:Importing libraries
2025-06-21 14:59:26,019:INFO:Copying training dataset
2025-06-21 14:59:26,088:INFO:Defining folds
2025-06-21 14:59:26,088:INFO:Declaring metric variables
2025-06-21 14:59:26,089:INFO:Importing untrained model
2025-06-21 14:59:26,089:INFO:Declaring custom model
2025-06-21 14:59:26,091:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-21 14:59:26,094:INFO:Cross validation set to False
2025-06-21 14:59:26,095:INFO:Fitting Model
2025-06-21 14:59:26,521:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-21 14:59:26,529:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004647 seconds.
2025-06-21 14:59:26,529:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-21 14:59:26,530:INFO:[LightGBM] [Info] Total Bins 6217
2025-06-21 14:59:26,531:INFO:[LightGBM] [Info] Number of data points in the train set: 3360, number of used features: 94
2025-06-21 14:59:26,533:INFO:[LightGBM] [Info] Start training from score -0.412772
2025-06-21 14:59:26,862:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-21 14:59:26,862:INFO:create_model() successfully completed......................................
2025-06-21 14:59:27,549:INFO:Initializing create_model()
2025-06-21 14:59:27,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=<catboost.core.CatBoostRegressor object at 0x0000020547C2F940>, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:59:27,550:INFO:Checking exceptions
2025-06-21 14:59:27,553:INFO:Importing libraries
2025-06-21 14:59:27,554:INFO:Copying training dataset
2025-06-21 14:59:27,627:INFO:Defining folds
2025-06-21 14:59:27,627:INFO:Declaring metric variables
2025-06-21 14:59:27,627:INFO:Importing untrained model
2025-06-21 14:59:27,628:INFO:Declaring custom model
2025-06-21 14:59:27,628:INFO:CatBoost Regressor Imported successfully
2025-06-21 14:59:27,633:INFO:Cross validation set to False
2025-06-21 14:59:27,633:INFO:Fitting Model
2025-06-21 14:59:36,373:INFO:<catboost.core.CatBoostRegressor object at 0x0000020547C42D40>
2025-06-21 14:59:36,373:INFO:create_model() successfully completed......................................
2025-06-21 14:59:36,918:INFO:Initializing create_model()
2025-06-21 14:59:36,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 14:59:36,918:INFO:Checking exceptions
2025-06-21 14:59:36,922:INFO:Importing libraries
2025-06-21 14:59:36,923:INFO:Copying training dataset
2025-06-21 14:59:36,993:INFO:Defining folds
2025-06-21 14:59:36,994:INFO:Declaring metric variables
2025-06-21 14:59:36,994:INFO:Importing untrained model
2025-06-21 14:59:36,994:INFO:Declaring custom model
2025-06-21 14:59:36,995:INFO:Random Forest Regressor Imported successfully
2025-06-21 14:59:36,999:INFO:Cross validation set to False
2025-06-21 14:59:36,999:INFO:Fitting Model
2025-06-21 14:59:40,514:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-21 14:59:40,514:INFO:create_model() successfully completed......................................
2025-06-21 14:59:41,158:INFO:_master_model_container: 20
2025-06-21 14:59:41,159:INFO:_display_container: 2
2025-06-21 14:59:41,160:INFO:[LGBMRegressor(n_jobs=-1, random_state=123), <catboost.core.CatBoostRegressor object at 0x0000020547C42D40>, RandomForestRegressor(n_jobs=-1, random_state=123)]
2025-06-21 14:59:41,161:INFO:compare_models() successfully completed......................................
2025-06-21 14:59:41,163:INFO:Initializing tune_model()
2025-06-21 14:59:41,164:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>)
2025-06-21 14:59:41,164:INFO:Checking exceptions
2025-06-21 14:59:41,164:INFO:Soft dependency imported: skopt: 0.10.2
2025-06-21 14:59:41,222:INFO:Copying training dataset
2025-06-21 14:59:41,269:INFO:Checking base model
2025-06-21 14:59:41,269:INFO:Base model : Light Gradient Boosting Machine
2025-06-21 14:59:41,285:INFO:Declaring metric variables
2025-06-21 14:59:41,298:INFO:Defining Hyperparameters
2025-06-21 14:59:41,806:INFO:Tuning with n_jobs=-1
2025-06-21 14:59:41,819:INFO:Initializing skopt.BayesSearchCV
2025-06-21 15:00:07,413:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.8608120752388259), ('actual_estimator__bagging_freq', 1), ('actual_estimator__feature_fraction', 0.4284489606984907), ('actual_estimator__learning_rate', 0.016133245419918712), ('actual_estimator__min_child_samples', 95), ('actual_estimator__min_split_gain', 0.8209314243567916), ('actual_estimator__n_estimators', 239), ('actual_estimator__num_leaves', 183), ('actual_estimator__reg_alpha', 8.662569304197528e-07), ('actual_estimator__reg_lambda', 5.001062744294253e-06)])
2025-06-21 15:00:07,414:INFO:Hyperparameter search completed
2025-06-21 15:00:07,414:INFO:SubProcess create_model() called ==================================
2025-06-21 15:00:07,415:INFO:Initializing create_model()
2025-06-21 15:00:07,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020547C486A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.8608120752388259, 'bagging_freq': 1, 'feature_fraction': 0.4284489606984907, 'learning_rate': 0.016133245419918712, 'min_child_samples': 95, 'min_split_gain': 0.8209314243567916, 'n_estimators': 239, 'num_leaves': 183, 'reg_alpha': 8.662569304197528e-07, 'reg_lambda': 5.001062744294253e-06})
2025-06-21 15:00:07,416:INFO:Checking exceptions
2025-06-21 15:00:07,417:INFO:Importing libraries
2025-06-21 15:00:07,417:INFO:Copying training dataset
2025-06-21 15:00:07,474:INFO:Defining folds
2025-06-21 15:00:07,474:INFO:Declaring metric variables
2025-06-21 15:00:07,483:INFO:Importing untrained model
2025-06-21 15:00:07,483:INFO:Declaring custom model
2025-06-21 15:00:07,497:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-21 15:00:07,522:INFO:Starting cross validation
2025-06-21 15:00:07,527:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 15:00:09,715:INFO:Calculating mean and std
2025-06-21 15:00:09,718:INFO:Creating metrics dataframe
2025-06-21 15:00:09,737:INFO:Finalizing model
2025-06-21 15:00:10,168:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-21 15:00:10,168:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-21 15:00:10,169:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-21 15:00:10,188:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-21 15:00:10,189:INFO:[LightGBM] [Warning] feature_fraction is set=0.4284489606984907, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4284489606984907
2025-06-21 15:00:10,190:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8608120752388259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8608120752388259
2025-06-21 15:00:10,190:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-21 15:00:10,194:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003113 seconds.
2025-06-21 15:00:10,195:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-21 15:00:10,195:INFO:[LightGBM] [Info] Total Bins 6207
2025-06-21 15:00:10,199:INFO:[LightGBM] [Info] Number of data points in the train set: 3360, number of used features: 92
2025-06-21 15:00:10,200:INFO:[LightGBM] [Info] Start training from score -0.412772
2025-06-21 15:00:10,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-21 15:00:10,541:INFO:Uploading results into container
2025-06-21 15:00:10,543:INFO:Uploading model into container now
2025-06-21 15:00:10,544:INFO:_master_model_container: 21
2025-06-21 15:00:10,545:INFO:_display_container: 3
2025-06-21 15:00:10,547:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06)
2025-06-21 15:00:10,547:INFO:create_model() successfully completed......................................
2025-06-21 15:00:11,040:INFO:SubProcess create_model() end ==================================
2025-06-21 15:00:11,041:INFO:choose_better activated
2025-06-21 15:00:11,048:INFO:SubProcess create_model() called ==================================
2025-06-21 15:00:11,049:INFO:Initializing create_model()
2025-06-21 15:00:11,049:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 15:00:11,050:INFO:Checking exceptions
2025-06-21 15:00:11,053:INFO:Importing libraries
2025-06-21 15:00:11,053:INFO:Copying training dataset
2025-06-21 15:00:11,102:INFO:Defining folds
2025-06-21 15:00:11,102:INFO:Declaring metric variables
2025-06-21 15:00:11,103:INFO:Importing untrained model
2025-06-21 15:00:11,103:INFO:Declaring custom model
2025-06-21 15:00:11,105:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-21 15:00:11,105:INFO:Starting cross validation
2025-06-21 15:00:11,107:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-06-21 15:00:13,303:INFO:Calculating mean and std
2025-06-21 15:00:13,304:INFO:Creating metrics dataframe
2025-06-21 15:00:13,308:INFO:Finalizing model
2025-06-21 15:00:13,747:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-21 15:00:13,754:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004590 seconds.
2025-06-21 15:00:13,754:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-21 15:00:13,755:INFO:[LightGBM] [Info] Total Bins 6217
2025-06-21 15:00:13,755:INFO:[LightGBM] [Info] Number of data points in the train set: 3360, number of used features: 94
2025-06-21 15:00:13,757:INFO:[LightGBM] [Info] Start training from score -0.412772
2025-06-21 15:00:14,030:INFO:Uploading results into container
2025-06-21 15:00:14,031:INFO:Uploading model into container now
2025-06-21 15:00:14,032:INFO:_master_model_container: 22
2025-06-21 15:00:14,032:INFO:_display_container: 4
2025-06-21 15:00:14,034:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-21 15:00:14,034:INFO:create_model() successfully completed......................................
2025-06-21 15:00:14,578:INFO:SubProcess create_model() end ==================================
2025-06-21 15:00:14,580:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8691
2025-06-21 15:00:14,582:INFO:LGBMRegressor(bagging_fraction=0.8608120752388259, bagging_freq=1,
              feature_fraction=0.4284489606984907,
              learning_rate=0.016133245419918712, min_child_samples=95,
              min_split_gain=0.8209314243567916, n_estimators=239, n_jobs=-1,
              num_leaves=183, random_state=123, reg_alpha=8.662569304197528e-07,
              reg_lambda=5.001062744294253e-06) result for R2 is 0.794
2025-06-21 15:00:14,583:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2025-06-21 15:00:14,583:INFO:choose_better completed
2025-06-21 15:00:14,583:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-21 15:00:14,603:INFO:_master_model_container: 22
2025-06-21 15:00:14,603:INFO:_display_container: 3
2025-06-21 15:00:14,605:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-21 15:00:14,605:INFO:tune_model() successfully completed......................................
2025-06-21 15:00:15,168:INFO:Initializing finalize_model()
2025-06-21 15:00:15,168:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-21 15:00:15,170:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-21 15:00:15,223:INFO:Initializing create_model()
2025-06-21 15:00:15,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-21 15:00:15,223:INFO:Checking exceptions
2025-06-21 15:00:15,226:INFO:Importing libraries
2025-06-21 15:00:15,226:INFO:Copying training dataset
2025-06-21 15:00:15,233:INFO:Defining folds
2025-06-21 15:00:15,233:INFO:Declaring metric variables
2025-06-21 15:00:15,234:INFO:Importing untrained model
2025-06-21 15:00:15,234:INFO:Declaring custom model
2025-06-21 15:00:15,237:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-21 15:00:15,240:INFO:Cross validation set to False
2025-06-21 15:00:15,240:INFO:Fitting Model
2025-06-21 15:00:15,813:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-06-21 15:00:15,820:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004664 seconds.
2025-06-21 15:00:15,820:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-21 15:00:15,821:INFO:[LightGBM] [Info] Total Bins 6528
2025-06-21 15:00:15,822:INFO:[LightGBM] [Info] Number of data points in the train set: 4200, number of used features: 93
2025-06-21 15:00:15,823:INFO:[LightGBM] [Info] Start training from score -0.414219
2025-06-21 15:00:16,185:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-21 15:00:16,185:INFO:create_model() successfully completed......................................
2025-06-21 15:00:16,773:INFO:_master_model_container: 22
2025-06-21 15:00:16,773:INFO:_display_container: 3
2025-06-21 15:00:16,794:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-21 15:00:16,795:INFO:finalize_model() successfully completed......................................
2025-06-21 15:00:17,357:INFO:Initializing save_model()
2025-06-21 15:00:17,357:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), model_name=formation_energy_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-06-21 15:00:17,358:INFO:Adding model into prep_pipe
2025-06-21 15:00:17,358:WARNING:Only Model saved as it was a pipeline.
2025-06-21 15:00:17,386:INFO:formation_energy_final_model.pkl saved in current working directory
2025-06-21 15:00:17,419:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNumber',
                                             'MagpieData range MendeleevNumber',
                                             '...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2025-06-21 15:00:17,420:INFO:save_model() successfully completed......................................
2025-06-21 15:00:17,999:INFO:Initializing load_model()
2025-06-21 15:00:17,999:INFO:load_model(model_name=formation_energy_final_model, platform=None, authentication=None, verbose=True)
2025-06-21 15:00:18,050:INFO:Initializing get_config()
2025-06-21 15:00:18,050:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, variable=X_test)
2025-06-21 15:00:18,051:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2025-06-21 15:00:18,051:WARNING:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.

2025-06-21 15:00:18,119:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
2030                       28.0                       80.0  \
3043                        8.0                       74.0   
3552                        5.0                        9.0   
380                        25.0                       25.0   
730                        11.0                       11.0   
...                         ...                        ...   
2572                        4.0                       14.0   
3757                        7.0                       20.0   
2377                        5.0                       92.0   
3499                       51.0                       92.0   
2893                       60.0                       91.0   

      MagpieData range Number  MagpieData mean Number   
2030                     52.0               54.000000  \
3043                     66.0               30.000000   
3552                      4.0                7.400000   
380                       0.0               25.000000   
730                       0.0               11.000000   
...                       ...                     ...   
2572                     10.0                6.500000   
3757                     13.0               14.526316   
2377                     87.0               22.400000   
3499                     41.0               64.666664   
2893                     31.0               67.750000   

      MagpieData avg_dev Number  MagpieData mode Number   
2030                  26.000000                    28.0  \
3043                  29.333334                     8.0   
3552                   1.920000                     9.0   
380                    0.000000                    25.0   
730                    0.000000                    11.0   
...                         ...                     ...   
2572                   3.750000                     4.0   
3757                   6.337950                    20.0   
2377                  27.840000                     5.0   
3499                  18.222221                    51.0   
2893                  11.625000                    60.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
2030                                61.0                                71.0  \
3043                                51.0                                87.0   
3552                                72.0                                93.0   
380                                 52.0                                52.0   
730                                  2.0                                 2.0   
...                                  ...                                 ...   
2572                                67.0                                78.0   
3757                                 7.0                                82.0   
2377                                20.0                                72.0   
3499                                20.0                                85.0   
2893                                18.0                                19.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
2030                              10.0                        66.000000  ...  \
3043                              36.0                        75.000000  ...   
3552                              21.0                        84.599998  ...   
380                                0.0                        52.000000  ...   
730                                0.0                         2.000000  ...   
...                                ...                              ...  ...   
2572                              11.0                        69.750000  ...   
3757                              75.0                        38.578949  ...   
2377                              52.0                        61.599998  ...   
3499                              65.0                        63.333332  ...   
2893                               1.0                        18.750000  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
2030                 4.0                   1            32.0  \
3043                 7.0                   0             1.0   
3552                 6.0                   1             8.0   
380                  2.0                   1            48.0   
730                  5.0                   1            16.0   
...                  ...                 ...             ...   
2572                 4.0                   1            32.0   
3757                 4.0                   1            16.0   
2377                 4.0                   1            32.0   
3499                 4.0                   1            16.0   
2893                 4.0                   1            32.0   

      crystal_system_cubic  crystal_system_hexagonal   
2030                 False                     False  \
3043                 False                     False   
3552                 False                     False   
380                  False                      True   
730                  False                     False   
...                    ...                       ...   
2572                 False                     False   
3757                 False                     False   
2377                 False                     False   
3499                 False                     False   
2893                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
2030                      False                        False  \
3043                      False                        False   
3552                       True                        False   
380                       False                        False   
730                       False                         True   
...                         ...                          ...   
2572                      False                        False   
3757                      False                        False   
2377                      False                        False   
3499                      False                        False   
2893                      False                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
2030                       True                     False  \
3043                      False                      True   
3552                      False                     False   
380                       False                     False   
730                       False                     False   
...                         ...                       ...   
2572                       True                     False   
3757                       True                     False   
2377                       True                     False   
3499                       True                     False   
2893                       True                     False   

      crystal_system_trigonal  
2030                    False  
3043                    False  
3552                    False  
380                     False  
730                     False  
...                       ...  
2572                    False  
3757                    False  
2377                    False  
3499                    False  
2893                    False  

[840 rows x 146 columns]
2025-06-21 15:00:18,119:INFO:get_config() successfully completed......................................
2025-06-21 15:00:18,120:INFO:Initializing get_config()
2025-06-21 15:00:18,120:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, variable=y_test)
2025-06-21 15:00:18,120:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2025-06-21 15:00:18,121:WARNING:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.

2025-06-21 15:00:18,146:INFO:Variable:  returned as 2030    0.219228
3043   -1.515973
3552   -2.173735
380     0.052632
730     0.010884
          ...   
2572    0.287101
3757   -0.733346
2377   -0.512027
3499   -0.514500
2893    0.295365
Name: target, Length: 840, dtype: float32
2025-06-21 15:00:18,146:INFO:get_config() successfully completed......................................
2025-06-21 15:00:18,147:INFO:Initializing get_config()
2025-06-21 15:00:18,147:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, variable=X_train)
2025-06-21 15:00:18,147:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-06-21 15:00:18,147:WARNING:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.

2025-06-21 15:00:18,204:INFO:Variable:  returned as       MagpieData minimum Number  MagpieData maximum Number   
3860                        7.0                       24.0  \
1975                       34.0                       60.0   
3260                       13.0                       16.0   
4063                       12.0                       14.0   
1778                        8.0                       39.0   
...                         ...                        ...   
1593                       14.0                       47.0   
4060                       12.0                       14.0   
1346                       12.0                       39.0   
3454                       27.0                       81.0   
3582                        8.0                       38.0   

      MagpieData range Number  MagpieData mean Number   
3860                     17.0               17.200001  \
1975                     26.0               44.400002   
3260                      3.0               14.800000   
4063                      2.0               13.142858   
1778                     31.0               20.400000   
...                       ...                     ...   
1593                     33.0               22.250000   
4060                      2.0               13.142858   
1346                     27.0               30.000000   
3454                     54.0               67.500000   
3582                     30.0               10.727273   

      MagpieData avg_dev Number  MagpieData mode Number   
3860                   8.160000                    24.0  \
1975                  12.480000                    34.0   
3260                   1.440000                    16.0   
4063                   0.979592                    14.0   
1778                  14.880000                     8.0   
...                         ...                     ...   
1593                  12.375000                    14.0   
4060                   0.979592                    14.0   
1346                  12.000000                    39.0   
3454                  20.250000                    81.0   
3582                   4.958678                     8.0   

      MagpieData minimum MendeleevNumber  MagpieData maximum MendeleevNumber   
3860                                49.0                                82.0  \
1975                                19.0                                89.0   
3260                                73.0                                88.0   
4063                                68.0                                78.0   
1778                                12.0                                87.0   
...                                  ...                                 ...   
1593                                65.0                                78.0   
4060                                68.0                                78.0   
1346                                12.0                                68.0   
3454                                58.0                                76.0   
3582                                 8.0                                87.0   

      MagpieData range MendeleevNumber  MagpieData mean MendeleevNumber  ...   
3860                              33.0                        62.200001  ...  \
1975                              70.0                        61.000000  ...   
3260                              15.0                        82.000000  ...   
4063                              10.0                        73.714287  ...   
1778                              75.0                        57.000000  ...   
...                                ...                              ...  ...   
1593                              13.0                        74.750000  ...   
4060                              10.0                        73.714287  ...   
1346                              56.0                        30.666666  ...   
3454                              18.0                        71.500000  ...   
3582                              79.0                        79.818184  ...   

      crystal_system_int  is_centrosymmetric  n_symmetry_ops   
3860                 4.0                   1             8.0  \
1975                 4.0                   0            10.0   
3260                 7.0                   0             2.0   
4063                 7.0                   0             2.0   
1778                 6.0                   1             8.0   
...                  ...                 ...             ...   
1593                 7.0                   1             4.0   
4060                 7.0                   0             2.0   
1346                 6.0                   1             4.0   
3454                 7.0                   0             1.0   
3582                 4.0                   1            32.0   

      crystal_system_cubic  crystal_system_hexagonal   
3860                 False                     False  \
1975                 False                     False   
3260                 False                     False   
4063                 False                     False   
1778                 False                     False   
...                    ...                       ...   
1593                 False                     False   
4060                 False                     False   
1346                 False                     False   
3454                 False                     False   
3582                 False                     False   

      crystal_system_monoclinic  crystal_system_orthorhombic   
3860                      False                        False  \
1975                      False                        False   
3260                      False                        False   
4063                      False                        False   
1778                       True                        False   
...                         ...                          ...   
1593                      False                        False   
4060                      False                        False   
1346                       True                        False   
3454                      False                        False   
3582                      False                        False   

      crystal_system_tetragonal  crystal_system_triclinic   
3860                       True                     False  \
1975                       True                     False   
3260                      False                      True   
4063                      False                      True   
1778                      False                     False   
...                         ...                       ...   
1593                      False                      True   
4060                      False                      True   
1346                      False                     False   
3454                      False                      True   
3582                       True                     False   

      crystal_system_trigonal  
3860                    False  
1975                    False  
3260                    False  
4063                    False  
1778                    False  
...                       ...  
1593                    False  
4060                    False  
1346                    False  
3454                    False  
3582                    False  

[3360 rows x 146 columns]
2025-06-21 15:00:18,204:INFO:get_config() successfully completed......................................
2025-06-21 15:00:18,205:INFO:Initializing get_config()
2025-06-21 15:00:18,205:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, variable=y_train)
2025-06-21 15:00:18,205:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2025-06-21 15:00:18,205:WARNING:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.

2025-06-21 15:00:18,221:INFO:Variable:  returned as 3860   -0.511424
1975   -2.191013
3260   -0.742211
4063    0.211632
1778   -3.919644
          ...   
1593    0.446244
4060    0.168126
1346    0.018895
3454    0.509697
3582   -0.130854
Name: target, Length: 3360, dtype: float32
2025-06-21 15:00:18,221:INFO:get_config() successfully completed......................................
2025-06-21 15:00:18,239:INFO:Initializing predict_model()
2025-06-21 15:00:18,239:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205478BBD30>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000205449EB2E0>)
2025-06-21 15:00:18,239:INFO:Checking exceptions
2025-06-21 15:00:18,239:INFO:Preloading libraries
2025-06-21 15:00:18,243:INFO:Set up data.
2025-06-21 15:00:18,328:INFO:Set up index.
2025-06-21 15:00:19,413:INFO:PyCaret RegressionExperiment
2025-06-21 15:00:19,413:INFO:Logging name: reg-default-name
2025-06-21 15:00:19,413:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-21 15:00:19,414:INFO:version 3.3.2
2025-06-21 15:00:19,414:INFO:Initializing setup()
2025-06-21 15:00:19,414:INFO:self.USI: 457f
2025-06-21 15:00:19,414:INFO:self._variable_keys: {'exp_id', 'gpu_param', 'y', 'y_test', 'X_train', 'USI', 'logging_param', 'fold_generator', 'gpu_n_jobs_param', 'fold_groups_param', 'html_param', 'target_param', 'seed', 'idx', '_ml_usecase', 'n_jobs_param', 'data', 'transform_target_param', 'exp_name_log', 'X', 'X_test', 'log_plots_param', 'y_train', 'memory', 'fold_shuffle_param', '_available_plots', 'pipeline'}
2025-06-21 15:00:19,414:INFO:Checking environment
2025-06-21 15:00:19,414:INFO:python_version: 3.10.16
2025-06-21 15:00:19,415:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-21 15:00:19,415:INFO:machine: AMD64
2025-06-21 15:00:19,415:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-21 15:00:19,422:INFO:Memory: svmem(total=6378008576, available=624279552, percent=90.2, used=5753729024, free=624279552)
2025-06-21 15:00:19,423:INFO:Physical Core: 4
2025-06-21 15:00:19,423:INFO:Logical Core: 8
2025-06-21 15:00:19,423:INFO:Checking libraries
2025-06-21 15:00:19,423:INFO:System:
2025-06-21 15:00:19,423:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-21 15:00:19,423:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-21 15:00:19,423:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-21 15:00:19,424:INFO:PyCaret required dependencies:
2025-06-21 15:00:19,424:INFO:                 pip: 25.1
2025-06-21 15:00:19,424:INFO:          setuptools: 78.1.1
2025-06-21 15:00:19,424:INFO:             pycaret: 3.3.2
2025-06-21 15:00:19,424:INFO:             IPython: 8.37.0
2025-06-21 15:00:19,424:INFO:          ipywidgets: 8.1.7
2025-06-21 15:00:19,424:INFO:                tqdm: 4.67.1
2025-06-21 15:00:19,425:INFO:               numpy: 1.26.4
2025-06-21 15:00:19,425:INFO:              pandas: 2.0.1
2025-06-21 15:00:19,425:INFO:              jinja2: 3.1.6
2025-06-21 15:00:19,425:INFO:               scipy: 1.10.1
2025-06-21 15:00:19,425:INFO:              joblib: 1.3.2
2025-06-21 15:00:19,425:INFO:             sklearn: 1.4.2
2025-06-21 15:00:19,425:INFO:                pyod: 2.0.5
2025-06-21 15:00:19,425:INFO:            imblearn: 0.13.0
2025-06-21 15:00:19,426:INFO:   category_encoders: 2.7.0
2025-06-21 15:00:19,426:INFO:            lightgbm: 4.6.0
2025-06-21 15:00:19,426:INFO:               numba: 0.61.0
2025-06-21 15:00:19,426:INFO:            requests: 2.32.3
2025-06-21 15:00:19,426:INFO:          matplotlib: 3.7.1
2025-06-21 15:00:19,426:INFO:          scikitplot: 0.3.7
2025-06-21 15:00:19,426:INFO:         yellowbrick: 1.5
2025-06-21 15:00:19,426:INFO:              plotly: 6.1.2
2025-06-21 15:00:19,426:INFO:    plotly-resampler: Not installed
2025-06-21 15:00:19,426:INFO:             kaleido: 0.2.1
2025-06-21 15:00:19,427:INFO:           schemdraw: 0.15
2025-06-21 15:00:19,427:INFO:         statsmodels: 0.14.4
2025-06-21 15:00:19,427:INFO:              sktime: 0.26.0
2025-06-21 15:00:19,427:INFO:               tbats: 1.1.3
2025-06-21 15:00:19,427:INFO:            pmdarima: 2.0.4
2025-06-21 15:00:19,427:INFO:              psutil: 7.0.0
2025-06-21 15:00:19,427:INFO:          markupsafe: 2.1.2
2025-06-21 15:00:19,427:INFO:             pickle5: Not installed
2025-06-21 15:00:19,428:INFO:         cloudpickle: 3.1.1
2025-06-21 15:00:19,428:INFO:         deprecation: 2.1.0
2025-06-21 15:00:19,428:INFO:              xxhash: 3.5.0
2025-06-21 15:00:19,428:INFO:           wurlitzer: Not installed
2025-06-21 15:00:19,428:INFO:PyCaret optional dependencies:
2025-06-21 15:00:19,428:INFO:                shap: 0.44.1
2025-06-21 15:00:19,429:INFO:           interpret: 0.6.9
2025-06-21 15:00:19,429:INFO:                umap: 0.5.7
2025-06-21 15:00:19,429:INFO:     ydata_profiling: 4.16.1
2025-06-21 15:00:19,429:INFO:  explainerdashboard: 0.4.8
2025-06-21 15:00:19,429:INFO:             autoviz: Not installed
2025-06-21 15:00:19,429:INFO:           fairlearn: 0.7.0
2025-06-21 15:00:19,429:INFO:          deepchecks: Not installed
2025-06-21 15:00:19,430:INFO:             xgboost: 3.0.2
2025-06-21 15:00:19,430:INFO:            catboost: 1.2.8
2025-06-21 15:00:19,430:INFO:              kmodes: 0.12.2
2025-06-21 15:00:19,430:INFO:             mlxtend: 0.23.4
2025-06-21 15:00:19,430:INFO:       statsforecast: 1.5.0
2025-06-21 15:00:19,430:INFO:        tune_sklearn: Not installed
2025-06-21 15:00:19,430:INFO:                 ray: Not installed
2025-06-21 15:00:19,430:INFO:            hyperopt: 0.2.7
2025-06-21 15:00:19,431:INFO:              optuna: 4.3.0
2025-06-21 15:00:19,431:INFO:               skopt: 0.10.2
2025-06-21 15:00:19,431:INFO:              mlflow: 2.22.0
2025-06-21 15:00:19,431:INFO:              gradio: 5.32.0
2025-06-21 15:00:19,431:INFO:             fastapi: 0.115.12
2025-06-21 15:00:19,431:INFO:             uvicorn: 0.34.3
2025-06-21 15:00:19,431:INFO:              m2cgen: 0.10.0
2025-06-21 15:00:19,432:INFO:           evidently: 0.4.40
2025-06-21 15:00:19,432:INFO:               fugue: 0.8.5
2025-06-21 15:00:19,432:INFO:           streamlit: Not installed
2025-06-21 15:00:19,432:INFO:             prophet: Not installed
2025-06-21 15:00:19,433:INFO:None
2025-06-21 15:00:19,433:INFO:Set up data.
2025-06-21 15:00:19,587:INFO:Set up folding strategy.
2025-06-21 15:00:19,587:INFO:Set up train/test split.
2025-06-21 15:00:19,649:INFO:Set up index.
2025-06-21 15:00:19,650:INFO:Assigning column types.
2025-06-21 15:00:19,734:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-21 15:00:19,734:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-21 15:00:19,746:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 15:00:19,757:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 15:00:19,945:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:20,046:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:20,047:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:20,052:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:20,054:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-21 15:00:20,062:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 15:00:20,072:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 15:00:20,248:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:20,337:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:20,338:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:20,343:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:20,344:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-21 15:00:20,354:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 15:00:20,363:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 15:00:20,550:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:20,661:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:20,662:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:20,668:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:20,684:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 15:00:20,697:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 15:00:20,930:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:21,049:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:21,051:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:21,058:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:21,060:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-21 15:00:21,084:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 15:00:21,290:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:21,416:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:21,418:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:21,426:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:21,449:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 15:00:21,645:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:21,757:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:21,759:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:21,764:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:21,765:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-21 15:00:22,002:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:22,122:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:22,123:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:22,130:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:22,367:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:22,478:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:22,479:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:22,485:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:22,487:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-21 15:00:22,679:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:22,767:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:22,772:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:22,972:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:23,080:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:23,086:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:23,088:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-21 15:00:23,398:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:23,406:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:23,739:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:23,747:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:23,751:INFO:Preparing preprocessing pipeline...
2025-06-21 15:00:23,751:INFO:Set up simple imputation.
2025-06-21 15:00:23,752:INFO:Set up removing multicollinearity.
2025-06-21 15:00:23,765:INFO:Set up column name cleaning.
2025-06-21 15:00:24,246:INFO:Finished creating preprocessing pipeline.
2025-06-21 15:00:24,270:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-21 15:00:24,271:INFO:Creating final display dataframe.
2025-06-21 15:00:24,810:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4200, 147)
4        Transformed data shape        (4200, 95)
5   Transformed train set shape        (3360, 95)
6    Transformed test set shape         (840, 95)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              457f
2025-06-21 15:00:25,125:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:25,131:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:25,461:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:25,467:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:25,470:INFO:setup() successfully completed in 6.13s...............
2025-06-21 15:00:25,498:INFO:Initializing evaluate_model()
2025-06-21 15:00:25,498:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205465672E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-06-21 15:00:25,573:INFO:Initializing plot_model()
2025-06-21 15:00:25,573:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205465672E0>, system=True)
2025-06-21 15:00:25,573:INFO:Checking exceptions
2025-06-21 15:00:25,680:INFO:Preloading libraries
2025-06-21 15:00:26,042:INFO:Copying training dataset
2025-06-21 15:00:26,042:INFO:Plot type: pipeline
2025-06-21 15:00:26,581:INFO:Visual Rendered Successfully
2025-06-21 15:00:27,309:INFO:plot_model() successfully completed......................................
2025-06-21 15:00:27,416:INFO:PyCaret RegressionExperiment
2025-06-21 15:00:27,416:INFO:Logging name: reg-default-name
2025-06-21 15:00:27,417:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-21 15:00:27,417:INFO:version 3.3.2
2025-06-21 15:00:27,417:INFO:Initializing setup()
2025-06-21 15:00:27,417:INFO:self.USI: 11d7
2025-06-21 15:00:27,417:INFO:self._variable_keys: {'exp_id', 'gpu_param', 'y', 'y_test', 'X_train', 'USI', 'logging_param', 'fold_generator', 'gpu_n_jobs_param', 'fold_groups_param', 'html_param', 'target_param', 'seed', 'idx', '_ml_usecase', 'n_jobs_param', 'data', 'transform_target_param', 'exp_name_log', 'X', 'X_test', 'log_plots_param', 'y_train', 'memory', 'fold_shuffle_param', '_available_plots', 'pipeline'}
2025-06-21 15:00:27,417:INFO:Checking environment
2025-06-21 15:00:27,417:INFO:python_version: 3.10.16
2025-06-21 15:00:27,418:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-21 15:00:27,418:INFO:machine: AMD64
2025-06-21 15:00:27,418:INFO:platform: Windows-10-10.0.22631-SP0
2025-06-21 15:00:27,426:INFO:Memory: svmem(total=6378008576, available=586969088, percent=90.8, used=5791039488, free=586969088)
2025-06-21 15:00:27,426:INFO:Physical Core: 4
2025-06-21 15:00:27,427:INFO:Logical Core: 8
2025-06-21 15:00:27,427:INFO:Checking libraries
2025-06-21 15:00:27,427:INFO:System:
2025-06-21 15:00:27,427:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-21 15:00:27,427:INFO:executable: c:\Users\sayee\miniconda3\envs\formation_env\python.exe
2025-06-21 15:00:27,427:INFO:   machine: Windows-10-10.0.22631-SP0
2025-06-21 15:00:27,427:INFO:PyCaret required dependencies:
2025-06-21 15:00:27,427:INFO:                 pip: 25.1
2025-06-21 15:00:27,428:INFO:          setuptools: 78.1.1
2025-06-21 15:00:27,428:INFO:             pycaret: 3.3.2
2025-06-21 15:00:27,428:INFO:             IPython: 8.37.0
2025-06-21 15:00:27,428:INFO:          ipywidgets: 8.1.7
2025-06-21 15:00:27,428:INFO:                tqdm: 4.67.1
2025-06-21 15:00:27,428:INFO:               numpy: 1.26.4
2025-06-21 15:00:27,428:INFO:              pandas: 2.0.1
2025-06-21 15:00:27,429:INFO:              jinja2: 3.1.6
2025-06-21 15:00:27,429:INFO:               scipy: 1.10.1
2025-06-21 15:00:27,429:INFO:              joblib: 1.3.2
2025-06-21 15:00:27,429:INFO:             sklearn: 1.4.2
2025-06-21 15:00:27,429:INFO:                pyod: 2.0.5
2025-06-21 15:00:27,429:INFO:            imblearn: 0.13.0
2025-06-21 15:00:27,429:INFO:   category_encoders: 2.7.0
2025-06-21 15:00:27,430:INFO:            lightgbm: 4.6.0
2025-06-21 15:00:27,430:INFO:               numba: 0.61.0
2025-06-21 15:00:27,430:INFO:            requests: 2.32.3
2025-06-21 15:00:27,430:INFO:          matplotlib: 3.7.1
2025-06-21 15:00:27,430:INFO:          scikitplot: 0.3.7
2025-06-21 15:00:27,430:INFO:         yellowbrick: 1.5
2025-06-21 15:00:27,430:INFO:              plotly: 6.1.2
2025-06-21 15:00:27,430:INFO:    plotly-resampler: Not installed
2025-06-21 15:00:27,430:INFO:             kaleido: 0.2.1
2025-06-21 15:00:27,431:INFO:           schemdraw: 0.15
2025-06-21 15:00:27,431:INFO:         statsmodels: 0.14.4
2025-06-21 15:00:27,431:INFO:              sktime: 0.26.0
2025-06-21 15:00:27,431:INFO:               tbats: 1.1.3
2025-06-21 15:00:27,431:INFO:            pmdarima: 2.0.4
2025-06-21 15:00:27,431:INFO:              psutil: 7.0.0
2025-06-21 15:00:27,431:INFO:          markupsafe: 2.1.2
2025-06-21 15:00:27,431:INFO:             pickle5: Not installed
2025-06-21 15:00:27,432:INFO:         cloudpickle: 3.1.1
2025-06-21 15:00:27,432:INFO:         deprecation: 2.1.0
2025-06-21 15:00:27,432:INFO:              xxhash: 3.5.0
2025-06-21 15:00:27,432:INFO:           wurlitzer: Not installed
2025-06-21 15:00:27,432:INFO:PyCaret optional dependencies:
2025-06-21 15:00:27,432:INFO:                shap: 0.44.1
2025-06-21 15:00:27,433:INFO:           interpret: 0.6.9
2025-06-21 15:00:27,433:INFO:                umap: 0.5.7
2025-06-21 15:00:27,433:INFO:     ydata_profiling: 4.16.1
2025-06-21 15:00:27,433:INFO:  explainerdashboard: 0.4.8
2025-06-21 15:00:27,433:INFO:             autoviz: Not installed
2025-06-21 15:00:27,433:INFO:           fairlearn: 0.7.0
2025-06-21 15:00:27,434:INFO:          deepchecks: Not installed
2025-06-21 15:00:27,434:INFO:             xgboost: 3.0.2
2025-06-21 15:00:27,434:INFO:            catboost: 1.2.8
2025-06-21 15:00:27,434:INFO:              kmodes: 0.12.2
2025-06-21 15:00:27,434:INFO:             mlxtend: 0.23.4
2025-06-21 15:00:27,434:INFO:       statsforecast: 1.5.0
2025-06-21 15:00:27,435:INFO:        tune_sklearn: Not installed
2025-06-21 15:00:27,435:INFO:                 ray: Not installed
2025-06-21 15:00:27,435:INFO:            hyperopt: 0.2.7
2025-06-21 15:00:27,435:INFO:              optuna: 4.3.0
2025-06-21 15:00:27,435:INFO:               skopt: 0.10.2
2025-06-21 15:00:27,435:INFO:              mlflow: 2.22.0
2025-06-21 15:00:27,436:INFO:              gradio: 5.32.0
2025-06-21 15:00:27,436:INFO:             fastapi: 0.115.12
2025-06-21 15:00:27,436:INFO:             uvicorn: 0.34.3
2025-06-21 15:00:27,436:INFO:              m2cgen: 0.10.0
2025-06-21 15:00:27,437:INFO:           evidently: 0.4.40
2025-06-21 15:00:27,437:INFO:               fugue: 0.8.5
2025-06-21 15:00:27,437:INFO:           streamlit: Not installed
2025-06-21 15:00:27,437:INFO:             prophet: Not installed
2025-06-21 15:00:27,438:INFO:None
2025-06-21 15:00:27,438:INFO:Set up data.
2025-06-21 15:00:27,559:INFO:Set up folding strategy.
2025-06-21 15:00:27,560:INFO:Set up train/test split.
2025-06-21 15:00:27,628:INFO:Set up index.
2025-06-21 15:00:27,630:INFO:Assigning column types.
2025-06-21 15:00:27,703:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-21 15:00:27,704:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-21 15:00:27,712:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 15:00:27,722:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 15:00:27,913:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,010:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:28,016:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:28,017:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,026:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,036:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,196:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,264:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,265:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:28,269:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:28,270:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-21 15:00:28,277:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,285:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,462:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,567:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,569:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:28,575:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:28,586:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,595:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,726:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,799:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:28,800:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:28,805:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:28,806:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-21 15:00:28,827:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 15:00:29,001:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:29,093:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:29,094:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:29,100:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:29,124:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-21 15:00:29,308:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:29,427:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:29,428:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:29,434:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:29,436:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-21 15:00:29,618:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:29,710:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:29,711:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:29,716:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:29,899:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:29,984:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-21 15:00:29,985:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:29,989:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:29,991:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-21 15:00:30,159:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:30,250:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:30,256:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:30,406:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-21 15:00:30,476:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:30,480:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:30,481:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-21 15:00:30,690:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:30,694:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:30,953:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:30,958:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:30,961:INFO:Preparing preprocessing pipeline...
2025-06-21 15:00:30,961:INFO:Set up simple imputation.
2025-06-21 15:00:30,961:INFO:Set up removing multicollinearity.
2025-06-21 15:00:30,973:INFO:Set up column name cleaning.
2025-06-21 15:00:31,244:INFO:Finished creating preprocessing pipeline.
2025-06-21 15:00:31,262:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                                             'MagpieData mode Column', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-21 15:00:31,262:INFO:Creating final display dataframe.
2025-06-21 15:00:31,716:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape       (4200, 147)
4        Transformed data shape        (4200, 95)
5   Transformed train set shape        (3360, 95)
6    Transformed test set shape         (840, 95)
7              Numeric features               139
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                 5
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              11d7
2025-06-21 15:00:31,968:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:31,972:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:32,231:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-21 15:00:32,235:INFO:Soft dependency imported: catboost: 1.2.8
2025-06-21 15:00:32,238:INFO:setup() successfully completed in 4.87s...............
2025-06-21 15:00:32,274:INFO:Initializing evaluate_model()
2025-06-21 15:00:32,274:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002054AEE5150>, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-06-21 15:00:32,331:INFO:Initializing plot_model()
2025-06-21 15:00:32,332:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002054AEE5150>, system=True)
2025-06-21 15:00:32,332:INFO:Checking exceptions
2025-06-21 15:00:32,360:INFO:Preloading libraries
2025-06-21 15:00:32,368:INFO:Copying training dataset
2025-06-21 15:00:32,368:INFO:Plot type: pipeline
2025-06-21 15:00:32,602:INFO:Visual Rendered Successfully
2025-06-21 15:00:33,167:INFO:plot_model() successfully completed......................................
2025-06-21 15:02:03,411:INFO:Initializing plot_model()
2025-06-21 15:02:03,411:INFO:plot_model(plot=learning, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002054AEE5150>, system=True)
2025-06-21 15:02:03,411:INFO:Checking exceptions
2025-06-21 15:02:03,435:INFO:Preloading libraries
2025-06-21 15:02:03,443:INFO:Copying training dataset
2025-06-21 15:02:03,443:INFO:Plot type: learning
2025-06-21 15:02:03,844:INFO:Fitting Model
2025-06-21 15:02:14,788:INFO:Visual Rendered Successfully
2025-06-21 15:02:15,390:INFO:plot_model() successfully completed......................................
2025-06-21 15:02:21,783:INFO:Initializing plot_model()
2025-06-21 15:02:21,783:INFO:plot_model(plot=learning, fold=KFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\sayee\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MagpieData minimum Number',
                                             'MagpieData maximum Number',
                                             'MagpieData range Number',
                                             'MagpieData mean Number',
                                             'MagpieData avg_dev Number',
                                             'MagpieData mode Number',
                                             'MagpieData minimum '
                                             'MendeleevNumber',
                                             'MagpieData maximum '
                                             'MendeleevNu...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000205465672E0>, system=True)
2025-06-21 15:02:21,783:INFO:Checking exceptions
2025-06-21 15:02:21,841:INFO:Preloading libraries
2025-06-21 15:02:21,934:INFO:Copying training dataset
2025-06-21 15:02:21,935:INFO:Plot type: learning
2025-06-21 15:02:22,296:INFO:Fitting Model
2025-06-21 15:03:04,253:INFO:Visual Rendered Successfully
2025-06-21 15:03:05,370:INFO:plot_model() successfully completed......................................
2025-07-16 18:22:27,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-16 18:22:27,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-16 18:22:27,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-16 18:22:27,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-16 18:25:56,707:WARNING:No electronegativity for He. Setting to NaN. This has no physical meaning, and is mainly done to avoid errors caused by the code expecting a float.

2025-07-16 18:25:56,821:WARNING:No electronegativity for Ar. Setting to NaN. This has no physical meaning, and is mainly done to avoid errors caused by the code expecting a float.

2025-07-16 18:25:57,248:WARNING:No electronegativity for Ne. Setting to NaN. This has no physical meaning, and is mainly done to avoid errors caused by the code expecting a float.

